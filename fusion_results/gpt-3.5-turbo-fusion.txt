(spelling correction,Used-for,spelling correction)(spelling correction,Evaluate-for,spelling correction)(spelling correction,Is-a-Prerequisite-of,language understanding)(spelling correction,Is-a-Prerequisite-of,correction systems)(spelling correction,Compare,correction systems)(spelling correction,Compare,language understanding)(spelling correction,Used-for,contextual language understanding)(spelling correction,Used-for,detecting errors)(spelling correction,Compare,grammatical error correction)(spelling correction,Is-a-Prerequisite-of,grammatical error correction)(spelling correction,Used-for,improving written communication)(spelling correction,Used-for,detecting mistakes)(spelling correction,Is-a-Prerequisite-of,automatic spelling correction)(spelling correction,Is-a-Prerequisite-of,downstream)(spelling correction,Evaluate-for,Chinese Spelling Correction)(spelling correction,Part-of,Chinese Spelling Correction)(spelling correction,Evaluate-for,autoregressive decoding)(spelling correction,Compare,joint decision making)(language understanding,Is-a-Prerequisite-of,spelling correction)(graph convolutional network,Used-for,spelling correction)
(neural network,Used-for,multi-task learning)(neural network,Compare,Deep Neural Networks)(neural network,Is-a-Prerequisite-of,Hierarchical recurrent neural network)(neural network,Compare,Neural Symbolic Machine)(neural network,Evaluate-for,Neural Machine Translation)(neural network,Part-of,Deep Neural Networks)(deep learning model,Used-for,neural network)(neural network,Used-for,generating responses)(neural network,Compare,relation extraction)(neural network,Is-a-Prerequisite-of,interpretability)(neural network,Used-for,building)(neural network,Used-for,multilingual learning)(neural network,Evaluate-for,named entity recognition)(NER,Used-for,neural network)(neural network,Compare,kernel methods)(neural network,Compare,deep neural networks)(neural network,Conjunction,RNNs)(neural network,Used-for,multi-task learning)(neural network,Evaluate-for,structured prediction backpropagation)(extractive summarization model,Is-a-Prerequisite-of,neural network)(language unseen pretraining,Evaluate-for,neural network)(neural network,Part-of,Neural Symbolic Machine)(neural network,Compare,symbolic computer)(neural network,Evaluate-for,language understanding)(adversarial search,Used-for,neural network)
(context free grammar,Is-a-Prerequisite-of,probabilistic context free grammar)(grammar induction,Evaluate-for,probabilistic context free grammar)(tree-adjoining grammars,Is-a-Prerequisite-of,probabilistic context free grammar)(probabilistic context free grammar,Is-a-Prerequisite-of,probabilistic linear context-free rewriting system)(CFG,Is-a-Prerequisite-of,probabilistic context free grammar)(context sensitive grammar,Compare,probabilistic context free grammar)
(context free grammar, Used-for, syntactic and semantic parsing)(context free grammar, Used-for, formal properties about SCFG)(context free grammar, Is-a-Prerequisite-of, compositionality in semantic parsing)(context free grammar, Used-for, grammar induction)(context free grammar, Is-a-Prerequisite-of, probabilistic context free grammar)(context free grammar, Is-a-Prerequisite-of, cky parsing)(context free grammar, Is-a-Prerequisite-of, context sensitive grammar)
(preprocessing, Compare, Multi-task learning)
(string comparison algorithm, Compare, edit distance)(string similarity, Compare, edit distance)
EMPTY G1.morphology and lexicon
EMPTY G1.dual problem
EMPTY G1.game playing in ai
(recommendation system, Is-a-Prerequisite-of, neural news recommendation approach)(recommendation system, Is-a-Prerequisite-of, personalized news recommendation)(recommendation system, Used-for, document retrieval)(recommendation system, Used-for, news recommendation)(recommendation system, Part-of, conversational recommendation)
(computation theory,Is-a-Prerequisite-of,neural techniques)(computation theory,Evaluate-for,efficiency)(computation theory,Is-a-Prerequisite-of,multiple relation extractions)(computation theory,Is-a-Prerequisite-of,end-to-end computational argumentation mining)
(text generation, Compare, neural language models)(text generation, Used-for, conversational text generation)(text generation, Is-a-Prerequisite-of, morphological inflection generation)(text generation, Is-a-Prerequisite-of, deep latent variable models)(text generation, Is-a-Prerequisite-of, neural language modeling)(text generation, Evaluate-for, fluency)(text generation, Evaluate-for, semantic coherence)(neural language modeling, Is-a-Prerequisite-of, text generation)(language model, Is-a-Prerequisite-of, text generation)(text generation, Used-for, natural language descriptions)(text generation, Compare, language generation task)(text generation, Used-for, generation of complex programs)(text generation, Is-a-Prerequisite-of, state-of-the-art results)(text generation, Is-a-Prerequisite-of, abstractive sentence summarization)(text generation, Is-a-Prerequisite-of, emotion and sentiment control)(text generation, Compare, language generation task)(text generation, Used-for, generating sentences)(text generation, Used-for, generating complex programs)(text generation, Used-for, generation of conversational text)(text generation, Is-a-Prerequisite-of, generating automatic Pyramid scores)(text generation, Is-a-Prerequisite-of, AMR-to-text generation)(text generation, Used-for, Automatic Retrieval)(generative latent-variable model, Evaluate-for, text generation)(latent variable model, Evaluate-for, text generation)(text infilling, Evaluate-for,
(concept, relation, concept)(character level language model, Used-for, character-level neural machine translation)(character level language model, Evaluate-for, predict the proficiency level of non-native English speakers)(character level language model, Conjunction, sequence of word tokens)(character level language model, Evaluate-for, bits-per-character performance)(character level language model, Part-of, hierarchical LSTM language model)(character level language model, Is-a-Prerequisite-of, language modeling)(character level language model, Compare, word level language model)(character level language model, Compare, open-vocabulary language model)(character level language model, Is-a-Prerequisite-of, generative neural language model)
(latent variable model, Used-for, conditional response generation)(latent variable model, Is-a-Prerequisite-of, response generation)(latent variable model, Evaluate-for, response generation)(latent variable model, Compare, generative latent variable model)(latent variable model, Compare, variational autoencoders)(latent variable model, Compare, traditional stochastic grammar)(latent variable model, Is-a-Prerequisite-of, aligned embeddings)(latent variable model, Used-for, learning multilingual word representations)(latent variable model, Is-a-Prerequisite-of, generative latent variable model)(latent variable model, Is-a-Prerequisite-of, entity-linking model)(latent variable model, Evaluate-for, multilingual word representations)(latent variable model, Hyponym-Of, Gaussian Mixture LVeGs)(latent variable model, Conjunction, generative latent-variable model)(latent variable model, Conjunction, variational autoencoder)(latent variable model, Evaluate-for, text generation)
EMPTY G1.lexicography
EMPTY G1.citation network
(conll-x,Part-of,penn treebank)(english-web treebank,Compare,penn treebank)(state-of-the-art parsers,Used-for,penn treebank)(penn treebank,Used-for,constituency parsing)(penn treebank,Used-for,part-of-speech tagging)(penn treebank,Used-for,dependency parsing)(penn treebank,Is-a-Prerequisite-of,part-of-speech tagging)(penn treebank,Is-a-Prerequisite-of,dependency parsing)(penn treebank,Is-a-Prerequisite-of,syntaxnet)(penn treebank,Is-a-Prerequisite-of,first-order logic)
(bio text mining, Part-of, entity resolution)(bio text mining, Is-a-Prerequisite-of, entity normalization)(bio text mining, Evaluate-for, text mining tools)(bio text mining, Used-for, knowledge base creation)(bio text mining, Used-for, text mining tools)(bio text mining, Is-a-Prerequisite-of, nlp for biology)
(concept,Used-for,document representation)(document representation,Compare,named entity recognition)(document representation,Compare,geolocation prediction)(document representation,Used-for,semantic parsing)(document representation,Evaluate-for,translation)
(lexicalized parsing, Part-of, neural lexicalized PCFGs)(lexicalized parsing, Is-a-Prerequisite-of, neural lexicalized PCFGs)(lexicalized parsing, Is-a-Prerequisite-of, syntax-aware machine translation)(lexicalized parsing, Is-a-Prerequisite-of, constituency parsing)(lexicalized parsing, Is-a-Prerequisite-of, generative grammar)(semantic graph parser, Is-a-Prerequisite-of, lexicalized parsing)(lexicalized parsing, Evaluate-for, natural language input)(lexicalized parsing, Part-of, neural machine translation system)(lexicalized parsing, Compare, syntax-agnostic NMT baseline)(lexicalized parsing, Used-for, syntactic analyzer)(lexicalized parsing, Evaluate-for, logical forms)
(handwriting recognition, Used-for, digitizing historical documents)(handwriting recognition, Used-for, improving text input methods)(handwriting recognition, Used-for, enabling machine understanding of human-written text)(handwriting recognition, Used-for, implicit discourse relation recognition)(handwriting recognition, Compare, image entity recognition)(handwriting recognition, Compare, text-based entity span detection)(handwriting recognition, Compare, Multimodal Named Entity Recognition)(Hidden Markov Models, Used-for, handwriting recognition)
EMPTY G1.tsne
(nlp and vision, Compare, Vision & Language Structured Evaluation)(nlp and vision, Is-a-Prerequisite-of, Vision & Language Structured Evaluation)(nlp and vision, Evaluate-for, Vision & Language Structured Evaluation)
(feature selection, Is-a-Prerequisite-of, data quality)(feature selection, Evaluate-for, model performance)(feature selection, Compare, training data selection)(feature selection, Used-for, task-specific model training)
(matrix factorization, Is-a-Prerequisite-of, latent feature space)(matrix factorization, Evaluate-for, predicting missing preferences)(matrix factorization, Is-a-Prerequisite-of, tensor factorization)(matrix factorization, Is-a-Prerequisite-of, TFBA)(matrix factorization, Is-a-Prerequisite-of, deep relevance model)(matrix factorization, Is-a-Prerequisite-of, TreeCRF extension)
(first order logic, Conjunction, logical reasoning)(first order logic, Is-a-Prerequisite-of, predicate logic)(first order logic, Evaluate-for, Document-level event argument extraction)(first order logic, Evaluate-for, chain reasoning paradigm)
EMPTY G1.vector representation
EMPTY G1.stack lstm
(graph-based nlp, Used-for, document summarization)(graph-based nlp, Used-for, relation extraction)(graph-based nlp, Is-a-Prerequisite-of, dependency parsing)(graph-based nlp, Is-a-Prerequisite-of, machine translation)(graph-based nlp, Compare, tree-based neural models)(graph-based nlp, Compare, LSTM)(graph-based nlp, Is-a-Prerequisite-of, semantic parsing)(graph-based nlp, Is-a-Prerequisite-of, structured output modeling)(graph-based nlp, Is-a-Prerequisite-of, citation networks)(graph-based nlp, Is-a-Prerequisite-of, pagerank)
- (phonetics, Compare, phonological distinctive features)- (phonetics, Compare, tongue twisters)- (phonetics, Is-a-Prerequisite-of, phonotactic patterns)- (phonetics, Part-of, phonotactic acquisition)- (phonetics, Evaluate-for, phonotactic patterns)- (phonetics, Is-a-Prerequisite-of, phonotactic learning)- (phonetics, Compare, phoneticians)- (phonology, Part-of, phonetics)
(syntax based machine translation, Is-a-Prerequisite-of, Neural Machine Translation)(syntax based machine translation, Is-a-Prerequisite-of, Gated Graph Neural Networks)(syntax based machine translation, Evaluate-for, Sequential Encoder-Decoder Framework)(syntax based machine translation, Hyponym-Of, Source-side Syntactic Trees)
(markov chain monte carlo, Evaluate-for, stochastic gradient)(markov chain monte carlo, Evaluate-for, model averaging)(markov chain monte carlo, Compare, stochastic optimization)(markov chain monte carlo, Compare, traditional training of RNNs)
(concept,Is-a-Prerequisite-of,social media analysis)(relation extraction,Used-for,social media analysis)
(conventional NLP tasks, Is-a-Prerequisite-of, speech synthesis)(natural language text, Evaluate-for, speech synthesis)(NLP models, Evaluate-for, speech synthesis)(speech synthesis, Is-a-Prerequisite-of, speech translation)(speech synthesis, Part-of, text-to-speech model)(speech synthesis, Evaluate-for, model training)(text-to-speech model, Is-a-Prerequisite-of, speech synthesis)(image captioning module, Part-of, speech synthesis)(sub-word speech units, Part-of, speech synthesis)(speech synthesis, Evaluate-for, improving automatic detection and active avoidance mechanisms for hate speech)(speech synthesis, Evaluate-for, language revitalization)(speech synthesis, Evaluate-for, capturing diverse visual semantics from images)(speech synthesis, Is-a-Prerequisite-of, hate speech detection)(speech synthesis, Is-a-Prerequisite-of, automating speech synthesis systems)(hate speech detection, Is-a-Prerequisite-of, speech synthesis)
(clustering, Used-for, spectral clustering)(clustering, Used-for, Compositor attribution)(clustering, Is-a-Prerequisite-of, unsupervised model)(clustering, Is-a-Prerequisite-of, neural sequence-to-sequence model)(clustering, Compare, unsupervised model)(clustering, Compare, neural sequence-to-sequence model)(k-means, Is-a-Prerequisite-of, clustering)(clustering, Is-a-Prerequisite-of, unsupervised learning)(spectral clustering, Used-for, clustering)(clustering, Used-for, document filtering)(clustering, Compare, dependency triples)(clustering, Used-for, frame induction)(clustering, Used-for, event extraction)(clustering, Is-a-Prerequisite-of, text summarization)(clustering, Is-a-Prerequisite-of, user intent classification)(clustering, Is-a-Prerequisite-of, unknown intent detection)(clustering, Is-a-Prerequisite-of, Mixture Models)
(dimensionality reduction, Is-a-Prerequisite-of, STS Benchmark)(dimensionality reduction, Used-for, generating sentence meta-embeddings)(dimensionality reduction, Is-a-Prerequisite-of, Manifold Learning)(dimensionality reduction, Is-a-Prerequisite-of, Principal Component Analysis)(dimensionality reduction, Is-a-Prerequisite-of, tsne)(dimensionality reduction, Is-a-Prerequisite-of, latent semantic indexing)(dimensionality reduction, Is-a-Prerequisite-of, singular value decomposition)
(concept, relation, concept)(gated recurrent unit, Compare, LSTM)(gated recurrent unit, Compare, simple RNN)(gated recurrent unit, Part-of, recurrent neural network)(gated recurrent unit, Is-a-Prerequisite-of, vanishing gradients)(gated recurrent unit, Evaluate-for, computational efficiency)
(course introduction, Used-for, understanding knowledge)(course introduction, Is-a-Prerequisite-of, semantic parsing)(concepts, Part-of, course introduction)(language model, Is-a-Prerequisite-of, course introduction)
EMPTY G1.k mean
(neural machine translation, Is-a-Prerequisite-of, learning morphology)(pointer network, Compare, neural machine translation)(neural machine translation, Evaluate-for, pointer network)(neural machine translation, Is-a-Prerequisite-of, bi-directional LSTMs)(neural machine translation, Compare, convolutional layers)(neural machine translation, Compare, recurrent networks)(neural machine translation, Part-of, NMT)(neural machine translation, Compare, statistical machine translation)(neural machine translation, Evaluate-for, translation performance)(neural machine translation, Used-for, encoding source sentence)(neural machine translation, Is-a-Prerequisite-of, state-of-the-art performance)(NMT, Hyponym-Of, neural machine translation)(neural machine translation, Evaluate-for, sequence-to-dependency neural machine translation)(neural machine translation, Evaluate-for, cross-lingual dependency parsing)(translation model, Is-a-Prerequisite-of, neural machine translation)(neural machine translation, Compare, phrase-based machine translation)(neural machine translation, Compare, unsupervised NMT)(neural machine translation, Evaluate-for, state-of-the-art baselines)(word embeddings, Is-a-Prerequisite-of, neural machine translation)(neural machine translation, Compare, machine translation)(error correction, Used-for, neural machine translation)(neural machine translation, Used-for, NMT)(neural networks, Compare, neural machine translation)(neural machine translation, Evaluate-for
EMPTY G1.machine translation technique
(kernel function, Is-a-Prerequisite-of, objective function)(kernel function, Is-a-Prerequisite-of, Mixture Models)
EMPTY G1.python
(latent dirichlet allocation, Used-for, ranking noun phrases)(latent dirichlet allocation, Is-a-Prerequisite-of, PageRank)(latent dirichlet allocation, Evaluate-for, topic modeling research)(latent dirichlet allocation, Is-a-Prerequisite-of, Salience Rank)(latent dirichlet allocation, Is-a-Prerequisite-of, neural topic modeling)(latent dirichlet allocation, Is-a-Prerequisite-of, Bidirectional Adversarial Topic model)(latent dirichlet allocation, Is-a-Prerequisite-of, Gaussian-BAT)(latent dirichlet allocation, Evaluate-for, text clustering)(latent dirichlet allocation, Compare, neural topic modeling)(latent dirichlet allocation, Evaluate-for, topic descriptors)(latent dirichlet allocation, Evaluate-for, document-topic distribution)(traditional topic models, Is-a-Prerequisite-of, latent dirichlet allocation)
(word embedding,Used-for,word analogy questions)(word embedding,Is-a-Prerequisite-of,additive compositionality)(word embedding,Used-for,vector calculus)(word embedding,Used-for,caption generation)(word embedding,Used-for,semantic composite)(word embedding,Compare,bag-of-words)(word embedding,Compare,Gaussian embeddings)(GloVe,Used-for,word embedding)(morphological inflection,Evaluate-for,word embedding)(sentence embedding,Compare,word embedding)(word embedding,Is-a-Prerequisite-of,diachronic word embeddings)(word embedding,Is-a-Prerequisite-of,syntaxnet)(word embedding,Is-a-Prerequisite-of,word embedding variations)
EMPTY G1.ensemble learning
(gated self-matching networks, Evaluate-for, reading comprehension)(question answering, Is-a-Prerequisite-of, reading comprehension)(`content`, Evaluate-for, reading comprehension)(reading comprehension, Evaluate-for, answering questions)(Hierarchical attention network, Used-for, reading comprehension)(comparison paragraphs, Is-a-Prerequisite-of, reading comprehension)(recurrent neural networks, Compare, reading comprehension)(reading comprehension, Part-of, machine reading comprehension)(reading comprehension, Is-a-Prerequisite-of, question answering)(reading comprehension, Conjunction, document)(reading comprehension, Conjunction, text)(reading comprehension, Is-a-Prerequisite-of, neural understanding)(reading comprehension, Conjunction, natural language)(reading comprehension, Evaluate-for, machine learning)(reading comprehension, Evaluate-for, language understanding)(reading comprehension, Is-a-Prerequisite-of, knowledge integration)(reading comprehension, Is-a-Prerequisite-of, document understanding)(document, Is-a-Prerequisite-of, reading comprehension)(text, Is-a-Prerequisite-of, reading comprehension)(machine learning, Is-a-Prerequisite-of, reading comprehension)(language understanding, Is-a-Prerequisite-of, reading comprehension)(neural understanding, Is-a-Prerequisite-of, reading comprehension)(natural language, Is-a-Prerequisite-of, reading comprehension)(gated self-matching networks, Used-for, reading comprehension)(recurrent neural networks, Part-of, reading comprehension)(natural language
(newton method, Compare, gradient descent)(newton method, Evaluate-for, finding roots of equations)(newton method, Is-a-Prerequisite-of, linear algebra)(newton method, Used-for, optimization)(newton method, Compare, bisection method)(newton method, Is-a-Prerequisite-of, calculus)(newton method, Compare, secant method)
(log-linear model, Used-for, integrating prior knowledge into neural machine translation)(log-linear model, Is-a-Prerequisite-of, representing prior knowledge sources as features)(log-linear model, Used-for, guiding the learning processing of the neural translation model)(log-linear model, Is-a-Prerequisite-of, softened constraints at training time)(log-linear model, Used-for, providing supervision with structured loss components)
EMPTY G1.deep q-network
(highway network, Used-for, modeling relationships among the utterances)(highway network, Is-a-Prerequisite-of, multi-turn conversation)(highway network, Compare, SMN)(highway network, Compare, GCN)(highway network, Is-a-Prerequisite-of, Hierarchical text classification)(highway network, Compare, Generative Feature Matching Network)(highway network, Compare, Neural Graph Matching Networks)
(caption generation, Used-for, question generation)(caption generation, Used-for, entailment generation)(caption generation, Compare, semantic summarization)(caption generation, Hyponym-Of, abstractive summarization)(caption generation, Is-a-Prerequisite-of, word-embedding models)(caption generation, Evaluate-for, word embedding)(word embedding, Used-for, caption generation)
EMPTY G1.heuristic search
(context-sensitive grammar, Compare, context-free grammar)(context-sensitive grammar, Compare, probabilistic context-free grammar)(context-sensitive grammar, Conjunction, linear indexed grammars)(context-sensitive grammar, Conjunction, tree-adjoining grammars)(context-sensitive grammar, Compare, mildly context-sensitive grammars)
(Multilingual neural machine translation, Used-for, machine translation)(abstractive summarization, Part-of, machine translation)(neural machine translation, Compare, machine translation)(encode-attend-decode paradigm, Used-for, machine translation)(morphology and semantics, Used-for, machine translation)(graph-based nlp, Is-a-Prerequisite-of, machine translation)(machine translation, Evaluate-for, morphology)(machine translation, Evaluate-for, semantics)(unsupervised learning, Is-a-Prerequisite-of, machine translation)(transliteration, Is-a-Prerequisite-of, machine translation)(stemming, Used-for, machine translation)(concept, Part-of, machine translation)(machine translation, Evaluate-for, translation accuracy)(sequence labeling model, Evaluate-for, machine translation)(sequence labeling model, Compare, machine translation)(language variation, Used-for, machine translation)(unsupervised bilingual word embeddings, Compare, machine translation)(unsupervised neural machine translation, Is-a-Prerequisite-of, machine translation)(transduction, Is-a-Prerequisite-of, machine translation)(neural machine translation, Is-a-Prerequisite-of, machine translation)(machine translation, Is-a-Prerequisite-of, automatic question answering)(unsupervised cross-lingual, Evaluate-for, machine translation)(unsupervised cross-lingual, Is-a-Prerequisite-of, machine translation)(response generation, Hyponym-Of, machine translation)(long short term
(activation function, Part-of, deep learning architecture)(activation function, Evaluate-for, performance)(activation function, Used-for, neural models)(activation function, Compare, compositional functions)
EMPTY G1.vector semantics
EMPTY G1.earley parsing
EMPTY G1.semi supervised learning
(parsing, Is-a-Prerequisite-of, constituency parsing)(parsing, Is-a-Prerequisite-of, syntaxnet)(parsing, Is-a-Prerequisite-of, statistical parsing)(parsing, Is-a-Prerequisite-of, semi supervised learning)(parsing, Is-a-Prerequisite-of, lexicalized parsing)(parsing, Is-a-Prerequisite-of, neural parsing)(parsing, Is-a-Prerequisite-of, parsing evaluation)(parsing, Is-a-Prerequisite-of, shallow parsing)(parsing, Is-a-Prerequisite-of, event detection)(parsing, Is-a-Prerequisite-of, semantic parsing)(parsing, Is-a-Prerequisite-of, dependency parsing)(dependency parsing, Evaluate-for, parsing)(parser, Used-for, parsing)(neural techniques, Used-for, parsing)(prosody, Used-for, parsing)(parsing, Evaluate-for, incorporating prosody for disfluent speech)(domain adaptation method, Part-of, parsing)(backpropagation, Used-for, parsing)(parsing, Hyponym-Of, language modeling)
(convolutional neural network, Is-a-Prerequisite-of, deep pyramid CNN)(convolutional neural network, Is-a-Prerequisite-of, Picturebook embeddings)(convolutional neural network, Is-a-Prerequisite-of, neural question answering)(convolutional neural network, Is-a-Prerequisite-of, ResNet)(convolutional neural network, Used-for, text categorization)(convolutional neural network, Used-for, generating word embeddings)(convolutional neural network, Compare, SoPa model)(convolutional neural network, Compare, recurrent neural network)(convolutional neural network, Compare, neural semantic parsing)(convolutional neural network, Compare, character-level CNN)(dependency parsing, Used-for, convolutional neural network)(recurrent neural network, Compare, convolutional neural network)
(word segmentation, Is-a-Prerequisite-of, sentence boundary recognition)(sentence boundary recognition, Used-for, segmental neural language model)(sentence boundary recognition, Evaluate-for, performance improvement)
EMPTY G1.topic modeling
(monte carlo method, Used-for, numerical simulations)(monte carlo method, Compare, statistical methods)(monte carlo method, Evaluate-for, stochastic processes)
(information retrieval, Evaluate-for, text understanding)(information retrieval, Compare, QA systems)(information retrieval, Is-a-Prerequisite-of, datasets)(information retrieval, Evaluate-for, machine reading)(information retrieval, Evaluate-for, similarity search)(information retrieval, Is-a-Prerequisite-of, toolkits for information retrieval)(information retrieval, Is-a-Prerequisite-of, document ranking)(information retrieval, Is-a-Prerequisite-of, search engines)(information retrieval, Is-a-Prerequisite-of, text mining)(information retrieval, Is-a-Prerequisite-of, image retrieval)(information retrieval, Is-a-Prerequisite-of, old book facts)(information retrieval, Is-a-Prerequisite-of, language models)(information retrieval, Is-a-Prerequisite-of, conversational Question Answering)
(conversational strategies,Compare,weakly-supervised learning)(entity linking without labeled data,Compare,weakly-supervised learning)(automated cognitive task analysis transcript parsing,Compare,weakly-supervised learning)
EMPTY G1.linear programming
EMPTY G1.expert system
EMPTY G1.machine learning resource
(concept, relation, concept)(unlexicalized parsing, Is-a-Prerequisite-of, semantic graph parser)(unlexicalized parsing, Is-a-Prerequisite-of, neural encoder-decoder transition-based parser)
EMPTY G1.data structure and algorithm
(logistic regression,Evaluate-for,assessing toxicity)(logistic regression,Compare,logistic regression classifiers)(logistic regression,Compare,continuous-time deconvolutional regressive neural network)(logistic regression,Compare,linguistic representations)(logistic regression,Compare,transformer-based architecture)
EMPTY G1.sequence classification and conditional random field
(research paper, Is-a-Prerequisite-of, scientific article summarization)(concept, Is-a-Prerequisite-of, scientific article summarization)(auxiliary tasks, Used-for, scientific article summarization)(semantic super-sense tagging, Used-for, scientific article summarization)(multi-word expressions, Used-for, scientific article summarization)(task, Compare, scientific article summarization)(deep recurrent neural networks, Used-for, scientific article summarization)(scientific KBC datasets, Part-of, scientific article summarization)(novel method, Used-for, scientific article summarization)(videos of talks at scientific conferences, Used-for, scientific article summarization)
(deep learning introduction,Part-of,artificial titles)(deep learning introduction,Evaluate-for,sequential training)(deep learning introduction,Is-a-Prerequisite-of,boosting performance for unsupervised adaptation)(deep learning introduction,Used-for,fine-tuning with limited data)(deep learning introduction,Is-a-Prerequisite-of,neural turing machine)(deep learning introduction,Is-a-Prerequisite-of,word embedding)(deep learning introduction,Is-a-Prerequisite-of,neural machine translation)(deep learning introduction,Is-a-Prerequisite-of,stack lstm)
(StructuredRegex,Is-a-Prerequisite-of,regular expression)(analysis,Used-for,regular expression)(MWEs,Used-for,regular expression)(Structural complexity,Compare,regular expression)(Natural language descriptions,Conjunction,regular expression)(natural language processing,Evaluate-for,regular expression)
EMPTY G1.morphology and semantics in machine translation
(clustering,Used-for,spectral clustering)(spectral clustering,Compare,Compositor attribution)(spectral clustering,Used-for,clustering)(spectral clustering,Compare,traditional clustering algorithms)(spectral clustering,Is-a-Prerequisite-of,graph theory)(spectral clustering,Evaluate-for,community detection)(spectral clustering,Compare,K-means clustering)(spectral clustering,Is-a-Prerequisite-of,Compositor attribution)(stemming,Used-for,spectral clustering)
(character level language model, Is-a-Prerequisite-of, language modeling)(cached mechanism, Part-of, language modeling)(deep neural network, Compare, language modeling)(deep learning tool, Compare, language modeling)(dialogue modeling, Is-a-Prerequisite-of, language modeling)(document context, Used-for, language modeling)(feedforward neural network, Used-for, language modeling)(generative language model, Used-for, language modeling)(generative neural language model, Is-a-Prerequisite-of, language modeling)(kernelized neural network, Compare, language modeling)(learning, Used-for, language modeling)(lexicon, Used-for, language modeling)(morphological disambiguation, Used-for, language modeling)(morphology, Is-a-Prerequisite-of, language modeling)(neural machine translation, Evaluate-for, language modeling)(neural topic modeling, Compare, language modeling)(part-of-speech tagging, Is-a-Prerequisite-of, language modeling)(parsing, Hyponym-Of, language modeling)(prediction, Evaluate-for, language modeling)(recurrent neural network, Evaluate-for, language modeling)(recurrent neural network, Used-for, language modeling)(recurrent neural networks, Evaluate-for, language modeling)(recurrent neural networks, Used-for, language modeling)(RNN model, Evaluate-for, language modeling)(RNNs, Evaluate-for, language modeling)(RNNs, Used-for, language modeling)(syntactic enc
(concept, relation, concept)(sentence representation, Part-of, Natural Language Processing)(sentence representation, Is-a-Prerequisite-of, language understanding systems)(sentence representation, Used-for, semantic parsing)(sentence representation, Evaluate-for, sentence-level sentiment classification)(sentence representation, Compare, word embeddings)(sentence representation, Compare, word representations)(aggregate vectors, Part-of, sentence representation)
(text mining, Used-for, extracting keyphrases)(text mining, Part-of, natural language processing)(text mining, Used-for, summarizing main points of a document)(text mining, Evaluate-for, improving the performance of generative models)(text mining, Is-a-Prerequisite-of, generating keyphrases)(natural language processing, Is-a-Prerequisite-of, text mining)(entity resolution, Evaluate-for, text mining)(named entity normalization, Evaluate-for, text mining)
(Concept, Evaluate-for, semantic similarity)(semantic similarity, Compare, stylistic similarity)(semantic similarity, Compare, lexical similarity)(semantic similarity, Used-for, text similarity measures)(semantic similarity, Used-for, document similarity measures)(document similarity measures, Is-a-Prerequisite-of, semantic similarity)(semantic similarity, Is-a-Prerequisite-of, thesaurus-based similarity)(semantic similarity, Is-a-Prerequisite-of, automated essay scoring)(semantic similarity, Is-a-Prerequisite-of, sentence simplification)(semantic similarity, Is-a-Prerequisite-of, relation extraction)(semantic similarity, Is-a-Prerequisite-of, text mining)(semantic similarity, Is-a-Prerequisite-of, word sense disambiguation)
1. (kernel graphical models, Evaluate-for, short text clustering)2. (kernel graphical models, Is-a-Prerequisite-of, Online Semantic-enhanced Dirichlet Model)3. (kernel graphical models, Is-a-Prerequisite-of, OSDM)4. (kernel graphical models, Is-a-Prerequisite-of, CompareNet)5. (short text clustering, Is-a-Prerequisite-of, OSDM)6. (short text clustering, Is-a-Prerequisite-of, CompareNet)
EMPTY G1.hilbert space
(dirichlet processes, Used-for, modeling words)(dirichlet processes, Is-a-Prerequisite-of, topic-sensitive representations)(dirichlet processes, Used-for, learning multiple topic-sensitive representations)(dirichlet processes, Is-a-Prerequisite-of, Hierarchical Dirichlet Process)(dirichlet processes, Is-a-Prerequisite-of, modeling topics)(dirichlet processes, Is-a-Prerequisite-of, integrating topic distributions)
(mean field approximation, Is-a-Prerequisite-of, second-order semantic dependency parser)(mean field approximation, Used-for, approximating second-order parsing)(mean field approximation, Used-for, second-order parsing)(mean field approximation, Used-for, recurrent layers)(mean field approximation, Is-a-Prerequisite-of, approximated second-order parsing)(mean field approximation, Compare, loopy belief approximation)
EMPTY G1.belief propagation
EMPTY G1.state space models
EMPTY G1.gaussian graphical model
EMPTY G1.kkt condition
EMPTY G1.message passing
(markov random fields, Is-a-Prerequisite-of, conditional random fields)(markov random fields, Evaluate-for, ner)(markov random fields, Is-a-Prerequisite-of, neurally parameterized conditional random fields)
(singular value decomposition, Is-a-Prerequisite-of, multimodal sentiment analysis)(singular value decomposition, Used-for, contrastive representation learning)(singular value decomposition, Used-for, contrastive feature decomposition)(singular value decomposition, Evaluate-for, enhancing representations)(singular value decomposition, Evaluate-for, feature decomposition)(singular value decomposition, Is-a-Prerequisite-of, Principal Component Analysis)
EMPTY G1.evaluation of dependency parsing
EMPTY G1.kullback leibler divergence
(word embeddings, Is-a-Prerequisite-of, entailment)(compositional distributional semantics, Is-a-Prerequisite-of, entailment)(compositional distributional semantics, Evaluate-for, entailment)
EMPTY G1.expectation maximization algorithm
EMPTY G1.knowledge representation
EMPTY G1.variable elimination
EMPTY G1.linear regression
EMPTY G1.lagrange duality
(clustering,Is-a-Prerequisite-of,unsupervised learning)(unsupervised learning,Evaluate-for,identifying patterns in data)(unsupervised learning,Is-a-Prerequisite-of,labeled sequence transduction)(unsupervised learning,Is-a-Prerequisite-of,machine translation)(word embeddings,Is-a-Prerequisite-of,unsupervised learning)(unsupervised learning,Evaluate-for,noisy labels)(task learning,Conjunction,unsupervised learning)
(word embedding variation, Compare, Probabilistic FastText),(word embedding variation, Evaluate-for, word sense induction),(word embedding variation, Evaluate-for, Gaussian mixtures),(word embedding variation, Evaluate-for, uncertainty information),(word sense induction, Is-a-Prerequisite-of, word embedding variation),(Gaussian mixtures, Is-a-Prerequisite-of, word embedding variation),(uncertainty information, Is-a-Prerequisite-of, word embedding variation)
EMPTY G1.naive bayes
EMPTY G1.resnet
EMPTY G1.sequence to sequence
EMPTY G1.visual qa
(canonical correlation analysis, Is-a-Prerequisite-of, PCCA)(canonical correlation analysis, Is-a-Prerequisite-of, CCA)(canonical correlation analysis, Is-a-Prerequisite-of, DPCCA)
(sampling,Evaluate-for,system)(sampling,Evaluate-for,training)
EMPTY G1.markov chain
(principal component analysis, Compare, Visual language grounding)(principal component analysis, Used-for, machine vision)
(autoencoders, Compare, generative models)(autoencoders, Used-for, improving variational autoencoders)(autoencoders, Used-for, text modeling)(autoencoders, Evaluate-for, probabilistic modeling)(autoencoders, Is-a-Prerequisite-of, understanding of encoder-decoder incompatibility)(autoencoders, Part-of, deep neural networks)(autoencoders, Part-of, generative modeling)
EMPTY G1.alphago
(concept:manifold learning, relation:Used-for, concept:feature representation learning)(concept:manifold learning, relation:Evaluate-for, concept:structured information modeling)
EMPTY G1.mixture models
EMPTY G1.meta-learning
EMPTY G1.variations of gans
EMPTY G1.tool for dl
EMPTY G1.restricted boltzmann machine, deep belief network
EMPTY G1.support vector machine
(communication,Used-for,multi-agent system)(language model,Used-for,multi-agent system)(multi-agent system,Is-a-Prerequisite-of,communication)(multi-agent system,Is-a-Prerequisite-of,language model)(multi-agent system,Is-a-Prerequisite-of,training)(multi-agent system,Is-a-Prerequisite-of,teaching)(multi-agent system,Is-a-Prerequisite-of,data-driven approaches)
EMPTY G1.first-order logic
(concept, relation, concept)(cross entropy, Evaluate-for, maximizing inter-class variance)(cross entropy, Evaluate-for, minimizing intra-class variance)(cross entropy, Used-for, training language models)(cross entropy, Compare, Models trained with MixCE outperform models trained with traditional cross-entropy)(cross entropy, Used-for, knowledge distillation)(cross entropy, Used-for, token-level adaptive training)(cross entropy, Evaluate-for, improving machine translation)(cross entropy, Evaluate-for, out-of-domain detection)(cross entropy, Is-a-Prerequisite-of, MixCE)(cross entropy, Is-a-Prerequisite-of, reverse cross-entropy)
EMPTY G1.random walk and harmonic function
(deep learning tool,Used-for,semantic role labeling)(planning,Is-a-Prerequisite-of,semantic role labeling)(syntax,Conjunction,semantic role labeling)(model,Used-for,semantic role labeling)(argument extraction,Compare,semantic role labeling)
EMPTY G1.evaluation of text classification
EMPTY G1.word sense disambiguation
EMPTY G1.nlp for database
(autonomous car,Is-a-Prerequisite-of,learning to follow instructions)(learning to follow instructions,Evaluate-for,autonomous car)(autonomous car,Used-for,vision-and-language navigation)(autonomous car,Part-of,agent)(learning to follow instructions,Compare,autonomous car)
(finite state machine,Used-for,NLP systems)(finite state machine,Part-of,Weighted finite-state machines)(finite state machine,Compare,Transformer in machine translation)(finite state machine,Compare,neural paraphrasing model)(finite state machine,Compare,multi-layer recurrent neural network model)(finite state machine,Evaluate-for,Computation of higher-order derivatives)(finite state machine,Evaluate-for,Automatic postediting (APE))
(neural parsing, Compare, dependency parsing)(neural parsing, Evaluate-for, robust performance)(neural machine translation, Compare, neural parsing)
(statistical part of speech tagging, Evaluate-for, recurrent neural networks)(statistical part of speech tagging, Evaluate-for, part-of-speech tagging)(statistical part of speech tagging, Is-a-Prerequisite-of, course introduction)
(neural machine translation, Is-a-Prerequisite-of, the ibm model)
(dynamic programming, Used-for, optimization)(dynamic programming, Part-of, spanning)(dynamic programming, Evaluate-for, training)(dynamic programming, Compare, greedy algorithm)(dynamic programming, Compare, exact inference)(dynamic programming, Compare, state-of-the-art results)(dynamic programming, Part-of, sentence compression)(dynamic programming, Is-a-Prerequisite-of, event coreference resolution)(dynamic programming, Is-a-Prerequisite-of, segmentation algorithm)(dynamic programming, Is-a-Prerequisite-of, cky parsing)(dynamic programming, Is-a-Prerequisite-of, course introduction)
(text to speech generation, Used-for, fast generation speed)(text to speech generation, Evaluate-for, generation speed improvement)(text to speech generation, Part-of, NAR-TTS models)(text to speech generation, Evaluate-for, voice quality improvement)(text to speech generation, Compare, traditional text-to-speech approaches)(text to speech generation, Part-of, generative dialogue models)(text to speech generation, Is-a-Prerequisite-of, natural language generation)
(word segmentation, Is-a-Prerequisite-of, sentence boundary recognition)(Speech register and prosody, Conjunction, word segmentation)(word segmentation, Compare, character LSTM models)(word segmentation, Compare, nonparametric Bayesian word segmentation models)(word segmentation, Used-for, pretraining character and word embeddings)(word segmentation, Compare, statistical segmentation research)(word segmentation, Evaluate-for, model accuracy improvement)(word segmentation, Compare, adversarial multi-criteria learning for CWS)(word segmentation, Part-of, Chinese word segmentation)(word segmentation, Evaluate-for, performance improvement)(word segmentation, Part-of, character embeddings)(word segmentation, Evaluate-for, representation comparison)(word segmentation, Evaluate-for, dependency parsing accuracy)(neural word segmentation, Is-a-Prerequisite-of, word segmentation)(character level language modeling, Compare, word segmentation)(word segmentation, Compare, neural char-based models)(neural word embeddings, Is-a-Prerequisite-of, word segmentation)(word segmentation, Is-a-Prerequisite-of, Chinese analysis)(word segmentation, Is-a-Prerequisite-of, different linguistic perspectives)
EMPTY G1.query expansion
EMPTY G1.noisy channel model
(linear algebra, Used-for, Quaternion algebra)(linear algebra, Used-for, Quaternion-inspired models)(linear algebra, Used-for, Quaternion attention Model)(linear algebra, Is-a-Prerequisite-of, Quaternion-inspired models)(linear algebra, Is-a-Prerequisite-of, Quaternion Transformer)(linear algebra, Is-a-Prerequisite-of, spectral methods)(linear algebra, Is-a-Prerequisite-of, structured learning)(linear algebra, Is-a-Prerequisite-of, mathematical models)(linear algebra, Is-a-Prerequisite-of, structured sparsity)(linear algebra, Is-a-Prerequisite-of, machine learning resources)(linear algebra, Is-a-Prerequisite-of, latent variable models)(linear algebra, Is-a-Prerequisite-of, dimensionality reduction)(linear algebra, Is-a-Prerequisite-of, Message Passing)(linear algebra, Is-a-Prerequisite-of, State Space Models)(linear algebra, Is-a-Prerequisite-of, Variations of GANs)(linear algebra, Is-a-Prerequisite-of, Mixture Models)(linear algebra, Is-a-Prerequisite-of, Manifold Learning)(linear algebra, Is-a-Prerequisite-of, Principal Component Analysis)
EMPTY G1.chomsky hierarchy
(named entity recognition,Is-a-Prerequisite-of,entity resolution)(named entity recognition,Compare,sequence labeling)(named entity recognition,Is-a-Prerequisite-of,natural language processing)(named entity recognition,Used-for,information extraction)(named entity recognition,Compare,local detection approach)(named entity recognition,Is-a-Prerequisite-of,multiple-speaker speech recognition)(named entity recognition,Is-a-Prerequisite-of,deep learning)(named entity recognition,Evaluate-for,multilingual learning)(named entity recognition,Evaluate-for,multi-task learning)(named entity recognition,Evaluate-for,language resource creation)(multilingual model,Compare,named entity recognition)(document representation,Compare,named entity recognition)(handwriting recognition,Is-a-Prerequisite-of,named entity recognition)(language modeling,Is-a-Prerequisite-of,named entity recognition)(training neural network,Is-a-Prerequisite-of,named entity recognition)(particle filter,Evaluate-for,named entity recognition)(NER system,Hyponym-Of,named entity recognition)(neural language modeling,Is-a-Prerequisite-of,named entity recognition)(speech recognition,Is-a-Prerequisite-of,named entity recognition)(linguistic knowledge identification,Evaluate-for,named entity recognition)(entity recognition ner aim,Evaluate-for,named entity recognition)(named entity recognition,Is-a-Prerequisite-of,entity recognition ner aim)(named entity recognition,Used-for,cross-domain knowledge transfer)(sequence labeling framework,Used
(dependency syntax, Compare, part-of)(dependency syntax, Conjunction, word embeddings)(dependency syntax, Is-a-Prerequisite-of, dependency parsing)(Neural Machine Translation, Evaluate-for, dependency syntax)(dependency syntax, Compare, joint extraction of entity mentions and relations)(dependency syntax, Used-for, deep neural architecture)(dependency parsing, Is-a-Prerequisite-of, dependency syntax)(dependency syntax, Compare, transition-based dependency parser)(dependency parsing, Compare, dependency syntax)(dependency syntax, Part-of, Abstract Meaning Representations)
(shift-reduce parsing, Evaluate-for, constituency parsing)(shift-reduce parsing, Is-a-Prerequisite-of, Deterministic attention mechanisms)(shift-reduce parsing, Compare, Sequence-to-sequence constituent parsing)(shift-reduce parsing, Compare, In-order linearization)(shift-reduce parsing, Is-a-Prerequisite-of, transition based dependency parsing)
(latent semantic indexing, Used-for, capture latent semantics)(latent semantic indexing, Compare, unsupervised representation)(latent semantic indexing, Evaluate-for, semantic textual similarity tasks)(latent semantic indexing, Is-a-Prerequisite-of, semantic textual similarity tasks)(latent semantic indexing, Compare, neural network models)(latent semantic indexing, Compare, skip-thought vectors)
EMPTY G1.agent-based view of ai
(policy gradient method, Evaluate-for, achieving new state-of-the-art performance)
EMPTY G1.nlp for the humanity
EMPTY G1.kernel
EMPTY G1.loss function
(image retrieval, Evaluate-for, relevance ranking)(image retrieval, Compare, text retrieval)(lossless representation, Part-of, image retrieval)
EMPTY G1.parsing evaluation
EMPTY G1.natural language processing intro
(propositional logic, Used-for, semantic relations)(propositional logic, Compare, compositional logical forms)
(adversarial search, Used-for, adversarial training)(adversarial search, Used-for, neural network)(adversarial search, Used-for, adversarial examples)(adversarial search, Used-for, robustness)(adversarial search, Used-for, Adversarial Attention Network)(adversarial search, Compare, why-question answering)(adversarial search, Used-for, neural machine translation (NMT))(adversarial search, Used-for, gradient-based method)
EMPTY G1.linear discriminant analysis
1. (named entity recognition, Used-for, information extraction)2. (event extraction, Part-of, information extraction)3. (relation extraction, Used-for, information extraction)4. (relation extraction, Is-a-Prerequisite-of, information extraction)5. (information extraction, Evaluate-for, question-answering systems)6. (information extraction, Is-a-Prerequisite-of, social network extraction)7. (information extraction, Is-a-Prerequisite-of, social media analysis)
EMPTY G1.grammar checker
(training neural network, Evaluate-for, task reward)(training neural network, Used-for, machine reading)(training neural network, Is-a-Prerequisite-of, symbol reasoning)(training neural network, Evaluate-for, model optimization)(training neural network, Compare, state-of-the-art models)(training neural network, Is-a-Prerequisite-of, question answering)(training neural network, Used-for, labelled sequence transduction)(training neural network, Used-for, question answering models)(training neural network, Is-a-Prerequisite-of, generative domain adaptive nets)(training neural network, Evaluate-for, model improvement)(training neural network, Is-a-Prerequisite-of, text categorization)(training neural network, Is-a-Prerequisite-of, named entity recognition)
EMPTY G1.speech signal analysis
EMPTY G1.graphical model
(combinatory categorial grammar,Used-for,statistical parsing)(statistical parsing,Evaluate-for,parser evaluations)(statistical parsing,Used-for,predicate-argument structure)(neural language modeling,Compare,statistical parsing)(statistical parsing,Used-for,parser evaluations)(statistical parsing,Used-for,predicate-argument structure)
(pagerank, Compare, Salience Rank)(pagerank, Used-for, extract keyphrases)(pagerank, Part-of, Salience Rank)(pagerank, Evaluate-for, efficiency benefit)(pagerank, Is-a-Prerequisite-of, running PageRank)(pagerank, Compare, hyperdoc2vec)(pagerank, Evaluate-for, superiority of hyperdoc2vec)(pagerank, Compare, EL)(pagerank, Evaluate-for, annotation speed)
EMPTY G1.n-gram model
(neural techniques, Used-for, bagging)(approach, Used-for, bagging)
(prosody, Used-for, parsing)(prosody, Evaluate-for, detecting concealed information)(prosody, Used-for, natural and expressive speech synthesis)(linguistics, Conjunction, prosody)
(dependency parsing,Evaluate-for,parsing)(dependency parsing,Evaluate-for,deep learning model)(dependency parsing,Is-a-Prerequisite-of,semantic role labeling)(dependency parsing,Is-a-Prerequisite-of,natural language descriptions)(dependency parsing,Is-a-Prerequisite-of,language generation task)(`content`,Used-for,dependency parsing)(dependency parsing,Part-of,end-to-end computational argumentation mining)(dependency parsing,Compare,token-based dependency parsing)(dependency parsing,Compare,token-based sequence tagging)(dependency parsing,Used-for,semantic dependency parsing)(dependency parsing,Evaluate-for,performance results)(dependency parsing,Is-a-Prerequisite-of,neural techniques)(Universal Dependencies,Is-a-Prerequisite-of,dependency parsing)(dependency parsing,Used-for,constructing a dependency treebank)(argument component level,Compare,dependency parsing)(dependency parsing,Is-a-Prerequisite-of,perform robustly across classification scenarios)(dependency parsing,Used-for,multi-task learning)(dependency parsing,Evaluate-for,accuracies)(BiLSTMs,Compare,dependency parsing)(penn treebank,Used-for,dependency parsing)(dependency parsing,Part-of,token-based dependency parsing)(dependency parsing,Evaluate-for,subpar performance results)(graph-based nlp,Is-a-Prerequisite-of,dependency parsing)(dependency parsing,Is-a-Prerequisite-of,semantic dependency parsing)(dependency
EMPTY G1.q learning
(discourse relation,Used-for,discourse analysis)(argument mining,Is-a-Prerequisite-of,discourse analysis)(discourse analysis,Is-a-Prerequisite-of,discourse parsing)
EMPTY G1.speech processing
EMPTY G1.chinese nlp
(domain adaptation, Is-a-Prerequisite-of, domain dependence problem)(domain adaptation, Compare, unsupervised domain adaptation)(domain adaptation, Evaluate-for, sentiment analysis)(domain adaptation, Is-a-Prerequisite-of, neural machine translation)(domain adaptation, Evaluate-for, named-entity recognition)(domain adaptation, Is-a-Prerequisite-of, dialog system building)(domain adaptation, Part-of, open information extraction)(domain adaptation, Is-a-Prerequisite-of, knowledge transfer)(data shift, Used-for, domain adaptation)(sentiment classification, Evaluate-for, domain adaptation)(bilingual tasks, Is-a-Prerequisite-of, domain adaptation)(ROUGE, Evaluate-for, question answering model)
(deep learning tool,Used-for,semantic role labeling)(deep learning tool,Compare,language modeling)(deep learning tool,Is-a-Prerequisite-of,automatic fake news detection)(deep learning tool,Compare,sentence scoring)(deep learning tool,Part-of,slot filling)
EMPTY G1.computational phonology
EMPTY G1.toolkits for information retrieval
EMPTY G1.class logistics
(question answering, Is-a-Prerequisite-of, zero pronoun resolution)(question answering, Is-a-Prerequisite-of, pointer network)(question answering, Is-a-Prerequisite-of, knowledge base)(question answering, Compare, end-to-end neural network model)(KB-QA, Used-for, question answering)(question answering, Is-a-Prerequisite-of, reading comprehension)(document, Evaluate-for, question answering)(natural language processing, Is-a-Prerequisite-of, question answering)(document classification, Is-a-Prerequisite-of, question answering)(automatic question answering, Is-a-Prerequisite-of, question answering)(reading comprehension, Is-a-Prerequisite-of, question answering)(training neural network, Is-a-Prerequisite-of, question answering)(semantic parsing, Part-of, question answering)(memory network, Used-for, question answering)(EviNets, Evaluate-for, question answering)(universal schema, Is-a-Prerequisite-of, question answering)(concept, Evaluate-for, question answering)
EMPTY G1.entropy
(morphological disambiguation, Used-for, language modeling)(morphological disambiguation, Evaluate-for, improving NLP applications)(morphological disambiguation, Conjunction, surface context)(morphological disambiguation, Evaluate-for, deep learning-based approach)(morphological disambiguation, Is-a-Prerequisite-of, morphological segmentation)(morphological disambiguation, Compare, semantics disambiguation)(morphological paradigm, Is-a-Prerequisite-of, morphological disambiguation)
EMPTY G1.classic parsing method
(gradient descent, Is-a-Prerequisite-of, Stochastic Gradient Descent (SGD))(gradient descent, Compare, Batch gradient learning)(gradient descent, Evaluate-for, Time complexity)(gradient descent, Evaluate-for, Adversarial training)(gradient descent, Is-a-Prerequisite-of, Gradient Ascent Post-training (GAP))(newton method, Compare, gradient descent)(gradient descent, Used-for, learn word representations)(gradient descent, Part-of, Stochastic Gradient Descent)(gradient descent, Evaluate-for, word representations)(gradient descent, Is-a-Prerequisite-of, generative learning)(gradient descent, Part-of, AllVec)(ROUGE, Evaluate-for, question answering model)(ROUGE, Used-for, question answering model)
(transliteration, Conjunction, Romanization)(transliteration, Is-a-Prerequisite-of, machine translation)(transliteration, Compare, translation)
(Multimodal sentiment analysis,Is-a-Prerequisite-of,multi-modal learning)  (Multilingual learning,Is-a-Prerequisite-of,multi-modal learning)
(search,Compare,dialogue systems)(HyDE,Used-for,search)(search,Is-a-Prerequisite-of,uncertainty)(search,Is-a-Prerequisite-of,logic and logical agents)(search,Is-a-Prerequisite-of,informed search)(search,Is-a-Prerequisite-of,problem solving and search)(search,Is-a-Prerequisite-of,heuristic search)(search,Is-a-Prerequisite-of,adversarial search)(search,Is-a-Prerequisite-of,a* search)(search,Is-a-Prerequisite-of,game playing in ai)
(paraphrasing, Used-for, sentence simplification)(paraphrasing, Used-for, paraphrase generation)(paraphrasing, Evaluate-for, text similarity measures)(paraphrasing, Is-a-Prerequisite-of, sentence simplification)(paraphrasing, Compare, summarization)(paraphrasing, Evaluate-for, automatic evaluation)
EMPTY G1.theory of computation
EMPTY G1.others
EMPTY G1.one-shot learning
(distributional word embeddings, Compare, multilingual word embedding)(cross-lingual word embeddings, Compare, multilingual word embedding)(bilingual word embeddings, Compare, multilingual word embedding)
EMPTY G1.document ranking
EMPTY G1.structured sparsity
(evaluation of information retrieval, Used-for, cope with abundant information)(evaluation of information retrieval, Compare, previous techniques)(evaluation of information retrieval, Compare, Semantic hashing)(evaluation of information retrieval, Compare, information pollution)(evaluation of information retrieval, Evaluate-for, determine what we should actually believe)(evaluation of information retrieval, Conjunction, Information retrieval and extraction)(evaluation of information retrieval, Used-for, developing a general framework)(evaluation of information retrieval, Is-a-Prerequisite-of, query expansion)
(nn sequence parsing,Is-a-Prerequisite-of,Sequence-to-Dependency Neural Machine Translation (SD-NMT))
- (combinatory categorial grammar, Is-a-Prerequisite-of, CCG parsing)- (combinatory categorial grammar, Used-for, statistical parsing)- (combinatory categorial grammar, Used-for, evaluating performance)- (combinatory categorial grammar, Evaluate-for, domain adaptation method)
(particle filter, Evaluate-for, multimedia event extraction)(particle filter, Evaluate-for, named entity recognition)(particle filter, Evaluate-for, melody-to-lyric generation)
EMPTY G1.neural question answering
EMPTY G1.facial recognition system
(programming language,Is-a-Prerequisite-of,code generation)(programming language,Used-for,code generation)(programming language,Evaluate-for,achieving state-of-the-art results)(programming language,Part-of,a general-purpose programming language like Python)(programming language,Compare,natural language)
EMPTY G1.nlp for biology
EMPTY G1.bag of word model
(mathematical model, Part-of, deep learning techniques)(mathematical model, Is-a-Prerequisite-of, learning)
(bias-variance,Is-a-Prerequisite-of,model complexity)(bias-variance,Is-a-Prerequisite-of,data size)
(document modeling,Used-for,event detection)(event detection,Is-a-Prerequisite-of,learn event)(event detection,Compare,personal health mention detection)(event detection,Compare,Nugget Proposal Networks)(event detection,Compare,categorization)(prediction,Is-a-Prerequisite-of,event detection)
EMPTY G1.dialog system
(Generative Domain-Adaptive Nets, Evaluate-for, semi-supervised learning)(novel training framework, Evaluate-for, semi-supervised learning)(Generative Model, Evaluate-for, semi-supervised learning)(deep reinforcement learning strategy, Used-for, semi-supervised learning)(Labeled sequence transduction, Used-for, semi-supervised learning)(Hybrid Code Networks, Is-a-Prerequisite-of, semi-supervised learning)(Exploiting neural network with regular expressions, Used-for, semi-supervised learning)(Unsupervised machine translation, Compare, semi-supervised learning)(generative latent-variable model, Is-a-Prerequisite-of, semi-supervised learning)(supervised learning, Is-a-Prerequisite-of, semi-supervised learning)(semi-supervised learning, Is-a-Prerequisite-of, labeled sequence transduction)(semi-supervised learning, Is-a-Prerequisite-of, generative model)(semi-supervised learning, Is-a-Prerequisite-of, graph convolutional networks)(semi-supervised learning, Is-a-Prerequisite-of, neural networks)
(language identification, Used-for, processing multilingual text)
EMPTY G1.harmonic function
EMPTY G1.shallow parsing
(calculus, Is-a-Prerequisite-of, spectral methods)(calculus, Is-a-Prerequisite-of, harmonic functions)(calculus, Is-a-Prerequisite-of, mathematical models)(calculus, Is-a-Prerequisite-of, structured sparsity)(calculus, Is-a-Prerequisite-of, recursive neural network)(calculus, Is-a-Prerequisite-of, machine learning resources)(calculus, Is-a-Prerequisite-of, latent variable models)(calculus, Is-a-Prerequisite-of, State Space Models)(calculus, Is-a-Prerequisite-of, Meta-Learning)(calculus, Is-a-Prerequisite-of, Mixture Models)(calculus, Is-a-Prerequisite-of, Manifold Learning)(calculus, Is-a-Prerequisite-of, newton method)
EMPTY G1.cky parsing
- (planning, Is-a-Prerequisite-of, multi-task learning)- (planning, Is-a-Prerequisite-of, adversarial learning)- (planning, Used-for, framework)- (planning, Is-a-Prerequisite-of, decentralized policies)- (planning, Evaluate-for, interpret agents messages)- (planning, Is-a-Prerequisite-of, translation model)- (planning, Is-a-Prerequisite-of, sequence transduction)- (planning, Used-for, labeled data generation)- (planning, Is-a-Prerequisite-of, event extraction)- (planning, Is-a-Prerequisite-of, semantic role labeling)- (planning, Is-a-Prerequisite-of, extractive summarization)- (planning, Is-a-Prerequisite-of, language resource creation)- (planning, Is-a-Prerequisite-of, question generation)- (planning, Is-a-Prerequisite-of, taxonomic learning)- (planning, Is-a-Prerequisite-of, network analysis)- (planning, Is-a-Prerequisite-of, robotics)- (planning, Is-a-Prerequisite-of, logic and logical agents)- (planning, Is-a-Prerequisite-of, problem solving and search)- (planning, Is-a-Prerequisite-of, adversarial search)- (planning, Is-a-Prerequisite-of, game
EMPTY G1.markov decision process
(morphology, Part-of, syntax)(semantics, Part-of, syntax)(syntax, Is-a-Prerequisite-of, semantic parsing)(syntax, Conjunction, semantic role labeling)(syntax, Evaluate-for, code generation)(syntax, Is-a-Prerequisite-of, deep learning frameworks)(syntax, Is-a-Prerequisite-of, NMT models)(part of speech, Is-a-Prerequisite-of, syntax)(syntax, Is-a-Prerequisite-of, CKY parsing)(syntax, Is-a-Prerequisite-of, SyntaxNet)(syntax, Is-a-Prerequisite-of, syntax based machine translation)(syntax, Is-a-Prerequisite-of, dependency syntax)(syntax, Is-a-Prerequisite-of, Penn Treebank)(syntax, Is-a-Prerequisite-of, shift-reduce parsing)
(concept, relation, concept) triplets after fusion:1. (graph convolutional network, Used-for, nested named entity)2. (social network extraction, Used-for, graph convolutional network)3. (neural networks, Compare, graph convolutional network)4. (graph convolutional network, Used-for, spelling correction)
EMPTY G1.spectral method
(concept, relation, concept)(pointer network, Used-for, zero pronoun resolution)(pointer network, Used-for, generating large-scale pseudo training data)(pointer network, Used-for, transfer cloze-style reading comprehension neural network model)(pointer network, Is-a-Prerequisite-of, two-step training mechanism)(question answering, Is-a-Prerequisite-of, pointer network)(pointer network, Compare, recurrent neural networks)(pointer network, Compare, neural machine translation)(pointer network, Compare, deep convolutional neural network)(neural machine translation, Evaluate-for, pointer network)(deep convolutional neural network, Evaluate-for, pointer network)(TriviaQA dataset, Evaluate-for, pointer network)
(sequence labeling, Evaluate-for, structured prediction)(dependency parsing, Part-of, structured prediction)(Sequence prediction algorithm, Is-a-Prerequisite-of, structured prediction)(Few-shot natural language generation, Is-a-Prerequisite-of, structured prediction)(Neural network models, Compare, structured prediction)
EMPTY G1.search engine
1. (Tree-LSTMs, Used-for, sentiment analysis)2. (feature extraction, Used-for, sentiment analysis)3. (text classification, Is-a-Prerequisite-of, sentiment analysis)4. (contextualized representation, Used-for, sentiment analysis)5. (domain adaptation, Evaluate-for, sentiment analysis)6. (word distribution, Used-for, sentiment analysis)7. (sequence labeling model, Is-a-Prerequisite-of, sentiment analysis)8. (relation classification, Is-a-Prerequisite-of, sentiment analysis)9. (sentiment analysis, Compare, sarcasm detection)10. (sentiment analysis, Is-a-Prerequisite-of, text features)11. (sentiment analysis, Evaluate-for, polarity orientation)12. (sentiment classification, Compare, sentiment analysis)13. (aspect-based sentiment analysis, Compare, sentiment analysis)14. (supervised sentiment classification, Used-for, sentiment analysis)15. (argument mining, Is-a-Prerequisite-of, sentiment analysis)16. (sentiment lexicon, Used-for, sentiment analysis)17. (concept, Used-for, sentiment analysis)18. (language understanding, Used-for, sentiment analysis)19. (argument extraction, Evaluate-for, sentiment analysis)20. (word embeddings, Used-for, sentiment analysis)21. (domain-invariant representation, Evaluate-for, sentiment analysis)22. (domain-specific representation, Evaluate-for, sentiment analysis)
EMPTY G1.a* search
(automated essay scoring, Is-a-Prerequisite-of, training data)(automated essay scoring, Evaluate-for, essay grading)(automated essay scoring, Compare, automated writing evaluation)(automated essay scoring, Used-for, formative feedback)(automated essay scoring, Part-of, AES models)(automated essay scoring, Is-a-Prerequisite-of, domain generalization)(automated essay scoring, Used-for, essay grading)(generative language model, Used-for, automated essay scoring)
EMPTY G1.matrix multiplication
EMPTY G1.evaluation of language modeling
(collaborative filtering, Compare, content-based filtering)(collaborative filtering, Part-of, recommendation system approach)(collaborative filtering, Is-a-Prerequisite-of, personalized recommendation)
(lexical semantics, Evaluate-for, interpretation)(lexical semantics, Used-for, semantic disambiguation)(lexical semantics, Is-a-Prerequisite-of, thesaurus-based similarity)(lexical semantics, Is-a-Prerequisite-of, event detection)
EMPTY G1.structured learning
(task learning, Used-for, transfer learning)(multi-task learning, Is-a-Prerequisite-of, transfer learning)(language model like bert, Used-for, transfer learning)(transfer learning, Conjunction, fine-tuning)(transfer learning, Compare, supervised learning)
EMPTY G1.genetic algorithm
(memory network,Used-for,question answering)(memory network,Is-a-Prerequisite-of,reading comprehension)(memory network,Compare,question answering)(memory network,Is-a-Prerequisite-of,cloze-style questions)(memory network,Is-a-Prerequisite-of,multi-hop architecture)(memory network,Is-a-Prerequisite-of,attention mechanism)(memory network,Is-a-Prerequisite-of,recurrent neural network)
(context sensitive grammar, Compare, traditional formulations)(context sensitive grammar, Compare, probabilistic context free grammar)(context sensitive grammar, Compare, mildly context-sensitive grammars)
(part of speech, Evaluate-for, lexical features)(part of speech, Evaluate-for, part-of-speech tagging)(part of speech, Is-a-Prerequisite-of, syntax)(syntax, Is-a-Prerequisite-of, part of speech)(part of speech, Evaluate-for, syntactic tasks)
(dynamic programming, Compare, greedy algorithm)(greedy algorithm, Is-a-Prerequisite-of, top-down inference)
(neural machine translation, Compare, statistical machine translation)(statistical machine translation, Is-a-Prerequisite-of, automatic question answering)
(thesaurus-based similarity, Compare, corpus-based word similarities)
(semantic parsing,Evaluate-for,question answering model)(semantic parsing,Used-for,question answering model)(neural semantic parser,Evaluate-for,semantic parsing)(semantic parsing,Part-of,neural semantic parser)(semantic parsing,Used-for,neural semantic parser)(neural semantic parser,Is-a-Prerequisite-of,semantic parsing)(semantic parsing,Used-for,semantic decoding)(semantic parsing,Is-a-Prerequisite-of,semantic decoding)(semantic parsing,Used-for,semantic decoding)(semantic parsing,Part-of,natural language processing)(neural semantic parser,Evaluate-for,natural language processing)(semantic parsing,Is-a-Prerequisite-of,natural language processing)(natural language understanding,Used-for,semantic parsing)(semantic parsing,Used-for,natural language understanding)(semantic parsing,Is-a-Prerequisite-of,natural language understanding)(semantic decoding,Used-for,semantic parsing)(semantic parsing,Compare,neural machine translation)(semantic parsing,Is-a-Prerequisite-of,neural machine translation)(semantic parsing,Used-for,neural machine translation)(neural semantic parser,Evaluate-for,semantic decoding)(semantic parsing,Compare,natural language generation task)(semantic parsing,Is-a-Prerequisite-of,natural language generation task)(semantic parsing,Used-for,natural language generation task)(semantic parser,Used-for,semantic parsing)(semantic parsing,Part-of,neural
- (spectral clustering, Is-a-Prerequisite-of, graph theory)- (graph theory, Used-for, knowledge graph completion)- (graph theory, Used-for, dependency parse structures)- (graph theory, Is-a-Prerequisite-of, Message Passing)
(neural turing machine, Compare, Global Context Layer)(neural turing machine, Is-a-Prerequisite-of, context-aware neural network model)(neural turing machine, Used-for, storing processed temporal relations)(neural turing machine, Is-a-Prerequisite-of, Neural Turing Machine)(neural turing machine, Is-a-Prerequisite-of, model with long-term memory and attention mechanisms)(neural turing machine, Compare, regular RNNs such as LSTM)
EMPTY G1.phrase based machine translation
EMPTY G1.uncertainty
(neural summarization, Is-a-Prerequisite-of, abstractive summarization)(neural summarization, Evaluate-for, generate summaries)(neural summarization, Compare, abstractive summarization)(neural summarization, Evaluate-for, document summarization)(neural summarization, Evaluate-for, extractive summarization)(neural summarization, Compare, traditional summarization approaches)(neural summarization, Evaluate-for, sentence scoring)(neural summarization, Evaluate-for, sentence selection)(neural summarization, Part-of, neural sequence-to-sequence model)(neural summarization, Evaluate-for, multi-task learning)(neural summarization, Evaluate-for, entailment generation)(neural summarization, Evaluate-for, question generation)(neural summarization, Evaluate-for, multi-task architectures)(neural summarization, Is-a-Prerequisite-of, scientific article summarization)
(generative adversarial network, Used-for, generating adversarial examples)(generative adversarial network, Compare, generative neural network)(generative adversarial network, Compare, recurrent network)(generative adversarial network, Compare, generative neural network model)(generative adversarial network, Compare, generative adversarial networks)(generative adversarial network, Compare, Generative Adversarial Networks)(generative adversarial network, Is-a-Prerequisite-of, adversarial training)(generative adversarial network, Is-a-Prerequisite-of, adversarial learning)(generative adversarial network, Evaluate-for, performance improvement)(generative adversarial network, Evaluate-for, robustness improvement)
EMPTY G1.information theory
EMPTY G1.attention model
(probabilistic grammar,Used-for,NLP)(NLU tasks,Compare,probabilistic grammar)
EMPTY G1.radial basis function network
(stemming, Is-a-Prerequisite-of, vector space representations)(stemming, Used-for, spectral clustering)(stemming, Compare, clustering)(stemming, Is-a-Prerequisite-of, word embeddings)(stemming, Used-for, machine translation)(stemming, Is-a-Prerequisite-of, natural language processing)
1. (concept, Hyponym-Of, computer vision)2. (computer vision, Compare, natural language processing)3. (computer vision, Is-a-Prerequisite-of, visual captioning)4. (computer vision, Is-a-Prerequisite-of, nlp and vision)
(finite state transducer, Compare, neural semantic parser)(finite state transducer, Compare, morphological complex languages)(finite state transducer, Used-for, handle tasks such as part-of-speech tagging and speech recognition)(finite state transducer, Compare, parallel graphics processing unit (GPU))(finite state transducer, Used-for, Accelerate finite state algorithms)(finite state transducer, Used-for, Achieve the best performance on GPU architecture)(finite state transducer, Compare, OpenFST)(finite state transducer, Part-of, encoder-decoder framework)(finite state transducer, Is-a-Prerequisite-of, end-to-end model for semantic parsing)(finite state transducer, Part-of, neural semantic parsers)(finite state transducer, Used-for, develop an approach to morph-based auto-completion)(finite state transducer, Used-for, map prefixes in a language to a set of possible completions)(finite state transducer, Compare, neural models)
(dual decomposition,Is-a-Prerequisite-of,compositional question)(dual decomposition,Is-a-Prerequisite-of,semantic parsing)(dual decomposition,Is-a-Prerequisite-of,multi-hop reading comprehension)(embedding models,Used-for,dual decomposition)(HSP method,Is-a-Prerequisite-of,dual decomposition)(dual decomposition,Used-for,semantic composition)(dual decomposition,Is-a-Prerequisite-of,hierarchical semantic parsing)(dual decomposition,Is-a-Prerequisite-of,multi-hop reasoning)(dual decomposition,Is-a-Prerequisite-of,model training)(embedding methods,Compare,dual decomposition)
(supertagging, Part-of, parsing algorithm)(supertagging, Used-for, achieve state-of-the-art parsing performance)(supertagging, Used-for, improve parsing accuracy)(supertagging, Is-a-Prerequisite-of, dependency parsing)
EMPTY G1.robotic locomotion
EMPTY G1.tree adjoining grammar
EMPTY G1.bidirectional recurrent neural network
EMPTY G1.regularization
(GBS, Hyponym-Of, beam search)(beam search, Conjunction, maintaining all found hypotheses in a single priority queue)(beam search, Compare, prioritizing hypotheses based on a universal score function)(algorithm, Used-for, beam search)(beam search, Used-for, neural machine translation)(beam search, Compare, hypotheses)(beam search, Is-a-Prerequisite-of, neural summarization)
EMPTY G1.wordnet
EMPTY G1.random forest
(social network extraction, Evaluate-for, classification)(CNN, Used-for, classification)(extraction, Is-a-Prerequisite-of, classification)(argument identification, Evaluate-for, classification)(classification, Is-a-Prerequisite-of, sentiment analysis)(classification, Is-a-Prerequisite-of, sequence classification and conditional random fields)(classification, Is-a-Prerequisite-of, sentence boundary recognition)
EMPTY G1.constraint satisfaction
(syntaxnet,Is-a-Prerequisite-of,abstract syntax networks)(syntaxnet,Used-for,semantic parsing)(syntaxnet,Is-a-Prerequisite-of,syntactic structure learning)(syntaxnet,Compare,Visually Grounded Neural Syntax Learner)(syntaxnet,Compare,syntax-infused variational autoencoder)(syntaxnet,Evaluate-for,word generation)(syntaxnet,Is-a-Prerequisite-of,treebank creation)(syntaxnet,Evaluate-for,syntactic structure improvement)
EMPTY G1.k-nn
1. (part of speech tagging, Compare, dependency parsing)2. (part of speech tagging, Is-a-Prerequisite-of, models)3. (models, Is-a-Prerequisite-of, part of speech tagging)4. (part of speech tagging, Evaluate-for, text infilling)5. (part of speech tagging, Is-a-Prerequisite-of, parsers)6. (parsers, Is-a-Prerequisite-of, part of speech tagging)7. (part of speech tagging, Is-a-Prerequisite-of, syntaxnet)8. (part of speech tagging, Is-a-Prerequisite-of, course introduction)9. (part of speech tagging, Is-a-Prerequisite-of, statistical part of speech tagging)
EMPTY G1.chat bot
EMPTY G1.search engine indexing
EMPTY G1.logic and reasoning
EMPTY G1.imagenet
(backpropagation, Used-for, training)(backpropagation, Evaluate-for, optimization)(backpropagation, Is-a-Prerequisite-of, training)(backpropagation, Is-a-Prerequisite-of, optimization)(backpropagation, Used-for, parsing)(backpropagation, Part-of, neural networks)(backpropagation, Is-a-Prerequisite-of, Variations of GANs)(backpropagation, Is-a-Prerequisite-of, Autoencoders)
(text similarity, Part-of, distributional vector space models)(text similarity, Compare, N-grams and skip-grams overlap)(text similarity, Is-a-Prerequisite-of, event detection)(text similarity, Is-a-Prerequisite-of, document representation)(text similarity, Is-a-Prerequisite-of, bio text mining)(text similarity, Is-a-Prerequisite-of, recommendation system)(text similarity, Is-a-Prerequisite-of, text mining)(text similarity, Is-a-Prerequisite-of, word sense disambiguation)(text similarity, Is-a-Prerequisite-of, information extraction)
EMPTY G1.capsule network
EMPTY G1.bayes theorem
EMPTY G1.bootstrapping
(text summarization, Is-a-Prerequisite-of, extractive summarization)(text summarization, Is-a-Prerequisite-of, abstractive summarization)(text summarization, Is-a-Prerequisite-of, neural summarization)(text summarization, Is-a-Prerequisite-of, summarization evaluation)(text summarization, Part-of, abstractive sentence summarization)(text summarization, Part-of, extractive multi-document summarization)(text summarization, Part-of, query-based summarization)(text summarization, Used-for, generating concise summaries)(social media, Used-for, text summarization)(extractive summary, Used-for, text summarization)(Sequence-to-sequence network, Is-a-Prerequisite-of, text summarization)(clustering, Is-a-Prerequisite-of, text summarization)(document summarization, Is-a-Prerequisite-of, text summarization)(text summarization, Compare, extractive summarization)(text summarization, Compare, abstractive summarization)(text summarization, Compare, query-based summarization)(text summarization, Evaluate-for, generate a shorter version)
(convolutional neural network, Compare, recurrent neural network)(deep recurrent neural network, Hyponym-Of, recurrent neural network)(memory network, Is-a-Prerequisite-of, recurrent neural network)(language modeling, Used-for, recurrent neural network)(speech perception, Used-for, recurrent neural network)(Hybrid Code Networks, Is-a-Prerequisite-of, recurrent neural network)(RNNs with domain-specific knowledge, Is-a-Prerequisite-of, recurrent neural network)(joint extraction of entity mentions and relations, Evaluate-for, recurrent neural network)(LSTM, Compare, recurrent neural network)(Machine Reading, Used-for, recurrent neural network)(Document Classification, Evaluate-for, recurrent neural network)(Machine Translation, Is-a-Prerequisite-of, recurrent neural network)(Stanford Parser, Compare, recurrent neural network)(factoid question answering, Evaluate-for, recurrent neural network)
(normalization, Used-for, training encoder-decoder architectures)(normalization, Evaluate-for, improving semantic role labeling)(normalization, Part-of, Automated processing)(normalization, Compare, outperforming existing models)(normalization, Evaluate-for, parser adaptation)(normalization, Evaluate-for, multi-task learning)(normalization, Used-for, parser adaptation)
(evaluation of question answering, Used-for, assessing the efficiency of question answering systems)(evaluation of question answering, Evaluate-for, assessing the effectiveness of question answering approaches)
EMPTY G1.knowledge graph
1. (SDP, Is-a-Prerequisite-of, discourse parsing)2. (sentence-level discourse analysis, Used-for, discourse parsing)3. (open-domain neural semantic parser, Used-for, discourse parsing)4. (deep learning model, Evaluate-for, discourse parsing)5. (SciDTB, Used-for, discourse parsing)6. (SPARK, Evaluate-for, discourse parsing)7. (transition-based discourse parser, Is-a-Prerequisite-of, discourse parsing)8. (text coherence model, Evaluate-for, discourse parsing)9. (long-span dependencies, Part-of, discourse parsing)10. (implicit discourse relations, Is-a-Prerequisite-of, discourse parsing)11. (neural framework, Used-for, discourse parsing)12. (document-level coherence score, Compare, discourse parsing)13. (argument mining, Compare, discourse parsing)14. (neural semantic parser, Used-for, discourse parsing)15. (ArgRewrite, Used-for, argument mining)16. (RST annotation, Evaluate-for, discourse parsing)17. (discourse segmentation, Part-of, discourse parsing)18. (Chinese implicit discourse relations, Is-a-Prerequisite-of, discourse parsing)19. (discourse coherence, Evaluate-for, discourse parsing)
1. (latent variable model, Compare, variational autoencoders)2. (dialog generation, Is-a-Prerequisite-of, variational autoencoders)3. (neural models, Compare, variational autoencoders)
EMPTY G1.maximum likelihood estimation
EMPTY G1.gibbs sampling
(random walk, Compare, autoregressive models)(random walk, Compare, biased random walkers)
(object detection,Used-for,event coreference)(object detection,Used-for,personal health mention detection)(object detection,Compare,event detection)(object detection,Is-a-Prerequisite-of,weakly-supervised spatio-temporally grounding natural sentence)(object detection,Compare,event detection)
EMPTY G1.monte carlo tree search
EMPTY G1.variational bayes model
EMPTY G1.probability
(recursive neural network, Used-for, text representation)
(sentence simplification, Part-of, sequence labeling)(paraphrasing, Used-for, sentence simplification)(paraphrasing, Is-a-Prerequisite-of, sentence simplification)(simple sentence, Evaluate-for, sentence simplification)(clinical letters, Used-for, sentence simplification)(sentence simplification, Compare, sentence-alignment)(sentence simplification, Is-a-Prerequisite-of, automated TS systems)(MSR abstractive sentence summarization datasets, Evaluate-for, sentence simplification)(sentence simplification, Part-of, sentence-alignment)(context-aware neural machine translation model, Used-for, sentence simplification)(sentence simplification, Is-a-Prerequisite-of, lexical simplification)(neural text simplification software, Used-for, sentence simplification)(sentence simplification, Used-for, sentence-alignment)
(discourse model, Evaluate-for, automatic identification of narrative modes)
(social medium analysis, Part-of, language use in social media)
(learning,Evaluate-for,benefits of our approach)(learning,Is-a-Prerequisite-of,software development)(learning,Is-a-Prerequisite-of,knowledge acquisition)(learning,Used-for,aspect-based sentiment analysis)(learning,Used-for,multi-task learning)(learning,Conjunction,labeled sequence transduction)(Kernel methods,Used-for,learning)(mathematical model,Is-a-Prerequisite-of,learning)(semantic parsing,Is-a-Prerequisite-of,learning)
(reinforcement learning,Evaluate-for,sentence selection)(reinforcement learning,Evaluate-for,bandit neural machine translation)(reinforcement learning,Is-a-Prerequisite-of,task-oriented dialogue systems)(reinforcement learning,Is-a-Prerequisite-of,dialogue policy learning)(reinforcement learning,Evaluate-for,conversational game)(reinforcement learning,Evaluate-for,end-to-end reinforcement learning)(reinforcement learning,Evaluate-for,coreference resolution)(reinforcement learning,Is-a-Prerequisite-of,policy gradient training)(reinforcement learning,Evaluate-for,historical text normalization)(reinforcement learning,Is-a-Prerequisite-of,unsupervised parsers)(reinforcement learning,Is-a-Prerequisite-of,incremental learning framework)(reinforcement learning,Is-a-Prerequisite-of,Generation-Evaluation framework)(reinforcement learning,Is-a-Prerequisite-of,robotics)(reinforcement learning,Is-a-Prerequisite-of,agent-based view of ai)
(robotics, Used-for, human-robot communication)(robotics, Is-a-Prerequisite-of, grounded verb semantics)(robotics, Used-for, acquiring optimal policy)(robotics, Evaluate-for, long-term reward)(robotics, Is-a-Prerequisite-of, interactive learning approach)(robotics, Is-a-Prerequisite-of, robotic locomotion)
(long short term memory network, Compare, Recurrent Neural Networks)(long short term memory network, Evaluate-for, Sentence Compression)(long short term memory network, Evaluate-for, Aspect-Level Sentiment Classification)(long short term memory network, Is-a-Prerequisite-of, Relation Extraction)(long short term memory network, Is-a-Prerequisite-of, Named-Entity Recognition)(long short term memory network, Is-a-Prerequisite-of, Information Extraction)(long short term memory network, Part-of, Affect-LM)(long short term memory network, Part-of, LSTM Noisy Channel Model)
(inference,Is-a-Prerequisite-of,natural language understanding)
EMPTY G1.summarization evaluation
EMPTY G1.transition based dependency parsing
(multi-task learning, Compare, adversarial multi-task learning framework)(multi-task learning, Used-for, text classification tasks)(multi-task learning, Evaluate-for, performance improvement)(multi-task learning, Is-a-Prerequisite-of, semantic parsing)(multi-task learning, Is-a-Prerequisite-of, improving semantic parsing performance)(multi-task learning, Is-a-Prerequisite-of, discourse coherence assessment)(multi-task learning, Is-a-Prerequisite-of, learning the shared layers)(multi-task learning, Is-a-Prerequisite-of, task-invariant features)(multi-task learning, Is-a-Prerequisite-of, accurate abstractive summarization)(multi-task learning, Is-a-Prerequisite-of, transfer learning)(multi-task learning, Is-a-Prerequisite-of, shared layers)(multi-task learning, Is-a-Prerequisite-of, off-the-shelf knowledge)(dependency parsing, Used-for, multi-task learning)(Neural network, Used-for, multi-task learning)(Neural network models, Used-for, multi-task learning)(concept, Used-for, multi-task learning)(Deep recurrent neural networks, Used-for, multi-task learning)(Neural Symbolic Machine, Evaluate-for, multi-task learning)(dependency parsing, Evaluate-for, multi-task learning)(neural summarization, Evaluate-for, multi-task learning)(response generation, Used-for, multi-task learning)(Neural network models, Is-a
(social network extraction, Evaluate-for, occupational class prediction)(social network extraction, Is-a-Prerequisite-of, homophily exploitation)(social network extraction, Evaluate-for, classification)(social network extraction, Conjunction, data set)(social network extraction, Used-for, graph convolutional network)(social network extraction, Is-a-Prerequisite-of, citation networks)
EMPTY G1.logic and logical agent
EMPTY G1.perceptron
EMPTY G1.generative and discriminative model
EMPTY G1.data structure
(conversation partners, contribute, relative information)(lexical entropy series, extract, features)(lexical entropy series, frequency domain representations, extracted)(task, extracting features, task success prediction)(information density, distributed, interlocutors)(conversation partners, interlocutors, information density)(task success prediction models, improve, SVM)(task-oriented dialogue, task success prediction, perspective)(task-oriented dialogue, task success prediction, predict)(interlocutor, contain, lexical entropy series)(PSO, predict, task success)(RP, predict, task success)(task success, information density, distribution)(domain, deployment shift, adaptation)(domain, temporal shift, adaptation)(domain adaptation, propose, solution)(domain adaptation, mismatch problem, frame)(adversarial training, proposed, scheme)(adversarial training, yields, improvement)(challenge, common, data shift)(deployment shift, domain adaptation, handle)(temporal shift, domain adaptation, handle)(model, frame, mismatch problem)(adaptation scenarios, yields, improvement)(source domain sentiment classifiers, reliance, existing methods)(sentiment classifiers, trained, source domains)(distributions, decline, performance)(entailment, form, multimodal word distributions)(word meanings, form, multimodal word distributions)(Gaussian mixtures, form, multimodal word distributions)(word embeddings, provide, representations)(Gaussian embeddings, outperforms, alternatives)(benchmark datasets, outperforms, approach)(sup
(neural language modeling, Compare, recurrent neural networks)(neural language modeling, Evaluate-for, machine-generated poems)(neural language modeling, Is-a-Prerequisite-of, language model perplexity)(neural language modeling, Part-of, LSTM (Long Short-Term Memory))(neural language modeling, Is-a-Prerequisite-of, Affect-LM)(neural language modeling, Part-of, sequence labeling)(neural language modeling, Evaluate-for, predicting text)(neural language modeling, Compare, statistical parsing)(neural language modeling, Is-a-Prerequisite-of, natural language processing)(neural language modeling, Evaluate-for, perception studies)(neural language modeling, Evaluate-for, text similarity measures)(neural language modeling, Is-a-Prerequisite-of, named entity recognition)(neural language modeling, Evaluate-for, document context incorporation)
(speech recognition, Is-a-Prerequisite-of, language processing)(speech recognition, Is-a-Prerequisite-of, natural language processing)(speech recognition, Is-a-Prerequisite-of, multi-speaker speech recognition)(speech recognition, Is-a-Prerequisite-of, named entity recognition)(speech recognition, Is-a-Prerequisite-of, language and vision tasks)(speech recognition, Is-a-Prerequisite-of, multimodal language processing)(speech recognition, Is-a-Prerequisite-of, end-to-end speech translation)(speech recognition, Used-for, automatic speech recognition)(speech recognition, Used-for, end-to-end automatic speech recognition)(speech recognition, Used-for, joint decoding algorithm)(speech recognition, Used-for, speech translation)(speech recognition, Used-for, action recognition)(speech recognition, Evaluate-for, word error rate estimation)(speech recognition, Evaluate-for, humor recognition)
(crawling the web, Used-for, creating the largest publicly available parallel corpora)(crawling the web, Compare, publishing benchmark datasets)(crawling the web, Used-for, sentence alignment)(crawling the web, Is-a-Prerequisite-of, sentence pair filtering)(crawling the web, Is-a-Prerequisite-of, creating machine translation systems)
EMPTY G1.tokenization
(optimization, Used-for, Deep neural networks)(optimization, Is-a-Prerequisite-of, Stochastic optimization)(optimization, Is-a-Prerequisite-of, Memory networks)(optimization, Is-a-Prerequisite-of, Dual decomposition)(optimization, Is-a-Prerequisite-of, Newton method)(optimization, Is-a-Prerequisite-of, Machine learning resources)(optimization, Is-a-Prerequisite-of, KKT conditions)(optimization, Is-a-Prerequisite-of, Lagrange duality)(optimization, Is-a-Prerequisite-of, Meta-Learning)(entity linking, Evaluate-for, optimization)(newton method, Used-for, optimization)(dynamic programming, Used-for, optimization)(backpropagation, Evaluate-for, optimization)(backpropagation, Is-a-Prerequisite-of, optimization)
EMPTY G1.predicate logic
1. (neural approach, Evaluate-for, hidden markov model)2. (neural approach, Evaluate-for, long short-term memory)3. (neural approach, Evaluate-for, long short-term memory)4. (neural approach, Evaluate-for, dialogue act classification)5. (neural approach, Evaluate-for, NMT models)6. (neural approach, Evaluate-for, NER models)7. (neural approach, Evaluate-for, sequence labelling model)8. (neural approach, Evaluate-for, named entity recognition)9. (neural approach, Evaluate-for, CHMM)10. (neural approach, Evaluate-for, CHMM-ALT)
EMPTY G1.decision tree
EMPTY G1.bayesian network
EMPTY G1.conditional probability
(feature learning, Used-for, text classification)(feature learning, Used-for, opinion analysis)(feature learning, Is-a-Prerequisite-of, fine-grained opinion analysis)(feature learning, Used-for, Manifold Learning)(text classification, Is-a-Prerequisite-of, feature learning)(CNN, Used-for, feature learning)
EMPTY G1.linguistics basic
(seq2seq, Compare, Pointer Network)(seq2seq, Compare, RNN)(seq2seq, Compare, Transformer)(seq2seq, Evaluate-for, Conversation Scenarios)(seq2seq, Hyponym-Of, Neural Generative Models)(seq2seq, Is-a-Prerequisite-of, end-to-end computational argumentation mining)(seq2seq, Is-a-Prerequisite-of, conversational agents)(seq2seq, Is-a-Prerequisite-of, neural abstractive summarization)(seq2seq, Is-a-Prerequisite-of, response generation)(seq2seq, Is-a-Prerequisite-of, task-oriented dialogue systems)(seq2seq, Is-a-Prerequisite-of, grammatical error correction)(seq2seq, Is-a-Prerequisite-of, Generative Neural Network for Slot Filling)(seq2seq, Is-a-Prerequisite-of, neural summarization)
(informed search, Used-for, neural search systems)(informed search, Compare, entity-oriented search)
EMPTY G1.problem solving and search
EMPTY G1.neural machine translation nmt
EMPTY G1.phonological feature
EMPTY G1.tuning pre trained language
(semantic representation, Compare, syntactic schemes)(semantic representation, Evaluate-for, sentence representation learning)(semantic representation, Used-for, understanding language)(entity representation, Is-a-Prerequisite-of, semantic representation)
EMPTY G1.commonsense question answering
EMPTY G1.code generation semantic parsing
(linguistic knowledge identification, Evaluate-for, event extraction)(linguistic knowledge identification, Evaluate-for, named entity recognition)(linguistic knowledge identification, Evaluate-for, coreference resolution)(linguistic knowledge identification, Evaluate-for, relation extraction)(linguistic knowledge identification, Evaluate-for, sentiment classification)(linguistic knowledge identification, Evaluate-for, personality detection)(linguistic knowledge identification, Evaluate-for, dialogue response generation)(linguistic knowledge identification, Part-of, document-grounded dialogue)(linguistic knowledge identification, Part-of, psycholinguistic knowledge)
(constrained text generation, Compare, controlled text generation)(S2S models, Evaluate-for, controlled text generation)
EMPTY G1.multilingual neural
(learn event,Is-a-Prerequisite-of,event detection)
EMPTY G1.visual dialogue
(commonsense evaluation, Used-for, coreference resolution)(commonsense evaluation, Compare, neural network models)(commonsense evaluation, Used-for, evaluation benchmark)
(sequence labeling model, Evaluate-for, natural language processing)(sequence labeling model, Evaluate-for, neural network architectures)(sequence labeling model, Evaluate-for, NLP tasks)(sequence labeling model, Evaluate-for, machine translation)(sequence labeling model, Compare, machine translation)(sequence labeling model, Compare, neural network architectures)(sequence labeling model, Compare, sequence-to-sequence learning)(sequence labeling model, Evaluate-for, entity recognition)(sequence labeling model, Is-a-Prerequisite-of, entity recognition)(sequence labeling model, Is-a-Prerequisite-of, sentiment analysis)
(argument invention,Evaluate-for,argument generation)(argument invention,Evaluate-for,argument mining)(argument invention,Evaluate-for,implicit event argument extraction)(argument mining,Used-for,argument invention)(implicit event argument extraction,Evaluate-for,argument invention)
EMPTY G1.language explanation prediction
EMPTY G1.ground truth parse tree
EMPTY G1.interpretability method
EMPTY G1.generated explanation
(topic model, Used-for, text classification)(topic model, Evaluate-for, document context)(topic model, Compare, LDA topic model)(topic model, Compare, word embedding models)(text classification, Is-a-Prerequisite-of, topic model)(joint extraction, Evaluate-for, topic model)(topic model, Used-for, language understanding)(topic model, Compare, LSTM)(topic model, Is-a-Prerequisite-of, multi-task learning)(topic model, Compare, topic models)(topic model, Evaluate-for, perplexity)
EMPTY G1.deep learning model nlp
(relation classification, Is-a-Prerequisite-of, relation extraction)(relation classification, Used-for, feature extraction)(relation classification, Is-a-Prerequisite-of, sentiment analysis)(relation classification, Is-a-Prerequisite-of, sarcasm detection)(relation classification, Is-a-Prerequisite-of, gaze information)(relation classification, Is-a-Prerequisite-of, learning system)(relation extraction, Compare, relation classification)(relation identification, Compare, relation classification)(relation classification, Evaluate-for, ranking loss)(relation classification, Is-a-Prerequisite-of, entity types)(relation classification, Evaluate-for, F1-score)(relation classification, Is-a-Prerequisite-of, state-of-the-art models)(relation detection, Hyponym-Of, relation classification)(entity relation extraction, Evaluate-for, relation classification)
EMPTY G1.automatic dialogue
EMPTY G1.faceted summarization
(social bias, Evaluate-for, text style transfer)
(distributed word representation, Used-for, NLP tasks)(distributed word representation, Used-for, modeling words)
EMPTY G1.domain aspect based sentiment
EMPTY G1.challenge semantic parsing
(representation learning, Used-for, improving distributional vector spaces)(representation learning, Compare, distributed word representations)(representation learning, Compare, Hierarchical Dirichlet Process)(representation learning, Compare, data text generation model)(AES models, Used-for, representation learning)(candidate answers, Is-a-Prerequisite-of, representation learning)
(external knowledge,Is-a-Prerequisite-of,specializing word embeddings)
EMPTY G1.annotated training
(unsupervised bilingual word embeddings, Compare, machine translation)(unsupervised bilingual word embeddings, Compare, back-translation)(unsupervised bilingual word embeddings, Used-for, unsupervised machine translation)(unsupervised bilingual word embeddings, Evaluate-for, method development)(unsupervised bilingual word embeddings, Compare, unsupervised cross-lingual)(unsupervised cross-lingual, Is-a-Prerequisite-of, unsupervised bilingual word embeddings)
EMPTY G1.natural language explanation nles
(image text retrieval, Is-a-Prerequisite-of, dense retrieval)  (dense retrieval, Compare, fully zero-shot dense retrieval systems)
(compositional distributional semantics model, Evaluate-for, semantic relatedness and entailment)(compositional distributional semantics model, Evaluate-for, compositionality degree of multiword expressions)(compositional distributional semantics model, Evaluate-for, prediction of compositionality)(compositional distributional semantics model, Used-for, decoding fMRI patterns)(compositional distributional semantics model, Compare, BERT)
EMPTY G1.based sentiment
(existing word embedding, Compare, distributional word embeddings)
- (sarcasm detection, Used-for, multimodal sarcasm detection)- (sarcasm detection, Evaluate-for, tweet datasets)- (sarcasm detection, Compare, author context)- (sarcasm detection, Is-a-Prerequisite-of, text features)- (sarcasm detection, Compare, Semi-supervised GeNerative Active Learning)- (sarcasm detection, Conjunction, social-media conversations)- (sarcasm detection, Evaluate-for, iSarcasm dataset)- (sarcasm detection, Evaluate-for, Stance detection dataset)- (sarcasm detection, Evaluate-for, TREE LSTM models)- (sarcasm detection, Evaluate-for, personal health mention detection)- (sarcasm detection, Compare, sentiment classification)- (sarcasm detection, Compare, satire detection)- (sarcasm detection, Compare, sarcasm detection)- (sarcasm detection, Evaluate-for, Multimodal Sarcasm Detection Dataset)- (sarcasm detection, Compare, argument extraction)- (sarcasm detection, Compare, sentiment analysis)- (sarcasm detection, Compare, satire detection)- (sarcasm detection, Is-a-Prerequisite-of, feature extraction)- (sarcasm detection, Is-a-Prerequisite-of, relation classification)- (sarcasm detection, Compare, text similarity measures)
(concept, relation, concept):(recurrent neural networks, Compare, recurrent neural tensor)(recurrent neural tensor, Is-a-Prerequisite-of, neural tensor)(recurrent neural tensor, Used-for, machine reading)
(neural parser, Is-a-Prerequisite-of, AMR parsing)(neural parser, Used-for, parsing documents in specific domains)(neural parser, Is-a-Prerequisite-of, Object-oriented Neural Programming (OONP))(neural parser, Used-for, semantically parsing documents)(neural parser, Evaluate-for, improving parsing results)(neural parser, Evaluate-for, generating abstractive summaries)(neural parser, Compare, sequence-to-sequence model)(neural parser, Used-for, parsing for constituency parsing)(neural parser, Compare, neural and non-neural parsers)(neural parser, Is-a-Prerequisite-of, structured output prediction)
(fact checking article, Used-for, detecting misinformation)(fact checking article, Evaluate-for, improving factual correctness)(fact checking article, Evaluate-for, claim verification)(fact checking article, Part-of, automated fact checking)(fact checking article, Evaluate-for, claim veracity prediction)(fact checking article, Is-a-Prerequisite-of, fact-checking system)(fact checking article, Compare, misinformation stories)(fact checking article, Evaluate-for, generating explanations)(fact checking article, Evaluate-for, verifying the truthfulness of a claim)(fact checking article, Evaluate-for, generating justifications for verdicts on claims)(fact checking article, Compare, misinformation stories)(fact checking article, Hyponym-Of, DialFact dataset)
EMPTY G1.generative retrieval
EMPTY G1.summarization task
EMPTY G1.machine translation mt
EMPTY G1.dialogue state tracking dst
EMPTY G1.cognate detection
(decoder, Is-a-Prerequisite-of, generated sentence)(source sequence, Is-a-Prerequisite-of, generated sentence)(model, Compare, generated sentence)
(concept, relation, concept)(visual semantic pretraining, Evaluate-for, text complexity)(visual semantic pretraining, Compare, distributional semantic representations)(visual semantic pretraining, Is-a-Prerequisite-of, improving language models)(visual semantic pretraining, Compare, contrastive visual semantic pretraining)
(contextual subword embeddings, Used-for, multilingual named entity recognition)(contextual subword embeddings, Compare, FastText)
(lexical expectation, Is-a-Prerequisite-of, lexical relations)(lexical expectation, Evaluate-for, models)(lexical expectation, Conjunction, pragmatic phenomena)
(morphological family, Conjunction, morphological inflection)(morphological family, Conjunction, morphological analysis)(morphological family, Conjunction, morphological relation)(morphological family, Part-of, morphological inflection)(morphological family, Part-of, morphological analysis)(morphological family, Part-of, morphological relation)(morphological family, Is-a-Prerequisite-of, morphological inflection)(morphological family, Is-a-Prerequisite-of, morphological analysis)(morphological family, Is-a-Prerequisite-of, morphological relation)
(vision language pre training, Used-for, VLP)(vision language pre training, Evaluate-for, downstream tasks)(vision language pre training, Compare, language model pre-training)(vision language pre training, Compare, multilingual vision-language pre-training)(vision language pre training, Compare, weakly supervised vision-and-language pre-training)
(sparse retrieval, Used-for, phrase embeddings)(sparse retrieval, Evaluate-for, phrase retrieval models)(sparse retrieval, Evaluate-for, question-passage matching)(sparse retrieval, Is-a-Prerequisite-of, contrastive learning)(sparse retrieval, Is-a-Prerequisite-of, dual-encoder model)(sparse retrieval, Is-a-Prerequisite-of, vector representations)
EMPTY G1.oriented dialogue system
-  (neural semantic parser, Used-for, converting natural language utterances to intermediate representations)-  (neural semantic parser, Compare, syntactic schemes)-  (finite state transducer, Compare, neural semantic parser)-  (natural language text, Used-for, neural semantic parser)-  (neural semantic parser, Evaluate-for, semantic parsing)-  (neural semantic parser, Used-for, code generation)-  (neural semantic parser, Is-a-Prerequisite-of, semantic parsing)-  (neural semantic parser, Evaluate-for, state-of-the-art performance on SPADES and GRAPHQUESTIONS)-  (neural semantic parser, Evaluate-for, competitive results on GEOQUERY and WEBQUESTIONS)-  (distributional semantic models, Compare, neural semantic parser)-  (neural semantic parser, Compare, neural architecture powered by a grammar model)-  (semantic parsing, Part-of, neural semantic parser)-  (neural semantic parser, Is-a-Prerequisite-of, interpretable model)-  (neural semantic parser, Is-a-Prerequisite-of, scalable model)
EMPTY G1.dialogue evaluation
EMPTY G1.data text generation
EMPTY G1.discourse mode
(speech synthesis,Is-a-Prerequisite-of,hate speech detection)(hate speech detection,Is-a-Prerequisite-of,speech synthesis)(hate speech detection,Evaluate-for,performance improvement)(hate speech detection,Compare,methods)(hate speech detection,Is-a-Prerequisite-of,hate speech)(hate speech detection,Evaluate-for,sentiment knowledge sharing)(hate speech detection,Evaluate-for,sentiment features)(hate speech detection,Evaluate-for,affective features)
EMPTY G1.aspect category opinion sentiment
(reading comprehension task, Is-a-Prerequisite-of, understanding natural texts and answering questions)
EMPTY G1.approach topic aware news
EMPTY G1.reasoning ability
(argument extraction, Used-for, relation extraction)(argument extraction, Is-a-Prerequisite-of, relation extraction)(argument extraction, Used-for, sentiment polarity and sarcasm detection)(argument extraction, Evaluate-for, sentiment analysis)(argument extraction, Evaluate-for, sarcasm detection)(argument extraction, Used-for, relation extraction)(argument extraction, Compare, semantic role labeling)(argument extraction, Evaluate-for, argument extraction)(with a novel attention-based recurrent neural network, Evaluate-for, argument extraction)(existing KB population methods, Evaluate-for, argument extraction)(novel open information extraction methods, Is-a-Prerequisite-of, argument extraction)
EMPTY G1.transition based parser
EMPTY G1.identifiability attention weight
(syntactic generalization performance, Is-a-Prerequisite-of, syntactic knowledge)(syntactic generalization performance, Compare, perplexity)(syntactic generalization performance, Compare, compositional generalization)(syntactic generalization performance, Evaluate-for, generalization performance)(syntactic generalization performance, Used-for, evaluating neural language models)(syntactic generalization performance, Is-a-Prerequisite-of, neural language models)
EMPTY G1.discourse treebank
(level distant relation extraction, Evaluate-for, noise reduction)(level distant relation extraction, Is-a-Prerequisite-of, relation extraction)
(single document summarization,Is-a-Prerequisite-of,document modeling)(single document summarization,Compare,multi-document summarization)(single document summarization,Evaluate-for,informativeness)(single document summarization,Is-a-Prerequisite-of,natural language understanding)
(structured knowledge, Used-for, reasoning)(task-oriented dialogue system, Is-a-Prerequisite-of, structured knowledge)
(concept, relation, concept)(entity linkage, Evaluate-for, entity linkage)
EMPTY G1.knowledge graph completion kgc
EMPTY G1.fine grained entity typing
EMPTY G1.multilingual pre trained
EMPTY G1.stanford question answering dataset
EMPTY G1.named entity recognition multiple
EMPTY G1.neural language
EMPTY G1.chinese named entity
(political debate, Is-a-Prerequisite-of, argument mining)(political debate, Evaluate-for, argument mining)(political debate, Compare, knowledge base population)(political debate, Used-for, understanding democratic political decision making)(political debate, Used-for, comparing candidates positions)(political debate, Used-for, citizen engagement)(political debate, Is-a-Prerequisite-of, argumentative components identification)(political debate, Used-for, typology investigation)(political debate, Used-for, empirical task addressing)(political debate, Used-for, releasing new corpus)(political debate, Used-for, sharing software with research community)(political debate, Used-for, promoting scientific advancement)(political debate, Is-a-Prerequisite-of, predicting human activities)(political debate, Is-a-Prerequisite-of, computational construction of discourse networks)(political debate, Used-for, citizens)(political debate, Compare, candidates positions)
EMPTY G1.sentence image
(political bias factuality reporting, Part-of, Media profiling)(political bias factuality reporting, Used-for, Detecting fake news)
EMPTY G1.multimodal dialogue
(concept: factuality prediction, relation: Evaluate-for, concept: factuality corpus)
EMPTY G1.knowledge graph kg
(tranlsation, Evaluate-for, human translator)(human translator, Compare, neural machine translation)
EMPTY G1.based parser
(argument mining, Evaluate-for, political debate)(argument mining, Used-for, argument invention)(argument mining, Is-a-Prerequisite-of, predicting the political bias)(argument mining, Is-a-Prerequisite-of, factuality of reporting)(argument mining, Is-a-Prerequisite-of, stance detection)(argument mining, Is-a-Prerequisite-of, entity recognition)(argument mining, Is-a-Prerequisite-of, sentiment analysis)(argument mining, Is-a-Prerequisite-of, discourse analysis)(argument mining, Compare, MeSH indexing)(argument mining, Compare, debate preparation)(argument mining, Compare, discourse parsing)(argument mining, Compare, event argument extraction)(argument mining, Conjunction, neural model)(argument mining, Conjunction, stance polarity and intensity prediction)(argument mining, Conjunction, discourse relation recognition)(argument mining, Part-of, task-specific parameterization)(argument mining, Evaluate-for, sentiment classification)(argument mining, Used-for, task)(argument mining, Is-a-Prerequisite-of, argument detection)
(constraint satisfaction problem, Used-for, poetry generation)(sequence-to-sequence model, Compare, neural machine translation)(nlg model, Used-for, reading comprehension)(document-level attention, Part-of, nlg model)
(task learning, Used-for, multi-task learning)(task learning, Evaluate-for, performance results)(task learning, Compare, dependency parsing)(task learning, Evaluate-for, state-of-the-art results)(task learning, Is-a-Prerequisite-of, knowledge base population)(task learning, Is-a-Prerequisite-of, error detection)(task learning, Evaluate-for, improvement)(task learning, Compare, event extraction)(task learning, Evaluate-for, labeled data)(task learning, Evaluate-for, accuracy)(task learning, Evaluate-for, QA datasets)(task learning, Evaluate-for, entailment task)(task learning, Used-for, transfer learning)(task learning, Conjunction, unsupervised learning)(task learning, Evaluate-for, human evaluations)
(coreference resolution, Evaluate-for, natural language question)(natural language question, Evaluate-for, answer generation)(info retrieval, Is-a-Prerequisite-of, natural language question)
(conversation model, Used-for, response selection for multi-turn conversation)(conversation model, Used-for, Sequential matching network (SMN))(conversation model, Compare, Dialogue perspective on relative information contributions)(conversation model, Used-for, Linguistic prior knowledge)(conversation model, Used-for, Neural Belief Tracking (NBT))(conversation model, Used-for, dialogue)(conversation model, Compare, generative models for conversational systems)
EMPTY G1.nlu task
EMPTY G1.latent relation learning
(neural ranking, Compare, Layer-wise relevance propagation)
EMPTY G1.machine translation model
EMPTY G1.retrieval model
EMPTY G1.nlp community
(summarization model, Is-a-Prerequisite-of, document summarization research)(summarization model, Compare, extractive summarization)(summarization model, Compare, abstractive summarization)(summarization model, Is-a-Prerequisite-of, model generated summary)(summarization model, Used-for, rewriting sentences)(summarization model, Used-for, summarization model)(summarization model, Part-of, summarization model)(summarization model, Part-of, document summarization research)(summarization model, Part-of, model generated summary)(summarization model, Part-of, rewriting sentences)(summarization model, Is-a-Prerequisite-of, query-based summarization)(summarization model, Compare, query-based summarization)
(bias pretrained language model, Compare, fact verification)
(DICE model, Evaluate-for, clinical event extraction)(data-efficient generative model, Evaluate-for, clinical event extraction)
EMPTY G1.sentiment element
EMPTY G1.cross lingual word embeddings
EMPTY G1.semantic parsing datasets
EMPTY G1.pre trained language model
EMPTY G1.diverse conversational corpus
EMPTY G1.reasoning datasets
(event knowledge,Is-a-Prerequisite-of,machine reading)(event knowledge,Used-for,database verbalisers)(event knowledge,Is-a-Prerequisite-of,recurrent neural networks)
EMPTY G1.machine translation nmt
(word embeddings,Compare,word embeddings)(word embeddings,Used-for,large language model)(word embeddings,Used-for,large language model)(word embeddings,Compare,bag-of-words)(word embeddings,Compare,Bag of Words (BoW)(word embeddings,Compare,word2vec skip-grams)(word embeddings,Compare,Gaussian embeddings)(word embeddings,Is-a-Prerequisite-of,word similarity)(word embeddings,Is-a-Prerequisite-of,entailment)(word embeddings,Conjunction,Gaussian mixtures)(word embeddings,Conjunction,word distributions)(word embeddings,Conjunction,multiple word meanings)(word embeddings,Evaluate-for,enhancing translation performance)(word embeddings,Is-a-Prerequisite-of,neural machine translation)(dense vectors,Part-of,word embeddings)(sentence representation,Compare,word embeddings)(word embeddings,Is-a-Prerequisite-of,unsupervised learning)(concept,Is-a-Prerequisite-of,word embeddings)(word embeddings,Used-for,sentiment classification tasks)(word embeddings,Is-a-Prerequisite-of,Domain Adapted (DA)(word embeddings,Is-a-Prerequisite-of,Generic word embeddings)(dependency syntax,Conjunction,word embeddings)(stemming,Is-a-Prerequisite-of,word embeddings)(word embeddings,Evaluate-for,semantic information)(word embeddings,Evaluate-for,text classification)(domain-sensitive word embeddings,Compare,word embeddings)(word embeddings,Part-of,deep learning architectures)
EMPTY G1.task oriented dialogue system
(semantic parsing, Is-a-Prerequisite-of, natural language generation task)(multilingual model, Is-a-Prerequisite-of, natural language generation task)(natural language processing, Part-of, natural language generation task)
EMPTY G1.various information retrieval
(language model,Is-a-Prerequisite-of,large language model)(neural language model,Compare,large language model)(word embeddings,Used-for,large language model)(neural machine translation models,Compare,large language model)(large language model,Used-for,language understanding systems)(large language model,Evaluate-for,semantic quality improvement)(large language model,Is-a-Prerequisite-of,dialogue state tracking)(large language model,Used-for,generation of rhythmic poetry)(large language model,Compare,recurrent neural networks)(large language model,Is-a-Prerequisite-of,LSTM language model)(large language model,Compare,neural machine translation models)(large language model,Evaluate-for,learning morphology)(large language model,Is-a-Prerequisite-of,GuessTwo task)(large language model,Part-of,NLP systems)(large language model,Used-for,adding pretrained context embeddings)(large language model,Evaluate-for,language model perplexity improvement)(large language model,Used-for,sequence labeling tasks)(large language model,Part-of,generative models)(large language model,Is-a-Prerequisite-of,neural machine translation system)
(sentiment classifier, Used-for, sentence-level sentiment classification)(sentiment classifier, Used-for, aspect sentiment classification)(sentiment classifier, Evaluate-for, performance improvement)
(unsupervised bilingual lexicon induction, Compare, bilingual lexicon induction)(cross-lingual embeddings, Used-for, bilingual lexicon induction)(bilingual lexicon induction, Is-a-Prerequisite-of, cross-lingual classification)(bilingual lexicon induction, Is-a-Prerequisite-of, cross-lingual sentiment classification)(bilingual lexicon induction, Compare, cross-lingual word embeddings)
(relation learning, Is-a-Prerequisite-of, multi-task learning)(relation learning, Evaluate-for, framework)(relation learning, Used-for, multi-lingual attention)(relation learning, Compare, dependency parsing)(relation learning, Hyponym-Of, error detection)(relation learning, Part-of, feature imitation framework)(relation learning, Evaluate-for, feature imitation)
EMPTY G1.relation extraction task
EMPTY G1.event ontology
EMPTY G1.modal datasets
1. (Neural Symbolic Machine, Is-a-Prerequisite-of, language understanding task)
(Cross-lingual transfer learning, Is-a-Prerequisite-of, multilingual translation)(multi-lingual, Used-for, multilingual translation)(multilingual translation, Evaluate-for, low-resource settings)
EMPTY G1.bias pretrained language
EMPTY G1.neural summarization model
(unsupervised bilingual lexicon induction, Used-for, unsupervised machine translation)(unsupervised bilingual lexicon induction, Compare, bilingual lexicon induction)(unsupervised bilingual lexicon induction, Is-a-Prerequisite-of, bilingual word embeddings)(unsupervised bilingual lexicon induction, Part-of, unsupervised methods)(unsupervised bilingual lexicon induction, Evaluate-for, graph similarity metric)(unsupervised bilingual lexicon induction, Evaluate-for, task of unsupervised bilingual lexicon induction)
(cross lingual semantic parsing, Used-for, neural translation)(cross lingual semantic parsing, Compare, multilingual semantic parsing)(cross lingual semantic parsing, Evaluate-for, performance improvement)
(semantic parser, Is-a-Prerequisite-of, zero-shot semantic parsing)(semantic parser, Used-for, parsing instructions)(semantic parser, Used-for, semantic parsing)(semantic parser, Evaluate-for, generating natural language)(semantic parser, Used-for, multilingual training)(parser, Hyponym-Of, semantic parser)(pre trained language, Part-of, semantic parser)(COREQA, Compare, semantic parser)
EMPTY G1.shot cross lingual transfer
(multimodal machine translation, Is-a-Prerequisite-of, visual features)(multimodal machine translation, Compare, neural machine translation)(multimodal machine translation, Compare, traditional machine translation)(multimodal machine translation, Is-a-Prerequisite-of, multimodal language)
EMPTY G1.summarization dataset
(dependency parse, Is-a-Prerequisite-of, token-based sequence tagging)  (dependency parse, Compare, token-based sequence tagging)  (dependency parse, Used-for, neural techniques for end-to-end computational argumentation mining)  (dependency parse, Compare, dependency graph)  (dependency parse, Part-of, natural language processing)  (dependency parse, Part-of, semantic parsing)  (dependency parse, Part-of, computational argumentation mining)  (dependency parse, Used-for, AM frame approaches)  (dependency parse, Compare, sequence tagging approaches)  (dependency parse, Evaluate-for, joint learning of subtasks)  (dependency parse, Used-for, Sequence-to-Dependency Neural Machine Translation method)  (dependency parse, Used-for, semantic dependency parsing)  
(image text retrieval, Used-for, cross-modal information retrieval)(image text retrieval, Part-of, VisualSparta)(image text retrieval, Compare, knowledge base question answering (KBQA))(image text retrieval, Is-a-Prerequisite-of, dense retrieval)(image text retrieval, Evaluate-for, zero-shot learning)(image text retrieval, Used-for, Natural Language Processing)
EMPTY G1.modified natural question dataset
EMPTY G1.political debate 50
EMPTY G1.prompt based model
(semantic representation,Evaluate-for,sentence representation learning)(word representation learning,Evaluate-for,sentence representation learning)(abstract meaning representations,Hyponym-Of,sentence representation learning)(SoPa,Used-for,sentence representation learning)(Tree Transformer,Used-for,sentence representation learning)(latent representations,Part-of,sentence representation learning)(sentence embeddings,Is-a-Prerequisite-of,sentence representation learning)(lexicon relations,Is-a-Prerequisite-of,sentence representation learning)(neural MT models,Compare,sentence representation learning)(encoder-decoder dialog model,Compare,sentence representation learning)
(relation extraction, Compare, shot relation extraction)
(named entity relation, Is-a-Prerequisite-of, Named Entity Disambiguation)(named entity relation, Used-for, Named Entity Disambiguation)(named entity relation, Compare, Named Entity Disambiguation)(named entity relation, Is-a-Prerequisite-of, Cross-lingual Named Entity Recognition)
(reading comprehension mrc model, Compare, recurrent neural networks)(reading comprehension mrc model, Evaluate-for, state-of-the-art systems)(reading comprehension mrc model, Hyponym-Of, neural reading comprehension model)(reading comprehension mrc model, Part-of, multi-passage MRC)
EMPTY G1.reading comprehension rc
EMPTY G1.complex named entity
EMPTY G1.recognition relation extraction
EMPTY G1.fact check
EMPTY G1.network rntn
1. (word embedding models, Compare, context word vector)2. (word embedding models, Compare, distributed representation of words)3. (context word vector, Compare, distributed representation of words)4. (context word vector, Is-a-Prerequisite-of, Neural Belief Tracking framework)5. (distributed representation of words, Compare, Neural Belief Tracking framework)
EMPTY G1.word embeddings different language
(dialog generation, Compare, story generation)(dialog generation, Is-a-Prerequisite-of, interpretable response generation)(dialog generation, Is-a-Prerequisite-of, encoder-decoder model)(dialog generation, Is-a-Prerequisite-of, variational autoencoders)
EMPTY G1.conditional text generation
EMPTY G1.unsupervised cross lingual
EMPTY G1.race nlp
(summarization datasets,Used-for,abstractive sentence summarization)(summarization datasets,Part-of,English Gigaword)(summarization datasets,Part-of,DUC 2004)(summarization datasets,Part-of,MSR abstractive sentence summarization)(summarization datasets,Used-for,extractive multi-document summarization)(summarization datasets,Used-for,compressive summarization)(summarization datasets,Part-of,CNN/Daily Mail dataset)(summarization datasets,Part-of,DUC-2002)(summarization datasets,Evaluate-for,evaluating summarization systems)
(adversarial search, Used-for, adversarial training)(adversarial attack, Is-a-Prerequisite-of, adversarial training)(adversarial training, Evaluate-for, robustness improvement)(shared attention layer, Is-a-Prerequisite-of, adversarial training)(generative adversarial network, Is-a-Prerequisite-of, adversarial training)(adversarial training, Used-for, improving robustness of models)(adversarial training, Evaluate-for, training adversarial examples)(adversarial training, Is-a-Prerequisite-of, crafting adversarial examples)(adversarial training, Evaluate-for, self-attentive neural networks)(adversarial training, Evaluate-for, text adversarial attack)(adversarial training, Evaluate-for, improving performance of neural models)(morphological tagging, Evaluate-for, adversarial training)(adversarial training, Used-for, improving model robustness)(adversarial training, Evaluate-for, model performance)(adversarial attacks, Is-a-Prerequisite-of, adversarial training)
(CMU-MOSEI dataset, Evaluate-for, multimodal language)(Multimodal Named Entity Disambiguation task, Used-for, multimodal language)(Multimodal dialogue systems, Is-a-Prerequisite-of, multimodal language)(Multimodal machine translation, Is-a-Prerequisite-of, multimodal language)
(morphological analyzer, Used-for, inflection generation)(morphological analyzer, Evaluate-for, accuracy improvement)(morphological analysis, Part-of, morphological analyzer)(inflection generation, Part-of, morphological analyzer)(morphological compositionality, Is-a-Prerequisite-of, morphological analyzer)
(long form question answering, Used-for, answering multiple choice questions)(long form question answering, Evaluate-for, facilitating geometric reasoning tasks)(long form question answering, Compare, distant supervised open-domain question answering)(long form question answering, Is-a-Prerequisite-of, dynamic neural semantic parsing)(long form question answering, Is-a-Prerequisite-of, reading comprehension)(long form question answering, Is-a-Prerequisite-of, question answering models)
1. (Codec connection, Is-a-Prerequisite-of, sentence generation)2. (sentence generation, Part-of, abstractive summarization)3. (sentence generation, Evaluate-for, response generation)4. (sentence generation, Part-of, dialog systems)5. (sentence generation, Evaluate-for, document modeling)
(dialogue generation model, Used-for, generating responses)(dialogue generation model, Evaluate-for, response relevance)(dialogue generation model, Evaluate-for, response diversity)(dialogue generation model, Evaluate-for, accuracy of response generation)(dialogue generation model, Compare, hierarchical recurrent encoder-decoder models)(dialogue generation model, Compare, neural dialogue models)
(discourse coherence, Is-a-Prerequisite-of, text parsing)(discourse coherence, Evaluate-for, discourse segmentation)(discourse coherence, Conjunction, discourse relations)(discourse coherence, Evaluate-for, discourse coherence assessment)(discourse coherence, Compare, dialogue coherence evaluation)(discourse coherence, Is-a-Prerequisite-of, dialogue systems)(discourse coherence, Is-a-Prerequisite-of, discourse parsers)(segmenter, Evaluate-for, discourse coherence)(Discourse parsing, Evaluate-for, discourse coherence)
EMPTY G1.underrepresented language
(neural retrieval model, Used-for, conversation generation)(neural retrieval model, Is-a-Prerequisite-of, coreference resolution)(neural retrieval model, Compare, sequence-to-sequence model)
EMPTY G1.zero shot text classification
(entity recognition ner aim, Used-for, auxiliary data)(entity recognition ner aim, Evaluate-for, named entity recognition)(entity recognition ner aim, Evaluate-for, natural language processing)(named entity recognition, Is-a-Prerequisite-of, entity recognition ner aim)(natural language processing, Is-a-Prerequisite-of, entity recognition ner aim)
(concept, relation, concept)(relation extraction model, Evaluate-for, relation extraction)(relation extraction model, Compare, existing relation extraction methods)(relation extraction model, Is-a-Prerequisite-of, utilizing mono-lingual attention for relation extraction)(relation extraction model, Evaluate-for, exploiting massive information from texts in various languages)(relation extraction model, Compare, multi-lingual neural relation extraction framework)(relation extraction model, Used-for, finding unknown relational facts from plain text)(relation extraction model, Compare, state-of-the-art relation extraction approaches)(relation extraction model, Evaluate-for, significant improvements in relation extraction)(relation extraction model, Is-a-Prerequisite-of, considering information consistency and complementarity among cross-lingual texts)(relation extraction model, Compare, existing relation extraction methods)(relation extraction model, Compare, multi-lingual neural relation extraction framework)
EMPTY G1.pre trained model
1. (morphological family, Conjunction, morphological inflection)2. (morphological family, Part-of, morphological inflection)3. (morphological family, Is-a-Prerequisite-of, morphological inflection)4. (morphological inflection, Used-for, morphological analysis)5. (morphological relation, Evaluate-for, morphological inflection)6. (morphological inflection, Used-for, morpheme)7. (morphological inflection, Evaluate-for, word embedding)8. (morphological inflection, Evaluate-for, language understanding systems)9. (morphological inflection, Is-a-Prerequisite-of, semantic quality)10. (morphological inflection, Is-a-Prerequisite-of, dialogue state tracking)11. (morphological inflection, Compare, word embeddings)12. (morphological inflection, Is-a-Prerequisite-of, word representations)13. (morphological inflection, Is-a-Prerequisite-of, words)
(language, Is-a-Prerequisite-of, social bias frame)
(translation model, Is-a-Prerequisite-of, neural machine translation)(translation model, Used-for, generating translations)(translation model, Compare, NMT+RNNG)(translation model, Used-for, improving translation performance)(planning, Is-a-Prerequisite-of, translation model)(translation model, Evaluate-for, adversarial source examples)(translation model, Evaluate-for, adversarial target inputs)
EMPTY G1.adversarial robustness
EMPTY G1.word embeddings widely
EMPTY G1.question answering dataset squad
EMPTY G1.answering dataset
EMPTY G1.representation morphological
EMPTY G1.multi task learning
EMPTY G1.detect hate speech
EMPTY G1.learning morphological inflection
(unsupervised selective rationalization, Part-of, deep learning models)(unsupervised selective rationalization, Evaluate-for, explanation for output)(unsupervised selective rationalization, Compare, unsupervised neural machine translation)(unsupervised selective rationalization, Compare, rationale generator)(unsupervised selective rationalization, Compare, predictor)(unsupervised selective rationalization, Evaluate-for, training technique)(unsupervised selective rationalization, Evaluate-for, rationale plausibility)
EMPTY G1.multi passage reading comprehension
EMPTY G1.oriented dialogue
EMPTY G1.chinese spelling correction csc
1. (generative adversarial network, Compare, recurrent network)2. (word embeddings, Is-a-Prerequisite-of, recurrent network)
(dependency parsing,Is-a-Prerequisite-of,language generation task)(text generation,Compare,language generation task)(semantic parsing,Compare,language generation task)
(social bias encoded, Is-a-Prerequisite-of, word embeddings)(social bias encoded, Compare, social biases in word embeddings)(social bias encoded, Evaluate-for, studies on society)
(UnitY, Is-a-Prerequisite-of, direct speech speech translation)(UnitY, Used-for, direct speech speech translation)
- (contextualized embeddings, Compare, traditional word embeddings)- (contextualized embeddings, Compare, Sense embeddings)- (contextualized embeddings, Evaluate-for, Word Sense Disambiguation tasks)- (contextualized embeddings, Evaluate-for, Named entity recognition)- (contextualized embeddings, Evaluate-for, temporal changes)- (contextualized embeddings, Evaluate-for, machine translation evaluation)- (contextualized embeddings, Evaluate-for, lexical substitution)- (contextualized embeddings, Is-a-Prerequisite-of, VAMPIRE)- (contextualized embeddings, Is-a-Prerequisite-of, WSD tasks)- (contextualized embeddings, Is-a-Prerequisite-of, Named entity recognition)- (contextualized embeddings, Is-a-Prerequisite-of, Concept-level analyses)- (contextualized embeddings, Is-a-Prerequisite-of, Social-oriented tasks)- (contextualized embeddings, Is-a-Prerequisite-of, argument clustering)- (contextualized embeddings, Is-a-Prerequisite-of, Word Sense Disambiguation)- (contextualized embeddings, Is-a-Prerequisite-of, VAMPIRE pretraining framework)
(oriented spoken dialogue system, Is-a-Prerequisite-of, end-to-end neural architecture for dialogue systems)(oriented spoken dialogue system, Part-of, GLAD)
(emotion cause pair extraction, Is-a-Prerequisite-of, emotion cause extraction)(emotion cause pair extraction, Compare, emotion-cause pair extraction)(emotion cause pair extraction, Compare, ECE)(emotion cause pair extraction, Part-of, Emotion-Cause Pair Extraction)(emotion cause pair extraction, Evaluate-for, emotion clause identification)(emotion cause pair extraction, Is-a-Prerequisite-of, document emotion analysis)(emotion cause pair extraction, Part-of, emotion-cause pair)(emotion cause pair extraction, Evaluate-for, emotion clause identification)(emotion cause pair extraction, Part-of, Emotion-Cause Pair Extraction)(emotion cause pair extraction, Compare, ECE)
(contextual embeddings, Part-of, word embeddings)(contextual embeddings, Evaluate-for, coherence)
EMPTY G1.annotated training data
(relation linking, Used-for, Knowledge Base Question Answering systems)(relation linking, Is-a-Prerequisite-of, Neural models)(relation linking, Evaluate-for, AMR semantic parse)(relation linking, Compare, Heuristics)(relation linking, Used-for, Knowledge Graphs)(relation linking, Evaluate-for, DBpedia)(relation linking, Is-a-Prerequisite-of, Transformer-based neural model)
(comprehension datasets, Is-a-Prerequisite-of, natural-language understanding systems)(comprehension datasets, Evaluate-for, development of natural-language understanding systems)(comprehension datasets, Is-a-Prerequisite-of, document and query relationship)(comprehension datasets, Evaluate-for, knowing the quality of reading comprehension datasets)(comprehension datasets, Evaluate-for, deep language understanding)(comprehension datasets, Evaluate-for, creation of an RC dataset)(comprehension datasets, Is-a-Prerequisite-of, understanding of common entities and their attributes)(comprehension datasets, Is-a-Prerequisite-of, GuessTwo task)(comprehension datasets, Part-of, TriviaQA dataset)(comprehension datasets, Part-of, DuoRC dataset)(comprehension datasets, Evaluate-for, question generation for reading comprehension)(comprehension datasets, Is-a-Prerequisite-of, neural approaches in language understanding)(comprehension datasets, Evaluate-for, evaluation of story comprehension and script learning)
(model semantic parsing,Is-a-Prerequisite-of,natural language descriptions)(model semantic parsing,Used-for,generating semantic representations)(model semantic parsing,Evaluate-for,automated keyphrase extraction)(model semantic parsing,Used-for,learning a classifier)(model semantic parsing,Is-a-Prerequisite-of,improving semantic parsing performance)(model semantic parsing,Is-a-Prerequisite-of,neural architecture)(model semantic parsing,Is-a-Prerequisite-of,neural semantic parsers)
(concept, Evaluate-for, professional fact checker)
EMPTY G1.summarization system
EMPTY G1.adversarial purification
EMPTY G1.self attentive parser
EMPTY G1.language model lm
EMPTY G1.hate speech detection model
1. (Automated evaluation, Evaluate-for, argument generation)2. (Argument invention, Evaluate-for, argument generation)3. (Argument generation, Used-for, discourse modes)4. (Argument generation, Evaluate-for, automatic essay scoring)5. (Argument generation, Evaluate-for, machine-generated poems)6. (Argument generation, Used-for, corrective REs generation)7. (Argument generation, Part-of, Paraphrase-50M dataset)8. (Argument generation, Compare, response generation)9. (Argument generation, Evaluate-for, open-domain dialog systems)10. (Argument generation, Part-of, summarization model)11. (Argument generation, Part-of, neural machine translation)12. (Argument generation, Evaluate-for, paraphrase generation)13. (Argument generation, Is-a-Prerequisite-of, abstractive question answering)14. (Argument generation, Evaluate-for, sentence-level supporting argument detection)15. (Argument generation, Is-a-Prerequisite-of, dialog systems)16. (Argument generation, Part-of, recurrent neural networks)17. (Argument generation, Evaluate-for, text similarity measures)18. (Argument generation, Is-a-Prerequisite-of, natural language understanding tasks)19. (Argument generation, Used-for, identifying abnormalities in medical images)20. (Argument generation, Compare, question generation)
EMPTY G1.graph embedding
EMPTY G1.based explanation
EMPTY G1.vision language
(dependency parser, Compare, sequence tagging)(dependency parser, Part-of, end-to-end computational argumentation mining)(dependency parser, Compare, dependency parsing)(dependency parser, Is-a-Prerequisite-of, multi-task learning setup)(dependency parser, Compare, transition-based parser)(dependency parser, Evaluate-for, State-of-the-art performance)
EMPTY G1.conversational corpus
(event knowledge,Is-a-Prerequisite-of,machine reading)(recurrent neural tensor,Used-for,machine reading)(machine reading,Evaluate-for,KBLSTM)(training neural network,Used-for,machine reading)(information retrieval,Evaluate-for,machine reading)(mneural machine translation,Used-for,machine reading)(layer-wise relevance propagation,Used-for,machine reading)
EMPTY G1.contemporary language model
EMPTY G1.predict sentiment
(task sentiment classification,Is-a-Prerequisite-of,Natural Language Processing)(task sentiment classification,Evaluate-for,Sentence Classification)
EMPTY G1.news summarization
EMPTY G1.parser trained
(adversarial sample, Used-for, neural classifier)
(better language, Evaluate-for, perplexity experiments)
(Neural Machine Translation,Is-a-Prerequisite-of,machine translation nmt model)(machine translation nmt model,Conjunction,layer-wise relevance propagation)
EMPTY G1.multi lingual
EMPTY G1.aspect level sentiment classification
(language generation nlg system, Used-for, natural language understanding)(language generation nlg system, Evaluate-for, content correctness)(natural language understanding systems, Is-a-Prerequisite-of, language generation nlg system)
(story ending generation, Is-a-Prerequisite-of, sentiment intensity control)  (story ending generation, Part-of, natural language generation)
(dialogue generation,Used-for,neural knowledge diffusion)(dialogue generation,Is-a-Prerequisite-of,task-completion dialogue agent)(dialogue generation,Compare,end-to-end neural dialogue generation)(dialogue generation,Evaluate-for,task success rate)(dialogue generation,Evaluate-for,reward)(dialogue generation,Evaluate-for,quality of dialogue responses)
EMPTY G1.translation task demonstrate
EMPTY G1.supervised ner
EMPTY G1.multi document summarization
EMPTY G1.bias mention
(zero shot cross lingual, Compare, cross-lingual OpenQA)(zero shot cross lingual, Compare, cross-lingual syntactic variation)(zero shot cross lingual, Compare, cross-lingual knowledge graph alignment)(zero shot cross lingual, Compare, abstractive sentence summarization)(zero shot cross lingual, Compare, cross-lingual document retrieval performance)(zero shot cross lingual, Compare, cross-lingual lexical entailment)(Multilingual BERT, Evaluate-for, zero shot cross lingual)
EMPTY G1.multi modal sarcasm detection
EMPTY G1.document level sentiment
EMPTY G1.dialogue agent
EMPTY G1.supervised relation
(conversational agents, Compare, automatic dialogue evaluation)(automatic dialogue evaluation, Evaluate-for, human judgments)(automatic dialogue evaluation, Compare, word-overlap metrics)(automatic dialogue evaluation, Is-a-Prerequisite-of, dialogue research)(automatic dialogue evaluation, Compare, self-reported user rating)(dialogue research, Is-a-Prerequisite-of, automatic dialogue evaluation)(automatic dialogue evaluation, Used-for, rapid prototyping and testing)(dialogue systems, Part-of, automatic dialogue evaluation)(automatic dialogue evaluation, Used-for, evaluating dialogue models)(automatic dialogue evaluation, Compare, human evaluation)(automatic dialogue evaluation, Compare, human judgment)(evaluation model, Is-a-Prerequisite-of, automatic dialogue evaluation)
EMPTY G1.aspect term extraction
EMPTY G1.fact checked claim
EMPTY G1.domain sentiment lexicon
1. (explainability method, Is-a-Prerequisite-of, machine learning models)2. (explainability method, Evaluate-for, interpretability of ML based question answering models)3. (explainability method, Compare, attention mechanism)4. (explainability method, Used-for, evaluating ML models)5. (explainability method, Is-a-Prerequisite-of, post hoc explanation methods)
EMPTY G1.question dataset
(joint entity relation extraction, Used-for, identifying relations between pairs of entity mentions)(joint entity relation extraction, Used-for, identifying relations between pairs of entity mentions)(joint entity relation extraction, Part-of, entity spans)(joint entity relation extraction, Is-a-Prerequisite-of, relation extraction)(joint entity relation extraction, Used-for, GraphRel)(GraphRel, Used-for, joint entity relation extraction)
EMPTY G1.debate topic expansion
(semantic parser, Evaluate-for, generating natural language)(semantic parser, Is-a-Prerequisite-of, generating natural language)(COREQA, Evaluate-for, generating natural language)(neural language model, Used-for, generating natural language)(algorithm, Evaluate-for, generating natural language)(text similarity measure, Is-a-Prerequisite-of, generating natural language)
(question, Is-a-Prerequisite-of, question answering system)(natural language text, Used-for, question answering system)(reading comprehension datasets, Is-a-Prerequisite-of, question answering system)(question answering system, Used-for, generating natural answers)(COREQA, Is-a-Prerequisite-of, question answering system)(question answering system, Is-a-Prerequisite-of, generating correct answers)(question answering system, Is-a-Prerequisite-of, generating coherent answers)(question answering system, Used-for, COREQA)(question answering system, Is-a-Prerequisite-of, question representation)(task question answering, Part-of, question answering system)
EMPTY G1.open domain question answering
(image text pair, Is-a-Prerequisite-of, sentiment calibrating)
EMPTY G1.question answering dataset
(pre trained language, Used-for, natural language understanding)(pre trained language, Part-of, semantic parser)
EMPTY G1.aspect level sentiment
1. (controllable text generation, Conjunction, emotion-controllable response generation)2. (controllable text generation, Evaluate-for, emotion expression)3. (controllable text generation, Is-a-Prerequisite-of, content consistency)4. (controllable text generation, Compare, sequence modeling)5. (controllable text generation, Compare, Conditional Text Generation)6. (controllable text generation, Is-a-Prerequisite-of, Pre-train and Plug-in Variational Auto-Encoder)7. (controllable text generation, Evaluate-for, diverse but less training effort)
(speech text translation, Is-a-Prerequisite-of, speech translation)(speech text translation, Part-of, end-to-end model)(speech text translation, Evaluate-for, translation quality improvement)(speech text translation, Used-for, trade)(speech text translation, Used-for, law)(speech text translation, Used-for, commerce)(speech text translation, Used-for, politics)(speech text translation, Used-for, literature)(speech text translation, Part-of, natural language processing)(speech text translation, Part-of, neural machine translation)
- (language generation, Compare, style transfer)- (language generation, Evaluate-for, sentiment preservation)- (generated text, Used-for, language generation)
EMPTY G1.improve translation
(conversation partners, Has-role, interlocutors)  (KB-InfoBot, Used-for, dialogue data)  (human power, Affects, linguistic alignment)  (neural architechture, Used-for, dialogue Act classification)  (Dialogue State Tracker, Is-a-Prerequisite-of, task-oriented dialogue systems)
EMPTY G1.learns event
(dependency parsing, Used-for, semantic dependency parsing)(dependency parsing, Is-a-Prerequisite-of, semantic dependency parsing)(semantic analysis, Used-for, semantic dependency parsing)(end-to-end dependency parsing, Used-for, semantic dependency parsing)(neural networks, Used-for, semantic dependency parsing)(semantic dependency parsing, Compare, tree-based models)(semantic dependency parsing, Is-a-Prerequisite-of, semantic graph parsing)(semantic dependency parsing, Is-a-Prerequisite-of, semantic relation)(parser, Evaluate-for, semantic dependency parsing)
(discourse relation, Compare, event coreference)(discourse relation, Compare, causal relations)(discourse relation, Evaluate-for, joint modeling)(discourse relation, Evaluate-for, coherence measurement)(discourse relation, Used-for, discourse analysis)(discourse relation, Conjunction, temporal relations)(discourse relation, Conjunction, causal relations)
EMPTY G1.knowledge inference
(data text generation model, Used-for, code generation)(data text generation model, Used-for, semantic parsing)(data text generation model, Compare, neural network architectures)(data text generation model, Compare, representation learning)(data text generation model, Evaluate-for, structured outputs)(data text generation model, Evaluate-for, semantic relevance)(data text generation model, Is-a-Prerequisite-of, end-to-end training)(data text generation model, Is-a-Prerequisite-of, data-to-text generation)(data text generation model, Is-a-Prerequisite-of, synthesis of abstract syntax networks)(data text generation model, Is-a-Prerequisite-of, entity-centric neural architecture)(abstract syntax networks, Is-a-Prerequisite-of, data text generation model)(entity-centric neural architecture, Compare, data text generation model)
EMPTY G1.percentage point ibm debater
(morphological paradigm, Is-a-Prerequisite-of, morphological analysis)(morphological paradigm, Evaluate-for, unsupervised morphological analysis)(morphological paradigm, Is-a-Prerequisite-of, morphological disambiguation)(morphological paradigm, Part-of, morphological tagging)(morphological paradigm, Is-a-Prerequisite-of, morphological regularization)
(large language model, Is-a-Prerequisite-of, dialogue state tracking)(morphological inflection, Is-a-Prerequisite-of, dialogue state tracking)(Global-Locally Self-Attentive Dialogue State Tracker, Is-a-Prerequisite-of, dialogue state tracking)(dialogue state tracking, Compare, belief tracker)(spoken dialogue system, Part-of, dialogue state tracking)(dialogue state tracking, Used-for, task-oriented dialogue systems)(natural language understanding, Used-for, dialogue state tracking)(entity representation, Part-of, dialogue state tracking)(entity representation, Used-for, dialogue state tracking)
EMPTY G1.event relation
EMPTY G1.non contextual subword embeddings
EMPTY G1.level sentiment classification
(text to speech generation,Is-a-Prerequisite-of,natural language generation)(neural text generation,Compare,natural language generation)(story ending generation,Part-of,natural language generation)(model,Used-for,natural language generation)(generate,Is-a-Prerequisite-of,natural language generation)(text similarity measure,Compare,natural language generation)(COREQA,Evaluate-for,natural language generation)(language model,Used-for,natural language generation)(natural language generation,Conjunction,sentiment intensity control)(natural language generation,Conjunction,subjective responses)(natural language generation,Conjunction,data-driven architecture)(natural language generation,Is-a-Prerequisite-of,semantic parsing)(natural language generation,Evaluate-for,response generation)(natural language generation,Used-for,generating human-like subjective responses)(natural language generation,Is-a-Prerequisite-of,end-to-end question answering systems)(natural language generation,Evaluate-for,question answering)
EMPTY G1.language model downstream task
EMPTY G1.distributional semantics
(neural text generation, Used-for, abstractive summarization)(neural text generation, Compare, sentence summarization using neural models)(neural text generation, Compare, abstractive document summarization)(neural text generation, Evaluate-for, abstractive document summarization)(neural text generation, Compare, natural language generation)(neural text generation, Is-a-Prerequisite-of, abstractive summarization)(dialog systems, Compare, neural text generation)(neural text generation, Compare, pre-trained language models)(neural text generation, Evaluate-for, performance improvement)(neural text generation, Part-of, transformers architecture)(neural text generation, Is-a-Prerequisite-of, text summarization models)
EMPTY G1.aspect sentiment
EMPTY G1.speech translation e2e st
EMPTY G1.word embeddings build
(context sensitive embeddings, Used-for, sequence labeling tasks)(context sensitive embeddings, Evaluate-for, NLP systems)(context sensitive embeddings, Part-of, deep neural network architecture)(context sensitive embeddings, Evaluate-for, PP attachment model)(context sensitive embeddings, Used-for, predicting prepositional phrase attachments)(context sensitive embeddings, Compare, word vectors)(context sensitive embeddings, Evaluate-for, sentiment classification)(context sensitive embeddings, Evaluate-for, sentiment-aware word embeddings)(context sensitive embeddings, Used-for, capturing stylistic similarity)(context sensitive embeddings, Compare, sentence embeddings)(context sensitive embeddings, Evaluate-for, sentence embeddings)(context sensitive embeddings, Is-a-Prerequisite-of, sentence embeddings)(context sensitive embeddings, Used-for, sentiment polarity classification)(context sensitive embeddings, Used-for, Word Sense Disambiguation)(context sensitive embeddings, Used-for, machine reading comprehension models)
EMPTY G1.nli model
EMPTY G1.improves adversarial robustness
EMPTY G1.domain learning
(flat NER, Is-a-Prerequisite-of, nested named entity)(machine reading comprehension, Evaluate-for, nested named entity)(Bidirectional LSTM, Used-for, nested named entity)(graph convolutional network, Used-for, nested named entity)
EMPTY G1.approach visual question answering
EMPTY G1.automatic argument generation
EMPTY G1.neural machine translation model
EMPTY G1.human attention keyphrase extraction
EMPTY G1.speech translation e2e
EMPTY G1.shot learning
EMPTY G1.category opinion sentiment
EMPTY G1.lingual word embeddings
EMPTY G1.free text relation
EMPTY G1.textual similarity sts task
EMPTY G1.speech translation s2st
EMPTY G1.semantic role labeling srl
(chain thought prompting, Used-for, improving reasoning capabilities)(chain thought prompting, Used-for, transferring reasoning capabilities)(chain thought prompting, Is-a-Prerequisite-of, improving task performance)(chain thought prompting, Used-for, incorporating external tools)(chain thought prompting, Part-of, MultiTool-CoT framework)(chain thought prompting, Evaluate-for, improving state-of-the-art performance)
EMPTY G1.unsupervised constituency parsing
EMPTY G1.domain question answering qa
EMPTY G1.cross lingual transfer
EMPTY G1.embeddings represent word
(source text, Evaluate-for, summary generation)(Automatic generation of image descriptions, Used-for, summary generation)(Style transfer, Evaluate-for, summary generation)(Automatic topic-to-essay generation, Is-a-Prerequisite-of, summary generation)(Automatic argument generation, Evaluate-for, summary generation)(Structured query generation, Is-a-Prerequisite-of, summary generation)(Sequence-to-sequence model, Is-a-Prerequisite-of, summary generation)
EMPTY G1.text generation text style
EMPTY G1.entity recognition relation extraction
(dialog datasets, Evaluate-for, performance)
1. (visually grounded language, Used-for, image grounding)2. (visually grounded language, Evaluate-for, multi-hop reasoning)3. (visually grounded language, Is-a-Prerequisite-of, natural language navigation)4. (image grounding, Part-of, visually grounded language)
EMPTY G1.unintended bias text
(continual relation extraction, Compare, relation extraction)(continual relation extraction, Evaluate-for, noise reduction)(relation extraction, Is-a-Prerequisite-of, continual relation extraction)(concept, Evaluate-for, continual relation extraction)(continual relation extraction, Is-a-Prerequisite-of, relation extraction)
EMPTY G1.neural semantic
EMPTY G1.generated summary
(level event argument extraction, Is-a-Prerequisite-of, document-level event extraction)(level event argument extraction, Is-a-Prerequisite-of, event argument extraction)(level event argument extraction, Is-a-Prerequisite-of, sentence-level event argument extraction)
- (general sentiment analysis, Compare, aspect based sentiment analysis)- (aspect based sentiment analysis, Evaluate-for, aspect extraction)
(neural dialogue generation, Used-for, knowledge diffusion)(neural dialogue generation, Compare, end-to-end neural dialogue generation)
(entity relation extraction, Used-for, relation extraction)(relation extraction, Compare, entity relation extraction)(entity relation extraction, Evaluate-for, downstream tasks)(entity relation extraction, Evaluate-for, relation classification)
(linguistically diverse conversational corpus, Used-for, Computational linguistics)(linguistically diverse conversational corpus, Used-for, Language technology)(linguistically diverse conversational corpus, Part-of, Interactional data)
EMPTY G1.political debate 50 year
EMPTY G1.natural language explanation prediction
EMPTY G1.text generation model
(deep latent variable models, Evaluate-for, response generation)(response generation, Compare, template-based summarization)(concept, Used-for, response generation)(latent variable model, Is-a-Prerequisite-of, response generation)(seq2seq, Is-a-Prerequisite-of, response generation)(sentence generation, Evaluate-for, response generation)(response generation, Hyponym-Of, machine translation)(argument generation, Compare, response generation)(response generation, Used-for, dialog systems)(response generation, Compare, iterative training process)(response generation, Used-for, boosting method)(response generation, Used-for, sequence-to-sequence architecture)(response generation, Evaluate-for, diversity of responses)(response generation, Evaluate-for, relevance of responses)(response generation, Part-of, abstractive summarization)(response generation, Is-a-Prerequisite-of, interpretability of responses)(response generation, Compare, NeuralREG model)(response generation, Compare, Spatio-Temporal Matching network)(response generation, Used-for, multi-task learning)(dialogue model, Evaluate-for, response generation)(natural language generation, Evaluate-for, response generation)(dialogue modeling, Evaluate-for, response generation)(response generation, Is-a-Prerequisite-of, human generates responses)(response generation, Used-for, interpretable response generation)
(trained language model,Is-a-Prerequisite-of,automatic generation)(trained language model,Used-for,poetry generation)(trained language model,Compare,generative neural language model)(trained language model,Is-a-Prerequisite-of,parsing and language modeling)(trained language model,Is-a-Prerequisite-of,hierarchical attention network)(trained language model,Part-of,neural language models)(trained language model,Part-of,recurrent neural network grammars)(trained language model,Is-a-Prerequisite-of,recurrent neural networks)(trained language model,Is-a-Prerequisite-of,recurrent neural tensor networks)(trained language model,Used-for,text classification)
EMPTY G1.binomial neural topic model
EMPTY G1.question answering model
(pretrained multilingual, Used-for, enhancing language understanding)
(neural machine translation, Evaluate-for, translation quality)
(relation prediction,Is-a-Prerequisite-of,relation extraction)  (relation detection,Is-a-Prerequisite-of,relation prediction)  
(event argument extraction eae,Is-a-Prerequisite-of,Frame-aware Event Argument Extraction)(event argument extraction eae,Compare,Joint extraction of entities and relations from unstructured texts)(event argument extraction eae,Compare,Zero-shot cross-lingual event argument extraction)(event argument extraction eae,Compare,Few-shot Document-Level Event Argument Extraction)(event argument extraction eae,Used-for,Document-level event argument extraction)
EMPTY G1.reasoning task
(natural language explanation, Evaluate-for, NER)(human annotated explanation, Used-for, natural language explanation)(natural language explanation, Part-of, human annotated explainable causal reasoning dataset)(natural language explanation, Is-a-Prerequisite-of, generating QA pairs)(natural language explanation, Evaluate-for, providing plausible explanations)(natural language explanation, Compare, generated explanations)
EMPTY G1.recurrent neural tensor network
EMPTY G1.machine translation paper
EMPTY G1.crossmodal attention
EMPTY G1.contrastive visual semantic
(concept, relation, concept)(text classification task, Used-for, multi-task learning)(text classification task, Is-a-Prerequisite-of, feature extraction)(text classification task, Is-a-Prerequisite-of, shared knowledge transfer)(text classification task, Evaluate-for, performance improvement)(text classification task, Is-a-Prerequisite-of, cognitive NLP systems)
(neural language model, Compare, large language model)(neural language model, Evaluate-for, language model prediction)(neural language model, Used-for, document context)(neural language model, Evaluate-for, generation of conversational text)(neural language model, Compare, hierarchical LSTM language model)(neural language model, Evaluate-for, disfluency detection)(neural language model, Evaluate-for, LSTM Noisy Channel Model)(neural language model, Used-for, rhythmic poetry generation)(neural language model, Evaluate-for, representing the broader document context)(neural language model, Evaluate-for, learn common poetic devices)(neural language model, Used-for, generation of conversational text)(sequence-to-sequence model, Is-a-Prerequisite-of, neural language model)(neural language model, Is-a-Prerequisite-of, language model)(neural language model, Compare, character-level language models)(neural language model, Used-for, generating natural language)(neural language model, Used-for, generating rhythmic poetry)(neural language model, Used-for, constraint satisfaction problem)(neural language model, Used-for, generating coherent poetry)(neural language model, Used-for, generate rhythmic poetry)(neural language model, Evaluate-for, written by humans)(neural language model, Compare, Affect-LM)(neural language model, Evaluate-for, improve language model prediction)(neural language model, Evaluate-for, detect changes in source code)(neural
(biomedical entity linking, Compare, named entity recognition)(biomedical entity linking, Evaluate-for, BEL)(biomedical entity linking, Evaluate-for, domain-specific knowledge)(biomedical entity linking, Part-of, XL-BEL)(biomedical entity linking, Compare, neural entity linking models)(biomedical entity linking, Is-a-Prerequisite-of, neural entity linking models)
(document level event extraction, Evaluate-for, large scale data labeling)(document level event extraction, Used-for, automatically labeled data)(document level event extraction, Is-a-Prerequisite-of, event modeling)(document level event extraction, Part-of, document understanding)
EMPTY G1.sentiment classification asc
EMPTY G1.latent topic
EMPTY G1.aware news representation
EMPTY G1.generate sentence
(compositional distributional semantics, Is-a-Prerequisite-of, semantic relatedness)(compositional distributional semantics, Is-a-Prerequisite-of, entailment)(compositional distributional semantics, Evaluate-for, models)(compositional distributional semantics, Compare, Functional Distributional Semantics)(Functional Distributional Semantics, Evaluate-for, semantic relatedness)(Functional Distributional Semantics, Evaluate-for, entailment)(compositional distributional semantics, Used-for, prediction)
EMPTY G1.named entity
EMPTY G1.task oriented dialogue
(spoken dialogue system, Is-a-Prerequisite-of, belief tracker)(belief tracker, Part-of, spoken dialogue system)(spoken dialogue system, Evaluate-for, Global-Locally Self-Attentive Dialogue State Tracker)(spoken dialogue system, Part-of, dialogue state tracking)
(single document summarization,Is-a-Prerequisite-of,document modeling)(document modeling,Used-for,summarization)(document modeling,Used-for,extractive summarization)(document modeling,Used-for,answer selection)(document modeling,Used-for,event detection)(document modeling,Compare,numerical modeling)(document modeling,Compare,question answering)(document modeling,Compare,text matching)(document modeling,Is-a-Prerequisite-of,abstractive summarization)(document modeling,Is-a-Prerequisite-of,document-level information)(document modeling,Is-a-Prerequisite-of,coreference resolution)(document modeling,Is-a-Prerequisite-of,roll-call prediction)(document modeling,Is-a-Prerequisite-of,coreference resolution)(language understanding,Used-for,document modeling)(sentence generation,Evaluate-for,document modeling)
EMPTY G1.multi party dialogue
EMPTY G1.domain sentiment
EMPTY G1.oriented dialogue summarization
(recurrent neural, Compare, traditional models)(recurrent neural, Compare, diverse models)
EMPTY G1.bias text
(level language modeling,Used-for,modeling sentences)(level language modeling,Is-a-Prerequisite-of,sentence level)(level language modeling,Part-of,generative neural language model)(level language modeling,Part-of,LSTM model)(LSTM model,Is-a-Prerequisite-of,level language modeling)
EMPTY G1.multilingual representation
(textual adversarial, Evaluate-for, adversarial attack)(textual adversarial, Used-for, generating adversarial examples)(textual adversarial, Is-a-Prerequisite-of, text adversarial attack)
(topic model,Used-for,text classification)(text classification,Is-a-Prerequisite-of,topic model)(event extraction,Used-for,text classification)(text classification,Used-for,multi-task learning)(text classification,Is-a-Prerequisite-of,sentiment analysis)(text classification,Used-for,sarcasm detection)(text classification,Is-a-Prerequisite-of,dialogue act classification)(text classification,Is-a-Prerequisite-of,Cross-lingual text classification)(text classification,Part-of,neural network models)(text classification,Evaluate-for,document classification)(sentiment classification,Compare,text classification)(neive bayes,Evaluate-for,text classification)(word embeddings,Evaluate-for,text classification)(feature learning,Used-for,text classification)(text classification,Is-a-Prerequisite-of,feature learning)(adversarial attacks,Used-for,text classification)(textual adversarial attack,Evaluate-for,text classification)(trained language model,Used-for,text classification)(attention based explanation,Conjunction,text classification)
EMPTY G1.neural network interpretability bayesian
EMPTY G1.end end relation extraction
(long short term memory, Used-for, sentiment classification)(long short term memory, Evaluate-for, sequence prediction)(long short term memory, Used-for, machine translation)(long short term memory, Hyponym-Of, neural network model)(long short term memory, Hyponym-Of, LSTM language model)(long short term memory, Part-of, Tree Long Short-Term Memory Networks)(long short term memory, Part-of, syntax-infused variational autoencoder)(long short term memory, Evaluate-for, syntactic evaluation)(long short term memory, Evaluate-for, language model performance)
EMPTY G1.event commonsense evaluation
EMPTY G1.text generation task
EMPTY G1.cross lingual continual learning
EMPTY G1.lexical sememe prediction
(document-level relation extraction, Compare, sentence relation extraction)(relation extraction, Compare, sentence relation extraction)
EMPTY G1.speech translation model
EMPTY G1.pretrained language
(adversarially trained, Used-for, neural response generation)(adversarially trained, Is-a-Prerequisite-of, robustness of neural networks against adversarial input perturbations)
(EviNets, Evaluate-for, factoid question answering)(SAN, Evaluate-for, factoid question answering)(EviNets, Used-for, factoid question answering)(conversational QA tasks, Compare, factoid question answering)(RC problem on Stanford Question Answering Dataset, Evaluate-for, factoid question answering)(Generative Domain-Adaptive Nets, Used-for, factoid question answering)(Universal Schema, Is-a-Prerequisite-of, factoid question answering)(transfer learning technique, Compare, factoid question answering)(end-to-end neural dialogue generation, Used-for, factoid question answering)(hierarchical attention network for reading comprehension-style QA, Evaluate-for, factoid question answering)(recurrent neural network, Evaluate-for, factoid question answering)
EMPTY G1.named entity disambiguation
EMPTY G1.topic distribution
EMPTY G1.pretraining language
(sequence labeling model,Evaluate-for,entity recognition)(sequence labeling model,Is-a-Prerequisite-of,entity recognition)(argument mining,Is-a-Prerequisite-of,entity recognition)(entity recognition,Compare,relation extraction)(gazetteers,Used-for,entity recognition)
EMPTY G1.translation task
EMPTY G1.automatic fake news
(Conditional Random Fields, Evaluate-for, aspect extraction)(aspect based sentiment analysis, Evaluate-for, aspect extraction)(aspect-based sentiment analysis, Is-a-Prerequisite-of, aspect extraction)(domain-specific embeddings, Part-of, aspect extraction)(domain-specific embeddings, Used-for, aspect extraction)(aspect extraction, Used-for, aspect-based sentiment analysis)(aspect extraction, Evaluate-for, coherence improvement)
(generated text, Evaluate-for, Semantic Relevance Based neural model)(generated text, Is-a-Prerequisite-of, model generations)(generated text, Used-for, language generation)(generated text, Compare, human-generated text)
EMPTY G1.neural language model lm
EMPTY G1.lingual embeddings
EMPTY G1.multilingual neural machine
EMPTY G1.dialogue summarization
(pretrained multilingual model, Used-for, natural language processing)(pretrained multilingual model, Compare, multilingual model)(natural language processing, Used-for, pretrained multilingual model)
(entity recognition multiple, Used-for, Gazetteers)(entity recognition multiple, Compare, gazetteers)(entity recognition multiple, Evaluate-for, machine learning)(entity recognition multiple, Is-a-Prerequisite-of, supervised learning)
(neural text classifier, Evaluate-for, make improvements)(neural text classifier, Evaluate-for, model interpretability)
(coherent paragraph summary, Compare, academic documents)(coherent paragraph summary, Compare, existing datasets)(coherent paragraph summary, Evaluate-for, human-evaluation)(coherent paragraph summary, Evaluate-for, readability)(coherent paragraph summary, Evaluate-for, world-knowledge)(coherent paragraph summary, Conjunction, how-to articles)
EMPTY G1.image text
EMPTY G1.multi modal datasets
(topic discovery,Used-for,natural language processing tasks)(topic discovery,Is-a-Prerequisite-of,document aggregation)(document aggregation,Is-a-Prerequisite-of,topic discovery)(topic discovery,Is-a-Prerequisite-of,keyphrase generation)(topic discovery,Used-for,uncovering supporting evidence)(topic discovery,Used-for,expanding intent classes)
(neural model, Used-for, semantic parsing)(neural model, Compare, LSTM language model)(neural model, Is-a-Prerequisite-of, Affect-LM)(neural model, Evaluate-for, market comments generation)(neural model, Hyponym-Of, memory augmented neural model)(neural model, Evaluate-for, language model perplexity)
(deep syntactic, Used-for, SRL performance)(deep syntactic, Part-of, abstract meaning representation)
EMPTY G1.word embeddings represent
(implicit opinions, Evaluate-for, aspect implicit opinion)
EMPTY G1.dialogue pre training
EMPTY G1.nlp task especially low
(language model like bert,Compare,recurrent neural networks)(language model like bert,Used-for,natural language processing)(language model like bert,Used-for,text generation)(language model like bert,Used-for,transfer learning)(language model like bert,Evaluate-for,perplexity measurement)(language model like bert,Evaluate-for,accuracy improvement)(language model like bert,Evaluate-for,disfluency detection)(language model like bert,Is-a-Prerequisite-of,sentiment classification model)(language model like bert,Is-a-Prerequisite-of,named entity recognition)(language model like bert,Is-a-Prerequisite-of,sequence labeling)(recurrent neural networks,Hyponym-Of,language model like bert)
(deep learning tool,Is-a-Prerequisite-of,automatic fake news detection)(automatic fake news detection,Used-for,fact-checking research)(automatic fake news detection,Evaluate-for,surface-level linguistic patterns)(automatic fake news detection,Compare,conventional neural network)(automatic fake news detection,Used-for,style analysis)
(approach, Evaluate-for, named entity recognition ner)(NER models, Is-a-Prerequisite-of, named entity recognition ner)
EMPTY G1.parsing idea treebank embedding
1. (`concept`, Is-a-Prerequisite-of, fact checking model)2. (fact checking model, Is-a-Prerequisite-of, state-of-the-art algorithms)3. (fact checking model, Used-for, veracity prediction)4. (Claim matching, Is-a-Prerequisite-of, fact checking model)5. (Claim verification, Part-of, fact checking model)6. (supporting evidence, Is-a-Prerequisite-of, fact checking model)7. (fact checking model, Evaluate-for, claim veracity)
EMPTY G1.generating summary
(language technology,Used-for,promoting multilingualism and linguistic diversity)(language technology,Evaluate-for,develop and improve NLP systems)(language technology,Conjunction,natural language processing)(language technology,Is-a-Prerequisite-of,building language models)(language technology,Part-of,computational linguistics)(language technology,Conjunction,machine translation)(language technology,Evaluate-for,expanding language diversity in NLP systems)(language technology,Used-for,developing automated syntactic parsing tools)(language technology,Is-a-Prerequisite-of,accurate language recognition)
EMPTY G1.seq2seq text generation
EMPTY G1.vision language model
EMPTY G1.neural network rnns
EMPTY G1.cross domain sentiment
EMPTY G1.identifiability attention
(dialogue model, Compare, generative models)(dialogue model, Evaluate-for, response generation)(dialogue model, Compare, recurrent models)(dialogue model, Is-a-Prerequisite-of, generative responses)(dialogue model, Used-for, interpretable response generation)
EMPTY G1.language model plms
EMPTY G1.embedding model
(language understanding, Conjunction, reading comprehension)(spelling correction, Is-a-Prerequisite-of, language understanding)(spelling correction, Compare, language understanding)(Chinese Spelling Correction, Is-a-Prerequisite-of, language understanding)(training neural network, Used-for, language understanding)(topic model, Used-for, language understanding)(neural symbolic machine, Used-for, language understanding)(language understanding, Compare, natural language understanding)(language understanding, Used-for, understanding spoken dialogue systems)(language understanding, Used-for, sentiment analysis)(language understanding, Used-for, action recognition)(language understanding, Used-for, document modeling)(language understanding, Is-a-Prerequisite-of, symbolic reasoning)(language understanding, Is-a-Prerequisite-of, language unseen pretraining)(pretraining, Evaluate-for, language understanding)(neural network, Evaluate-for, language understanding)
1. (argument generation, Evaluate-for, paraphrase generation)2. (paraphrasing, Used-for, paraphrase generation)
EMPTY G1.unsupervised bilingual word
EMPTY G1.aspect based sentiment
EMPTY G1.bias nlp
EMPTY G1.classification task
(multilingual model, Used-for, language classification)(multilingual model, Compare, named entity recognition)(multilingual model, Compare, part-of-speech tagging)(multilingual model, Is-a-Prerequisite-of, natural language generation task)(multilingual model, Compare, natural language processing)(multilingual model, Evaluate-for, low-resource settings)(multilingual model, Used-for, parsing natural language sentences)(multilingual model, Compare, neural machine translation models)(multilingual model, Is-a-Prerequisite-of, multilingual learning)(multilingual model, Used-for, multilingual distributed representations)(multilingual model, Compare, multilingual neural machine translation)(multilingual model, Part-of, cross-lingual embeddings)(multilingual model, Compare, contextual representation for NLP)(multilingual model, Is-a-Prerequisite-of, multilingual digital helpdesk service)(multilingual model, Compare, multilingual coreference model)
(generation semantic parsing, Used-for, code generation)(code generation, Is-a-Prerequisite-of, generation semantic parsing)(generation semantic parsing, Evaluate-for, structured logical forms)(structured logical forms, Evaluate-for, generation semantic parsing)
EMPTY G1.lingual openqa
EMPTY G1.chinese word segmentation cws
EMPTY G1.unsupervised parsing
(AMR, Is-a-Prerequisite-of, linguistic representation)
EMPTY G1.argument extraction eae
EMPTY G1.orthography morphological feature lexicalized
EMPTY G1.unsupervised semantic parsing
EMPTY G1.free text rationale
EMPTY G1.video question answering
(con-text,Is-a-Prerequisite-of,generative neural language model)(con-text,Part-of,improving accuracy on different sequence labeling tasks)(con-text,Conjunction,Affect-LM)(con-text,Compare,traditional training of RNNs using back-propagation through time)(con-text,Evaluate-for,language model prediction)(con-text,Used-for,automatic generation of rhythmic poetry)(con-text,Evaluate-for,effectiveness of generated poems)
EMPTY G1.nlp task especially
(conceptualized word embeddings, Used-for, open-domain argument search)(conceptualized word embeddings, Used-for, argument classification)(conceptualized word embeddings, Used-for, argument clustering)(fastText, Is-a-Prerequisite-of, conceptualized word embeddings)(conceptualized word embeddings, Used-for, affect dimension capture)(conceptualized word embeddings, Evaluate-for, examining gender portrayals)(conceptualized word embeddings, Used-for, argument search)(conceptualized word embeddings, Compare, non-contextual subword embeddings)(non-contextual subword embeddings, Compare, conceptualized word embeddings)(argument search, Evaluate-for, conceptualized word embeddings)
(concept: lingual transfer, relation: Used-for, concept: improve the accuracy of low-resource task language)(concept: lingual transfer, relation: Is-a-Prerequisite-of, concept: availability of parallel texts)(concept: lingual transfer, relation: Evaluate-for, concept: improved semantic parsing results)
(natural language processing, Used-for, sentiment classification)(sentiment classification, Compare, text classification)(CNN, Used-for, sentiment classification)(Model, Is-a-Prerequisite-of, sentiment classification)(FST, Is-a-Prerequisite-of, sentiment classification)(linguistic knowledge identification, Evaluate-for, sentiment classification)(sentiment classification, Compare, sentiment analysis)(word distributions, Evaluate-for, sentiment classification)(context sensitive embeddings, Evaluate-for, sentiment classification)(sentiment classification, Used-for, text classification tasks)(sentiment classification, Evaluate-for, sentiment polarity)(sentiment classification, Evaluate-for, sarcasm detection)(sentiment classification, Evaluate-for, argument mining)(sentiment classification, Evaluate-for, domain adaptation)(sentiment classification, Is-a-Prerequisite-of, aspect sentiment classification)(long short term memory, Used-for, sentiment classification)(NLP, Evaluate-for, sentiment classification)(conditional language model, Is-a-Prerequisite-of, sentiment classification)(concept, Evaluate-for, sentiment classification)(embedding models, Evaluate-for, sentiment classification)(opinion entity extraction, Evaluate-for, sentiment classification)
(chinese spelling correction, Compare, spelling correction)(chinese spelling correction, Evaluate-for, Spelling Check)(chinese spelling correction, Is-a-Prerequisite-of, language understanding ability)(chinese spelling correction, Used-for, Chinese texts)(chinese spelling correction, Compare, Language model)(chinese spelling correction, Is-a-Prerequisite-of, error model)(chinese spelling correction, Compare, Textual information)(chinese spelling correction, Is-a-Prerequisite-of, phonetic information)(chinese spelling correction, Is-a-Prerequisite-of, semantic information)(chinese spelling correction, Used-for, neural networks)(chinese spelling correction, Evaluate-for, spell checking)
EMPTY G1.task word segmentation
EMPTY G1.language vision
(generative language model, Used-for, poetry generation)(generative language model, Evaluate-for, machine-generated poems)(generative language model, Used-for, language modeling)(generative language model, Evaluate-for, code generation)(generative language model, Used-for, automated essay scoring)
(monolingual embeddings, Compare, multilingual pre-trained)(monolingual embeddings, Concept, N/A)
EMPTY G1.embeddings domain specific embeddings
EMPTY G1.stanford question answering
EMPTY G1.domain question answering
(learning morphological, Used-for, low-resource languages)(learning morphological, Evaluate-for, morphological analysis)
EMPTY G1.generalization semantic parsing
EMPTY G1.improve summarization system
EMPTY G1.cross lingual dependency parsing
EMPTY G1.outperform strong baseline dialogue
EMPTY G1.improves adversarial
(textual adversarial attack, Used-for, generating adversarial examples)(textual adversarial attack, Evaluate-for, impact on deep neural networks)(textual adversarial attack, Is-a-Prerequisite-of, generating stable attacks)(textual adversarial attack, Evaluate-for, text classification)(textual adversarial attack, Evaluate-for, neural machine translation)(textual adversarial attack, Evaluate-for, NLP systems)(textual adversarial attack, Is-a-Prerequisite-of, generating adversarial perturbations)(textual adversarial attack, Is-a-Prerequisite-of, robust NLP models)(textual adversarial attack, Evaluate-for, adversarial attacks on NMT)(textual adversarial attack, Evaluate-for, adversarial attacks on text classification)(textual adversarial attack, Evaluate-for, neural-based system vulnerabilities)
EMPTY G1.entity embeddings
(dialogue system, Is-a-Prerequisite-of, Neural Belief Tracking)(dialogue system, Is-a-Prerequisite-of, End-to-end learning of recurrent neural networks (RNNs))(dialogue system, Is-a-Prerequisite-of, Query-based summarization)(dialogue system, Used-for, task-oriented spoken dialogue systems)(dialogue system, Used-for, open-domain non-task-oriented dialogue systems)(dialogue system, Is-a-Prerequisite-of, Taylors law)(dialogue system, Hyponym-Of, task-oriented dialogue systems)(dialogue system, Evaluate-for, achieving the goal in collaborative dialogue setting)(end-to-end dialogue system, Part-of, dialogue system)(dialogue system, Is-a-Prerequisite-of, goal-oriented visual dialogue)
(multilingual masked language modeling, Compare, BERT)(multilingual masked language modeling, Compare, Multilingual BERT)(multilingual masked language modeling, Is-a-Prerequisite-of, Multilingual language modeling)(multilingual masked language modeling, Compare, Transformer model)(multilingual masked language modeling, Compare, Language understanding tasks)(multilingual masked language modeling, Part-of, Multilingual models)(multilingual masked language modeling, Is-a-Prerequisite-of, Cross-lingual transfer)
EMPTY G1.shot text classification
(interactive semantic parsing, Compare, semantic parsing)(interactive semantic parsing, Part-of, semantic parsing)
(machine reading comprehension, Evaluate-for, nested named entity)(reading comprehension, Part-of, machine reading comprehension)(relation extraction, Is-a-Prerequisite-of, machine reading comprehension)
EMPTY G1.language model downstream
1. (neural networks, Compare, discourse structure)2. (Rhetorical Structure Theory, Is-a-Prerequisite-of, discourse structure)3. (discourse parser, Used-for, discourse structure)
EMPTY G1.natural language generation nlg
(conversational machine reading, Used-for, answer user questions)(conversational machine reading, Evaluate-for, user question answering accuracy)(conversational machine reading, Is-a-Prerequisite-of, asking clarification questions)(conversational machine reading, Compare, existing approaches)(conversational machine reading, Compare, decision making strategies)(conversational machine reading, Part-of, conversational AI system)(conversational machine reading, Conjunction, user questions and clarification questions)(conversational machine reading, Part-of, neural machine translation)(conversational machine reading, Conjunction, prior knowledge integration)(conversational machine reading, Evaluate-for, performance improvement)(conversational machine reading, Used-for, extracting decision rules)(conversational machine reading, Evaluate-for, state-of-the-art achievement)(conversational machine reading, Part-of, question answering model)(conversational machine reading, Is-a-Prerequisite-of, reason about conversation history)(conversational machine reading, Compare, response diversity generation)(conversational machine reading, Compare, linguistic prior integration)(conversational machine reading, Compare, training data diversification)
EMPTY G1.news representation
(coherent summary, Compare, generated headlines)(coherent summary, Compare, factual headlines)(coherent summary, Is-a-Prerequisite-of, stylistic headlines)(coherent summary, Evaluate-for, salient information)(coherent summary, Evaluate-for, cross-document relations)
(task natural language generation, Evaluate-for, Neural semantic parser)
(visual semantic pretraining,Compare,contrastive visual semantic pretraining)(contrastive visual semantic pretraining,Is-a-Prerequisite-of,mitigating anisotropy)(contrastive visual semantic pretraining,Compare,GPT-2)(contrastive visual semantic pretraining,Compare,CLIP)(contrastive visual semantic pretraining,Evaluate-for,mitigates anisotropy in contextualized word embeddings from GPT-2)(contrastive visual semantic pretraining,Evaluate-for,significantly improves performance on word-level semantic intrinsic evaluation tasks)
(orthography morphological feature, Compare, lexicalized forms)
EMPTY G1.generate coherent informative comment
(emotion detection, Used-for, hate detection)(deep learning models, Used-for, hate detection)
EMPTY G1.word embeddings according
(text summarization,Is-a-Prerequisite-of,extractive summarization)(text summarization,Compare,extractive summarization)(summarization model,Compare,extractive summarization)(SWAP-NET,Used-for,extractive summarization)(extractive summarization,Compare,abstractive summarization)(extractive summarization,Is-a-Prerequisite-of,sequence-to-sequence models)(extractive summarization,Used-for,sentence scoring)(extractive summarization,Is-a-Prerequisite-of,sentence selection)(planning,Is-a-Prerequisite-of,extractive summarization)(neural summarization,Evaluate-for,extractive summarization)(SWAP-NET,Is-a-Prerequisite-of,extractive summarization)(end-to-end neural network framework,Is-a-Prerequisite-of,extractive summarization)(document modeling,Used-for,extractive summarization)(summarization,Is-a-Prerequisite-of,extractive summarization)(abstractive summarization,Compare,extractive summarization)
(distributional semantics model, Compare, Functional Distributional Semantics)(distributional semantics model, Evaluate-for, downstream applications)(distributional semantics model, Compare, Pixie Autoencoder)(distributional semantics model, Evaluate-for, semantic similarity in context)
(satire detection, Part-of, automatic hate speech detection)(satire detection, Evaluate-for, sarcasm detection)(satire detection, Used-for, multimodal sarcasm detection)(satire detection, Compare, sarcasm detection)(satire detection, Is-a-Prerequisite-of, sarcasm detection)
EMPTY G1.trained language
EMPTY G1.multilingual pre
EMPTY G1.text generation text
1. (extractive summarization model, Used-for, sentence scoring)2. (extractive summarization model, Used-for, sentence selection)3. (extractive summarization model, Hyponym-Of, SWAP-NET)4. (extractive summarization model, Compare, abstractive summarization model)5. (extractive summarization model, Used-for, summarization)6. (extractive summarization model, Is-a-Prerequisite-of, neural network)
EMPTY G1.treebank embeddings
(neural machine translation, Is-a-Prerequisite-of, multilingual neural machine translation)
EMPTY G1.commonsense knowledge base
(textual adversarial, Evaluate-for, adversarial attack)(adversarial attack, Is-a-Prerequisite-of, adversarial training)
EMPTY G1.bias category
EMPTY G1.word embeddings represent word
(concept,Compare,abstractive summarization)  (concept,Hyponym-Of,abstractive summarization)  (concept,Part-of,abstractive summarization)  (neural text generation,Used-for,abstractive summarization)  (extractive summarization,Compare,abstractive summarization)  (document summarization,Is-a-Prerequisite-of,abstractive summarization)  (query-based summarization,Is-a-Prerequisite-of,abstractive summarization)  (machine translation,Part-of,abstractive summarization)  (model generated summary,Is-a-Prerequisite-of,abstractive summarization)  (caption generation,Hyponym-Of,abstractive summarization)  (neural summarization,Is-a-Prerequisite-of,abstractive summarization)  (graph-based framework,Is-a-Prerequisite-of,abstractive summarization)  (sentence generation,Part-of,abstractive summarization)  (response generation,Part-of,abstractive summarization)  (document modeling,Is-a-Prerequisite-of,abstractive summarization)  (generative hashing methods,Part-of,abstractive summarization)  (selective encoding model,Is-a-Prerequisite-of,abstractive summarization)  (abstractive summarization,Compare,extractive summarization)  (double-level attention model,Is-a-Prerequisite-of,abstractive summarization
EMPTY G1.topic aware
(document context, Evaluate-for, language model)(language model, Is-a-Prerequisite-of, large language model)(language model, Is-a-Prerequisite-of, text generation)(Lifelong learning, Is-a-Prerequisite-of, language model)(language model, Is-a-Prerequisite-of, course introduction)(language model, Used-for, multi-agent system)(multi-agent system, Is-a-Prerequisite-of, language model)(language model, Evaluate-for, performance improvement)(language model, Used-for, language modeling)(language modeling, Is-a-Prerequisite-of, language model)(language model, Evaluate-for, text generation)(neural language model, Is-a-Prerequisite-of, language model)(language model, Used-for, downstream task)(language model, Used-for, natural language generation)(language model, Evaluate-for, syntactic and structural collocation learning)(language model, Is-a-Prerequisite-of, CAGE)(concept, Used-for, language model)
(vision language navigation, Is-a-Prerequisite-of, grounding instructions)(vision language navigation, Evaluate-for, goal completion)(vision language navigation, Used-for, agents)(vision language navigation, Used-for, VLN task)(vision language navigation, Evaluate-for, instruction fidelity)(vision language navigation, Is-a-Prerequisite-of, neural module networks)(vision language navigation, Is-a-Prerequisite-of, autonomous agents)(vision language navigation, Part-of, VLN models)(vision language navigation, Is-a-Prerequisite-of, refer360°)(vision language navigation, Evaluate-for, navigation tasks)(vision language navigation, Evaluate-for, long paths)(vision language navigation, Evaluate-for, BabyWalk)(vision language navigation, Used-for, artificial intelligence research)(vision language navigation, Part-of, natural language processing)(vision language navigation, Evaluate-for, VLN agents)
EMPTY G1.fact-checking datasets
EMPTY G1.grammatical error correction gec
EMPTY G1.sentiment analysis absa
(latent dirichlet allocation,Is-a-Prerequisite-of,neural topic modeling)(latent dirichlet allocation,Compare,neural topic modeling)(neural topic modeling,Compare,traditional topic models)(document-topic distribution,Part-of,neural topic modeling)(neural topic modeling,Evaluate-for,text clustering)(neural topic modeling,Used-for,text understanding)(neural topic modeling,Is-a-Prerequisite-of,topic generation)(neural topic modeling,Compare,language modeling)
(relation extraction method, Evaluate-for, relation extraction)(relation extraction method, Used-for, extracting relations)(relation extraction method, Compare, Open Information Extraction methods)(relation extraction method, Compare, context-aware neural network model)(relation extraction method, Compare, neural Open IE approach)
(task question answering, Evaluate-for, performance evaluation)(task question answering, Part-of, neural network-based methods)(task question answering, Part-of, question answering system)
(deep learning based chinese, Part-of, NLP)(deep learning based chinese, Compare, neural char-based models)(deep learning based chinese, Part-of, MLHTC)(deep learning based chinese, Used-for, deep learning tasks)
(neural word, Compare, Multi-task learning)
(extractive qa,Is-a-Prerequisite-of,Abstractive summarization)(extractive qa,Is-a-Prerequisite-of,Query-based summarization)(extractive qa,Used-for,Extractive summarization)(extractive qa,Compare,Abstractive summarization)(extractive qa,Compare,Query-based summarization)
EMPTY G1.chinese named entity recognition
1. (COREQA, Used-for, natural language inference)2. (TextFlow, Compare, natural language inference)3. (ONLG, Evaluate-for, natural language inference)4. (semantic graph parser, Used-for, natural language inference)5. (NER and MD tasks, Evaluate-for, natural language inference)
EMPTY G1.explanation prediction
EMPTY G1.detecting correcting
EMPTY G1.named entity recognition relation
EMPTY G1.dataset bias
(syntactic parsing, Is-a-Prerequisite-of, neural machine translation)(syntactic parsing, Is-a-Prerequisite-of, natural language processing)(syntactic parsing, Is-a-Prerequisite-of, semantic parsing)(semantic parsing, Evaluate-for, syntactic parsing)
EMPTY G1.word embeddings trained
(dialogue learning, Used-for, dialogue systems)(dialogue learning, Compare, language learning)(dialogue learning, Compare, multimodal information)(dialogue learning, Compare, sequential concept learning)(dialogue learning, Is-a-Prerequisite-of, conversational agents)(dialogue learning, Evaluate-for, task-completion dialogue agent)(dialogue learning, Evaluate-for, natural language processing)(dialogue learning, Evaluate-for, social power)(dialogue learning, Evaluate-for, supervised language learning)(dialogue learning, Evaluate-for, multimodal user information)(dialogue learning, Evaluate-for, semantic parsing)(dialogue learning, Evaluate-for, sequential concept learning)
EMPTY G1.automatic argument
EMPTY G1.trained language model plms
EMPTY G1.interpretable description
EMPTY G1.current state nlp
(language unseen pretraining, Evaluate-for, neural network)(language understanding, Is-a-Prerequisite-of, language unseen pretraining)
(visual question answering, Is-a-Prerequisite-of, Python)
EMPTY G1.chinese relation extraction
EMPTY G1.domain sentiment classification
EMPTY G1.visual semantic
(speech text translation, Is-a-Prerequisite-of, speech translation)(speech synthesis, Is-a-Prerequisite-of, speech translation)(speech recognition, Used-for, speech translation)(speech translation, Is-a-Prerequisite-of, speech-to-speech translation)(speech recognition model, Is-a-Prerequisite-of, speech translation)(speech-to-text translation, Is-a-Prerequisite-of, speech translation)(speech translation, Evaluate-for, end-to-end modeling techniques)(speech encoder, Used-for, speech translation)(speech translation, Is-a-Prerequisite-of, end-to-end modeling techniques)(speech encoder, Is-a-Prerequisite-of, speech translation)(s2st, Compare, speech translation)
EMPTY G1.performance neural machine translation
(attention weight, Evaluate-for, interpretability of a model)  (attention weight, Is-a-Prerequisite-of, explanation of models predictions)  (attention weight, Used-for, explanation of models predictions)  
(learning word embedding,Used-for,neural word segmentation)(learning word embedding,Is-a-Prerequisite-of,zero-shot learning)
EMPTY G1.oriented visual dialogue
1. (speech recognition, Is-a-Prerequisite-of, language processing)
EMPTY G1.parsing model
EMPTY G1.form question answering
EMPTY G1.controllable summarization
EMPTY G1.inter sentence relation extraction
EMPTY G1.morphological task
(conceptualized representation, Used-for, sentiment analysis)(conceptualized representation, Evaluate-for, identifying author characteristics)(conceptualized representation, Evaluate-for, lexical relation distinction)(conceptualized representation, Used-for, multilingual unsupervised NMT)(conceptualized representation, Is-a-Prerequisite-of, denoising autoencoding)(conceptualized representation, Used-for, multilingual training)
(extractive summary, Is-a-Prerequisite-of, effective email subject line)(extractive summary, Used-for, text summarization)(extractive summary, Part-of, MDS news dataset)(extractive summary, Compare, abstractive summary)(extractive summary, Is-a-Prerequisite-of, document encoding)(extractive summary, Evaluate-for, event extraction improvement)
(topic aware news representation, Is-a-Prerequisite-of, user representation learning)
EMPTY G1.approach topic aware
(entity extraction,Is-a-Prerequisite-of,Named Entity Disambiguation)(entity extraction,Used-for,relation extraction)
EMPTY G1.transformer language model
(error detection,Is-a-Prerequisite-of,error correction)(error correction,Conjunction,error detection)(error correction,Compare,human-level language understanding ability)(error correction,Compare,state-of-the-art approaches)(error correction,Is-a-Prerequisite-of,semantic parse correction)(error correction,Is-a-Prerequisite-of,masked language model incorporation)(error correction,Used-for,multilingual GEC models)(error correction,Used-for,neural machine translation)(error correction,Used-for,metric validation)(error correction,Part-of,GEC systems)(error correction,Evaluate-for,global errors)(error correction,Evaluate-for,local errors)(error correction,Evaluate-for,accuracy improvement)(error correction,Evaluate-for,grammaticality improvement)(error correction,Compare,seq2seq models)(error correction,Compare,Shallow Aggressive Decoding)(error correction,Is-a-Prerequisite-of,fluency boost learning)(error correction,Is-a-Prerequisite-of,fluency boosting inference)
EMPTY G1.sentiment analysis absa aim
(sentiment, Evaluate-for, sentiment polarity)(aspect-based sentiment analysis, Evaluate-for, sentiment polarity)(sentiment classification, Evaluate-for, sentiment polarity)
EMPTY G1.goal oriented visual dialogue
EMPTY G1.structured sentiment
EMPTY G1.rnn cnn model
EMPTY G1.multi modal dialogue
EMPTY G1.advance neural text generation
(fact checking, Used-for, verifying claim)(fact checking, Evaluate-for, verifying veracity)(fact checking, Is-a-Prerequisite-of, scientific fact checking)(fact checking, Is-a-Prerequisite-of, automated fact checking)(fact checking, Evaluate-for, truthfulness of a claim)(fact checking, Evaluate-for, veracity of claims)(fact checking, Evaluate-for, reasoning about multiple retrievable evidence)(fact checking, Hyponym-Of, automated fact checking)
(represent max likelihood parse, Compare, ground truth)(represent max likelihood parse, Compare, performance metric)(represent max likelihood parse, Evaluate-for, sentences that are close to the ground truth)(represent max likelihood parse, Evaluate-for, sequence-level smoothing approach)
EMPTY G1.lingual continual learning
EMPTY G1.visual question answering vqa
EMPTY G1.question answer
EMPTY G1.machine reading comprehension mrc
EMPTY G1.sentiment knowledge
EMPTY G1.category opinion sentiment quadruple
(neural models, Used-for, computational psycholinguistics)(computer science, Is-a-Prerequisite-of, computational psycholinguistics)
EMPTY G1.lingual cross modal
EMPTY G1.structured topic model
(character level language modeling, Is-a-Prerequisite-of, word-based models)(character level language modeling, Used-for, processing Chinese text)(character level language modeling, Evaluate-for, performance improvements)(Chinese word segmentation, Is-a-Prerequisite-of, character level language modeling)(character level language modeling, Used-for, text infilling)(character level language modeling, Used-for, hybrid language modeling)(character level language modeling, Evaluate-for, Chinese word segmentation)(character level language modeling, Evaluate-for, entity mentions storing)(character level language modeling, Compare, word-based models)(character level language modeling, Compare, word segmentation)(character level language modeling, Compare, structure-aware models)(character level language modeling, Compare, sequential recurrent neural networks)(language modeling, Part-of, character level language modeling)
EMPTY G1.multilingual pre training
EMPTY G1.monolingual word embeddings
(neural abstractive summarization, Is-a-Prerequisite-of, abstractive summarization)(neural abstractive summarization, Evaluate-for, conventional sequence-to-sequence model)(neural abstractive summarization, Evaluate-for, reduction of repetition)(neural abstractive summarization, Evaluate-for, improvement of factual accuracy)(neural abstractive summarization, Evaluate-for, global encoding framework)(neural abstractive summarization, Evaluate-for, Transformer-based encoder-decoder framework)(seq2seq, Is-a-Prerequisite-of, neural abstractive summarization)
EMPTY G1.gender bias
EMPTY G1.unsupervised semantic
EMPTY G1.recurrent neural network rnns
EMPTY G1.topic aware news
(entity mention relation, Compare, joint extraction of entity mentions and relations)(entity mention relation, Used-for, NLP applications)(entity mention relation, Conjunction, semantic relations)(entity mention relation, Used-for, relation extraction)
EMPTY G1.cross lingual embeddings
(conversational models, Is-a-Prerequisite-of, neural conversational models)(graph neural, Used-for, relation extraction)(graph neural, Is-a-Prerequisite-of, structured projection of intermediate gradients)(graph neural, Used-for, graph measures)(graph neural, Used-for, learning graph embeddings)
EMPTY G1.visual language
(neural dialogue, Evaluate-for, human-like dialogue responses)(neural dialogue, Is-a-Prerequisite-of, successful task-oriented dialogue systems)(neural dialogue, Used-for, guided generation)(neural dialogue, Used-for, incorporating knowledge into dialogue generation)(neural dialogue, Part-of, end-to-end neural dialogue generation)(neural dialogue, Is-a-Prerequisite-of, successful multi-turn dialogue modeling)(neural dialogue, Is-a-Prerequisite-of, automatic diagnosis dialogue systems)(neural dialogue, Compare, task-oriented dialogue system)
(prototype mention embeddings, Compare, word embeddings)  (prototype mention embeddings, Evaluate-for, high quality of the word)
EMPTY G1.annotated semantic relatedness
EMPTY G1.morphological typology
(morphologically rich,Evaluate-for,language understanding systems)(morphologically rich,Used-for,improving distributional vector spaces)(morphologically rich,Part-of,language)(morphologically rich,Conjunction,morph-fitting procedure)(morphologically rich,Compare,insensitive to distinct lexical relations)
EMPTY G1.specializing word embeddings according
(word embedding model, Used-for, word analogy questions)(word embedding model, Used-for, caption generation)(word embedding model, Hyponym-Of, neural word embeddings)(word embedding model, Compare, bag-of-words)(word embedding model, Is-a-Prerequisite-of, bidirectional language models)(word embedding model, Compare, traditional approaches)
(conceptual entity, Part-of, Text similarity measures)(conceptual entity, Compare, Deep learning)
(link prediction, Used-for, knowledge graph completion)  (graph theory, Used-for, knowledge graph completion)
(spelling correction, Compare, grammatical error correction)(spelling correction, Is-a-Prerequisite-of, grammatical error correction)(seq2seq, Is-a-Prerequisite-of, grammatical error correction)(grammatical error correction, Compare, fact verification)(grammatical error correction, Compare, masked language model (MLM))(grammatical error correction, Used-for, correction)(grammatical error correction, Is-a-Prerequisite-of, fact verification)
EMPTY G1.offensive language classifier
EMPTY G1.knowledge graph embedding
1. (explanation attention, Compare, Scratchpad Mechanism)2. (explanation attention, Evaluate-for, interpretability of attention distributions)
EMPTY G1.large language model llm
(parsing, Is-a-Prerequisite-of, constituency parsing)(constituency parsing, Is-a-Prerequisite-of, deep learning model)(shift-reduce parsing, Evaluate-for, constituency parsing)(lexicalized parsing, Is-a-Prerequisite-of, constituency parsing)(penn treebank, Used-for, constituency parsing)(generative neural models, Used-for, constituency parsing)(Generative neural models, Is-a-Prerequisite-of, constituency parsing)
EMPTY G1.event causality identification
(morphological compositionality,Is-a-Prerequisite-of,morphological analyzer)(morphological compositionality,Used-for,train word embeddings)(morphological compositionality,Evaluate-for,word similarity)(morphology-based models,Hyponym-Of,morphological compositionality)(Train word embeddings,Is-a-Prerequisite-of,morphological compositionality)
EMPTY G1.embeddings semantic
EMPTY G1.vision language pre
EMPTY G1.shot continual relation extraction
(natural language processing, Used-for, pretrained language model)(state-of-the-art, Evaluate-for, pretrained language model)(LSTM, Is-a-Prerequisite-of, pretrained language model)(pretrained language model, Compare, Generative models defining joint distributions over parse trees and sentences)(pretrained language model, Evaluate-for, reducing perplexity metric)(pretrained language model, Is-a-Prerequisite-of, learning to predict surrounding words for every word in the dataset)
EMPTY G1.compositional generalization semantic parsing
(explainable nlp, Used-for, explainable systems)(explainable nlp, Compare, traditional nlp models)(explainable nlp, Used-for, explainable machine learning systems)(explainable nlp, Conjunction, natural language processing)(explainable nlp, Is-a-Prerequisite-of, generative explanation framework)
EMPTY G1.speech text translation st
EMPTY G1.multimodal embeddings
EMPTY G1.summarization largely
EMPTY G1.bias mitigation
(language target language, Is-a-Prerequisite-of, NMT models)(language target language, Evaluate-for, translation)(language target language, Used-for, document retrieval)
EMPTY G1.natural question dataset
(transcribed speech, Evaluate-for, downstream SLU performance)(transcribed speech, Used-for, ASR training data)(ASR, Is-a-Prerequisite-of, transcribed speech)
(reading comprehension datasets, Is-a-Prerequisite-of, reading comprehension system)(reading comprehension datasets, Evaluate-for, system evaluation)(reading comprehension datasets, Compare, natural-language understanding datasets)(reading comprehension datasets, Is-a-Prerequisite-of, dataset analysis)(reading comprehension datasets, Evaluate-for, machine learning model)(reading comprehension datasets, Is-a-Prerequisite-of, neural reading comprehension model)(reading comprehension datasets, Is-a-Prerequisite-of, reading comprehension performance)(reading comprehension datasets, Is-a-Prerequisite-of, question answering system)(reading comprehension datasets, Is-a-Prerequisite-of, machine comprehension system)(reading comprehension datasets, Evaluate-for, model performance)(reading comprehension datasets, Is-a-Prerequisite-of, TriviaQA dataset)(reading comprehension datasets, Is-a-Prerequisite-of, squad dataset)(reading comprehension datasets, Is-a-Prerequisite-of, WikiReading dataset)(natural language text, Used-for, reading comprehension datasets)
EMPTY G1.machine translation using
(dialogue modeling,Evaluate-for,response generation)(dialogue modeling,Used-for,dialog systems)(dialogue modeling,Evaluate-for,multi-turn setting)(dialogue modeling,Compare,single-turn dialogue modeling)(dialogue modeling,Compare,hybrid language modeling)(dialogue modeling,Evaluate-for,response selection)
(cross lingual cross modal,Is-a-Prerequisite-of,pre-training)(cross lingual cross modal,Compare,multilingual)(cross lingual cross modal,Compare,cross-lingual)(cross lingual cross modal,Compare,cross-modal)
EMPTY G1.neural topic model
EMPTY G1.word vector
EMPTY G1.textual feature
(language model like, Compare, neural language model)(language model like, Evaluate-for, perplexity experiments)
EMPTY G1.output attention weight
(word segmentation,Is-a-Prerequisite-of,neural word segmentation)(neural word segmentation,Used-for,building a modular segmentation model)(word embeddings,Is-a-Prerequisite-of,neural word segmentation)(neural word segmentation,Evaluate-for,entity mentions)(neural word segmentation,Used-for,external training sources)(neural word segmentation,Is-a-Prerequisite-of,joint extraction of entity mentions and relations)(learning word embedding,Used-for,neural word segmentation)(neural word segmentation,Is-a-Prerequisite-of,word segmentation)(neural word segmentation,Evaluate-for,segmenting words)(neural word segmentation,Evaluate-for,improving accuracy)(neural word segmentation,Used-for,aspect-based sentiment analysis)(neural word segmentation,Is-a-Prerequisite-of,word embeddings)(neural word segmentation,Evaluate-for,coherence of aspects)(neural word segmentation,Compare,statistical segmentation)(neural word segmentation,Part-of,segmentation model)(neural word segmentation,Hyponym-Of,Chinese word segmentation)(neural word segmentation,Used-for,Chinese NER)(neural word segmentation,Evaluate-for,NLP benchmark tasks)
EMPTY G1.nested named entity recognition
EMPTY G1.grained sentiment
EMPTY G1.neural text
(entity recognition ner, Used-for, natural language processing)(entity recognition ner, Part-of, named entity recognition)(named entity recognition, Is-a-Prerequisite-of, entity recognition ner)(entity recognition ner, Compare, emotion recognition)(entity recognition ner, Is-a-Prerequisite-of, named entity recognition systems)
EMPTY G1.perplexity language model
(link prediction, Used-for, knowledge graph completion)(link prediction, Is-a-Prerequisite-of, automatic knowledge graph completion)
EMPTY G1.bias multilingual representation
(summarization model, Is-a-Prerequisite-of, model generated summary)  (abstractive summarization, Is-a-Prerequisite-of, model generated summary)
EMPTY G1.information retrieval task
(opinion entity extraction, Used-for, opinion opinion pairs extraction)(opinion entity extraction, Evaluate-for, sentiment classification)(opinion entity extraction, Is-a-Prerequisite-of, opinion mining)(opinion entity extraction, Used-for, downstream tasks)
EMPTY G1.transformer based language
EMPTY G1.dependency parsing performance
(modeling morphological, Used-for, capturing linguistic regularities)
EMPTY G1.embeddings pre
EMPTY G1.multilingual machine translation
(discourse segmenters, Is-a-Prerequisite-of, statistical discourse segmenters)(discourse segmenters, Used-for, detecting intra-sentential segment boundaries)(discourse segmenters, Used-for, learning discourse segmenters)(discourse segmenters, Is-a-Prerequisite-of, fully supervised system)(discourse segmenters, Evaluate-for, F1 score)(discourse segmenters, Evaluate-for, unsupervised (cross-lingual)(discourse segmenters, Is-a-Prerequisite-of, statistical discourse segmenters)
(constrained stem change rules,Is-a-Prerequisite-of,unsupervised morphological)(unsupervised morphological,Evaluate-for,unsupervised morphological paradigm completion)(unsupervised morphological,Evaluate-for,unsupervised cross-lingual learning)
(natural language text, Used-for, neural semantic parser)(natural language text, Used-for, question answering system)(natural language text, Used-for, rhythmic poetry generation)(natural language text, Used-for, parsing natural language descriptions)(natural language text, Used-for, reading comprehension datasets)(natural language text, Used-for, inference in GuessTwo task)(natural language text, Used-for, natural language interfaces to databases)(natural language text, Evaluate-for, speech synthesis)
EMPTY G1.advance neural text
EMPTY G1.language model fine tuning
EMPTY G1.semantic retrieval
(bilingual word embeddings, Is-a-Prerequisite-of, large parallel corpora)(bilingual word embeddings, Compare, multilingual word embedding)(unsupervised bilingual lexicon induction, Is-a-Prerequisite-of, bilingual word embeddings)(bilingual word embeddings, Used-for, neural machine translation)(bilingual word embeddings, Is-a-Prerequisite-of, neural word segmentation research)
(event extraction,Is-a-Prerequisite-of,document-level event extraction)(event extraction,Used-for,supervised learning)(supervised learning,Is-a-Prerequisite-of,event extraction)(world knowledge,Evaluate-for,event extraction)(linguistic knowledge,Is-a-Prerequisite-of,event extraction)(event extraction,Used-for,text classification)(event extraction,Part-of,information extraction)(event extraction,Evaluate-for,event argument extraction)(event extraction,Is-a-Prerequisite-of,trained model tuning)(event extraction,Is-a-Prerequisite-of,trigger word identification)(event extraction,Compare,generative event extraction)(event extraction,Compare,supervised event extraction)(event extraction,Is-a-Prerequisite-of,key arguments detection)(event extraction,Is-a-Prerequisite-of,trigger words identification)(event extraction,Is-a-Prerequisite-of,arguments exploitation in event detection)(event extraction,Part-of,joint extraction task)(event extraction,Compare,feature extraction)(event extraction,Is-a-Prerequisite-of,relation extraction)(relation extraction,Compare,event extraction)(clustering,Used-for,event extraction)(planning,Is-a-Prerequisite-of,event extraction)(linguistic knowledge identification,Evaluate-for,event extraction)(task learning,Compare,event extraction)(automatic labeling,Used-for,event extraction)(training data,Is-a-Prerequisite-of,event extraction)(trigger words,Is-a-Prerequisite-of,event extraction)(global view,Part-of,event extraction)(event extraction,Is
EMPTY G1.entity detection
EMPTY G1.rumor detection
EMPTY G1.language generation nlg
(concepts,Is-a-Prerequisite-of,natural language understanding)(common entities,Is-a-Prerequisite-of,natural language understanding)(language generation nlg system,Used-for,natural language understanding)(pre trained language,Used-for,natural language understanding)(language understanding,Compare,natural language understanding)(relation extraction,Compare,natural language understanding)(inference,Is-a-Prerequisite-of,natural language understanding)(linguistic corpora,Used-for,natural language understanding)(natural language understanding,Used-for,task optimization)(natural language understanding,Used-for,symbolic reasoning)(natural language understanding,Used-for,program learning)(natural language understanding,Used-for,dialogue state tracking)(natural language understanding,Used-for,common language system)(natural language understanding,Used-for,semantic parsing)(reading comprehension,Is-a-Prerequisite-of,natural language understanding)
(lingual semantic parsing, Is-a-Prerequisite-of, neural architecture)(lingual semantic parsing, Is-a-Prerequisite-of, learning algorithm)(lingual semantic parsing, Is-a-Prerequisite-of, semantic parsers)(lingual semantic parsing, Used-for, learning classifiers)(lingual semantic parsing, Compare, semantic parsing)
(COREQA, Evaluate-for, answering system)
(concept, relation, concept)(Memory networks, Used-for, aspect sentiment classification)(Attention mechanism, Used-for, aspect sentiment classification)(Target-sensitive memory networks, Is-a-Prerequisite-of, aspect sentiment classification)(Neural models, Used-for, aspect sentiment classification)(sentiment classifier, Used-for, aspect sentiment classification)(sentiment classification, Is-a-Prerequisite-of, aspect sentiment classification)
(concept-hierarchical attention network, relation-Used-for, concept-fine-grained language embeddings)(concept-hierarchical attention network, relation-Used-for, concept-answering questions in narrative paragraphs)(concept-hierarchical attention network, relation-Part-of, concept-hierarchical attention network)(concept-hierarchical attention network, relation-Used-for, concept-answering questions from narrative paragraphs)(concept-trained language model, relation-Is-a-Prerequisite-of, concept-hierarchical attention network)(concept-hierarchical attention network, relation-Used-for, concept-reading comprehension style question answering)(concept-hierarchical attention network, relation-Compare, concept-average attention network)(concept-hierarchical attention network, relation-Compare, concept-structured projection of intermediate gradients)(concept-hierarchical attention network, relation-Part-of, concept-neural network-based approach)(concept-hierarchical attention network, relation-Evaluate-for, concept-validate the effectiveness of the proposed method)(concept-hierarchical attention network, relation-Is-a-Prerequisite-of, concept-reading comprehension)(concept-hierarchical attention network, relation-Used-for, concept-fully fuse information from both global and attended representations)(concept-hierarchical attention network, relation-Used-for, concept-focus on the answer span progressively with multi-level soft-alignment)(concept-hierarchical attention network, relation-Is-a-Prerequisite-of, concept-reading comprehension style question answering)(concept-hierarchical attention network,
(spelling error, Evaluate-for, detecting the native language of a writer)(character n-grams, Compare, spelling error)(spelling error, Conjunction, lexical features)(spelling error, Used-for, classification of texts in the TOEFL11 corpus)(spelling error, Conjunction, other lexical features)(spelling error, Evaluate-for, detecting the native language of the author)(spelling error, Conjunction, detecting and correcting spelling errors)(spelling error, Used-for, Chinese Spelling Correction)(spelling error, Hyponym-Of, Chinese Spelling Check)
(robustness, Used-for, adversarial example)(adversarial example, Evaluate-for, model performance)
(attention based explanation, Compare, Automatic Content Extraction)(attention based explanation, Compare, MultiRC)(attention based explanation, Conjunction, machine attention maps)(attention based explanation, Conjunction, human attention maps)(attention based explanation, Conjunction, text classification)(attention based explanation, Evaluate-for, model prediction)(attention based explanation, Evaluate-for, explainability)(attention based explanation, Evaluate-for, reliability)(attention based explanation, Is-a-Prerequisite-of, generating explanations)(attention based explanation, Is-a-Prerequisite-of, black-box models)(attention based explanation, Is-a-Prerequisite-of, model faithfulness)(attention based explanation, Is-a-Prerequisite-of, interpretability)(attention based explanation, Part-of, Visualizing)(attention based explanation, Part-of, Discrimination)(attention based explanation, Used-for, extracting entity mentions and relations)
(conjunction, Conjunction, morphological analysis)(morphological family, Part-of, morphological analysis)(morphological family, Is-a-Prerequisite-of, morphological analysis)(morphological inflection, Used-for, morphological analysis)(morphological analysis, Evaluate-for, morphological relation)(inflection generation, Compare, morphological analysis)(inflection generation, Is-a-Prerequisite-of, morphological analysis)(morphological analysis, Part-of, morphological analyzer)(morphological analysis, Evaluate-for, language understanding systems)(morphological inflection, Evaluate-for, morphological analysis)(morphological paradigm, Is-a-Prerequisite-of, morphological analysis)(learning morphological, Evaluate-for, morphological analysis)(morphological analysis, Is-a-Prerequisite-of, morphological tagging)(suffixation, Part-of, morphological analysis)(infixation, Part-of, morphological analysis)(prefixation, Part-of, morphological analysis)(full and partial reduplication, Part-of, morphological analysis)
EMPTY G1.attention based
EMPTY G1.sentence compression model
EMPTY G1.machine translation system
EMPTY G1.evaluation benchmark korean
(event language model,Used-for,generation of rhythmic poetry)(event language model,Compare,neural language model)(event language model,Compare,LSTM)(event language model,Compare,unsupervised neural machine translation)(event language model,Evaluate-for,emotional sentence generation)
(event extraction, Evaluate-for, event argument extraction)(argument mining, Compare, event argument extraction)(stance detection, Compare, event argument extraction)(level event argument extraction, Is-a-Prerequisite-of, event argument extraction)(sentence-level event argument extraction, Is-a-Prerequisite-of, event argument extraction)(event argument extraction, Used-for, document-level event extraction)(event argument extraction, Compare, ERE)(event argument extraction, Is-a-Prerequisite-of, document-level event extraction)(event argument extraction, Is-a-Prerequisite-of, FewDocAE)(event argument extraction, Used-for, event relation extraction)(event argument extraction, Compare, sentence-level and document-level EAE)(event argument extraction, Is-a-Prerequisite-of, zero-shot cross-lingual event argument extraction)
(Language Models, Evaluate-for, unsupervised syntactic parsing)(RNN, Used-for, unsupervised syntactic parsing)(LSTM, Used-for, unsupervised syntactic parsing)(Tree Kernels, Used-for, unsupervised syntactic parsing)(Neural Networks, Used-for, unsupervised syntactic parsing)(Triframes, Evaluate-for, unsupervised syntactic parsing)(Unsupervised constituency parsing, Is-a-Prerequisite-of, unsupervised syntactic parsing)(Unsupervised abstractive summarization, Is-a-Prerequisite-of, unsupervised syntactic parsing)(Open Information Extraction, Used-for, unsupervised syntactic parsing)(Encoder-decoder models, Used-for, unsupervised syntactic parsing)(Conventional Open Information Extraction systems, Compare, neural Open IE approach)(Encoder-decoder models, Compare, neural Open IE approach)(Parsing-Reading-Predict architecture, Compare, neural Open IE approach)(Rapid progress, Compare, neural Open IE approach)
- (LSTM, Used-for, short term memory)
EMPTY G1.neural topic
EMPTY G1.speech speech translation s2st
(subword units, Part-of, word representation)
(extractive summarization model, Compare, abstractive summarization model)
(semantic decoding, Used-for, semantic parsing)(semantic parsing, Is-a-Prerequisite-of, semantic decoding)
(entity representation, Used-for, morphological constraints)(entity representation, Compare, word vector collection)(entity representation, Evaluate-for, language understanding systems)(entity representation, Is-a-Prerequisite-of, semantic representation)(entity representation, Part-of, dialogue state tracking)(entity representation, Used-for, dialogue state tracking)
EMPTY G1.phonological representation
(fake news detection, Used-for, combating fake news)(fake news detection, Used-for, verify whether a news document is trusted or fake)(fake news detection, Used-for, differentiate fake news from real ones)(fake news detection, Used-for, prevent dissemination of misinformation on social media)(fake news detection, Used-for, fake news detection at the knowledge element level)(fake news detection, Used-for, detecting biased language)(concept: methods for automatic fake news detection, Evaluate-for, fake news detection)(concept: social impacts, Evaluate-for, fake news detection)
EMPTY G1.event mention
(document level relation extraction, Used-for, integrating information within and across multiple sentences)(document level relation extraction, Compare, span-level relation extraction)(document level relation extraction, Is-a-Prerequisite-of, inter-sentence relation extraction)(document level relation extraction, Is-a-Prerequisite-of, aggregating relevant information in the document)(document level relation extraction, Is-a-Prerequisite-of, multi-hop reasoning)(document level relation extraction, Is-a-Prerequisite-of, relational reasoning across sentences)(document level relation extraction, Compare, span-level task)(document level relation extraction, Compare, token-level models)
EMPTY G1.cross lingual summarization
(sentence embeddings, Is-a-Prerequisite-of, sentence representation learning)(word embeddings, Compare, sentence embeddings)(sentence embeddings, Used-for, sentence relatedness evaluation)(context sensitive embeddings, Compare, sentence embeddings)(context sensitive embeddings, Evaluate-for, sentence embeddings)
EMPTY G1.shot semantic parsing
EMPTY G1.multi hop reading comprehension
(human annotated explanation, Used-for, natural language explanation)(human annotated explanation, Is-a-Prerequisite-of, explanation-guided representations)(human annotated explanation, Compare, automatically generated QA pairs)(human annotated explanation, Evaluate-for, classifier performance)
(zero pronoun resolution, Evaluate-for, annotated data)(zero pronoun resolution, Used-for, annotated data)(annotated data, Compare, neural network models)
EMPTY G1.question answering qa
