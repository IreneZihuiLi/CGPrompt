('Chinese Spelling Correction', 'Is-a-Prerequisite-of', 'language understanding')
('spelling correction', 'Used-for', 'reducing character errors')
('spelling correction', 'Used-for', 'reducing word errors')
('spelling correction', 'Used-for', 'enhancing readability')
('Chinese Spelling Correction', 'Used-for', 'improving machine translation')
('Chinese Spelling Correction', 'Used-for', 'ensuring accurate information dissemination')
('autoregressive decoding', 'Evaluate-for', 'Machine Translation efficiency')
('GCN-based coherence model', 'Used-for', 'assessing discourse coherence')
('GCN-based coherence model', 'Used-for', 'automated essay scoring')
('pinyin-to-character objective', 'Used-for', 'learning phonetic representations')
('spelling correction', 'Hyponym-Of', 'text correction')
('EXPECT', 'Used-for', 'enhancing GEC systems')
('spelling correction', 'Part-of', 'OCR post-correction')
('multi-input attention averaging', 'Used-for', 'achieving consensus in decoding')
('sequence-to-sequence model with attention', 'Used-for', 'single-input correction')
('shared layers', 'Part-of', 'neural network')
('neural network', 'Evaluate-for', 'text classification tasks')
('adversarial multi-task learning framework', 'Used-for', 'improving neural network feature extraction')
('neural network', 'Used-for', 'transfer learning')
('neural network models', 'Used-for', 'language understanding')
('Neural Symbolic Machine', 'Part-of', 'neural network')
('neural network', 'Used-for', 'Neural Machine Translation (NMT')
('neural network', 'Evaluate-for', 'gradient diffusion problem')
('neural network', 'Used-for', 'reading comprehension')
('probabilistic context free grammar', 'Used-for', 'modelling sentences')
('collapsed variational inference', 'Used-for', 'inference in context-dependent grammar')
('probabilistic context free grammar', 'Compare', 'mildly context-sensitive grammars')
('Operation Trees', 'Used-for', 'constructing corpus for question answering')
('OTTA', 'Hyponym-Of', 'semantic parsing corpus')
('probabilistic context free grammar', 'Evaluate-for', 'reducing computational complexity in parsing')
('syntax-aware language models', 'Used-for', 'producing better samples')
('probabilistic context free grammar', 'Used-for', 'probabilistic linear context-free rewriting system formalism')
('probabilistic context free grammar', 'Part-of', 'natural language processing')
('probabilistic context\n(context free grammar', 'Is-a-Prerequisite-of', 'synchronous context-free grammar')
('context free grammar', 'Is-a-Prerequisite-of', 'weakly equivalent synchronous tree-adjoining grammar')
('context free grammar', 'Is-a-Prerequisite-of', 'compound probabilistic context free grammar')
('context free grammar', 'Is-a-Prerequisite-of', 'controllable context free grammar')
('synchronous context-free grammar', 'Used-for', 'represent families of graphs in syntactic parsing')
('synchronous context-free grammar', 'Used-for', 'semantic parsing')
('synchronous tree-adjoining grammar', 'Evaluate-for', 'translation performance')
('compound probabilistic context free grammar', 'Used-for', 'semantic parsing')
('controllable context free grammar', 'Used-for', 'generating language classes')
('pushdown adjoining automaton', 'Is-a-Prerequisite-of', 'pushdown automata controlling context free grammars')
('pushdown adjoining automaton', 'Used-for', 'generating new language representational forms')
('preprocessing', 'Part-of', 'feature extraction')
('preprocessing', 'Used-for', 'NLP tasks')
('preprocessing', 'Is-a-Prerequisite-of', 'feature extraction')
('preprocessing', 'Used-for', 'normalization of historical texts')
('morphology', 'Used-for', 'inflectional modeling')
('morphology', 'Part-of', 'morphological supervision')
('morphology', 'Evaluate-for', 'character language models performance')
('morphology', 'Is-a-Prerequisite-of', 'morphological inflection models')
('morphological supervision', 'Used-for', 'improving bits-per-character performance')
('morphological supervision', 'Used-for', 'performance enhancement in low-resource settings')
('morphological supervision', 'Used-for', 'generalization across languages')
('character language models', 'Used-for', 'language modeling')
('bits-per-character', 'Evaluate-for', 'language model performance assessment')
('inflection', 'Hyponym-Of', 'morphology')
('inflection', 'Used-for', 'extending past tense forms')
('Inflectional modeling', 'Used-for', 'generalizing to new words')
('game playing in AI', 'Hyponym-Of', 'AI applications')
('deep reinforcement learning', 'Used-for', 'developing game playing agent')
('deep reinforcement learning', 'Evaluate-for', 'sample efficiency')
('world-perceiving modules', 'Used-for', 'decomposing tasks')
('world-perceiving modules', 'Used-for', 'pruning actions')
('two-phase training framework', 'Used-for', 'decoupling language learning from reinforcement learning')
('natural language annotations', 'Used-for', 'model interpretability')
('linear probing', 'Used-for', 'predicting domain-specific terms')
('imitation learning', 'Compare', 'reinforcement learning')
('policy networks', 'Part-of', 'game playing in AI')
('policy networks', 'Evaluate-for', 'encoding high-level abstractions')
('Neural News Recommendation', 'Used-for', 'Learning user representations')
('News encoder', 'Part-of', 'Neural News Recommendation')
('User encoder', 'Part-of', 'Neural News Recommendation')
('Personalized news recommendation', 'Used-for', 'Improving online news reading experience')
('Fine-grained Interest Matching method', 'Is-a-Prerequisite-of', 'Personalized news recommendation')
('Multi-turn information seeking conversation systems', 'Used-for', 'Industrial applications')
('Transfer learning', 'Used-for', 'Adapting neural models to new domains')
('DuRecDial', 'Used-for', 'Studying conversational recommendation')
('Attention network', 'Used-for', 'Selecting important words in news titles')
('GRU network', 'Used-for', 'Learning short-term user representations')
('NeuralDater', 'Used-for', 'Document Dating')
('Graph Convolutional Network', 'Used-for', 'NeuralDater')
('Document Dating', 'Part-of', 'Temporal data analysis techniques')
('text-to-text generation', 'Used-for', 'language model prediction')
('text generation', 'Hyponym-Of', 'language generation task')
('text generation', 'Used-for', 'video captioning')
('text generation', 'Used-for', 'conversational text generation')
('Affect-LM', 'Used-for', 'conversational text generation')
('text generation', 'Used-for', 'AMR-to-text generation')
('text generation', 'Used-for', 'language understanding tasks')
('natural language descriptions', 'Used-for', 'code generation')
('neural architecture', 'Used-for', 'parsing natural language descriptions')
('grammar model', 'Part-of', 'neural architecture')
('source code', 'Evaluate-for', 'parsing natural language descriptions')
('semantic parsing', 'Compare', 'code generation')
('LSTM', 'Used-for', 'conversational text generation')
('Perception studies', 'Evaluate-for', 'Affect-LM')
('automatic\n(character level language model', 'Used-for', 'generating sequences of word tokens character by character')
('character level language model', 'Evaluate-for', 'improving language model prediction')
('character level language model', 'Is-a-Prerequisite-of', 'handling unsegmented languages')
('character level language model', 'Part-of', 'hybrid language modeling')
('character level language model', 'Evaluate-for', 'creating new word types not attested in training corpus')
('character level language model', 'Compare', 'fixed-vocabulary language models')
('character level language model', 'Compare', 'lexicalized grammars')
('self-attention mechanism', 'Used-for', 'character level language modeling')
('morphological analyzer', 'Used-for', 'tokenization')
('neural networks', 'Used-for', 'parsing with RNNGs')
('LSTM', 'Used-for', 'conversational text generation conditioned on affect categories')
('pretrained models', 'Used-for', 'open-domain dialog generation')
('latent variable model', 'Used-for', 'capturing discourse-level diversity in encoding conversational intents')
('latent variable model', 'Used-for', 'controlled response generation in dialog systems')
('latent variable model', 'Used-for', 'prediction of team members consistency understanding in group decisions')
('latent variable model', 'Used-for', 'learning multilingual word representations')
('latent variable model', 'Is-a-Prerequisite-of', 'generative modeling of text')
('latent variable model', 'Hyponym-Of', 'stochastic models')
('deep generative model', 'Used-for', 'stock movement prediction')
('neural parser', 'Used-for', 'AMR parsing')
('conditional variational autoencoders', 'Part-of', 'latent variable model')
('latent variable grammars', 'Part-of', 'LVeGs')
('latent variables', 'Used-for', 'capturing stochastic nature in data')
('variational autoencoders', 'Used-for', 'end-to-end text generation framework')
('latent variable model', 'Used-for', 'semi-supervised learning of morphological inflectors')
('Penn Treebank', 'Used-for', 'Constituency Parsing')
('Dependency Parsing', 'Part-of', 'Penn Treebank')
('Constituency Parsing', 'Part-of', 'Penn Treebank')
('Penn Treebank', 'Evaluate-for', 'Natural Language Processing Tasks')
('Penn Treebank', 'Used-for', 'Syntactic Annotation')
('Penn Treebank', 'Used-for', 'Training Language Models')
('Penn Treebank', 'Used-for', 'Sentiment Analysis')
('Sentiment Analysis', 'Evaluate-for', 'Penn Treebank')
('Language Models', 'Evaluate-for', 'Penn Treebank')
('Annotated English Gigaword', 'Conjunction', 'Penn Treebank')
('English Gigaword', 'Used-for', 'Enhancing Penn Treebank')
('biomedical named entities', 'Part-of', 'bio text mining')
('normalization', 'Evaluate-for', 'incompleteness of provided synonyms')
('bio text mining', 'Used-for', 'learning representations of biomedical entities')
('model-based candidate selection', 'Used-for', 'bio text syllabi enhancement')
('synonyms', 'Part-of', 'biomedical named entities')
('marginal likelihood', 'Used-for', 'bio text mining evaluation')
('BioSyn', 'Used-for', 'biomedical entity normalization')
('biomedical text mining tools', 'Part-of', 'bio text mining')
('NeuralREG', 'Used-for', 'lexicalized parsing')
('lexicalized grammar', 'Is-a-Prerequisite-of', 'REG models')
('lexicalized parsing', 'Hyponym-Of', 'parsing')
('encoder-decoder parser', 'Used-for', 'lexicalized parsing')
('hybrid system', 'Evaluate-for', 'producing lexicalized logical forms')
('L-PCFGs', 'Used-for', 'lexicalized parsing')
('NeuralREG', 'Evaluate-for', 'improving form and content of lexicalized expressions')
('ArgRewrite', 'Part-of', 'ArgRewrite revisions corpus')
('ArgRewrite revisions corpus', 'Used-for', 'writing comparison')
('ArgRewrite revisions corpus', 'Used-for', 'revision analysis')
('nlp and vision', 'Used-for', 'describing images with text')
('language-guided image editing dataset', 'Part-of', 'nlp and vision research')
('relational speaker model', 'Used-for', 'generating relational captions')
('nlp and vision', 'Used-for', 'dual supervised learning')
('MOOCCube', 'Part-of', 'nlp and vision applications')
('Prerequisite discovery task', 'Is-a-Prerequisite-of', 'MOOCCube usage')
('Pair-wise Aspect and Opinion Terms Extraction', 'Part-of', 'fine-grained ABSA')
('Neural module networks', 'Used-for', 'vision and language comprehension tasks')
('knowledge graph embedding', 'Used-for', 'KG link prediction')
('knowledge graph embedding', 'Used-for', 'incomplete KG question answering')
('Transformers', 'Used-for', 'KG link prediction')
('feature extraction', 'Is-a-Prerequisite-of', 'feature selection')
('message passing algorithm', 'Used-for', 'feature selection')
('domain adaptation', 'Used-for', 'feature selection')
('algebraic perspective', 'Used-for', 'feature selection')
('linear transformation', 'Used-for', 'feature selection')
('text chunking', 'Evaluate-for', 'feature selection')
('matrix factorization', 'Used-for', 'representing users’ preference as a user-topic matrix')
('matrix factorization', 'Used-for', 'mapping users and topics onto a latent feature space')
('matrix factorization', 'Evaluate-for', 'modeling inter-topic preferences')
('matrix factorization', 'Used-for', 'low rank approximation of the original document-word matrix')
('matrix factorization', 'Used-for', 'topic discovery through spatial aggregation')
('None', 'Is-a-Prerequisite-of', 'first order logic')
('first order logic', 'Used-for', 'creating compositional reasoning rules')
('T-norm fuzzy logic', 'Evaluate-for', 'first order logic optimization')
('vector representation', 'Used-for', 'capturing semantic information')
('vector representation', 'Compare', 'point representations')
('vector representation', 'Used-for', 'spectral clustering')
('spectral clustering', 'Used-for', 'linking synonyms and antonyms')
('vector representation', 'Used-for', 'multimodal word distributions')
('multimodal word distributions', 'Is-a-Prerequisite-of', 'semantic information expressivity')
('vector representation', 'Used-for', 'entailment tasks')
('vector representation', 'Part-of', 'natural language processing models')
('natural language processing models', 'Used-for', 'text categorization')
('natural language processing models', 'Used-for', 'neural machine translation')
('vector representation', 'Used-for', 'morpheme segmentation')
('vector representation', 'Evaluate-for', 'semantic quality of entire word vector collection')
('Stack-LSTM', 'Is-a-Prerequisite-of', 'AMR Parsing')
('Stack-LSTM', 'Used-for', 'Augmenting Training with Policy Learning')
('Stack-LSTM', 'Hyponym-Of', 'RNN')
('Stack-LSTM', 'Part-of', 'Transition-based AMR Parser')
('Stack-LSTM', 'Used-for', 'Smatch Score Improvement')
('Smatch Score', 'Used-for', 'Evaluating AMR Parser')
('RNN', 'Part-of', 'Transformer')
('graph-based nlp', 'Used-for', 'abstrative summarization')
('graph-based nlp', 'Used-for', 'synset induction')
('graph-based nlp', 'Used-for', 'meeting speech summarization')
('graph-based nlp', 'Used-for', 'semantic frame induction')
('graph-based nlp', 'Used-for', 'relation extraction')
('graph-based nlp', 'Used-for', 'fact verification')
('graph-based attention mechanism', 'Part-of', 'graph-based nlp')
('semantic dependency parsing', 'Used-for', 'graph-based nlp')
('dependency parsing', 'Used-for', 'graph-based nlp')
('event factuality prediction', 'Used-for', 'graph-based nlp')
('neural semantic parsing', 'Used-for', 'graph-based nlp')
('text classification', 'Used-for', 'graph-based nlp')
('AMR-to-text generation', 'Used-for', 'graph-based nlp')
('\n(None', 'Part-of', 'phonetic information')
('phonetic information', 'Used-for', 'phonotactic acquisition')
('TwistList', 'Used-for', 'tongue twister generation')
('Dense Passage Retriever', 'Used-for', 'similarities computation')
('Distinctive features', 'Compare', 'Feature-naive model')
('Feature-naive', 'Is-a-Prerequisite-of', 'human judgments')
('TwisterMisters', 'Evaluate-for', 'tongue twister generation')
('Open-domain TableQA models', 'Used-for', 'question answering')
('Late interaction models', 'Used-for', 'fine-grained interaction')
('None', 'Used-for', 'syntax based machine generative models')
('syntax based machine translation', 'Is-a-Prerequisite-of', 'sequence-to-sequence models')
('syntax based machine translation', 'Used-for', 'enhancing structural accuracy in translated text')
('Syntax Trees', 'Part-of', 'syntax based machine translation')
('syntax based machine translation', 'Evaluate-for', 'translation quality improvement')
('Bi-directional Tree Encoder', 'Used-for', 'syntax based machine translation')
('SD-NMT', 'Hyponym-Of', 'syntax based machine translation')
('syntax based machine translation', 'Used-for', 'improving statistical machine translation')
('markov chain monte carlo', 'Used-for', 'learning weight uncertainty in RNNs')
('stochastic optimization', 'Used-for', 'training RNNs')
('back-propagation through time', 'Used-for', 'traditional training of RNNs')
('RNNs', 'Part-of', 'language modeling')
('gradient noise', 'Used-for', 'enhancing exploration of the model-parameter space')
('model averaging', 'Used-for', 'model testing')
('proposed approach', 'Evaluate-for', 'superiority over stochastic optimization')
('speech synthesis', 'Used-for', 'language revitalization')
('speech synthesis', 'Part-of', 'multimodal synthesis techniques')
('speech synthesis', 'Is-a-Prerequisite-of', 'spoken audio captions')
('multitask learning', 'Used-for', 'speech translation')
('recognition decoder', 'Used-for', 'output generation in ST model')
('translation decoder', 'Used-for', 'final translations in ST model')
('word embedding', 'Used-for', 'improving multitask ST model')
('structuredRegex', 'Hyponym-Of', 'regex synthesis dataset')
('speech synthesis', 'Compare', 'text-to-speech systems')
('articulatory vectors', 'Used-for', 'learning phoneme representations')
('neural text-to-speech systems', 'Evaluate-for', 'high-resource scenarios')
('neural models', 'Evaluate-for', 'low-resource speech synthesis systems')
('MatSci-NLP', 'Used-for', 'evaluating NLP models on materials science text')
('Vector space representations', 'Used-for', 'Clustering of words')
('SWAP-NET', 'Used-for', 'Extractive summarization')
('Synonyms', 'Part-of', 'Vector space representations')
('Antonyms', 'Part-of', 'Vector space representations')
('Word embeddings', 'Used-for', 'Spectral clustering')
('Spectral clustering', 'Evaluate-for', 'Analyzing word relationships')
('Compositor attribution', 'Is-a-Prerequisite-of', 'Orthographic variation analysis')
('Compositor attribution', 'Is-a-Prerequisite-of', 'Visual inspection')
('Orthographic variation', 'Used-for', 'Compositor attribution')
('Visual inspection', 'Used-for', 'Compositor attribution')
('Clustering of pages', 'Used-for', 'Identifying individual compositors')
('Compositor attribution', 'Used-for', 'Bibliographic tasks')
('Shakespeare’s First Folio', 'Used-for', 'Compositor attribution evaluation')
('Signed spectral normalized graph cut algorithm', 'Used-for', 'Spectral clustering')
('DAZER', 'Used-for', 'Zero-shot document filtering')
('Deep relevance model', 'Used-for', 'Information filtering')
('sentence meta-embeddings', 'Part-of', 'Semantic Textual Similarity task')
('Semantic Textual Similarity task', 'Evaluate-for', 'unsupervised State of The Art')
('sentence meta-embeddings', 'Evaluate-for', 'STS Benchmark')
('sentence meta-embeddings', 'Evaluate-for', 'STS12-STS16 datasets')
('dimensionality reduction', 'Part-of', 'meta-embedding methods')
('meta-embedding methods', 'Hyponym-Of', 'word embedding techniques')
('dimensionality reduction', 'Used-for', 'generalized Canonical Correlation Analysis')
('dimensionality reduction', 'Used-for', 'cross-view auto-encoders')
('gated recurrent unit', 'Used-for', 'extracting character level dependencies')
('gated recurrent unit', 'Used-for', 'capturing contextual information')
('grids', 'Hyponym-Of', 'bidirectional gated recurrent structures')
('bidirectional gated recurrent structures', 'Part-of', 'deep neural network architecture')
('deep neural network architecture', 'Used-for', 'context sensitive lemmatization')
('deep neural network architecture', 'Used-for', 'supervised learning')
('deep neural network architecture', 'Evaluate-for', 'language independence in lemmatization')
('bidirectional gated recurrent structures', 'Evaluate-for', 'lemma identification')
('bi-directional language models', 'Used-for', 'adding pretrained context embeddings')
('bi-directional language models', 'Used-for', 'sequence labeling tasks')
('bi-directional language models', 'Evaluate-for', 'producing context sensitive representations')
('LSTM', 'Compare', 'word averaging')
('k-means algorithm', 'Used-for', 'clustering data points')
('k-means algorithm', 'Is-a-Prerequisite-of', 'vector quantization')
('k-means algorithm', 'Evaluate-for', 'cluster coherence')
('k-means algorithm', 'Hyponym-Of', 'clustering algorithms')
('clustering data points', 'Used-for', 'data analysis')
('vector quantization', 'Used-for', 'data compression')
('cluster coherence', 'Evaluate-for', 'model performance')
('clustering algorithms', 'Hyponym-Of', 'machine learning methods')
('data analysis', 'Conjunction', 'data visualization')
('data compression', 'Used-for', 'reducing data size')
('model performance', 'Evaluate-for', 'algorithm effectiveness')
('machine learning methods', 'Compare', 'statistical methods')
('neural machine translation', 'Part-of', 'artificial intelligence')
('neural machine translation', 'Used-for', 'translating languages')
('neural machine translation', 'Compare', 'statistical machine translation')
('bi-directional LSTMs', 'Used-for', 'neural machine translation')
('convolutional layers', 'Used-for', 'neural machine translation')
('LAUs', 'Used-for', 'neural machine translation')
('deep multiagent policies', 'Evaluate-for', 'neural machine translation')
('posterior regularization', 'Used-for', 'neural machine translation')
('Parallel RNN encoder', 'Used-for', 'Incorporate source syntax into NMT')
('Hierarchical RNN encoder', 'Used-for', 'Incorporate source syntax into NMT')
('Mixed RNN encoder', 'Used-for', 'Incorporate source syntax into NMT')
('Deep Neural Networks', 'Compare', 'LSTM-based NMT models')
('LAUs', 'Compare', 'LSTM and GRU for reducing gradient propagation')
('Multi-modal Neural Machine Translation', 'Used-for', 'Incorporate spatial visual features into translation')
('Bidirectional LSTM', 'Is-a-Prerequisite-of', 'Neural Machine Translation')
('Source-side syntactic trees', 'Used-for', 'Enhance NMT by guiding attention mechanism')
('Chunk-based decoders', 'Used-for', 'Improve translation performance in NMT')
('Machine Translation Technique', 'Compare', 'Statistical Machine Translation')
('Machine Translation Technique', 'Compare', 'Phrase-based Machine Translation')
('python', 'Is-a-Prerequisite-of', 'code generation')
('python', 'Is-a-Prerequisite-of', 'NL-to-code generation')
('python', 'Is-a-Prerequisite-of', 'modular code generation')
('code generation', 'Evaluate-for', 'generating complex programs from natural language descriptions')
('code generation', 'Evaluate-for', 'achieving state-of-the-art results')
('NL-to-code generation', 'Used-for', 'interpreting natural language intents into source code')
('StackOverflow', 'Used-for', 'mining NL-code pairs')
('API documentation', 'Used-for', 'retrieving programming related information')
('data augmentation', 'Used-for', 'improving BLEU score')
('retrieval-based data re-sampling', 'Used-for', 'improving BLEU score')
('modular code generation', 'Used-for', 'visual question answering')
('COVR dataset', 'Evaluate-for', 'testing accuracy of visual models')
('GQA dataset', 'Evaluate-for', 'testing accuracy of visual models')
('Topical PageRank', 'Used-for', 'ranking of noun phrases')
('Latent Dirichlet Allocation', 'Used-for', 'inferring latent topic distribution')
('Salience Rank', 'Compare', 'Topical PageRank')
('Salience Rank', 'Used-for', 'extracting keyphrases')
('named entities', 'Used-for', 'domain-specific terms')
('named entities', 'Evaluate-for', 'improving topic quality')
('Neural topic models', 'Used-for', 'automatic topic extraction')
('Latent Dirichlet Allocation', 'Compare', 'Neural topic models')
('Bidirectional Adversarial Topic model', 'Used-for', 'neural topic modeling')
('Bidirectional Adversarial Topic model', 'Hyponym-Of', 'Neural topic models')
('Gaussian-BAT', 'Hyponym-Of', 'Bidirectional Adversarial Topic model')
('Bidirectional Adversarial Topic model with Gaussian', 'Used-for', 'incorporating word relatedness information')
('word embedding', 'Used-for', 'solving word analogies')
('word embedding', 'Used-for', 'caption generation')
('Skip-Gram model', 'Used-for', 'learning word embeddings')
('word embedding', 'Evaluate-for', 'compositional capability')
('Sufficient Dimensionality Reduction', 'Used-for', 'obtaining parameters from Skip-Gram model')
('aspect extraction', 'Used-for', 'aspect-based sentiment analysis')
('neural word embeddings', 'Used-for', 'improving coherence of aspects')
('dictionary-based mapping', 'Used-for', 'bilingual word embeddings')
('neural network-based models', 'Used-for', 'Chinese word segmentation')
('neural encoder-decoder', 'Used-for', 'semantic graph parsing')
('multimodal word embeddings', 'Used-for', 'entailment')
('Context-Aware Network Embedding', 'Used-for', 'link prediction')
('Gated-Attention Reader', 'Used-for', 'answering cloze-style questions')
('gated attention-based recurrent networks', 'Used-for', 'obtain question-aware passage representation')
('self-matching attention mechanism', 'Used-for', 'refine passage representation')
('pointer networks', 'Used-for', 'locate positions of answers')
('SQuAD dataset', 'Evaluate-for', 'reading comprehension models')
('sentence selection', 'Used-for', 'produce answers from selected sentences')
('cloze-style reading comprehension', 'Hyponym-Of', 'reading comprehension')
('attention-over-attention reader', 'Used-for', 'cloze-style reading comprehension')
('N-best re-ranking strategy', 'Used-for', 'validate the candidates')
('constituent-centric neural architecture', 'Used-for', 'generation of candidate answers')
('TriviaQA', 'Used-for', 'test reading comprehension models\nNone\n(None')
('highway network', 'Used-for', 'controlling useful neighbourhood expansion in GCN')
('highway network', 'Part-of', 'multilayer recurrent highway network')
('multilayer recurrent highway network', 'Used-for', 'modeling temporal nature of spoken speech')
('GCN', 'Used-for', 'multiview geolocation')
('gated attention-based recurrent networks', 'Used-for', 'obtaining question-aware passage representation')
('self-matching attention mechanism', 'Used-for', 'refining passage representation')
('pointer networks', 'Used-for', 'locating answer positions in passages')
('sequential matching network', 'Used-for', 'response selection in multi-turn conversation')
('Graph Convolutional Networks', 'Used-for', 'text and network context analysis in geolocation')
('Pre-train and Plug-in Variational Auto-Encoder', 'Used-for', 'flexible conditional text generation')
('language-aware interlingua', 'Used-for', 'learning language-independent representation in multilingual NMT')
('BERT', 'Used-for', 'obtaining domain-related contextualized representations')
('Multi-Choice Matching Networks', 'Used-for', 'unifying low-shot relation extraction')
('multiple synonyms\n(word-embedding models', 'Used-for', 'caption generation')
('heuristic search', 'Used-for', 'learning graph-to-string rules')
('heuristic search', 'Used-for', 'bootstrap a neural transducer')
('heuristic search', 'Evaluate-for', 'AMR-to-text generation')
('heuristic search', 'Part-of', 'paradigm discovery problem')
('heuristic search', 'Evaluate-for', 'lexical clustering in paradigm discovery')
('NAS', 'Used-for', 'architecture search')
('AMR-to-text generation', 'Evaluate-for', 'neural architecture search')
('graph transducer', 'Used-for', 'collapsing input AMRs')
('neural transducer', 'Used-for', 'predict words in empty paradigm slots')
('RBE', 'Evaluate-for', 'textual content moderation')
('context-sensitive grammar', 'Is-a-Prerequisite-of', 'SCFG')
('context-sensitive grammar', 'Compare', 'CFG')
('SCFG', 'Is-a-Prerequisite-of', 'STAG')
('STAG', 'Part-of', 'Weirs hierarchy')
('Weirs hierarchy', 'Used-for', 'defining language classes')
('bidirectional gated recurrent structures', 'Used-for', 'lemma identification')
('lemma identification', 'Used-for', 'language processing')
('context-sensitive grammar', 'Evaluate-for', 'natural language processing applications')
('edit tree', 'Used-for', 'representing transformations in lemmatization')
('context-sensitive embeddings', 'Used-for', 'prepositional phrase attachment prediction')
('context-sensitive embeddings', 'Part-of', 'neural network architectures')
('neural network architectures', 'Used-for', 'NLP tasks')
('bi-directional LSTMs', 'Used-for', 'machine translation')
('convolutional layers', 'Used-for', 'machine machine translation')
('recurrent networks', 'Compare', 'convolutional layers')
('Deep Neural Networks', 'Used-for', 'Neural Machine Translation')
('Linear Associative Units', 'Used-for', 'reducing gradient problems in RNNs')
('multiagent policies', 'Used-for', 'machine translation through differentiable communication channels')
('neural machine translation', 'Hyponym-Of', 'machine translation')
('Grammatical error correction', 'Part-of', 'machine translation')
('output layer optimization', 'Evaluate-for', 'neural machine translation')
('neural machine translation', 'Used-for', 'learning morphology')
('layer-wise relevance propagation', 'Used-for', 'interpreting neural machine translation')
('posterior regularization', 'Used-for', 'integrating\n(None')
('vector semantics', 'Used-for', 'representing words in NLP tasks')
('word embedding', 'Is-a-Prerequisite-of', 'vector semantics')
('semantic relevance', 'Evaluate-for', 'vector semantics')
('vector semantics', 'Compare', 'distributional semantic models')
('compositional semantics', 'Part-of', 'semantic relevance')
('semantic models', 'Hyponym-Of', 'vector semantics')
('vector semantics', 'Used-for', 'semantic similarity evaluation')
('sentence embeddings', 'Part-of', 'vector semantics')
('vector semantics', 'Used-for', 'decode fMRI patterns')
('unsupervised embeddings', 'Part-of', 'vector semantics')
('sentiment-aware embeddings', 'Part-of', 'vector semantics')
('domain-specific embeddings', 'Part-of', 'vector semantics')
('sentence content task', 'Evaluate-for', 'vector semantics')
('paragraph embeddings', 'Part-of', 'vector semantics')
('multi-space variational encoder-decoders', 'Used-for', 'labeled sequence transduction')
('neural networks', 'Used-for', 'handling discrete and continuous latent variables')
('semi-supervised learning', 'Used-for', 'exploiting unlabeled data in tasks')
('generative model', 'Part-of', 'multi-space variational encoder-decoders')
('semi-supervised learning', 'Is-a-Prerequisite-of', 'multi-space variational encoder-decoders')
('semi-supervised learning', 'Is-a-Prerequisite-of', 'Generative Domain-Adaptive Nets')
('Hybrid Code Networks', 'Used-for', 'dialog systems')
('semi-supervised learning', 'Used-for', 'boosting performance of question answering models')
('semi-supervised label propagation algorithm', 'Used-for', 'learning goal-acts for specific locations')
('semi-supervised learning', 'Used-for', 'inflection generation')
('Generative Domain-Adaptive Nets\n(parsing', 'Used-for', 'code generation')
('parsing', 'Used-for', 'semantic role labeling')
('natural language descriptions', 'Is-a-Prerequisite-of', 'parsing')
('parsing', 'Evaluate-for', 'generation of complex programs')
('tree structures', 'Used-for', 'parsing')
('AMR parsing', 'Used-for', 'Abstract Meaning Representation')
('parsing', 'Used-for', 'dependency graph generation')
('syntax', 'Used-for', 'parsing')
('parsing', 'Used-for', 'sequence tagging')
('token-based dependency parsing', 'Hyponym-Of', 'parsing')
('sequence-based parsing models', 'Hyponym-Of', 'parsing')
('CCG parsing', 'Hyponym-Of', 'parsing')
('parsing', 'Used-for', 'translation')
('convolutional neural network', 'Used-for', 'text categorization')
('convolutional neural network', 'Used-for', 'local coherence model')
('convolutional neural network', 'Used-for', 'multi-modal neural machine translation')
('convolutional neural network', 'Used-for', 'character embeddings generation')
('convolutional neural network', 'Used-for', 'entity grid representation in text')
('convolutional neural network', 'Used-for', 'domain adaptability in sentence compression')
('convolutional neural network', 'Compare', 'recurrent neural network')
('convolutional neural network', 'Is-a-Prerequisite-of', 'deep pyramid CNN')
('convolutional neural network', 'Hyponym-Of', 'deep pyramid CNN')
('deep pyramid CNN', 'Used-for', 'sentiment classification')
('deep pyramid CNN', 'Used-for', 'topic\n(None')
('topic modeling', 'Used-for', 'document context modeling')
('topic modeling', 'Compare', 'LDA topic model')
('Tandem Anchors', 'Used-for', 'interactive topic modeling')
('topic modeling', 'Used-for', 'understanding large text collections')
('topic-like architecture', 'Part-of', 'neural language model')
('Tandem Anchors', 'Hyponym-Of', 'topic modeling techniques')
('topic models', 'Evaluate-for', 'aspect-based sentiment analysis')
('topic modeling', 'Used-for', 'generating related sentences for a topic')
('Integer Linear Programming', 'Is-a-Prerequisite-of', 'Compressive Summarization')
('Integer Linear Programming', 'Used-for', 'Event Coreference Resolution')
('Integer Linear Programming', 'Used-for', 'Multi-Document Summarization')
('Integer Linear Programming', 'Used-for', 'Revealing Upper Bound Performance')
('Integer Linear Programming', 'Evaluate-for', 'User Feedback Optimization')
('Non-Autoregressive Unsupervised Summarization', 'Used-for', 'Efficient Text Summarization')
('supervised machine learning models', 'Part-of', 'machine learning resource')
('unsupervised machine learning', 'Part-of', 'machine learning resource')
('autoML', 'Part-of', 'machine learning resource')
('feature attribution methods', 'Used-for', 'machine learning resource')
('unlexicalized parsing', 'Used-for', 'predicting graphs jointly with token alignments')
('neural encoder-decoder transition-based parser', 'Used-for', 'full-coverage semantic graph parsing')
('neural encoder-decompiler transition-based parser', 'Is-a-Prerequisite-of', 'unlexicalized parsing')
('GPU batch processing', 'Evaluate-for', 'speed of parsing')
('Relational Realizational Grammar', 'Compare', 'Lexicalized Grammar')
('NeuralREG', 'Used-for', 'deciding form and content of discourse references')
('parameterized lexicalized-PCFGs', 'Used-for', 'modeling bilexical dependencies')
('argumentation datasets', 'Used-for', 'analyzing argumentative text')
('argumentation datasets', 'Used-for', 'developing computational methods')
('participant profiles', 'Evaluate-for', 'analyzing the effect of user traits on debate outcome')
('linguistic features', 'Compare', 'user traits')
('debate outcome', 'Is-a-Prerequisite-of', 'user traits')
('debate outcome', 'Is-a-Prerequisite-of', 'linguistic features')
('logistic regression', 'Used-for', 'probing PTLMs')
('PTLMs', 'Hyponym-Of', 'language models')
('toxicity', 'Part-of', 'NLP challenges')
('logistic regression', 'Used-for', 'quantifying harmful content')
('CDRNN', 'Is-a-Prerequisite-of', 'studying human language processing')
('linguistic representations', 'Used-for', 'enhancing cross-domain performance')
('transformer-based architecture', 'Used-for', 'relation extraction')
('syntactic graphs', 'Conjunction', 'semantic graphs')
('language models', 'Used-for', 'predicting masked tokens')
('relation extraction', 'Evaluate-for', 'generalization in NLP')
('sequence classification', 'Used-for', 'natural language understanding')
('machine reading comprehension', 'Part-of', 'natural language understanding')
('cross-lingual span extraction', 'Used-for', 'natural language understanding')
('source-language fine-tuning', 'Is-a-Prerequisite-of', 'cross-lingual generalization')
('mPMR', 'Used-for', 'cross-lingual generalization')
('mPLMs', 'Used-for', 'natural language understanding')
('mPMR', 'Used-for', 'sequence classification')
('mPMR', 'Used-for', 'cross-lingual span extraction')
('Keyphrase boundary classification', 'Part-of', 'scientific article summarization')
('Semantic super-sense tagging', 'Used-for', 'scientific article summarization')
('Multi-word expressions identification', 'Used-for', 'scientific article summarization')
('Deep recurrent neural networks', 'Used-for', 'scientific article summarization')
('Scientific article summarization', 'Used-for', 'generating summaries for scientific papers')
('Video of talks', 'Used-for', 'scientific article summarization')
('Paper summaries dataset', 'Hyponym-Of', 'scientific article summarization')
('Transformer-based model', 'Used-for', 'scientific article summarization')
('Decoder', 'Part-of', 'Transformer-based model')
('Encoder-decoder attention', 'Used-for', 'copy mechanism')
('Self-attention layer', 'Part-of', 'Transformer-based model')
('Degree centrality', 'Used-for', 'guiding the copy process in summarization')
('Seq2seq network', 'Used-for', 'text summarization')
('Salient ontological terms', 'Used-for', 'enhancing clinical abstractive summarization')
('MIMIC-CXR', 'Part-of', 'clinical data')
('regular expression', 'Used-for', 'pattern matching')
('regular expression', 'Compare', 'natural language')
('StructuredRegex', 'Used-for', 'regex synthesis')
('regex synthesis', 'Part-of', 'NLP tasks')
('regular expression', 'Used-for', 'search and replace operations')
('regex', 'Is-a-Prerequisite-of', 'regex generation from natural language')
('regex generation from natural language', 'Evaluate-for', 'linguistic diversity')
('structured complex regexes', 'Part-of', 'StructuredRegex')
('linguistically diverse descriptions', 'Used-for', 'understanding complex regexes')
('StackOverflow', 'Used-for', 'real-world regex examples collection')
('regex generation', 'Used-for', 'regex tasks automation')
('real users examples', 'Used-for', 'regex testing')
('None', 'Is-a-Prerequisite-of', 'spectral clustering')
('spectral clustering', 'Used-for', 'word embeddings')
('word embeddings', 'Compare', 'sentence embeddings')
('Multi-document summarization', 'Evaluate-for', 'large document collections')
('Wikipedia Current Events Portal', 'Used-for', 'Multi-document summarization dataset')
('Common Crawl', 'Used-for', 'Multi-document summarization dataset extension')
('DeCLUTR', 'Used-for', 'unsupervised sentence embeddings pretraining')
('deep metric learning', 'Used-for', 'DeCLUTR')
('mixture prior autoencoding topic model', 'Used-for', 'data clustering')
('ensemble language model', 'Evaluate-for', 'diverse linguistic samples')
('Feature Cluster Loss Correction', 'Used-for', 'noise correction in fine-grained entity typing')
('language modeling', 'Used-for', 'generation of conversational text')
('language modeling', 'Used-for', 'generation of rhythmic poetry')
('language modeling', 'Used-for', 'parsing sentences to semantic representations')
('language modeling', 'Used-for', 'sentence prediction')
('language modeling', 'Part-of', 'artificial intelligence')
('language modeling', 'Evaluate-for', 'language model perplexity')
('language modeling', 'Hyponym-Of', 'natural language processing')
('rhythmic poetry', 'Used-for', 'language modeling')
('conversational text', 'Used-for', 'language modeling')
('semantic representations', 'Used-for', 'language modeling')
('sentence prediction', 'Used-for', 'language modeling')
('language model perplexity', 'Evaluate-for', 'language modeling')
('neural networks', 'Used-for', 'language modeling')
('recurrent neural networks', 'Used-for', 'language modeling')
('language modeling', 'Hyponym-Of', 'machine learning')
('kernelized neural network', 'Part-of', 'language modeling')
('machine learning', 'Hyponym-Of', 'language modeling')
('language modeling', 'Part-of', 'knowledge graph building')
('Semantic parsing', 'Evaluate-for', 'Sentence representation')
('Neural semantic parser', 'Used-for', 'Converting natural language utterances')
('Predicate-argument structures', 'Part-of', 'Semantic parsing')
('Domain-general natural language representations', 'Hyponym-Of', 'Sentence representation')
('Intermediate representations', 'Hyponym-Of', 'Sentence representation')
('Transition system', 'Used-for', 'Inducing predicate-argument structures')
('Morph-fitting procedure', 'Used-for', 'Improving distributional vector spaces')
('Vector space models', 'Evaluate-for', 'Language understanding systems')
('Dialogue state tracking', 'Used-for', 'Morph-fitted vectors')
('AMR', 'Is-a-Prerequisite-of', 'Semantic parsing')
('Translation of sentences', 'Used-for', 'Neural machine translation')
('Convolutional layers', 'Used-for', 'Encoding source sentences')
('text mining', 'Used-for', 'extracting knowledge of actions and objects from language')
('joint inference', 'Used-for', 'improving performance in knowledge acquisition')
('ontological resources', 'Used-for', 'scoring semantic fluency responses')
('distributional semantic models', 'Used-for', 'characterizing semantic fluency')
('hierarchical information', 'Used-for', 'predicting compositionality of phrases')
('distributional information', 'Used-for', 'predicting compositionality of phrases')
('semantic similarity', 'Used-for', 'plagiarism detection')
('semantic similarity', 'Used-for', 'information ranking')
('semantic similarity', 'Used-for', 'recognition of paraphrases')
('semantic similarity', 'Used-for', 'textual entailment recognition')
('TextFlow', 'Evaluate-for', 'semantic similarity')
('semantic similarity', 'Hyponym-Of', 'text similarity measures')
('Semantic Relevance Based neural model', 'Used-for', 'improve semantic relevance')
('sentence mover’s similarity', 'Used-for', 'evaluating machine-generated texts')
('semantic similarity', 'Part-of', 'NLP tasks')
('semantic similarity', 'Compare', 'lexical overlap')
('semantic similarity', 'Evaluate-for', 'image description generation')
('semantic similarity', 'Used-for', 'sentence semantic similarity prediction')
('Dirichlet Processes', 'Used-for', 'modeling topics in NLP tasks')
('Hierarchical Dirichlet Process', 'Is-a-Prerequisite-of', 'multiple topic-sensitive representations')
('multiple topic-sensitive representations', 'Used-for', 'distinguishing between different meanings of words')
('lexical substitution task', 'Evaluate-for', 'effectiveness of word representations')
('REV', 'Used-for', 'evaluating rationale-label pairs')
('REV', 'Compare', 'existing metrics')
('information-theoretic perspective', 'Used-for', 'evaluating new information in rationales')
('conditional V-information', 'Used-for', 'quantifying new information in rationales')
('rationale evaluations', 'Evaluate-for', 'consistency with human judgments')
('mean field approximation', 'Used-for', 'second-order semantic dependency parsing')
('mean field approximation', 'Hyponym-Of', 'variational inference')
('variational inference', 'Used-for', 'neural mixed counting models')
('second-order semantic dependency parsing', 'Used-for', 'approximating interactions between dependency edges')
('neural mixed counting models', 'Evaluate-for', 'dispersed topic discovery')
('belief propagation', 'Used-for', 'evaluating the similarities between propagation tree structures in rumor detection')
('belief propagation', 'Used-for', 'computing the contribution of contextual words in neural machine translation')
('belief propagation', 'Used-for', 'analyzing token contributions in neural machine translation')
('belief propagation', 'Used-for', 'capturing robust structural features in rumor detection')
('belief propagation', 'Used-for', 'approximating second-order semantic dependency parsing')
('None', 'Compare', 'None')
('None', 'Evaluate-for', 'None')
('Kullback Leibler divergence', 'Used-for', 'approximate a model’s posterior on latent variables')
('Kullback Leibler divergence', 'Hyponym-Of', 'Statistical measure')
('Posterior collapse', 'Evaluate-for', 'Kullback Leibler divergence')
('Variational Autoencoder', 'Used-for', 'generative model')
('VAE', 'Part-of', 'Variational Autoencoder')
('Batch Normalized-VAE', 'Is-a-Prerequisite-of', 'Variational Autoencoder')
('BN-VAE', 'Used-for', 'regularizing the distribution of the approximate posterior’s parameters')
('Conditional VAE', 'Hyponym-Of', 'Variational Autoencoder')
('BN-VAE', 'Conjunction', 'Conditional VAE')
('entailment', 'Used-for', 'Natural Language Inference')
('entailment', 'Used-for', 'Recognizing Textual Entailment')
('Textual Entailment Recognition', 'Hyponym-Of', 'Natural Language Inference')
('knowledge-guided adversarial example generators', 'Used-for', 'entailment models')
('Natural Language Inference', 'Evaluate-for', 'logical relationship inference')
('entailment datasets', 'Used-for', 'evaluating NLI models')
('textual entailment', 'Part-of', 'NLI tasks')
('expectation maximization algorithm', 'Used-for', 'parsing and language modeling')
('expectation maximisation algorithm', 'Evaluate-for', 'variational inference')
('expectation maximization algorithm', 'Evaluate-for', 'denoising word alignment')
('expectation maximization algorithm', 'Is-a-Prerequisite-of', 'understanding neural decoder optimization')
('expectation maximization algorithm', 'Used-for', 'sequence labeling')
('expectation maximization algorithm', 'Used-for', 'learning latent variable models')
('expectation maximization algorithm', 'Used-for', 'unsupervised reconstruction of ancient word forms')
('expectation maximization algorithm', 'Used-for', 'modeling annotator group bias')
('expectation maximization algorithm', 'Used-for', 'multi-party dialogue response generation')
('expectation maximization algorithm', 'Used-for', 'discovering new intents in dialogue systems')
('variational inference', 'Is-a-Prerequisite-of', 'understanding the optimization of generative models')
('parsing and language modeling', 'Part-of', 'natural language processing')
('denoising word alignment', 'Used-for', 'improving cross-lingual transferability')
('multi\n(semantic parser', 'Used-for', 'knowledge representation')
('predicate-argument structures', 'Part-of', 'semantic parser')
('intermediate representations', 'Part-of', 'knowledge representation')
('AMR parsing', 'Used-for', 'knowledge representation')
('AMR generation', 'Used-for', 'knowledge representation')
('graph-to-sequence conversions', 'Part-of', 'AMR parsing')
('unsupervised learning', 'Used-for', 'generating Arabic word embeddings')
('unsupervised learning', 'Used-for', 'word-level language detection')
('unsupervised learning', 'Used-for', 'Neural Machine Translation')
('unsupervised learning', 'Evaluate-for', 'metaphor identification task')
('unsupervised generative model', 'Part-of', 'automatic error detection in text annotations')
('unsupervised learning', 'Is-a-Prerequisite-of', 'creating language resources without labeled data')
('unsupervised learning', 'Used-for', 'analyzing code-switched text')
('unsupervised Neural Machine Translation', 'Hyponym-Of', 'unsupervised learning')
('unsupervised learning', 'Used-for', 'training models without labeled data')
('unsupervised learning', 'Used-for', 'inducing bilingual dictionaries')
('bilingual word embeddings', 'Used-for', 'cross-lingual twitter sentiment classification')
('bilingual word embeddings', 'Used-for', 'medical bilingual lexicon induction')
('adversarial training', 'Used-for', 'mapping monolingual embeddings to a shared space')
('word embedding variation', 'Evaluate-for', 'effectiveness in unsupervised bilingual dictionary induction')
('Probabilistic FastText', 'Is-a-Prerequisite-of', 'multi-sense representations')
('Gaussian mixtures', 'Used-for', 'modeling multimodal word distributions in word embeddings')
('word embedding variation', 'Used-for', 'capturing uniquely expressive semantic information')
('None', 'Part-of', 'sequence-to-sequence models')
('sequence-to-sequence models', 'Used-for', 'parsing and generating text using Abstract Meaning Representation')
('sequence-to-sequence models', 'Used-for', 'neural machine translation')
('sequence-to-sequence models', 'Used-for', 'text summarization')
('sequence-to-sequence models', 'Used-for', 'abstractive sentence summarization')
('sequence-to-sequence models', 'Used-for', 'video captioning')
('sequence-to-sequence models', 'Used-for', 'Chinese poem generation')
('sequence-to-sequence models', 'Used-for', 'text simplification')
('sequence-to-sequence models', 'Used-for', 'confidence modeling in neural semantic parsers')
('sequence-to-sequence models', 'Used-for', 'grammatical error correction')
('sequence-to-sequence models', 'Used-for', 'task-oriented dialogue systems')
('memory mechanism', 'Used-for', 'balancing linguistic accordance and\n(None')
('DPCCA', 'Used-for', 'optimizing bilingual text embeddings')
('PCCA', 'Used-for', 'bilingual text embeddings')
('Canonical Correlation Analysis', 'Used-for', 'aligning generic and domain specific word embeddings')
('canonical correlation analysis', 'Compare', 'Kernel CCA')
('Generalized Canonical Correlation Analysis', 'Used-for', 'meta-embedding methods')
('Deep PCCA', 'Is-a-Prerequisite-of', 'DPCCA')
('Partial Canonical Correlation Analysis', 'Is-a-Prerequisite-of', 'Deep PCCA')
('sampling', 'Used-for', 'generating word representations')
('sampling', 'Used-for', 'learning model parameters')
('stochastic gradient descent', 'Used-for', 'optimization')
('negative sampling', 'Is-a-Prerequisite-of', 'word2vec')
('Skip-Gram Negative Sampling', 'Hyponym-Of', 'negative sampling')
('stochastic gradient descent', 'Compare', 'Riemannian optimization')
('latent variables', 'Used-for', 'improving variational autoencoder')
('active learning', 'Used-for', 'training data collection')
('active learning', 'Used-for', 'adapting neural models')
('sampling', 'Evaluate-for', 'efficiency in machine learning tasks')
('AllVec', 'Compare', 'stochastic gradient descent with negative Its')
('negative sampling', 'Used-for', 'training distributed word representations')
('uncertainty sampling', 'Used-for', 'testing active learning strategies')
('latent variables', 'Used-for', 'hidden state averaging')
('hybrid semi-Markov conditional random fields', 'Is-a-Prerequisite-of', 'neural sequence labeling')
('conditional random fields', 'Part-of', 'hybrid semi-Markov conditional random fields')
('word-level labels', 'Used-for', 'deriving segment scores in SCRFs')
('segment-level information', 'Used-for', 'SCRF methods')
('CRF output layer', 'Conjunction', 'SCRF output layer')
('neural semi-Markov CRF alignment model', 'Used-for', 'monolingual word alignment')
('external gazetteers', 'Used-for', 'benefiting segmental neural NER models')
('monolingual word alignment', 'Evaluate-for', 'text-to-text generation tasks')
('hybrid semi-Markov CRF architecture', 'Part-of', 'segmental neural NER models')
('external knowledge', 'Compare', 'hand-crafted features')
('autoencoders', 'Used-for', 'natural language generation')
('autoencoders', 'Used-for', 'latent variable approximation')
('autoencoders', 'Part-of', 'variational autoencoders')
('autoencoders', 'Used-for', 'unsupervised paraphrasing')
('autoencoders', 'Used-for', 'syntax transfer generation')
('autoencoders', 'Used-for', 'generating syntactically controlled sentences')
('autoencoders', 'Part-of', 'syntax-infused variational autoencoder')
('autoencoders', 'Used-for', 'preventing posterior collapse')
('autoencoders', 'Used-for', 'generative modeling')
('autoencoders', 'Used-for', 'machine translation evaluation')
('Variational autoencoders', 'Is-a-Prerequisite-of', 'syntax-infused variational autoencoder')
('Syntax-infused variational autoencoder', 'Used-for', 'improving sentence grammar')
('Syntax-infused variational autoencoder', 'Used-for', 'generating sentences and syntactic trees')
('Latent variables', 'Part-of', 'Variational autoencoders')
('Sufficient Dimensionality Reduction', 'Used-for', 'obtaining parameters from Skip-Gram models')
('Latent Vector Grammars', 'Is-a-Prerequisite-of', 'GM-LVeGs')
('Gaussian Mixture LVeGs', 'Used-for', 'part-of-speech tagging and constituency parsing')
('Probabilistic FastText', 'Used-for', 'capturing multiple word senses and sub-word structures')
('mixture models', 'Used-for', 'formulating weights in Gaussian Mixture LVeGs')
('mixture models', 'Used-for', 'representing word senses in Probabilistic FastText')
('multi-space variational encoder-decoders', 'Used-for', 'labeled sequence transduction')
('recurrent neural networks', 'Used-for', 'dialog systems')
('Hybrid Code Networks', 'Used-for', 'dialog state representation')
('interactive topic models', 'Used-for', 'understanding text collections')
('LSTM Noisy Channel Model', 'Used-for', 'disfluency detection')
('holographic embeddings', 'Compare', 'complex embeddings')
('bi-directional LSTMs', 'Used-for', 'text representation')
('language-model-based evaluator', 'Used-for', 'sentence compression')
('generative neural network model', 'Used-for', 'slot filling')
('cross-lingual word embedding', 'Used-for', 'neural machine translation')
('gender bias in machine translation', 'Evaluate-for', 'automatic evaluation method')
('context-aware network embeddings', 'Used-for', 'network analysis')
('Mild Cognitive Impairment', 'Used-for', 'detecting MCI')
('Complex Networks Enriched with Embedding', 'Used-for', 'representing short texts')
('Complex Networks Enriched with Embedding', 'Evaluate-for', 'MCI detection')
('Support Vector Machine', 'Compare', 'LSTM-based recurrent neural network')
('Support Vector Machine', 'Used-for', 'MCI classification')
('Support Vector Machine', 'Compare', 'traditional classifiers')
('Abugida graphemes', 'Used-for', 'developing input methods')
('Support Vector Machine', 'Used-for', 'recovering original text in abugida')
('Simultaneous machine translation', 'Used-for', 'live and streaming scenarios')
('Simultaneous machine translation', 'Used-for', 'balancing quality against latency')
('Monotonic Infinite Lookback attention', 'Part-of', 'simultaneous translation system')
('Neural machine translation model', 'Used-for', 'adaptive scheduling')
('Monotonic Infinite Lookback attention', 'Compare', 'wait-k strategy')
('Multi-agent system', 'Used-for', 'automatic CXR report generation')
('Findings', 'Is-a-Prerequisite-of', 'Impression')
('Neural machine translation model', 'Hyponym-Of', 'Machine Translation')
('GIZA++', 'Used-for', 'training statistical machine translation models')
('Transformer model', 'Used-for', 'unsupervised word alignment')
('Multi-agent communication', 'Used-for', 'natural language learning')
('Multi-agent system', 'Conjunction', 'traditional data-driven approaches')
('Spatio-Temporal Video Question Answering', 'Used-for', 'retrieving moments and detecting visual concepts')
('first-order logic', 'Used-for', 'reasoning in TECHS')
('first-order logic', 'Used-for', 'pruning in SMP')
('first-order logic', 'Used-for', 'document-level event argument extraction')
('TECHS', 'Part-of', 'first-order reasoning')
('SMP', 'Used-for', 'adapting PLMs to downstream tasks')
('first-order pruning', 'Used-for', 'compression of PLMs')
('first-order pruning', 'Part-of', 'SMP')
('dependency parsers', 'Used-for', 'analysis of syntactic structure')
('neural encoders', 'Used-for', 'dependency parsing')
('BERT', 'Used-for', 'neural parsing')
('Temporal logiCal grapH networkS', 'Hyponym-Of', 'reasoning frameworks')
('chain reasoning', 'Used-for', 'event argument extraction')
('cross entropy', 'Used-for', 'training extractive summarization models')
('cross entropy', 'Used-for', 'knowledge distillation')
('cross entropy', 'Evaluate-for', 'perfecting token-level adaptive training in machine translation')
('cross entropy', 'Used-for', 'training autoregressive language models')
('cross entropy', 'Is-a-Prerequisite-of', 'structured prediction in knowledge distillation')
('cross entropy', 'Compare', 'negative sampling loss functions')
('cross entropy', 'Part-of', 'MixCE objective')
('knowledge distillation', 'Used-for', 'transferring knowledge between models')
('structured prediction', 'Part-of', 'knowledge distillation')
('MixCE objective', 'Used-for', 'improving text generation in language models')
('token-level adaptive training', 'Used-for', 'alleviating token imbalance in machine translation')
('semantic role labeling', 'Used-for', 'predicate-argument structure recognition')
('semantic role labeling', 'Used-for', 'dependency SRL')
('semantic role labeling', 'Evaluate-for', 'improving Chinese SRL')
('semantic role labeling', 'Used-for', 'argument span detection')
('semantic role labeling', 'Used-for', 'question generation')
('semantic role labeling', 'Used-for', 'syntactic information utilization')
('semantic role labeling', 'Used-for', 'modeling the syntax-semantic dependency correlation')
('semantic role labeling', 'Evaluate-for', 'span-level accuracy')
('semantic role facts', 'Used-for', 'semantic structure reasoning')
('deep highway BiLSTM architecture', 'Part-of', 'semantic role labeling')
('semantic role labeling', 'Used-for', 'high semantic similarity promotion')
('evaluation of text classification', 'Used-for', 'analyzing model performance')
('evaluation of text classification', 'Evaluate-for', 'perplexity')
('evaluation of text classification', 'Evaluate-for', 'Normalized Pointwise Mutual Information')
('evaluation of text alerts', 'Evaluate-for', 'Micro F1 measure')
('evaluation of text classification', 'Evaluate-for', 'sentence compositionality')
('evaluation of text classification', 'Evaluate-for', 'handling rare words through character embeddings')
('evaluation of text classification', 'Evaluate-for', 'semantic coherence')
('evaluation of text classification', 'Evaluate-for', 'adversarial robustness')
('evaluation of text classification', 'Used-for', 'discourse structure analysis')
('word sense disambiguation', 'Used-for', 'identifying the correct meaning of polysemous words')
('WordNet', 'Used-for', 'word sense disambiguation')
('lexical ambiguity', 'Is-a-Prerequisite-of', 'word sense disambiguation')
('disambiguation algorithm', 'Used-for', 'word sense disambiguation')
('lexical resources', 'Used-for', 'word sense disambiguation')
('contextual embeddings', 'Used-for', 'word sense disambiguation')
('Neural Language Modelling', 'Used-for', 'word sense disambiguation')
('rare senses', 'Evaluate-for', 'word sense disambiguation effectiveness')
('neural architectures', 'Used-for', 'word sense disambiguation')
('knowledge bases', 'Used-for', 'word sense disambiguation')
('lexical knowledge', 'Used-for', 'word sense disambiguation')
('sense\n(semantic parsing', 'Is-a-Prerequisite-of', 'nlp for database')
('transformer models', 'Used-for', 'answering queries from natural language text')
('nlp for database', 'Used-for', 'supporting database queries')
('modular architecture', 'Used-for', 'answering database-style queries')
('nlp for database', 'Evaluate-for', 'reasoning over sets of relevant facts')
('WikiNLDB', 'Used-for', 'evaluating nlp for database systems')
('finite state machine', 'Used-for', 'part-of-speech tagging')
('finite state machine', 'Used-for', 'speech recognition')
('finite state machine', 'Used-for', 'higher-order derivatives computation')
('finite state machine', 'Used-for', 'morph-based auto-completion')
('FST composition operation', 'Part-of', 'finite state machine')
('morph-based auto-completion', 'Used-for', 'incremental building of complex words')
('finite state transducers', 'Hyponym-Of', 'weighted finite-state machines')
('neural parsing', 'Used-for', 'linguistically-expressive semantic representations')
('neural parsing', 'Is-a-Prerequisite-of', 'semantic dependency graph formalisms')
('neural parsing', 'Evaluate-for', 'Minimal Recursion Semantics (MRS')
('neural parsing', 'Evaluate-for', 'Abstract Meaning Representation (AMR')
('NMT+RN&G', 'Evaluate-for', 'neural parsing')
('neural parsing', 'Part-of', 'Natural Language Processing')
('neural encoder-decoder transition-based parser', 'Used-for', 'neural parsing')
('neural parsing', 'Used-for', 'building semantic graphs')
('neural parsing', 'Used-for', 'sentence parsing')
('stack-based embedding features', 'Used-for', 'neural parsing')
('neural parsing', 'Used-for', 'predicting graphs jointly')
('dynamic programming', 'Used-for', 'constituency parsing')
('dynamic programming', 'Used-for', 'greedy top-down inference algorithm')
('dynamic programming', 'Used-for', 'integer linear programming formulation')
('dynamic programming', 'Used-for', 'non-projectivity in dependency parsing')
('dynamic programming', 'Used-for', 'latent tree learning')
('dynamic programming', 'Used-for', 'temporal and causal relations extraction')
('dynamic programming', 'Used-for', 'sentence segmentation')
('dynamic programming', 'Part-of', 'subword segmentation algorithm')
('dynamic programming', 'Used-for', 'unsupervised summarization')
('dynamic programming', 'Used-for', 'length-control decoding')
('constituency parsing', 'Is-a-Prerequisite-of', 'state-of-the-art single-model performance')
('greedy top-down inference algorithm', 'Part-of', 'constituency parsing')
('integer linear programming\n(text to speech generation', 'Used-for', 'generating speech mel-spectrograms')
('Non-autoregressive text to speech models', 'Part-of', 'text to speech generation')
('text to speech generation', 'Compare', 'Non-autoregressive text to speech models')
('Laplacian mixture loss', 'Used-for', 'modeling multimodal distributions in text to speech generation')
('GAN and Glow', 'Used-for', 'achieving best voice quality in text to speech generation')
('text to text generation', 'Evaluate-for', 'bias estimation')
('response generation', 'Is-a-Prerequisite-of', 'text to speech generation')
('text to speech generation', 'Evaluate-for', 'overcoming low coverage bias')
('Vocabulary Pyramid Network', 'Used-for', 'improving response generation')
('text to speech generation', 'Evaluate-for', 'voice quality improvement')
('word segmentation', 'Used-for', 'neural word segmentation')
('word segmentation', 'Used-for', 'statistical segmentation')
('pretraining character and word embeddings', 'Part-of', 'neural word segmentation')
('external training sources', 'Used-for', 'neural word segmentation')
('word embeddings', 'Used-for', 'dependency parsing')
('word segmentation', 'Is-a-Prerequisite-of', 'Chinese word segmentation')
('subword units', 'Used-for', 'neural machine translation')
('word embeddings', 'Hyponym-Of', 'distributed word representations')
('character embeddings', 'Part-of', 'word segmentation')
('adversarial multi-criteria learning', 'Used-for', 'Chinese word segmentation')
('Chinese word segmentation', 'Evaluate-for', 'segmentation criteria')
('neural network-based joint models', 'Used-for', 'Chinese word segmentation')
('Bayesian unsupervised text\n(Query Expansion', 'Used-for', 'Attribute Value Extraction')
('Query Expansion', 'Evaluate-for', 'Performance Improvement in QA-based AVE')
('Knowledge-driven Query Expansion', 'Hyponym-Of', 'Query Expansion')
('Query Expansion', 'Used-for', 'Improving performance for rare and ambiguous queries')
('Noisy Channel Model', 'Used-for', 'Generating n-best candidate disfluency analyses')
('Noisy Channel Model', 'Part-of', 'LSTM Noisy Channel Model')
('MaxEnt reranker', 'Used-for', 'Identifying the most plausible analysis')
('LSTM language model', 'Evaluate-for', 'Scoring underlying fluent sentences')
('LSTM language model', 'Part-of', 'LSTM Noisy Channel Model')
('Weighted finite-state machines', 'Used-for', 'Building block of NLP systems')
('Weighted finite-state machines', 'Used-for', 'Computation of higher-order derivatives')
('Noisy Channel Model', 'Used-for', 'Language model prompting in few-shot text classification')
('Channel models', 'Compare', 'Direct models')
('Channel prompt tuning', 'Is-a-Prerequisite-of', 'Few-shot learning with limited updates')
('Channel models', 'Part-of', 'Noisy Channel Model')
('linear algebra', 'Used-for', 'solving algebraic word problems')
('linear algebra', 'Is-a-Prerequisite-of', 'Integer Linear Programming (ILP')
('Named Entity Recognition', 'Used-for', 'Information Extraction from biomedical abstracts')
('Named Entity Recognition', 'Is-a-Prerequisite-of', 'Coreference Resolution')
('Named Entity Recognition', 'Compare', 'Mention Detection')
('Named Entity Recognition', 'Part-of', 'Natural Language Processing')
('Named Entity Recognition', 'Used-for', 'Improving topic modeling in news content')
('Hidden Markov Model', 'Used-for', 'Aggregating crowd labels')
('Long Short Term Memory', 'Used-for', 'Predicting sequences in unannotated text')
('SynTime', 'Used-for', 'Time expression recognition')
('Lexical Resources', 'Used-for', 'Part-of-speech induction')
('Fixed-size Ordinally Forgetting Encoding', 'Used-for', 'Named Entity Recognition')
('Convolutional Neural Network', 'Used-for', 'Local coherence model')
('Bidirectional LSTM', 'Used-for', 'German named entity recognition')
('dependency syntax', 'Is-a-Prerequisite-of', 'transition-based parsing')
('transition-based parsing', 'Used-for', 'constructing dependency trees')
('transition-based parsers', 'Used-for', 'dependency parsing tasks')
('dependency syntax', 'Is-a-Prerequisite-of', 'statistical machine translation')
('dependency parsing tasks', 'Compare', 'classification scenarios')
('structural knowledge', 'Used-for', 'improving machine translation')
('token-based dependency parsing', 'Used-for', 'computational argumentation mining')
('dependency syntax', 'Part-of', 'natural language processing')
('dependency syntax', 'Evaluate-for', 'error reduction in NMT models')
('dependency syntax', 'Used-for', 'sentence semantic analysis')
('dependency syntax', 'Evaluate-for', 'increasing parsing accuracy')
('dependency parser', 'Used-for', 'semantic tree construction')
('Covington parser', 'Used-for', 'non-projective parsing')
('shift-reduce parsing', 'Evaluate-for', 'Chinese discourse parsing')
('shift-reduce parsing', 'Used-for', 'rhetorical relation recognition')
('shift-reduce parsing', 'Is-a-Prerequisite-of', 'syntax analysis')
('shift-reduce parsing', 'Part-of', 'constituency parsing')
('shift-reduce parsing', 'Compare', 'sequence-to-sequence constituent parsing')
('Chinese discourse parsing', 'Used-for', 'rhetorical relation recognition')
('syntactic distance', 'Used-for', 'topology determination')
('constituency parsing', 'Used-for', 'syntax analysis')
('in-order linearization', 'Compare', 'top-down tree linearization')
('policy gradient method', 'Used-for', 'directly optimizing for exact matches')
('policy gradient method', 'Used-for', 'reducing exposure bias during training')
('policy to policy gradient method', 'Evaluate-for', 'training constituency parsers')
('policy gradient method', 'Used-for', 'optimizing coreference evaluation metrics')
('policy gradient method', 'Used-for', 'training semantic dependency parsing models')
('policy gradient method', 'Used-for', 'fine-tuning language models')
('policy gradient method', 'Part-of', 'reinforcement learning')
('constituency parsers', 'Is-a-Prerequisite-of', 'policy gradient method')
('coreference resolution', 'Is-a-Prerequisite-of', 'policy gradient method')
('semantic dependency parsing', 'Is-a-Prerequisite-of', 'policy gradient method')
('language model training', 'Is-a-Prerequisite-of', 'policy gradient method')
('reinforcement learning', 'Hyponym-Of', 'machine learning')
('sentence-level policy gradient method', 'Used-for', 'summarization model training')
('dynamic oracles', 'Used-for', 'providing supervision for policy gradient training')
('Cross-lingual text classification', 'Used-for', 'taxonomy categorization')
('Model distillation', 'Is-a-Prerequisite-of', 'Cross-lingual text classification')
('Model distillation', 'Used-for', 'model compression')
('Adversarial feature adaptation', 'Used-for', 'reducing distribution mismatch')
('CARI', 'Evaluate-for', 'formal style transfer in text')
('CARI', 'Evaluate-for', 'improving pre-trained models performance on sentiment analysis')
('Gender bias', 'Evaluate-for', 'detection of exclusionary practices in language technologies')
('Misgendered', 'Used-for', 'evaluating large language models gender-neutral pronoun usage')
('Social bias benchmarks', 'Evaluate-for', 'ranking models based on bias representation')
('Misgendered', 'Used-for', 'improving language model accuracy in pronoun prediction')
('Cross-lingual text classification', 'Part-of', 'nlp for the humanity')
('Model distillation', 'Part-of', 'nlp for the humanity')
('None', 'Hyponym-Of', 'String Kernels')
('Kernel methods', 'Used-for', 'language learning')
('Kernel methods', 'Used-for', 'inference tasks')
('Tree Kernels', 'Used-for', 'NLP')
('String Kernels', 'Used-for', 'automatic essay scoring')
('None', 'Hyponym-Of', 'Representation Kernels')
('Deep neural networks', 'Compare', 'Kernel methods')
('Kernel methods', 'Used-for', 'modeling structured information')
('Kernel methods', 'Used-for', 'learning non-linear decision functions')
('Nystrom low-rank approximation', 'Evaluate-for', 'pre-training input layer')
('Kernel Graph Attention Network', 'Used-for', 'fine-grained fact verification')
('String Kernels', 'Used-for', 'similarity capture among strings')
('Domain Adapted word embeddings', 'Used-for', 'sentiment classification tasks')
('Deep neural networks', 'Evaluate-for', 'learning feature representations')
('Nystrom low-rank approximation', 'Part-of', 'Kernel methods')
('Structured prediction', 'Used-for', 'Evaluation of output structure')
('Structured prediction', 'Used-for', 'Coreference resolution')
('Loss function', 'Evaluate-for', 'Structured prediction')
('Loss function', 'Used-for', 'Coreference resolution')
('Loss function', 'Part-of', 'Unified model')
('Unified model', 'Used-for', 'Combining extractive and abstractive summarization')
('Extractive summarization', 'Used-for', 'Obtaining sentence-level attention')
('Abstractive summarization', 'Used-for', 'Generating readable paragraphs')
('Inconsistency loss function', 'Part-of', 'Novel loss function')
('Novel loss function', 'Used-for', 'Penalizing inconsistency')
('Max-violating constraint', 'Part-of', 'Loss function')
('Loss function', 'Used-for', 'Model comparison')
('Coreference resolution', 'Used-for', 'Evaluation of loss functions')
('image retrieval', 'Compare', 'image annotation')
('image retrieval', 'Compare', 'scene understanding')
('image retrieval', 'Used-for', 'action recognition')
('action recognition', 'Part-of', 'image retrieval')
('image retrieval', 'Used-for', 'image editing')
('image editing', 'Part-of', 'image retrieval')
('image retrieval', 'Compare', 'image compression')
('image retrieval', 'Compare', 'natural language compression')
('image compression', 'Compare', 'natural language compression')
('parsing evaluation', 'Used-for', 'semantic representations')
('parsing evaluation', 'Used-for', 'multilingual model training')
('multilingual model', 'Is-a-Prerequisite-of', 'parsing evaluation')
('parsing evaluation', 'Evaluate-for', 'multilingual GeoQuery corpus')
('parsing evaluation', 'Evaluate-for', 'multilingual ATIS corpus')
('statistical significance testing', 'Evaluate-for', 'parsing evaluation')
('natural language processing', 'Is-a-Prerequisite-of', 'semantic parsing')
('semantic parsing', 'Part-of', 'natural language processing')
('predicate-argument structures', 'Used-for', 'semantic parsing')
('neural semantic parser', 'Used-for', 'converting natural language to domain-specific languages')
('transition system', 'Used-for', 'inducing predicate-argument structures')
('annotated logical forms', 'Used-for', 'training semantic parsers')
('SPADES', 'Evaluate-for', 'semantic parsing performance')
('GRAPHQUESTIONS', 'Evaluate-for', 'semantic parsing performance')
('GEOQUERY', 'Evaluate-for', 'semantic parsing performance')
('WEBQUESTIONS', 'Evaluate-for', 'semantic parsing performance')
('predicate-argument structures', 'Used-for', 'mapping to target domains')
('reporting bias', 'Compare', 'commonsense knowledge')
('knowledge acquisition', 'Used-for', 'inferencing physical knowledge from text')
('program synthesis', 'Part-of', 'natural language processing')
('adversarial search', 'Used-for', 'creating robust self-learning algorithms')
('adversarial search', 'Used-for', 'improving model generalization through adversarial training')
('adversarial search', 'Used-for', 'evaluating cross-lingual word embeddings')
('adversarial search', 'Used-for', 'generating white-box adversarial examples')
('adversarial training', 'Part-of', 'adversarial search')
('gradient-based method', 'Used-for', 'generation of adversarial inputs in NMT')
('adversarial inputs', 'Used-for', 'attacking the model to improve robustness')
('adversarial examples', 'Evaluate-for', 'NMT model robustness')
('adversarial examples', 'Evaluate-for', 'text classification accuracy')
('adversarial examples', 'Evaluate-for', 'visual language grounding robustness')
('Distant supervision', 'Used-for', 'information extraction')
('Joint extraction of entity mentions and relations', 'Used-for', 'information/shared information extraction')
('Entity mentions', 'Part-of', 'Joint extraction of entity mentions and relations')
('Relations between entities', 'Part-of', 'Joint extraction of entity mentions and relations')
('Keyphrase prediction', 'Used-for', 'information extraction')
('Text similarity measures', 'Used-for', 'information extraction')
('TextFlow', 'Hyponym-Of', 'Text similarity measures')
('Knowledge graphs', 'Used-for', 'information extraction')
('Cross-lingual attention', 'Used-for', 'multi-lingual neural relation extraction')
('Mono-lingual attention', 'Part-of', 'multi-lingual neural relation extraction')
('Dynamic transition matrix', 'Used-for', 'characterizing noise in training data for information extraction')
('Novel\nNone\n(None', 'Used-for', 'training neural network')
('None', 'Is-a-Prerequisite-of', 'training neural network')
('None', 'Evaluate-for', 'training neural network')
('training neural network', 'Used-for', 'language modeling')
('training neural network', 'Used-for', 'zero pronoun resolution')
('training neural network', 'Used-for', 'question answering')
('training neural network', 'Used-for', 'sentence compression')
('training neural inetwork', 'Used-for', 'review spam detection')
('training neural network', 'Used-for', 'relation detection')
('training neural network', 'Used-for', 'reading comprehension')
('training neural network', 'Used-for', 'neural machine translation')
('training neural network', 'Used-for', 'neural symbolic machine')
('Neural Symbolic Machine', 'Part-of', 'training neural network')
('iterative maximum-likelihood training', 'Hyponym-Of', 'training neural network')
('cloze-style reading comprehension neural network model', 'Part-of', 'training neural network')
('spoken language acquisition', 'Is-a-Prerequisite-of', 'speech signal analysis')
('speech signal analysis', 'Used-for', 'detecting word-like acoustic units')
('speech signal analysis', 'Used-for', 'associating words with image regions')
('child-directed speech', 'Compare', 'adult-directed speech')
('synthetic speech', 'Hyponym-Of', 'speech')
('acoustic units', 'Part-of', 'speech signal analysis')
('semantic information', 'Used-for', 'enriching word recognition')
('models', 'Evaluate-for', 'task performance')
('factor graph model', 'Is-a-Prerequisite-of', 'graphical model')
('graphical model', 'Used-for', 'argument mining')
('graphical model', 'Used-for', 'argumentative relation prediction')
('graphical model', 'Used-for', 'network analysis')
('graphical model', 'Used-for', 'learning context-aware network embeddings')
('graphical model', 'Used-for', 'enhancing abstractive text summarization')
('graphical model', 'Used-for', 'learning representation of political actors')
('graphical model', 'Used-for', 'enhanced performance of neural models')
('graphical model', 'Evaluate-for', 'structure constraints enforcement')
('graphical model', 'Evaluate-for', 'expressing dependencies between relations')
('statistical parsing', 'Is-a-Prerequisite-of', 'semantic representations')
('statistical parsing', 'Used-for', 'Minimal Recursion Semantics (MRS')
('statistical parsing', 'Evaluate-for', 'knowledge base completion')
('statistical parsing', 'Evaluate-for', 'semantic graph construction')
('Parse', 'Compare', 'Execute')
('Intermediate meaning representation', 'Used-for', 'semantic interpretation')
('Neural Machine Translation', 'Compare', 'Statistical Machine Translation')
('sequence-to-sequence model', 'Used-for', 'program mapping')
('Neural Symbolic Machine', 'Part-of', 'sequence-to-sequence model')
('Neural Symbolic Machine', 'Part-of', 'Lisp interpreter')
('dependency structure', 'Conjunction', 'word sequence')
('Syntax', 'Used-for', 'language understanding')
('prosody', 'Used-for', 'word segmentation')
('speech register', 'Conjunction', 'prosody')
('prosody boundary information', 'Used-for', 'differentiating adult-directed from infant-directed speech')
('prosody', 'Used-for', 'segmenting speech units')
('prosody', 'Compare', 'pitch and intensity features')
('prosody variation', 'Hyponym-Of', 'prosody')
('CUC-VAE', 'Used-for', 'modelling prosody variation')
('acoustic features', 'Conjunction', 'prosody')
('None', 'Is-a-Prerequisite-of', 'dependency parsing')
('token-based dependency parsing', 'Used-for', 'end-to-end computational argumentation mining')
('token-based sequence tagging', 'Used-for', 'end-to-end computational argumentation mining')
('dependency parsing', 'Compare', 'sequence tagging')
('BiLSTMs', 'Used-for', 'token-based sequence tagging')
('dynamic oracle', 'Used-for', 'Covington parser')
('non-monotonic system', 'Used-for', 'dependency parsing')
('semantic dependency parsing', 'Used-for', 'Maximum Subgraph algorithms')
('semantic dependency parsing', 'Used-for', 'Lagrangian Relaxation-based algorithm')
('covington algorithm', 'Used-for', 'non-monotonic transition system')
('dependency parsers', 'Evaluate-for', 'parsing error reduction')
('Universal Dependencies', 'Used-for', 'dependency parsing')
('dependency trees', 'Used-for', 'semantic relation extraction')
('word embeddings', 'Used-for', 'dependency parsing')
('character strings', 'Used-for', 'word embeddings')
('BiLSTMs', 'Used-for', 'fewer feature dependency parsing models')
('automatic content extraction', 'Used-for', 'semantic relation extraction')
('discourse analysis', 'Used-for', 'evaluation of spoken language coherence')
('Rhetorical Structure Theory', 'Used-for', 'discourse analysis')
('discourse analysis', 'Part-of', 'natural language processing')
('ArgRewrite', 'Used-for', 'discourse analysis research')
('discourse cohesion', 'Evaluate-for', 'discourse parsing performance')
('sentence-level discourse analysis', 'Is-a-Prerequisite-of', 'RST discourse tree parsing')
('EDU', 'Used-for', 'discourse analysis')
('discourse segmenter', 'Used-for', 'discourse analysis')
('discourse parser', 'Used-for', 'discourse analysis')
('discourse analysis', 'Compare', 'predicate argument structure analysis')
('discourse analysis', 'Used-for', 'understanding human communication')
('variable-in-situ logico-semantic graphs', 'Used-for', 'discourse analysis')
('Chinese NLP', 'Used-for', 'Chinese word segmentation')
('Chinese NLP', 'Used-for', 'POS tagging')
('Chinese NLP', 'Used-for', 'dependency parsing')
('Chinese NLP', 'Used-for', 'Chinese semantic role labeling')
('Chinese NLP', 'Used-for', 'Chinese zero pronoun resolution')
('Chinese NLP', 'Used-for', 'Chinese NER')
('Chinese NLP', 'Used-for', 'Chinese social media text summarization')
('Chinese NLP', 'Used-for', 'Chinese argument generation')
('Chinese NLP', 'Used-for', 'Chinese hypernym prediction')
('Chinese NLP', 'Used-for', 'Chinese implicit discourse relations analysis')
('Chinese NLP', 'Is-a-Prerequisite-of', 'Chinese word segmentation')
('Chinese word segmentation', 'Is-a-Prerequisite-of', 'dependency parsing')
('Chinese word segmentation', 'Part-of', 'Chinese NLP')
('dependency parsing', 'Part-of', 'Chinese NLP')
('domain adaptation', 'Used-for', 'generalizing to new domain')
('domain-specific intent and slot models', 'Used-for', 'predictions on new domain')
('mixed fine tuning', 'Is-a-Prerequisite-of', 'neural machine translation performance improvement')
('artificial tags', 'Used-for', 'domain indication in corpora')
('neural machine translation', 'Evaluate-for', 'domain adaptation method success')
('cross-domain parsing accuracy', 'Used-for', 'evaluating domain embedding approach')
('multitasking approach', 'Compare', 'tag-hierarchy model')
('dialog system', 'Evaluate-for', 'domain adaptation method success')
('meta-learning', 'Used-for', 'domain adaptive dialog generation')
('unsupervised adaptation method', 'Used-for', 'improving neural machine translation')
('\n(deep learning tool', 'Used-for', 'semantic role labeling')
('deep learning tool', 'Used-for', 'text similarity measurement')
('deep learning tool', 'Used-for', 'automatic question generation')
('deep learning tool', 'Used-for', 'natural language generation')
('deep learning tool', 'Used-for', 'fake news detection')
('deep learning tool', 'Used-for', 'morphological disambiguation')
('deep learning tool', 'Used-for', 'extractive document summarization')
('deep learning tool', 'Used-for', 'structured query generation')
('deep learning tool', 'Evaluate-for', 'performance in different NLP tasks')
('deep highway BiLSTM architecture', 'Part-of', 'deep learning tool')
('constrained decoding', 'Part-of', 'deep learning tool')
('TextFlow', 'Is-a-Prerequisite-of', 'deep learning tool')
('AliMe Chat', 'Used-for', 'real-world industrial application')
('AliMe Chat', 'Used-for', 'optimizing joint results of IR and Seq2Seq models')
('Information Retrieval', 'Used-for', 'volatility prediction')
('Information Retrieval', 'Used-for', 'sentiment analysis')
('Seq2Seq based generation models', 'Used-for', 'open-domain chatbot engine')
('Information Retrieval', 'Used-for', 'cross-lingual information retrieval')
('Knowledge Graphs', 'Used-for', 'improving generalization in neural ranking models')
('Information Retrieval', 'Used-for', 'enhancing question answering systems')
('Publicly available datasets', 'Used-for', 'NLP education and research')
('TutorialBank', 'Part-of', 'NLP education and research resources')
('Multitask learning', 'Used-for', 'improving query-document alignment in cross-lingual information retrieval')
('gated self-matching networks', 'Used-for', 'question answering')
('gated attention-based recurrent networks', 'Used-for', 'question-aware passage representation')
('self-matching attention mechanism', 'Used-for', 'passage representation refinement')
('pointer networks', 'Used-for', 'locating answer positions in passages')
('COREQA', 'Is-a-Prerequisite-of', 'generating natural language answers in question answering')
('relation detection', 'Used-for', 'Knowledge Base Question Answering')
('semi-supervised question answering', 'Part-of', 'question answering')
('Open Information Extraction', 'Used-for', 'semi-structured knowledge generation in question answering')
('Memory networks', 'Used-for', 'natural language question answering')
('transfer learning', 'Used-for', 'improving question answering model performance')
('relation names', 'Conjunction', 'input question')
('SQuAD', 'Evaluate-for', 'reading comprehension question answering model performance')
('morphological disambiguation', 'Used-for', 'refine machine translation')
('morphological disambiguation', 'Used-for', 'optimize POS tagging')
('morphological disambiguation', 'Is-a-Prerequisite-of', 'context-sensitive representation learning')
('morphological disambiguation', 'Evaluate-for', 'agglutinative languages')
('characters', 'Part-of', 'character n-grams')
('character n-grams', 'Used-for', 'word representation')
('word embeddings', 'Used-for', 'machine translation')
('data-driven sub-word units', 'Used-for', 'morphological segmentation')
('character CNN', 'Used-for', 'learning word embeddings')
('language modeling', 'Used-for', 'testing morphological typologies')
('Winograd Schema Challenge', 'Evaluate-for', 'natural language understanding')
('unsupervised bilingual lexicon induction', 'Evaluate-for', 'word translation accuracy')
('neural machine translation system', 'Evaluate-for', 'sensitivity to token ratio')
('unsupervised bilingual lexion induction', 'Compare', 'supervised methods')
('morphological\nNone\n(Stochastic Gradient Descent', 'Used-for', 'learning word representations')
('Stochastic Gradient Descent', 'Compare', 'AllVec')
('AllVec', 'Used-for', 'generating word representations from all training samples')
('Gradient Ascent Post-training', 'Evaluate-for', 'enhancing zero-shot generalization capabilities')
('Gradient Ascent Post-training', 'Part-of', 'updating pretrained language models')
('Adversarial training', 'Evaluate-for', 'improving the robustness of deep language models')
('distribution shift risk minimization', 'Used-for', 'estimating adversarial loss')
('distribution shift risk minimization', 'Evaluate-for', 'achieving robust model minimizing global loss under adversarial attacks')
('multi-modal learning', 'Used-for', 'sentiment analysis')
('multi-modal learning', 'Used-for', 'emotion recognition')
('multi-modal learning', 'Used-for', 'speaker trait analysis')
('Deep Fusion Graph', 'Used-for', 'multi-modal learning')
('Multi-task learning', 'Compare', 'multi-modal learning')
('Low-rank Multimodal Fusion', 'Used-for', 'multi-modal learning')
('multi-modal learning', 'Used-for', 'integrating multiple unimodal representations')
('multi-modal data', 'Part-of', 'multi-modal learning')
('structured information', 'Compare', 'multi-modal learning')
('multi-modal learning', 'Used-for', 'multilingual learning')
('paraphrasing', 'Used-for', 'plagiarism detection')
('paraphrasing', 'Used-for', 'information ranking')
('paraphrasing', 'Used-for', 'textual entailment recognition')
('paraphrasing', 'Used-for', 'paraphrase detection')
('paraphrasing', 'Used-for', 'semantic content abstraction')
('paraphrasing', 'Conjunction', 'sentence splitting')
('paraphrasing', 'Conjunction', 'lexical substitution')
('paraphrasing', 'Conjunction', 'content restructuring')
('paraphrasing', 'Conjunction', 'text simplification')
('paraphrasing', 'Hyponym-Of', 'text transformation')
('paraphrasing', 'Is-a-Prerequisite-of', 'natural language understanding')
('monolingual paraphrasing', 'Compare', 'supervised machine translation')
('monolingual paraphrasing', 'Part-of', 'paraphrasing')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Conjunction', 'None')
('None', 'Is-a-Prerequisite-of', 'domain adaptation')
('None', 'Is-a-Prerequisite-of', 'cross-lingual classification')
('None', 'Used-for', 'unsupervised bilingual dictionary induction')
('multilingual word embedding', 'Used-for', 'cross-lingual classification')
('multilingual word embedding', 'Used-for', 'bilingual tasks')
('cross-lingual classification', 'Evaluate-for', 'domain adaptation')
('domain adaptation', 'Used-for', 'enhancing performance in low-resource language scenarios')
('unsupervised bilingual dictionary induction', 'Evaluate-for', 'morphologically rich languages')
('evaluation of information retrieval', 'Used-for', 'predicting volatility from sentiment analysis in financial markets')
('evaluation of information data', 'Used-for', 'forecasting market risk using factual market data')
('evaluation of information retrieval', 'Used-for', 'characterizing financial sector reports')
('entity annotations', 'Used-for', 'document representation in Entity-Duet Neural Ranking Model')
('knowledge graphs', 'Used-for', 'semantic integration in EDRM')
('evaluation of information retrieval', 'Hyponym-Of', 'Natural Language Processing')
('evaluation of information retrieval', 'Used-for', 'estimating trustworthiness of information sources')
('information retrieval', 'Used-for', 'augmenting Neural Machine Translation training data')
('information retrieval', 'Used-for', 'support in conversational QA systems')
('Sequence parsing', 'Used-for', 'Computational argumentation mining')
('Computational argumentation mining', 'Is-a-Prerequisite-of', 'Sequence parsing')
('Sequence-to-Dependency Neural Machine Translation', 'Part-of', 'Sequence parsing')
('Sequence parsing', 'Compare', 'Neural Machine Translation')
('Sequence parsing', 'Used-for', 'Semantic parsing')
('Deep Neural Networks', 'Used-for', 'Sequence parsing')
('Sequence parsing', 'Compare', 'Constituency parsing')
('combinatory categorial grammar', 'Used-for', 'statistical parsing')
('combinatory categorial grammar', 'Used-for', 'generating language classes')
('dependency trees', 'Used-for', 'automatic generation of CCG corpora')
('CCG parser', 'Evaluate-for', 'biomedical texts')
('CCG parser', 'Evaluate-for', 'speech conversation')
('CCG parser', 'Evaluate-for', 'math problems')
('CCG parser', 'Evaluate-for', 'question sentences')
('CCG corpora', 'Part-of', 'domain adaptation method')
('domain adaptation method', 'Used-for', 'CCG parsing')
('predicate-argument structure', 'Used-for', 'evaluation in statistical parsing')
('decomposed scoring', 'Evaluate-for', 'CCG parser performance')
('decomposed scoring', 'Is-a-Prerequisite-of', 'combinatory categorial grammar')
('decomposed scoring', 'Compare', 'standard evaluation method')
('neural question answering', 'Used-for', 'reading comprehension')
('(neural question answering', 'Used-for', 'factoid question answering')
('neural question answering', 'Evaluate-for', 'SQuAD dataset')
('gated self-matching networks', 'Part-of', 'neural question answering')
('COREQA', 'Part-of', 'neural question answering')
('EviNets', 'Part-of', 'neural question answering')
('pointer networks', 'Used-for', 'locating answer positions in passages for neural question answering')
('recurrent neural networks', 'Used-for', 'neural question answering')
('cross-attention mechanism', 'Used-for', 'improving question representation in neural question answering')
('universal schema', 'Used-for', 'aligning structured KBs and unstructured text for neural question answering')
('Generative Domain-Adaptive Nets', 'Used-for', 'training on unlabeled text to enhance neural question answering models')
('hierarchical attention network', 'Used-for', 'progress\n(None')
('None', 'Part-of', 'programming language')
('Python', 'Is-a-Prerequisite-of', 'programming language')
('programming language', 'Used-for', 'code generation')
('programming language', 'Hyponym-Of', 'general-purpose programming language')
('programming language', 'Used-for', 'naturalize')
('declarative programming language', 'Used-for', 'DAG transducer')
('declarative programming language', 'Part-of', 'programming language')
('programming language', 'Used-for', 'querying databases')
('programming language', 'Used-for', 'manipulating text')
('programming language', 'Used-for', 'analyzing data')
('bag of word model', 'Compare', 'continuous bag of words (CBOW')
('bag of word model', 'Used-for', 'legal judgment prediction')
('legal judgment prediction', 'Evaluate-for', 'English legal judgment prediction dataset')
('paragraph embedding', 'Compare', 'bag of word model')
('bag of word model', 'Used-for', 'feature extraction in text classification')
('mathematical model', 'Used-for', 'semantic-based text generalization')
('semantic-based text generalization', 'Part-of', 'abstractive text summarization')
('mathematical model', 'Is-a-Prerequisite-of', 'semantic-based text generalization')
('mathematical model', 'Used-for', 'news content structure analysis')
('news content structure analysis', 'Evaluate-for', 'event coreference resolution')
('mathematical model', 'Used-for', 'arithmetic reasoning in AI systems')
('arithmetic reasoning', 'Hyponym-Of', 'mathematical reasoning')
('mathematical reasoning', 'Used-for', 'numerical calculations performance')
('mathematical model', 'Used-for', 'network analysis')
('network analysis', 'Used-for', 'node-based feature representations')
('None', 'Is-a-Prerequisite-of', 'bias-variance tradeoff')
('bias-variance tradeoff', 'Compare', 'bias-variance-noise decomposition')
('bias-variance', 'Compare', 'variance due to optimization')
('ensemble methods', 'Used-for', 'decrease variance due to optimization')
('bias-variance tradeoff', 'Used-for', 'balance model complexity with data size')
('event detection', 'Used-for', 'event type classification')
('event detection', 'Used-for', 'argument identification')
('trigger detection', 'Is-a-Prerequisite-of', 'event detection')
('event coreference', 'Is-a-Prerequisite-of', 'event detection')
('event anaphoricity', 'Used-for', 'event coreference')
('supervised learning', 'Used-for', 'event detection')
('Nugget Proposal Networks', 'Used-for', 'event detection')
('Nugget Proposal Networks', 'Evaluate-for', 'Chinese event triggers detection')
('fixed-size ordinally forgetting encoding', 'Used-for', 'mention detection')
('joint model', 'Used-for', 'learning event coreference and trigger detection')
('event detection', 'Evaluate-for', 'emotion detection from text')
('event detection', 'Evaluate-for', 'knowledge base population')
('argument information', 'Used-for', 'event detection')
('Neural Belief Tracking', 'Part-of', 'dialog system')
('memory-to-sequence', 'Part-of', 'dialog system')
('encoder-decoder dialog model', 'Used-for', 'dialog system')
('task-oriented dialogue system', 'Is-a-Prerequisite-of', 'response selection')
('task-oriented dialogue system', 'Is-a-Prerequisite-of', 'dialog state tracking')
('dialog state tracking', 'Part-of', 'task-oriented dialogue system')
('Global-Locally Self-Attentive Dialogue State Tracker', 'Used-for', 'dialog state tracking')
('Visual language grounding', 'Used-for', 'neural image captioning')
('neural image captioning', 'Used-for', 'Visual language grounding')
('dialog system', 'Used-for', 'automatic diagnosis')
('dialog belief tracking', 'Part-of', 'dialog system')
('end-to-end learning framework', 'Used-for', 'dialog systems')
('language identification', 'Used-for', 'processing multilingual text')
('language identification', 'Used-for', 'analyzing code-switched text')
('feature hashing', 'Used-for', 'language identification')
('ensemble of low-dimension hash-based classifiers', 'Used-for', 'boosting language identification performance')
('character-based sequence-to-sequence model', 'Used-for', 'language identification')
('unsupervised word-level language detection technique', 'Used-for', 'language identification in code-switched text')
('socially inclusive', 'Evaluate-for', 'language identification')
('language identification', 'Is-a-Prerequisite-of', 'developing NLP tools')
('shallow parsing', 'Used-for', 'identifying phrase structures in sentences')
('shallow parsing', 'Part-of', 'natural language processing')
('natural language processing', 'Part-of', 'computer science')
('shallow parsing', 'Compare', 'deep parsing')
('deep parsing', 'Used-for', 'comprehensive syntactic analysis')
('shallow parsing', 'Evaluate-for', 'speed in processing text')
('deep parsing', 'Evaluate-for', 'accuracy in syntactic analysis')
('shallow decoder', 'Part-of', 'Transformer architecture')
('Shallow Aggressive Decoding', 'Used-for', 'improving online inference efficiency')
('shallow decoder', 'Used-for', 'reducing computational cost during inference')
('Multi-step Episodic Markov decision process extractive SUMmarizer', 'Is-a-Prerequisite-of', 'reinforcement-learning-based extractive summarizer')
('Markov decision process', 'Used-for', 'formulating named entity recognition task in DiffusionNER')
('Markov decision process', 'Used-for', 'stochastic decision-making in multi-source test-time model adaptation')
('Syntax', 'Used-for', 'Parsing natural language descriptions into source code')
('Syntax', 'Is-a-Prerequisite-of', 'Effective language generation')
('Syntax', 'Part-of', 'Grammar model')
('Syntax', 'Used-for', 'Capturing target syntax in source code generation')
('Syntax', 'Used-for', 'Understanding morpho-syntactic regularities in morpheme segmentation')
('Syntax', 'Used-for', 'Improving translation accuracy in Neural Machine Translation')
('Syntax', 'Used-for', 'Representing abstract syntax trees in code generation')
('Syntax', 'Evaluate-for', 'Enhancing semantic parsing capabilities')
('Syntax', 'Hyponym-Of', 'Source syntax in Neural Machine Translation')
('Syntax', 'Used-for', 'Explicating encoded structural information in neural models')
('Syntax', 'Evaluate-for', 'Improving state-of-the-art results in semantic parsing')
('Syntax', 'Used-for', 'Morphological analysis')
('Syntax', 'Used-for', 'Enhancing model architecture in number agreement tasks')
('Syntax', 'Used-for', 'Learning syntactic dependencies in language models')
('graph convolutional network', 'Used-for', 'extracting drug-drug interactions from texts')
('graph convolutional network', 'Used-for', 'model training in NLP')
('graph convolutional network', 'Used-for', 'multimodal data fusion')
('graph convolutional network', 'Used-for', 'predicting drug-drug interactions from molecular structures')
('graph convolutional network', 'Used-for', 'extracting relations in text')
('graph convolutional network', 'Used-for', 'capturing structural information in natural language')
('graph convolutional network', 'Part-of', 'NeuralDater')
('graph convolutional network', 'Part-of', 'multimodal geolocation model')
('graph convolutional network', 'Part-of', 'drur-drug interaction extraction system')
('convolutional neural network', 'Used-for', 'text classification')
('convolutional neural network', 'Used-for', 'image feature extraction')
('convolutional neural network', 'Used-for', 'semantic feature extraction from visual data')
('NeuralDater', 'Evaluate-for', 'document dating accuracy')
('spectral method', 'Part-of', 'language modeling tasks')
('language modeling tasks', 'Evaluate-for', 'spectral method')
('spectral models', 'Part-of', 'spectral method')
('statistics from long substrings', 'Used-for', 'spectral method')
('language modeling tasks', 'Used-for', 'capture long-range dependencies')
('large matrices', 'Used-for', 'spectral method')
('moment matching', 'Used-for', 'spectral method')
('spectral learning', 'Used-for', 'maximize perplexity')
('ngram models', 'Compare', 'spectral method')
('None', 'Part-of', 'NLP tasks')
('structured prediction', 'Used-for', 'mapping unstructured inputs to structured outputs')
('structured prediction', 'Used-for', 'search problem solving')
('deep neural networks', 'Used-for', 'learning feature representations')
('kernel methods', 'Used-for', 'modeling structured information')
('Tree Kernels', 'Is-a-Prerequisite-of', 'kernel methods')
('Nystrom low-rank approximation', 'Used-for', 'pre-training neural networks')
('deep architecture', 'Part-of', 'kernelized neural network')
('structured prediction', 'Evaluate-for', 'output structure evaluation')
('coreference resolution', 'Evaluate-for', 'complex loss functions')
('abstract syntax networks', 'Used-for', 'code generation')
('abstract syntax networks', 'Used-for', 'semantic parsing')
('abstract syntax trees', 'Part-of', 'abstract syntax networks')
('Bi-directional LSTMs', 'Used-for', 'text representation')
('encoder-decoder framework', 'Used-for', 'table-to-text generation')
('low resource scenario', 'Evaluate-for', 'key fact prediction')
('sequential recurrent neural networks', 'Used-for', 'language modeling')
('search engine', 'Used-for', 'multi-passage machine reading comprehension')
('entity linking', 'Evaluate-for', 'search engine')
('search engine', 'Used-for', 'personalized query completions')
('recurrent neural network language model', 'Used-for', 'generating query completions')
('sentiment analysis', 'Compare', 'aspect-based sentiment analysis')
('neural word embeddings', 'Used-for', 'aspect extraction')
('sentiment analysis', 'Used-for', 'volatility prediction')
('domain adaptation', 'Used-for', 'sentiment analysis')
('sentiment lexicons', 'Part-of', 'sentiment analysis')
('cross-domain sentiment analysis', 'Is-a-Prerequisite-of', 'domain adaptation')
('aspect extraction', 'Is-a-Prerequisite-of', 'aspect sentiment classification')
('attention mechanism', 'Used-for', 'improving coherence')
('LSTM', 'Used-for', 'multimodal sentiment analysis')
('visual reasoning language dataset', 'Evaluate-for', 'linguistic phenomena')
('automated essay scoring', 'Is-a-Prerequisite-of', 'argument persuasiveness scoring')
('automated essay scoring', 'Compare', 'neural AES')
('automated essay scoring', 'Used-for', 'grading essays')
('automated essay scoring', 'Evaluate-for', 'essay quality')
('essay quality', 'Part-of', 'automated essay scoring')
('automated essay scoring', 'Hyponym-Of', 'automated writing evaluation')
('string kernels', 'Used-for', 'automated essay scoring')
('neural essay scoring engine', 'Used-for', 'generating chess commentary')
('automated essay scoring', 'Used-for', 'measuring thesis strength')
('prompt mapping', 'Used-for', 'improving AES generalization ability')
('Topical Components', 'Used-for', 'feature-based AES')
('matrix multiplication', 'Used-for', 'multiplying a matrix by a few-hot vector')
('multiplying a matrix by a few-hot vector', 'Hyponym-Of', 'matrix multiplication')
('GPU algorithms', 'Part-of', 'Operations using sparse structures')
('neural networks', 'Used-for', 'matrix multiplication')
('matrix multiplication', 'Evaluate-for', 'GPU efficiency')
('sparse data structures', 'Used-for', 'natural language models')
('GPU algorithms', 'Used-for', 'accelerating operations on dense matrices/tensors')
('neural networks', 'Used-for', 'Operations using sparse structures')
('Recurrent neural networks', 'Used-for', 'language modeling')
('Stochastic optimization', 'Evaluate-for', 'language modeling')
('Generative models', 'Used-for', 'language modeling')
('Taylor’s law', 'Evaluate-for', 'language modeling')
('language modeling', 'Used-for', 'understanding linguistic structures')
('unsupervised parsers', 'Evaluate-for', 'language modeling')
('collaborative filtering', 'Used-for', 'personalization of content')
('collaborative filtering', 'Part-of', 'machine learning techniques')
('collaborative filtering', 'Used-for', 'rating prediction')
('collborative filtering', 'Hyponym-Of', 'information filtering systems')
('ESCOFILT', 'Used-for', 'collaborative filtering')
('rating prediction', 'Evaluate-for', 'collaborative filtering')
('user-item interactions', 'Part-of', 'collaborative filtering')
('lexical semantics', 'Part-of', 'natural language processing')
('discriminative training', 'Used-for', 'lexical feature estimation')
('lexical features', 'Used-for', 'part-of-speech induction')
('lexical features', 'Used-for', 'named-entity recognition')
('distributional vector space models', 'Evaluate-for', 'lexical semantics')
('morph-fitting procedure', 'Used-for', 'improving lexical semantics quality')
('lexical resources', 'Used-for', 'training generative models')
('semantic quality', 'Hyponym-Of', 'lexical semantics')
('lexical entropy series', 'Hyponym-Of', 'lexical semantics')
('structured learning', 'Used-for', 'taxonomy learning')
('structured learning', 'Used-for', 'hypernym prediction')
('structured learning', 'Hyponym-Of', 'semi-supervised learning')
('structured learning', 'Compare', 'supervised learning')
('structured learning', 'Part-of', 'transductive learning approach')
('structured learning', 'Used-for', 'query understanding')
('structured learning', 'Used-for', 'fine-grained entity categorization')
('genetic algorithm', 'Used-for', 'automatic training data generation')
('genetic algorithm', 'Evaluate-for', 'optimization-based extractive multi-document summarization')
('automatic Pyramid', 'Part-of', 'optimization-based extractive multi-document summarization')
('genetic algorithm', 'Used-for', 'automatic Pyramid as the fitness function')
('memory network', 'Used-for', 'modeling inference in human language')
('neural network', 'Used-for', 'answering cloze-style questions')
('neural network', 'Used-for', 'sequence-to-sequence learning problems')
('neural network', 'Used-for', 'predicting predicate argument structure')
('recurrent neural network', 'Part-of', 'neural network')
('neural network model', 'Used-for', 'representing the questions and candidate answers dynamically')
('gated self-matching networks', 'Part-of', 'neural network')
('gated self-matching networks', 'Used-for', 'reading comprehension style question answering')
('cloze-style reading comprehension neural network model', 'Used-for', 'zero pronoun resolution task')
('cloze-style reading comprehension neural network model', 'Is-a-Prerequisite-of', 'two-step training mechanism')
('sequential inference models based on chain LSTMs', 'Part-of', 'memory network')
('grammar induction', 'Used-for', 'unsupervised discontinuous parsing')
('context sensitive grammar', 'Part-of', 'natural language processing')
('supervised learning', 'Used-for', 'correct edit tree identification')
('correct edit tree', 'Evaluate-for', 'word-lemma pair transformation')
('bidirectional gated recurrent structures', 'Used-for', 'character level dependencies extraction')
('bidirectional gated recurrent structures', 'Used-for', 'context capturing')
('pre-trained word embeddings', 'Used-for', 'context sensitive representations')
('context sensitive representations', 'Evaluate-for', 'named entity recognition')
('context sensitive representations', 'Evaluate-for', 'chunking')
('probabilistic context free grammar', 'Compare', 'context sensitive grammar')
('collapsed variational inference', 'Used-for', 'context-dependent grammar inference')
('multi-task learning framework', 'Used-for', 'time to event prediction')
('neural machine translation', 'Used-for', 'machine translation')
('part of speech', 'Is-a-Prerequisite-of', 'morphological tagging')
('part of speech', 'Used-for', 'syntax analysis')
('part of speech', 'Used-for', 'language modeling')
('part of speech induction', 'Used-for', 'named-entity recognition')
('neural machine translation', 'Used-for', 'source and target language understanding')
('morphological tagging', 'Used-for', 'lexical feature analysis')
('meta-model', 'Used-for', 'combining character and word embeddings')
('weighted finite state transducers', 'Used-for', 'speech recognition')
('sequence-to-sequence framework', 'Used-for', 'multi-speaker speech recognition')
('lattice transformer', 'Used-for', 'speech translation')
('top-down inference', 'Part-of', 'constituency parsing')
('constituency parsing', 'Used-for', 'natural language processing')
('greedy algorithm', 'Used-for', 'recursive partitioning')
('recursive partitioning', 'Used-for', 'input division')
('input division', 'Part-of', 'natural language processing')
('greedy algorithm', 'Evaluate-for', 'prediction schemes')
('prediction schemes', 'Used-for', 'constituency parsing')
('greedy algorithm', 'Conjunction', 'Lagrangian Relaxation-based algorithm')
('Lagrangian Relaxation-based algorithm', 'Used-for', 'combining pages into a book')
('statistical machine translation', 'Compare', 'neural machine translation')
('neural machine translation', 'Used-for', 'generating fluent translation results')
('statistical machine translation', 'Used-for', 'better translation adequacy than NMT')
('neural machine translation', 'Used-for', 'Chinese-to-English translation')
('statistical machine translation', 'Used-for', 'Chinese-to-English translation')
('neural machine translation', 'Used-for', 'Japanese-English translation')
('phrase-based machine translation', 'Used-for', 'domain adaptation')
('statistical machine translation', 'Evaluate-for', 'compound splitting')
('neural machine translation', 'Evaluate-for', 'sentence splitting')
('statistical machine translation', 'Evaluate-for', 'recognizing textual entailment')
('neural machine translation', 'Used-for', 'paraphrase generation')
('posterior regularization', 'Used-for', 'integrating prior knowledge into neural machine translation')
('corpus-based similarity', 'Compare', 'thesaurus-based similarity')
('checking procedure', 'Used-for', 'evaluating thesauri')
('thesaurus-based similarity', 'Evaluate-for', 'word sense description')
('checking procedure', 'Part-of', 'analysis of discrepancies')
('Russian wordnet', 'Part-of', 'thesauri')
('None', 'Part-of', 'natural language processing')
('semantic parsing', 'Used-for', 'mapping natural language utterances to formal meaning representations')
('semantic parsing', 'Used-for', 'executing natural language commands in a machine-interpretable format')
('predicate-argument structures', 'Used-for', 'semantic parsing')
('semantic representation', 'Used-for', 'semantic parsing')
('transition system', 'Used-for', 'inducing predicate-argument structures in semantic parsing')
('logical forms', 'Is-a-Prerequisite-of', 'semantic parsing')
('executable programs', 'Is-a-Prerequisite-of', 'semantic parsing')
('reinforcement learning', 'Used-for', 'improving semantic parsing accuracy')
('maximum marginal likelihood', 'Used-for', 'improving semantic parsing accuracy')
('transition-based parser', 'Used-for', 'UCCA parsing')
('abstract syntax networks', 'Used-for', 'code generation in semantic parsing')
('abstract syntax trees', 'Part-of', 'abstract syntax networks')
('encoder-decoder model', 'Used-for', 'semantic parsing')
('semi-supervised learning', 'Used-for', 'enhancing semantic parsing')
('sequence-to-tree model', 'Used-for', 'multilingual semantic parsing')
('(graph theory', 'Part-of', 'graph theoretic measures')
('graph theory', 'Used-for', 'constructing document-level graphs')
('graph theory', 'Used-for', 'building labelled edge graph convolutional neural network model')
('graph theory', 'Evaluate-for', 'inter-sentence relation extraction')
('graph theoretic measures', 'Used-for', 'analyzing character portrayal in movies')
('inter-sentence relation extraction', 'Is-a-Prerequisite-of', 'multi-instance learning with bi-affine pairwise scoring')
('graph convolutional neural network model', 'Used-for', 'capturing local and non-local dependency information in documents')
('graph convolutional neural network model', 'Part-of', 'novel inter-sentence relation extraction model')
('Neural Machine Translation', 'Compare', 'Phrase-based Machine Translation')
('Phrase-based Machine Translation', 'Used-for', 'Translation Adequacy')
('Mixed Fine Tuning', 'Evaluate-for', 'Phrase-based Machine Translation')
('Phrase-based Machine Translation', 'Part-of', 'Statistical Machine Translation')
('Phrase-based Machine Translation', 'Is-a-Prerequisite-of', 'Effective Neural Models')
('Translation Adequacy', 'Evaluate-for', 'Phrase-based Machine Translation')
('Phrase-based Machine Translation', 'Evaluate-for', 'Recognizing Textual Entailment')
('Phrase-based Machine Translation', 'Conjunction', 'Neural Machine Translation')
('uncertainty', 'Used-for', 'confidence modeling')
('uncertainty', 'Used-for', 'error propagation analysis')
('uncertainty', 'Used-for', 'rumour verification')
('uncertain predictions', 'Part-of', 'uncertainty classification')
('uncertainty', 'Used-for', 'uncertainty estimation')
('uncertainty classification', 'Used-for', 'model performance interpretation')
('confidence scores', 'Evaluate-for', 'model predictions')
('model uncertainty', 'Used-for', 'filtering erroneous predictions')
('uncertainty assessment', 'Used-for', 'enhancing model reliability')
('uncertainty estimation', 'Used-for', 'out-of-distribution detection')
('probabilistic FastText', 'Hyponym-Of', 'word embeddings')
('multimodal word distributions', 'Hyponym-Of', 'word embeddings')
('neural summarization', 'Used-for', 'document summarization')
('neural summarization', 'Used-for', 'meeting speech summarization')
('query-based summarization', 'Part-of', 'neural summarization')
('encode-attend-decode paradigm', 'Used-for', 'neural summarization')
('query attention model', 'Part-of', 'neural summarization')
('diversity based attention model', 'Part-of', 'neural summarization')
('pointer-generator network', 'Part-of', 'neural summarization')
('coverage mechanism', 'Part-of', 'neural summarization')
('selective encoding model', 'Part-of', 'neural summarization')
('SWAP-NET', 'Hyponym-Of', 'neural summarization')
('template-based summarization', 'Compare', 'neural summarization')
('graph\n(generative adversarial network', 'Used-for', 'increasing effectiveness in neural machine translation systems')
('generative adversarial network', 'Used-for', 'enhancing cross-language translation')
('generative adversarial network', 'Used-for', 'generating spurious features in adversarial attacks')
('generative adversarial network', 'Used-for', 'eliminating fake features in adversarial training')
('generative adversarial network', 'Compare', 'Maximum Mean Discrepancy')
('Maximum Mean Discrepancy', 'Used-for', 'distribution matching')
('generative neural network architecture', 'Part-of', 'Dialogue Act classification')
('Recurrent Neural Network framework', 'Part-of', 'generative neural network architecture')
('natural language processing', 'Part-of', 'generative conversational systems')
('context information', 'Used-for', 'dialog processing')
('information theory', 'Used-for', 'quantifying information')
('entropy', 'Is-a-Prerequisite-of', 'information theory')
('Shannon', 'Hyponym-Of', 'information theory')
('mutual information', 'Part-of', 'information theory')
('data compression', 'Used-for', 'applications of information theory')
('error detection and correction', 'Used-for', 'applications of information theory')
('information density', 'Used-for', 'evaluating communication effectiveness in information theory')
('algorithm efficiency', 'Evaluate-for', 'information theory')
('attention model', 'Used-for', 'focusing on salient content in text')
('attention model', 'Hyponym-Of', 'machine learning models')
('attention model', 'Used-for', 'word reordering in neural machine translation')
('attention model', 'Used-for', 'sentence scoring in document summarization')
('hard attention mechanism', 'Is-a-Prerequisite-of', 'morphological inflection generation')
('hard attention mechanism', 'Compare', 'soft attention mechanism')
('soft attention mechanism', 'Part-of', 'attention model')
('recursive neural network', 'Used-for', 'computing text representation with attention model')
('Neural Machine Translation', 'Used-for', 'employing attention model to improve translation accuracy')
('Bahdanau', 'Hyponym-Of', 'soft attention mechanism')
('probabilistic grammar', 'Is-a-Prerequisite-of', 'regex synthesis')
('regex synthesis', 'Used-for', 'natural language description of regex patterns')
('probabilistic grammar', 'Used-for', 'generating complex regexes from StackOverflow posts')
('regex synthesis', 'Part-of', 'StructuredRegex dataset')
('StructuredRegex dataset', 'Evaluate-for', 'linguistic diversity and complexity in regex tasks')
('stemming', 'Used-for', 'reducing words to their base form')
('Word embeddings', 'Used-for', 'spectral clustering')
('Taylor’s law', 'Used-for', 'quantifying structural complexity in linguistic time series')
('Dependency triples', 'Used-for', 'semantic frame induction')
('SF-ID network', 'Used-for', 'joint intent detection and slot filling')
('OSDM', 'Used-for', 'clustering short text streams')
('Neural Machine Translation', 'Used-for', 'computer vision')
('Transkimmer architecture', 'Used-for', 'computer vision')
('UniCoRN', 'Used-for', 'computer vision')
('Adversarial attacks', 'Evaluate-for', 'computer vision')
('Deep neural networks', 'Is-a-Prerequisite-of', 'computer vision')
('Image captioning', 'Used-for', 'computer vision')
('Transfer learning', 'Used-for', 'computer vision')
('Parameter adaptation', 'Evaluate-for', 'computer vision')
('KGA', 'Compare', 'computer vision unlearning methods')
('fMRI2text', 'Used-for', 'computer vision')
('N3', 'Compare', 'traditional fine-tuning in computer vision')
('Neural Networks from Natural Language', 'Hyponym-Of', 'N3')
('Finite State Transducer', 'Used-for', 'Part-of-Speech Tagging')
('Finite State Transducer', 'Used-for', 'Speech Recognition')
('GPU implementation of FST composition', 'Part-of', 'Finite State Transducer')
('Speech Recognition', 'Used-for', 'Transducing natural language sentences')
('Encoder-decoder framework', 'Used-for', 'Semantic Parsing')
('Finite State Morphological Analyzer', 'Used-for', 'Morph-based Auto-completion')
('Finite State Approach', 'Used-for', 'Mapping prefixes in language learning')
('Neural Semantic Parsers', 'Evaluate-for', 'Semantic Parsing')
('GPU implementation of FST composition', 'Compare', 'Serial implementation')
('Lane and Bird', 'Used-for', 'Proposing finite state approach in language learning')
('dual decomposition', 'Used-for', 'semantic parsing')
('Complex question semantic parsing', 'Is-a-Prerequisite-of', 'dual decomposition')
('Hierarchical Semantic Parsing', 'Is-a-Prerequisite-of', 'dual decomposition')
('ComplexWEBQUESTIONS dataset', 'Evaluate-for', 'dual decomposition')
('sub-question generation', 'Is-a-Prerequisite-of', 'dual decomposition')
('span prediction', 'Is-a-Prerequisite-of', 'dual decomposition')
('supertagging', 'Used-for', 'dependency tree parsing')
('MGbank', 'Is-a-Prerequisite-of', 'Minimalist Grammar parsing')
('holographic embeddings', 'Used-for', 'supertagging')
('null heads', 'Used-for', 'MG parsing')
('AMR graph', 'Part-of', 'semantic parsing')
('Joint extraction of entities and relations', 'Used-for', 'information extraction')
('representation learning', 'Used-for', 'biomedical concepts')
('semantic parser', 'Used-for', 'Abstract Meaning Representations')
('C&C parser', 'Used-for', 'CCG parsing')
('supertagger', 'Used-for', 'constituency parsing')
('synchronous context-free grammar', 'Is-a-Prerequisite-of', 'tree adjoining grammar')
('tree adjoining grammar', 'Compare', 'synchronous tree-adjoining grammar')
('tree adjoining grammar', 'Part-of', 'language classes hierarchy')
('prefix lexicalized', 'Used-for', 'synchronous tree-adjoining grammar')
('context-free grammar', 'Is-a-Prerequisite-of', 'tree adjoining grammar')
('tree adjoining grammar', 'Compare', 'synchronous tree-adjoining grammar')
('Pushdown Adjoining Automaton', 'Compare', 'tree adjoining grammar')
('configurable pushdown automata', 'Is-a-Prerequisite-of', 'tree adjoining grammar')
('regularization', 'Used-for', 'neural machine translation')
('posterior regularization', 'Is-a-Prerequisite-of', 'prior knowledge integration')
('posterior regularization', 'Used-for', 'guiding the learning process')
('aggressive regularization', 'Used-for', 'improving LSTM models')
('Monte-Carlo Dropout', 'Hyponym-Of', 'regularization')
('Monte-Carlo Dropout', 'Used-for', 'providing uncertainty in predictions')
('posterior regularization', 'Used-for', 'neural machine translation')
('regularization', 'Used-for', 'optimizing model parameters')
('beam search', 'Used-for', 'decoding sentences in neural machine translation')
('Grid Beam Search', 'Is-a-Prerequisite-of', 'beam search')
('Lexically Constrained Decoding', 'Used-for', 'incorporating auxillary knowledge into model’s output')
('beam search', 'Part-of', 'Grid Beam Search')
('beam search', 'Used-for', 'finding good candidate translations')
('Delayed SGD update', 'Used-for', 'training neural machine translation models with long representations like linearized syntax')
('beam search', 'Hyponym-Of', 'search algorithms')
('WordNet', 'Used-for', 'lexical ambiguity representation')
('WordNet', 'Used-for', 'semantic concept embedding')
('semantic concepts', 'Hyponym-Of', 'WordNet')
('WordNet', 'Used-for', 'context-sensitive word representation')
('synsets', 'Hyponym-Of', 'WordNet')
('WordNet', 'Is-a-Prerequisite-of', 'type-level word embeddings')
('WordNet', 'Used-for', 'unsupervised bilingual lexicon induction')
('WordNet', 'Used-for', 'analyzing code-switched text')
('semantic concepts', 'Part-of', 'WordNet')
('synsets', 'Used-for', 'document analysis')
('semantic concepts', 'Used-for', 'semantic regularities transfer across languages')
('classification', 'Is-a-Prerequisite-of', 'text classification')
('text classification', 'Used-for', 'classifying documents')
('cross-lingual text classification', 'Used-for', 'classifying documents in different languages')
('sentence-level sentiment classification', 'Used-for', 'capture linguistic role in sentiment expression')
('implicit discourse relation classification', 'Used-for', 'recognition of discourse relations without connectives')
('temporal relation classification', 'Used-for', 'classifying timing relationships between events')
('question classification', 'Used-for', 'utilizing answer data for improving question representation')
('keyphrase boundary classification', 'Used-for', 'detecting and labeling keyphrases in texts')
('aspect sentiment classification', 'Used-for', 'classifying sentiment based on specific targets in sentences')
('classification', 'Used-for', 'evaluating model performance')
('classification', 'Hyponym-Of', 'machine learning tasks')
('abstract syntax trees', 'Used-for', 'code generation')
('abstract syntax trees', 'Part-of', 'abstract syntax networks')
('abstract syntax networks', 'Used-for', 'semantic parsing')
('semantic parsing', 'Used-for', 'mapping unstructured inputs to executable outputs')
('syntaxnet', 'Is-a-Prerequisite-of', 'abstract syntax networks')
('syntaxnet', 'Used-for', 'parsing natural language into dependency trees')
('code generation', 'Evaluate-for', 'semantic parsing')
('syntax in ensembles', 'Used-for', 'Neural Machine Translation')
('syntax', 'Used-for', 'improving number agreement in model architecture')
('syntax', 'Hyponym-Of', 'language structures')
('syntax-aware models', 'Used-for', 'unsupervised syntactic parsing')
('syntax', 'Used-for', 'enhancing language models')
('syntax-infused variational autoencoder\n(k-nn', 'Used-for', 'Improving translation accuracy')
('k-nn', 'Used-for', 'Noise reduction in prediction')
('Adaptive kNN-MT', 'Used-for', 'Dynamic determination of k in translation')
('Meta-k Network', 'Used-for', 'Training Adaptive kNN-MT')
('k-nn', 'Hyponym-Of', 'Machine Learning Algorithms')
('part of speech tagging', 'Used-for', 'linguistic pattern analysis')
('part of speech tagging', 'Used-for', 'syntactic task performance improvement')
('part of speech tagging', 'Part-of', 'natural language processing')
('neural networks', 'Used-for', 'part of speech tagging')
('recurrent neural networks', 'Used-for', 'part of speech tagging')
('Stanford Parser', 'Evaluate-for', 'part of speech tagging')
('bidirectional networks', 'Evaluate-for', 'part of speech tagging')
('Weighted finite state transducers', 'Used-for', 'part of speech tagging')
('GPU', 'Used-for', 'finite state transducer operations')
('BERT', 'Evaluate-for', 'multilingual part of speech tagging')
('FastText', 'Compare', 'BPEmb')
('BPEmb', 'Compare', 'BERT')
('SMN', 'Used-for', 'response selection')
('context vector', 'Part-of', 'response selection')
('RNN', 'Part-of', 'SMN')
('Seq2Seq', 'Used-for', 'response generation')
('AliMe Chat', 'Is-a-Prerequisite-of', 'chat bot')
('IR', 'Conjunction', 'Seq2Seq')
('chat bot', 'Used-for', 'real-world industrial application')
('Seq2Seq', 'Evaluate-for', 'diverse requirements')
('Seq2Seq', 'Evaluate-for', 'specific requirements')
('customer service', 'Used-for', 'specific response generation')
('logic and reasoning', 'Used-for', 'human reasoning')
('logic and reasoning', 'Used-for', 'decision-making processes')
('logic and represents', 'Conjunction', 'logic and reasoning')
('logical reasoning', 'Is-a-Prerequisite-of', 'machine reading comprehension')
('logical reasoning', 'Is-a-Prerequisite-of', 'analogical reasoning')
('logical reasoning', 'Is-a-Prerequisite-of', 'conversational machine reading')
('logical reasoning', 'Is-a-Prerequisite-of', 'multi-hop reading comprehension')
('logical reasoning', 'Used-for', 'evaluating Chinese word embeddings')
('logical reasoning', 'Is-a-Prerequisite-of', 'visual question answering')
('logical reasoning', 'Is-a-Prerequisite-of', 'natural language for visual reasoning')
('logical reasoning', 'Used-for', 'answering complex logical queries')
('logical reasoning', 'Used-for', 'zero-shot reasoning')
('logical reasoning', 'Evaluate-for', 'constructing high-quality arguments')
('logical reasoning', 'Is-a-Prerequisite-of', 'solving Ravens Progressive Matrices')
('logical reasoning', 'Part-of', 'encoder-decoder style neural network models')
('backpropagation', 'Used-for', 'training neural networks')
('backpropagation', 'Evaluate-for', 'optimization of deep learning models')
('backpropagation', 'Part-of', 'gradient descent optimization')
('Neural Machine Translation', 'Used-for', 'modeling complex linguistic structures')
('Recurrent Neural Networks', 'Used-for', 'language modeling')
('gradient diffusion', 'Hyponym-Of', 'optimization challenges')
('Linear Associative Units', 'Used-for', 'reducing gradient propagation path')
('stochastic gradient Markov Chain Monte Carlo', 'Used-for', 'learning weight uncertainty in RNNs')
('MultiScale Collaborative framework', 'Used-for', 'training deeper NMT models')
('backpropagation', 'Used-for', 'error correction in learning process')
('text similarity', 'Part-of', 'natural language processing')
('TextFlow', 'Used-for', 'text similarity')
('semantic hashing', 'Used-for', 'fast similarity search')
('document matching', 'Used-for', 'text similarity')
('sentence clustering', 'Evaluate-for', 'thematic similarity')
('thematic similarity', 'Part-of', 'text similarity')
('skip-grams', 'Used-for', 'text similarity')
('vector space models', 'Used-for', 'text similarity')
('n-grams', 'Used-for', 'text similarity')
('Neural network', 'Used-for', 'Event detection')
('capsule network', 'Used-for', 'Paraphrastic sentence embeddings')
('paraphrastic sentence embeddings', 'Evaluate-for', 'capsule network')
('capsule network', 'Compare', 'Neural machine translation')
('capsule network', 'Used-for', 'Question Answering')
('question answering', 'Evaluate-for', 'capsule network')
('capsule network', 'Used-for', 'Text Classification')
('text classification', 'Evaluate-for', 'capsule network')
('BONIE', 'Used-for', 'extracting Open IE tuples')
('bootstrapping', 'Is-a-Prerequisite-of', 'BONIE')
('bootstrapping', 'Used-for', 'learning specific dependency patterns')
('bootstrapping', 'Evaluate-for', 'seed selection')
('bootstrapping', 'Evaluate-for', 'noise reduction')
('bootstrapping', 'Used-for', 'relation extraction methods')
('HITS algorithm', 'Used-for', 'ranking relation instances')
('K-means', 'Used-for', 'selecting cluster centroids')
('IRN', 'Used-for', 'improving general NLG systems')
('bootstrapping', 'Used-for', 'sampling training candidates')
('bootstrapping', 'Used-for', 'self-training neural relation classifiers')
('self-training', 'Hyponym-Of', 'bootstrapping')
('contrastive clustering-based bootstrapping', 'Used-for', 'fine-grained classification')
('bootstrapping', 'Used-for', 'refining labels of passages')
('bootstrapping', 'Used-for', 'creation of ClarQ dataset')
('text summarization', 'Is-a-Prerequisite-of', 'abstractive summarization')
('text summarization', 'Is-a-Prerequisite-of', 'query-based summarization')
('text summarization', 'Is-a-Prerequisite-of', 'extractive summarization')
('text summarization', 'Is-a-Prerequisite-of', 'multi-document summarization')
('abstractive summarization', 'Used-for', 'generating shorter versions of documents')
('query-based summarization', 'Used-for', 'highlighting query-relevant points')
('extractive summarization', 'Used-for', 'selecting and rearranging passages')
('multi-document summarization', 'Used-for', 'summarizing multiple documents')
('abstractive summarization', 'Compare', 'extractive summarization')
('encode-attend-decode paradigm', 'Used-for', 'machine translation')
('encode-attend-decode paradigm', 'Used-for', 'dialog systems')
('recurrent neural request', 'Evaluate-for', 'parsing sentences into Abstract Meaning Representations')
('recurrent neural network', 'Compare', 'convolutional layers')
('recurrent neural network', 'Evaluate-for', 'question answering')
('recurrent neural network', 'Hyponym-Of', 'neural network')
('recurrent neural network', 'Is-a-Prerequisite-of', 'deep learning architectures')
('neural machine translation', 'Used-for', 'translating languages using neural networks')
('cloze style task', 'Part-of', 'zero pronoun resolution training')
('pseudo training data', 'Used-for', 'training machine learning models')
('sentiment classification', 'Used-for', 'evaluating polarity in text')
('attention mechanism', 'Used-for', 'focusing on relevant features in neural networks')
('LSTM', 'Hyponym-Of', 'recurrent neural network')
('bi-directional LSTM', 'Compare', 'convolutional layers')
('normalization', 'Part-of', 'pre-processing step')
('normalization', 'Used-for', 'improving parsing performance')
('normalization', 'Used-for', 'retaining content in sentiment-to-sentiment translation')
('pre-normalization', 'Used-for', 'historical text processing')
('encoder-decoder architectures', 'Used-for', 'historical text processing')
('encoder-decoder architectures', 'Is-a-Prerequisite-of', 'multi-task learning')
('multi-task learning', 'Used-for', 'semantic role labeling')
('grapheme-to-phoneme dictionary', 'Used-for', 'multi-task learning')
('semantic role labeling', 'Evaluate-for', 'performance improvement')
('deep highway BiLSTM architecture', 'Used-for', 'semantic role labeling')
('constrained decoding', 'Used-for', 'limiting error in deep learning models')
('semantic parsers', 'Used-for', 'improving semantic parsing performance')
('evaluation of question answering', 'Used-for', 'assessing QA models effectiveness')
('COREQA', 'Used-for', 'generating natural answers for knowledge inquired questions')
('EviNets', 'Used-for', 'combining evidence signals for joint reasoning in QA')
('universal schema', 'Used-for', 'reasoning on both structured KBs and unstructured text')
('SAN', 'Used-for', 'multi-step reasoning in machine reading comprehension')
('knowledge graph', 'Part-of', 'Knowledge Bases')
('knowledge graph', 'Used-for', 'integrating prior knowledge into algorithms')
('semantic representation', 'Is-a-Prerequisite-of', 'knowledge graph')
('Knowledge Bases', 'Used-for', 'creating linguistically challenging micro-planning data-to-text corpora')
('Knowledge Bases', 'Used-for', 'training and learning KB verbalisers')
('Knowledge Bases', 'Used-for', 'accessing substantial knowledge via KB-QA')
('Knowledge Bases', 'Used-for', 'improving knowledge extraction algorithms')
('integrating prior knowledge into algorithms', 'Used-for', 'enhancing machine learning models')
('KB-QA', 'Evaluate-for', 'accessing knowledge in Knowledge Bases')
('neural network model', 'Used-for', 'dynamic question representation')
('neural network model', 'Used-for', 'leveraging global knowledge from underlying KB')
('discourse parsing', 'Used-for', 'building discourse structures')
('discourse segmentation', 'Is-a-Prerequisite-of', 'discourse parsing')
('statistical discourse segmenters', 'Used-for', 'discourse parsing')
('memory networks', 'Used-for', 'discourse parsing')
('Rhetorical Structure Theory', 'Used-for', 'discourse parsing')
('RST discourse treebank', 'Used-for', 'discourse parsing')
('discourse relation identification', 'Part-of', 'discourse parsing')
('discourse coherence', 'Evaluate-for', 'discourse parsing')
('transition-based discourse parser', 'Used-for', 'discourse parsing')
('neural framework for sentence-level discourse analysis', 'Used-for', 'discourse parsing')
('Pointer Networks', 'Used-for', 'discourse parsing')
('Gibbs sampling', 'Used-for', 'generative model for document clustering and topic coherence')
('generative model', 'Part-of', 'short text aggregation')
('Gibbs sampling', 'Evaluate-for', 'interpretability of topics')
('random walk', 'Used-for', 'reasoning models')
('random walk', 'Part-of', 'biased random walkers')
('biased random walkers', 'Evaluate-for', 'uncovering ground-truth graphs')
('pretrained language models', 'Used-for', 'inferring networks of symbols')
('GAP', 'Used-for', 'enhancing zero-shot generalization capabilities')
('SCRFs', 'Used-for', 'neural sequence labeling')
('word-level labels', 'Used-for', 'deriving segment scores')
('NB-NTM', 'Used-for', 'dispersed topic discovery')
('JS dependency measure', 'Used-for', 'optimal score calculation')
('negative sampling', 'Used-for', 'embedding algorithm')
('pseudo-demonstrations', 'Used-for', 'improving zero-shot results')
('NER', 'Is-a-Prerequisite-of', 'neural sequence labeling')
('Zero-shot learning', 'Used-for', 'object detection')
('object detection', 'Part-of', 'Language & Vision tasks')
('VID-sentence dataset', 'Used-for', 'object detection')
('spontaneous speech transcripts', 'Is-a-Prerequisite-of', 'object detection')
('pragmatic speaker', 'Evaluate-for', 'object detection')
('Adaptive scaling', 'Used-for', 'object detection')
('neural network based detection models', 'Used-for', 'object \\detection\\')
('detection tasks', 'Hyponym-Of', 'object detection')
('monte carlo tree search', 'Used-for', 'guiding the search procedure')
('monte carlo tree search', 'Used-for', 'dynamically allocating computing budgets')
('CH-SIMS', 'Used-for', 'studying interaction between modalities')
('CH-SIMS', 'Used-for', 'unimodal sentiment analysis')
('multimodal sentiment analysis', 'Is-a-Prerequisite-of', 'CH-SIMS')
('action recognition', 'Used-for', 'image annotation')
('action recognition', 'Used-for', 'scene understanding')
('action recognition', 'Used-for', 'image retrieval')
('language model', 'Used-for', 'advising single-step actions')
('tree search', 'Used-for', 'finding a sequence of correct steps')
('Variational Autoencoder', 'Is-a-Prerequisite-of', 'variational bayes model')
('Variational autoencoders', 'Used-for', 'natural language generation')
('Variational Autoencoder', 'Used-for', 'approximate a model’s posterior on latent variables')
('StructVAE', 'Hyponym-Of', 'variational bayes model')
('Variational autoencoders', 'Used-for', 'recovering missing facts in a knowledge base')
('Variational autoencoders', 'Part-of', 'latent variable models')
('Variational Bayes', 'Used-for', 'word representation learning in BHWR')
('Bayesian Hierarchical Words Representation', 'Evaluate-for', 'variational bayes model')
('Sequence-to-Action', 'Used-for', 'semantic graph generation')
('probabilistic treatment', 'Used-for', 'phonological typology')
('probabilistic treatment', 'Hyponym-Of', 'computational methods')
('phonological typology', 'Used-for', 'studying natural vowel inventory')
('probabilistic FastText', 'Used-for', 'capturing multiple word senses')
('recursive neural network', 'Used-for', 'explicitly modeling structured information')
('Rhetorical Structure Theory', 'Used-for', 'benefits text categorization')
('recursive neural network', 'Is-a-Prerequisite-of', 'semantic role labeling')
('recursive neural network', 'Is-a-Prerequisite-of', 'inferencing tasks in NLP')
('recursive neural network', 'Compare', 'chain LSTMs')
('neural text simplification', 'Used-for', 'lexical simplification')
('neural text simplification', 'Used-for', 'content reduction')
('sentence alignment', 'Used-for', 'training automatic text simplification systems')
('neural Machine Translation', 'Used-for', 'sentence splitting')
('Machine Translation', 'Used-for', 'text simplification')
('sentence splitting', 'Hyponym-Of', 'text simplification operations')
('sentence splitting', 'Used-for', 'text simplification')
('sentence splitting', 'Is-a-Prerequisite-of', 'neural Machine Translation')
('sentence alignment', 'Used-for', 'text simplification')
('semantic parsing', 'Used-for', 'sentence splitting')
('discourse modes', 'Used-for', 'automatic essay scoring (AES')
('discourse modes', 'Used-for', 'features in classifiers')
('discourse modes', 'Used-for', 'identifying salient discussion points in spoken meetings')
('discourse relations', 'Part-of', 'discourse modes')
('discourse relations', 'Hyponym-Of', 'discourse modes')
('neural sequence labeling model', 'Used-for', 'identification of discourse modes')
('implicit discourse relation classification', 'Used-for', 'improving recognition without connectives')
('ArgRewrite', 'Used-for', 'advanced research in writing comparison and revision analysis')
('statistical discourse segmenters', 'Used-for', 'detecting intra-sentential segment boundaries')
('attention-based Bi-LSTM', 'Used-for', 'modeling argument pairs for discourse relationship recognition')
('social medium analysis', 'Used-for', 'estimating socio-economic profiles')
('social medium analysis', 'Used-for', 'predictive modeling of income')
('temporal orientation', 'Is-a-Prerequisite-of', 'predictive model of income')
('temporal orientation', 'Used-for', 'regression')
('dependency parsing', 'Used-for', 'handling Twitter-specific conventions')
('English dependency parsing', 'Used-for', 'parsing social media English')
('AAE', 'Hyponym-Of', 'social media English')
('Universal Dependencies 2.0', 'Part-of', 'dependency parsing')
('fake news detection', 'Used-for', 'preventing misinformation')
('echo chambers', 'Hyponym-Of', 'social media challenges')
('algorithms', 'Evaluate-for', 'counter argument detection')
('social medium analysis', 'Used-for', 'fake news detection')
('multi-task learning', 'Is-a-Prerequisite-of', 'neural network models')
('shared layers', 'Used-for', 'extracting common features')
('adversarial multi-task learning framework', 'Used-for', 'alleviating feature space interference')
('shared knowledge', 'Used-for', 'transfer to new tasks')
('translation model', 'Used-for', 'interpreting agents messages')
('object naming', 'Part-of', 'referring expression generation')
('distributional word embeddings', 'Used-for', 'linking visual to lexical information')
('event extraction', 'Used-for', 'knowledge base population')
('semantic role labeling', 'Used-for', 'understanding sentence structure')
('end-to-end ASR', 'Used-for', 'speech recognition without linguistic resources')
('Hybrid Code Networks', 'Used-for', 'dialog systems with less training data')
('syntax incorporation in NMT', 'Used-for', 'improving translation accuracy')
('robotics', 'Used-for', 'human-robot communication and collaboration')
('grounded verb semantics', 'Part-of', 'human-robot communication')
('reinforcement learning', 'Used-for', 'acquiring optimal policy for question-asking behaviors')
('interactive learning', 'Evaluate-for', 'grounded verb semantics')
('interactive learning', 'Used-for', 'engaging robots in interaction with humans')
('interactive learning approach', 'Compare', 'previous work')
('models for grounded verb semantics', 'Used-for', 'performance gain in new situations')
('noisy environment', 'Evaluate-for', 'robustness of robot models')
('Long Short Term Memory network', 'Used-for', 'predicting sequences in unannotated text')
('Long Short Term Memory network', 'Used-for', 'generation of conversational text')
('Long Short Term Memory network', 'Used-for', 'extraction of entity mentions and relations')
('Long Short Term Memory network', 'Hyponym-Of', 'recurrent neural networks')
('Neural approach', 'Used-for', 'prediction of sequences in unannotated text')
('Novel Hidden Markov Model variant', 'Used-for', 'aggregating sequential crowd labels')
('Affect-LM', 'Used-for', 'generation of emotional sentences')
('Attention mechanism', 'Used-for', 'extracting semantic relations')
('Syntax-infused variational autoencoder', 'Used-for', 'generation of syntactic trees')
('Restricted recurrent neural tensor networks', 'Compare', 'recurrent neural networks')
('Convolutional neural networks', 'Compare', 'long short term network')
('Aspect-level sentiment classification', 'Used-for', 'identifying sentiment in specific aspects of text')
('Automatic Content Extraction', 'Used-for', 'training of neural models')
('Deep Neural Networks', 'Used-for', 'feature representations learning')
('Expressive kernels', 'Compare', 'Deep Neural Networks')
('Nystrom low-rank approximation', 'Used-for', 'pre-training input layer of deep architecture')
('Kernelized Neural Network', 'Used-for', 'achieving state-of-the-art accuracy')
('Linguistic Patterns', 'Used-for', 'extracting users’ preferences')
('Matrix factorization', 'Used-for', 'modeling inter-topic preferences')
('Named Entity Recognition', 'Evaluate-for', 'metonymy resolution')
('Coreference Resolvers', 'Used-for', 'generalization to unseen domains')
('Recursive Neural Networks', 'Used-for', 'demographic inference on Twitter')
('Cross-cultural differences', 'Used-for', 'understanding slang terms across languages')
('Deep Neural Network', 'Used-for', 'improving bilingual text embeddings')
('Natural Language Inference', 'Is-a-Prerequisite-of', 'Recognizing Textual Entailment')
('Discourse markers', 'Used-for', 'augmenting quality of NLI model')
('summarization evaluation', 'Evaluate-for', 'discourse modes')
('Compressive summarization', 'Evaluate-for', 'summarization evaluation')
('extractive summarization', 'Hyponym-Of', 'summarization evaluation')
('abstractive summarization', 'Hyponym-Of', 'summarization evaluation')
('human evaluation', 'Is-a-Prerequisite-of', 'summarization evaluation')
('automatic metrics', 'Used-for', 'summarization evaluation')
('ROUGE', 'Used-for', 'abstractive summarization')
('BLEU', 'Used-for', 'summarization evaluation')
('neural models', 'Used-for', 'abstractive summarization')
('summarization evaluation', 'Evaluate-for', 'extractive and abstractive methods')
('transition based dependency parsing', 'Used-for', 'producing certain attachments between tokens')
('arc-swift', 'Is-a-Prerequisite-of', 'transition based dependency parsing')
('shift and reduce operations', 'Used-for', 'transition based dependency parsing')
('lexical information', 'Evaluate-for', 'transition based dependency parsing')
('error propagation', 'Evaluate-for', 'transition based dependency optionally parsing')
('biLSTM', 'Used-for', 'capturing long-range dependencies in transition based dependency parsing')
('multitask learning', 'Used-for', 'improving transition based dependency parsing')
('bidirectional LSTM', 'Used-for', 'feature extraction in transition based dependency parsing')
('neural network', 'Used-for', 'transition based dependency parsing')
('convolutional neural network', 'Used-for', 'composing word representations in transition based dependency parsing')
('MH₄ algorithm', 'Used-for', 'supporting non-projectivity in transition based dependency parsing')
('\n(Multi-task learning', 'Used-for', 'extracting common features across different tasks')
('Multi-task learning', 'Used-for', 'improving machine learning model performance')
('Multi-task learning', 'Is-a-Prerequisite-of', 'transferring knowledge to new tasks')
('Adversarial multi-task learning framework', 'Part-of', 'Multi-task learning')
('Text classification', 'Evaluate-for', 'Multi-task learning')
('Neural Machine Translation', 'Used-for', 'Multi-task learning')
('Interactive multi-task learning network', 'Part-of', 'Multi-task learning')
('Semantic parsing', 'Used-for', 'Multi-task learning')
('Dependency parsing', 'Evaluate-for', 'Multi-task learning')
('Keyphrase boundary classification', 'Used-for', 'Multi-task learning')
('Aspect-based sentiment analysis', 'Used-for', 'Multi-task learning')
('Encoder-decoder architectures', 'Used-for', 'Multi-task learning')
('Multi-task learning', 'Compare', 'Single-task learning')
('Knowledge graph embedding', 'Used-for', 'predicting missing facts')
('hyperbolic embedding', 'Is-a-Prerequisite-of', 'Knowledge graph embedding')
('hyperbolic embedding', 'Used-for', 'modeling hierarchical data')
('attention mechanisms', 'Used-for', 'modeling complex relational patterns')
('Knowledge graph', 'Used-for', 'predicting missing facts')
('Euclidean-based efforts', 'Compare', 'hyperbolic-based efforts')
('Machine translation', 'Used-for', 'multilingual model')
('translationese', 'Hyponym-Of', 'Machine translation')
('translationese', 'Evaluate-for', 'producing higher BLEU scores')
('natural text', 'Hyponym-Of', 'Machine translation')
('natural text', 'Used-for', 'yielding natural outputs')
('deep transformers', 'Used-for', 'Text-to-SQL semantic parsing')
('shallow layers', 'Compare', 'deep transformers')
('RoBERTa\nNone\n(generative and discriminative model', 'Compare', 'performance on parsing')
('generative and discriminative model', 'Compare', 'language modeling performance')
('generative and discriminative model', 'Part-of', 'encoder-decoder framework')
('generative model', 'Used-for', 'language modeling')
('discriminative model', 'Used-for', 'language modeling')
('encoder-decoder framework', 'Used-for', 'marrying models for parsing and language modeling')
('expectation maximization', 'Evaluate-for', 'interpretation of framework')
('variational inference', 'Evaluate-for', 'interpretation of framework')
('generative and discriminative model', 'Used-for', 'unsupervised relation extraction')
('Snorkel framework', 'Is-a-Prerequisite-of', 'data programming')
('cross-lingual transfer', 'Used-for', 'syntactic analysis in low-resource languages')
('Hyperbolic Capsule Networks', 'Used-for', 'Multi-Label Classification')
('generative model', 'Hyponym-Of', 'unsupervised relation extraction methods')
('Kernel spaces', 'Part-of', 'Nystrom low-rank approximation')
('Structured representations', 'Used-for', 'Language learning')
('Tree Kernels', 'Used-for', 'NLP')
('Structured information', 'Used-for', 'Syntactic knowledge')
('Deep neural networks', 'Used-for', 'Learning feature representations')
('Tensor data', 'Compare', 'Structured information')
('Deep neural networks', 'Compare', 'Kernel methods')
('Propaganda trees', 'Evaluate-for', 'Kernel-based method')
('Sequence-to-Dependency Neural Machine Translation', 'Used-for', 'Neural Machine Translation')
('Dependency structure', 'Part-of', 'Sequence-to-Dependency Neural Machine Translation')
('Rumor detection', 'Evaluate-for', 'Propagation Tree Kernel')
('Argument mining', 'Evaluate-for', 'Factor graph model')
('Deep neural networks', 'Used-for', 'Modeling linguistic structures')
('Probabilistic FastText', 'Used-for', 'Word embeddings')
('Hierarchical information', 'Used-for', 'Entity linking')
('word distribution', 'Compare', 'semantic representation')
('word distribution', 'Compare', 'semantic model')
('word distribution', 'Hyponym-Of', 'statistical distribution')
('word distribution', 'Is-a-Prerequisite-of', 'language modeling')
('word distribution', 'Part-of', 'morphological constraints')
('word distribution', 'Part-of', 'NLP applications')
('word distribution', 'Used-for', 'learning word representations')
('word distribution', 'Used-for', 'inducing accurate representations')
('language modeling', 'Used-for', 'yielding semantic understanding')
('neural word embeddings', 'Compare', 'topic models')
('neural word embeddings', 'Conjunction', 'language modeling')
('semantic representation', 'Part-of', 'NLP systems')
('semantic model', 'Conjunction', 'word embeddings')
('lexical features', 'Evaluate-for', 'social scientific prediction')
('adversarial training', 'Used-for', 'domain adaptation')
('domain adaptation', 'Compare', 'method adaptation')
('domain adaptation', 'Used-for', 'reducing distribution mismatch')
('cross-lingual text classification', 'Used-for', 'document classification')
('neural language model', 'Used-for', 'representing content in poetic forms')
('neural language model', 'Used-for', 'constraining content based on form in poetry generation')
('neural language models', 'Evaluate-for', 'language model perplexity')
('neural language models', 'Used-for', 'generating related sentences for a topic')
('neural language model', 'Used-for', 'parsing natural language into source code')
('RNNs', 'Is-a-Prerequisite-of', 'neural language modeling')
('LSTM', 'Hyponym-Of', 'RNNs')
('LSTM language model', 'Used-for', 'generation of conversational text conditioned on affect categories')
('neural language model', 'Used-for', 'incorporating document context in language modeling')
('\n(speech recognition', 'Used-for', 'automatic transcription')
('speech recognition', 'Hyponym-Of', 'natural language processing')
('speech recognition', 'Part-of', 'multimodal language processing')
('end-to-end automatic speech recognition', 'Is-a-Prerequisite-of', 'multi-speaker speech recognition')
('attention-based methods', 'Used-for', 'aligning acoustic frames with recognized symbols')
('connectionist temporal classification', 'Used-for', 'solving sequential problems')
('hybrid CTC/attention architecture', 'Used-for', 'speech recognition')
('weighted finite state transducers', 'Used-for', 'speech recognition')
('multi-speaker speech recognition', 'Used-for', 'decoding speech from multiple sources')
('fixed-size ordinally forgetting encoding', 'Used-for', 'named entity recognition')
('probabilistic reachability masks', 'Used-for', 'adapting self-attention to lattices in speech tasks')
('conventional DNN/HMM ASR systems', 'Compare', 'end-to-end automatic speech recognition')
('latent Dirichlet Allocation', 'Used-for', 'topic modeling')
('crawling the web', 'Used-for', 'building publicly available parallel corpora')
('parallel corpora', 'Is-a-Prerequisite-of', 'machine translation systems')
('machine translation systems', 'Evaluate-for', 'usefulness of parallel corpora')
('self-attention networks', 'Part-of', 'pre-trained models')
('redundancy', 'Compare', 'utilization in self-attention networks')
('HiddenCut', 'Used-for', 'regularizing models')
('HiddenCut', 'Used-for', 'learning generalizable features')
('data augmentation', 'Compare', 'HiddenCut')
('GLUE benchmark', 'Evaluate-for', 'HiddenCut method')
('parameterization', 'Used-for', 'enhancing small PLMs')
('matrix product operator', 'Used-for', 'over-parameterization')
('demographic biases', 'Part-of', 'pretrained language models (PLMs')
('CausalDebias', 'Used-for', 'debiasing PLMs')
('CausalDebias', 'Used-for', 'improving task performance in N\n(None')
('stochastic optimization', 'Used-for', 'large training sets')
('gradient noise', 'Used-for', 'enhancing exploration of the model-parameter space')
('Riemannian optimization', 'Used-for', 'optimizing SGNS objective')
('learning automatic Pyramid scores', 'Used-for', 'optimization-based extractive multi-document summarization')
('robust self-learning algorithm', 'Used-for', 'iterative improvement of embedding alignment')
('counterfactual learning', 'Used-for', 'improving neural semantic parsing systems')
('optimization', 'Evaluate-for', 'improving BLEU score in neural machine translation')
('optimization', 'Evaluate-for', 'training deep neural networks')
('optimization', 'Evaluate-for', 'search problem solving in structured prediction')
('genetic algorithm', 'Used-for', 'automatic training data generation')
('Bayesian learning algorithm', 'Evaluate-for', 'learning weight uncertainty in RNNs')
('predicate logic', 'Is-a-Prerequisite-of', 'predicate argument structure analysis')
('predicate logic', 'Used-for', 'assessing commitment towards predicates')
('predicate logic', 'Hyponym-Of', 'formal ontology')
('predicate logic', 'Used-for', 'semantic disambighuation')
('predicate logic', 'Hyponym-Of', 'typed entailment graphs')
('predicate logic', 'Evaluate-for', 'Logical forms production')
('predicate logic', 'Used-for', 'logical reasoning over text')
('Conditional Hidden Markov Model', 'Hyponym-Of', 'Hidden Markov Model')
('Hidden Markov Model', 'Used-for', 'aggregating sequential crowd labels')
('Hidden Markov Model variant', 'Hyponym-Of', 'Hidden Markov Model')
('Hidden Markov Model', 'Used-for', 'predicting sequences in unannotated text')
('Neural Hidden Markov Model', 'Hyponym-Of', 'Hidden Markov Model')
('Neural Hidden Markov Model', 'Used-for', 'neural network-based alignment')
('Neural Hidden Hidden Markov Model', 'Used-for', 'lexicon models')
('Bayesian Network', 'Is-a-Prerequisite-of', 'Interpretable Relationships')
('Bayesian Network', 'Part-of', 'Bayesian Network Ensembles')
('Bayesian Network Ensembles', 'Used-for', 'Automatic Diagnosis')
('Automatic Diagnosis', 'Evaluate-for', 'Clinical Use')
('Interpretable Relationships', 'Used-for', 'Concept Graph Refinement')
('Concept Graphs', 'Part-of', 'Text Understanding Systems')
('Entity-Aware Convolutional Neural Networks', 'Part-of', 'Bayesian Network Ensembles')
('Bayesian Network', 'Used-for', 'Probabilistic Inference')
('feature learning', 'Used-for', 'inducing embeddings for rare or unseen words')
('feature learning', 'Part-of', 'multi-space variational encoder-decoders')
('feature hashing', 'Is-a-Prerequisite-of', 'feature learning')
('neural networks', 'Used-for', 'feature learning')
('feature learning', 'Used-for', 'transfer learning')
('transfer learning', 'Used-for', 'Universal Language Model Fine-tuning')
('domain adaptation', 'Used-for', 'feature learning')
('feature learning', 'Used-for', 'enhancing performance in NLP tasks')
('kernel methods', 'Hyponym-Of', 'feature learning')
('neural networks', 'Used-for', 'handling discrete and continuous latent variables')
('event extraction', 'Used-for', 'knowledge base population')
('labeling training data', 'Evaluate-for', 'improving supervised learning models')
('seq2seq', 'Used-for', 'named entity recognition')
('seq2node', 'Used-for', 'machine translation')
('seq2seq', 'Compare', 'RNN-based approaches')
('seq2seq', 'Compare', 'convolutional seq2seq model')
('convolutional seq2seq model', 'Compare', 'Transformer model')
('seq2seq', 'Part-of', 'neural machine translation')
('seq2seq', 'Used-for', 'response generation in conversation')
('seq2seq', 'Part-of', 'Multi-Task Learning')
('seq2seq', 'Used-for', 'grammatical error correction')
('seq2seq', 'Used-for', 'task-oriented dialog systems')
('seq2seq', 'Used-for', 'response selection in retrieval-based chatbots')
('seq2seq', 'Used-for', 'slot filling in spoken language understanding systems')
('Entity annotations', 'Used-for', 'representing queries and documents in EDRM')
('Distributed representations', 'Used-for', 'integrating semantics from knowledge graphs')
('Knowledge graphs', 'Used-for', 'improving generalization ability of neural ranking models')
('Neural ranking networks', 'Part-of', 'Entity-Duet Neural Ranking Model')
('Semantic integration', 'Used-for', 'enhancing entity representations in EDRM')
('problem solving and search', 'Is-a-Prerequisite-of', 'NumS2T')
('NumS2T', 'Used-for', 'math word problem solving')
('NumS2T', 'Evaluate-for', 'enhancing math word problem solving performance')
('math word problem solving', 'Evaluate-for', 'numerical values incorporation')
('math word problem solving', 'Part-of', 'end-to-end math problem solving system')
('geometry problem solving', 'Part-of', 'end-to-end math problem solving system')
('Interpretable Geometry Problem Solver', 'Used-for', 'geometry problem solving')
('Interpretable Geometry Problem Solver', 'Evaluate-for', 'symbolic reasoning')
('theoretical knowledge', 'Is-a-Prerequisite-of', 'theorem prediction')
('theorem prediction', 'Used-for', 'geometry problem solving')
('geometry problem solving', 'Evaluate-for', 'abstract problem understanding')
('symbolic reasoning', 'Used-for', 'Interpretable Geometry Problem Solver')
('symbolic reasoning', 'Compare', 'implicit\n(Neural Machine Translation (NMT')
('Gradient Diffusion', 'Part-of', 'Challenges in deep architecture NMT')
('Bidirectional LSTMs', 'Used-for', 'neural machine translation (NMT')
('phonological feature', 'Evaluate-for', 'learning phonotactic patterns')
('distinctive feature', 'Compare', 'phonological feature')
('representations of subword units', 'Used-for', 'capturing morphological regularities')
('lexical resources', 'Used-for', 'training generative model')
('lexical features', 'Used-for', 'representing context of mentions')
('lexical features', 'Is-a-Prerequisite-of', 'coreference resolution')
('generative model', 'Used-for', 'observing lexical resources')
('part-of-speech induction', 'Used-for', 'evaluating generative model approach')
('low-resource named-entity recognition', 'Used-for', 'evaluating generative model approach')
('discriminative training', 'Used-for', 'estimating lexical feature weights')
('generative approach', 'Compare', 'discriminative training')
('morphological typologies', 'Evaluate-for', 'effectiveness of character representations')
('morphological typologies', 'Part-of', 'language modeling')
('neural model', 'Used-for', 'morphological inflection generation')
('semantic representation', 'Compare', 'syntactic representation')
('Semantic representation', 'Used-for', 'clarifying research goals')
('AMR', 'Used-for', 'parsing and generating text')
('AMR', 'Part-of', 'semantic representation')
('UCCA', 'Part-of', 'semantic representation')
('GMB', 'Part-of', 'semantic representation')
('UDS', 'Part-of', 'semantic representation')
('sequence-to-sequence models', 'Used-for', 'AMR parsing')
('sequence-to-sequence models', 'Used-for', 'AMR generation')
('Kernel methods', 'Used-for', 'textual data representation')
('Kernels', 'Hyponym-Of', 'Kernel methods')
('Tree Kernels', 'Hyponym-Of', 'Kernels')
('deep neural networks', 'Used-for', 'learning feature representations')
('neural language model', 'Used-for', 'incorporating document context')
('code generation', 'Is-a-Prerequisite-of', 'semantic parsing')
('semantic parsing', 'Used-for', 'mapping natural language to executable programs')
('reinforcement learning', 'Used-for', 'exploration in learning algorithms')
('maximum marginal likelihood', 'Used-for', 'systematic search in learning algorithms')
('abstract syntax trees', 'Part-of', 'semantic parsing')
('SpanBasedSP', 'Used-for', 'compositional generalization in semantic parsing')
('Seq2Tree models', 'Used-for', 'code generation')
('contextual embeddings', 'Used-for', 'word sense disambiguition')
('counterfactual learning', 'Used-for', 'improving semantic parsing')
('knowledge base', 'Used-for', 'semantic parsing')
('controlled text generation', 'Is-a-Prerequisite-of', 'fine-grained control in text output')
('controlled text generation', 'Used-for', 'conditional text generation')
('controlled text generation', 'Evaluate-for', 'compliance with specific rules and conditions')
('neural models', 'Used-for', 'abstractive sentence summarization')
('graph-based attention', 'Used-for', 'neural abstractive document summarization')
('neural models', 'Compare', 'extractive methods')
('graph-based attention', 'Part-of', 'sequence-to-sequence framework')
('saliency factor', 'Evaluate-for', 'summarization effectiveness')
('data-to-text generation model', 'Used-for', 'Summary generation')
('tracking module', 'Used-for', 'selection and memorization of salient information')
('generation module', 'Used-for', 'summary generation based on tracking module')
('Pre-train and Plug-in Variational Auto-Encoder', 'Used-for', 'flexible conditional text generation')
('predictive models', 'Used-for', 'classify news posts as suspicious or verified')
('neural network models', 'Evaluate-for', 'classification of news posts')
('lexical models', 'Compare', 'neural network models')
('syntax and grammar features', 'Evaluate-for', 'model performance')
('linguistic features', 'Used-for', 'improves classification results')
('social interaction features', 'Used-for', 'finer-grained separation between types of suspicious news posts')
('GloVe', 'Used-for', 'learn vector representations of word meaning')
('co-occurrence statistics', 'Used-for', 'capture information about relationships between words')
('relation vectors', 'Used-for', 'embed into vector space')
('Integer Linear Programming', 'Used-for', 'event coreferences resolution')
('topic transition sentences', 'Conjunction', 'main event chains')
('local coreference relation classifier', 'Used-for', 'resolving multiple event chains')
('multi-step reasoning', 'Used-for', 'visual dialogue answer inference')
('visual dialogue', 'Used-for', 'question-answering about images')
('visual dialogue', 'Hyponym-Of', 'multimodal dialogue systems')
('ReDAN', 'Evaluate-for', 'progressive question-answering')
('visual dialogue', 'Compare', 'traditional text-based dialogue systems')
('multi-step reasoning', 'Part-of', 'ReDAN')
('visual clues', 'Used-for', 'contextual relevance in visual dialogue')
('textual clues', 'Used-for', 'contextual relevance in visual dialogue')
('iterative refinement', 'Used-for', 'enhanced answer accuracy in visual dialogue')
('commonsense evaluation', 'Used-for', 'assessing AI models on commonsense reasoning tasks')
('commonsense evaluation', 'Used-for', 'improving performance of machine learning models')
('commonsense evaluation', 'Compare', 'traditional cognitive assessment')
('commonsense reasoning', 'Is-a-Prerequisite-of', 'commonsense evaluation')
('domain-specific knowledge', 'Is-a-Prerequisite-of', 'commonsense evaluation')
('evaluation metrics', 'Used-for', 'quantifying performance in commonsense evaluation')
('neural machine translation', 'Evaluate-for', 'cross-lingual commonsense reasoning')
('cross-lingual commonsense reasoning', 'Evaluate-for', 'commonsense evaluation')
('vector cosine', 'Compare', 'rank-based metric in word embeddings evaluation')
('BLEU metric', 'Evaluate-for', 'neural machine translation systems')
('neural-symbolic reasoner', 'Used-for', 'reasoning over commonsense knowledge graphs')
('Commonsense Knowledge\n(discourse modes', 'Used-for', 'automatic essay scoring')
('automatic identification', 'Used-for', 'sequence labeling model')
('sequence labeling model', 'Used-for', 'named entity recognition')
('sequence labeling model', 'Is-a-Prerequisite-of', 'training data')
('narration', 'Part-of', 'discourse modes')
('exposition', 'Part-of', 'discourse modes')
('description', 'Part-of', 'discourse modes')
('argument', 'Part-of', 'discourse modes')
('emotion expressing sentences', 'Part-of', 'discourse modes')
('neural sequence labeling model', 'Hyponym-Of', 'sequence labeling model')
('F1-score', 'Evaluate-for', 'sequence labeling model')
('named entity recognition', 'Used-for', 'sequence labeling model')
('fofe method', 'Used-for', 'sequence labeling model')
('feedforward neural network', 'Used-for', 'sequence labeling model')
('named entity recognition', 'Compare', 'mention detection')
('question generation', 'Used-for', 'sequence modeling')
('sequence modeling', 'Hyponym-Of', 'sequence labeling model')
('sequence labeling model', 'Used-for', 'information extraction')
('Natural-language Inference over Label', 'Used-for', 'Explanation generation')
('NL explanation', 'Evaluate-for', 'Model decision-making faithfulness')
('BabbleLabble', 'Used-for', 'Noisy label generation')
('Label explanation', 'Is-a-Prerequisite-of', 'Explanation-based learning')
('Explanation-based learning', 'Used-for', 'Increased model transparency')
('Generative explanation framework', 'Used-for', 'Generating human-readable explanations')
('Natural language explanations', 'Evaluate-for', 'Classifier training')
('None', 'Part-of', 'interpretability')
('Interpretability method', 'Used-for', 'explain model behavior')
('Interpretability method', 'Evaluate-for', 'Neural networks')
('DihEdral', 'Used-for', 'Interpretability method')
('Sensitivity analysis', 'Used-for', 'Interpretability method')
('ConvE', 'Compare', 'Interpretability method')
('LIME', 'Compare', 'Interpretability method')
('Input perturbation', 'Compare', 'Interpretability method')
('Self-explanatory attention mechanism', 'Compare', 'Input perturbation')
('Interpretability method', 'Used-for', 'Machine learning models')
('Entity-Aware CNN', 'Evaluate-for', 'Interpretability method')
('Bayesian Network', 'Evaluate-for', 'Interpretability method')
('Word2Sense embeddings', 'Conjunction', 'Interpretability method')
('Functional Distributional Semantics', 'Used-for', 'Interpretability method')
('Sequence-to-Dependency Neural Machine Translation', 'Used-for', 'generating translations with dependency structure context')
('training classifiers', 'Used-for', 'generating noisy labels using BabbleLabble framework')
('entity-centric neural architecture', 'Used-for', 'generating text conditioned on entity memories with hierarchical attention')
('sentence movers similarity', 'Used-for', 'evaluating semantic similarity in generated text')
('Graph-aware Co-Attention Networks', 'Used-for', 'generating explanations for fake news detection')
('Transformer-based generation framework', 'Used-for', 'generating text from knowledge triples in table-to-text generation')
('ExpBERT', 'Used-for', 'generating explanation-guided representations for relation extraction tasks')
('training classifiers', 'Compare', 'providing explanations vs. just labels in terms of speed and accuracy')
('Neural Machine Translation', 'Evaluate-for', 'generating translations with reference data incorporation through Reference Network')
('topic model', 'Compare', 'neural language model')
('neural language model', 'Used-for', 'language model perplexity improvement')
('neural language model', 'Hyponym-Of', 'language models')
('document context', 'Part-of', 'neural language model')
('language model perplexity', 'Evaluate-for', 'neural language model')
('topic model', 'Used-for', 'generation of related sentences')
('neural word embeddings', 'Used-for', 'aspect extraction')
('aspect extraction', 'Used-for', 'aspect-based sentiment analysis')
('neural word embeddings', 'Hyponym-Of', 'word embeddings')
('topic model', 'Hyponym-Of', 'latent Dirichlet allocation (LDA')
('cognitive NLP systems', 'Used-for', 'augmenting text-based features')
('cognitive features', 'Used-for', 'text subtleties evaluation')
('manual extraction', 'Evaluate-for', 'tackling text subtleties')
('Sentiment Analysis', 'Is-a-Prerequisite-of', 'sarcasm detection')
('cognitive features', 'Used-for', 'Sentiment Analysis')
('cognitive features', 'Used-for', 'sarcasm detection')
('relation classification', 'Used-for', 'implicit discourse recognition')
('relation classification', 'Hyponym-Of', 'NLP systems')
('implicit relation network', 'Used-for', 'relation classification')
('feature imitation framework', 'Used-for', 'relation classification')
('convolutional neural network', 'Used-for', 'feature extraction')
('learning system', 'Used-for', 'automatic feature delegation')
('neural network', 'Used-for', 'relation classification')
('None', 'Used-for', 'generating responses')
('automatic dialogue', 'Used-for', 'collecting symptoms')
('automatic dialogue', 'Used-for', 'response selection')
('encoder-decoder', 'Part-of', 'automatic dialogue')
('belief spans', 'Part-of', 'automatic dialogue')
('world model', 'Part-of', 'automatic dialogue')
('SQuADRUn', 'Evaluate-for', 'automatic dialogue')
('Two Stage CopyNet', 'Used-for', 'automatic dialogue')
('EuroSense', 'Evaluate-for', 'automatic dialogue')
('distributed word representation', 'Used-for', 'modeling words in NLP tasks')
('distributed word representation', 'Hyponym-Of', 'word vectors')
('AllVec', 'Used-for', 'generating distributed word representations')
('Neural Belief Tracking', 'Evaluate-for', 'distributed word representation')
('Neural Belief Tracking', 'Used-for', 'distributed representation of user utterances')
('Semantic similarity', 'Evaluate-for', 'distributed word representation')
('Skip-gram model', 'Used-for', 'learning distributed word representations')
('Korean language', 'Evaluate-for', 'distributed word performance')
('Hierarchical Dirichlet Process', 'Used-for', 'learning multiple distributed word representations')
('Entity-Duet Neural Ranking Model', 'Used-for', 'distributed representations of queries and documents')
('Word Sememe Information', 'Evaluate-for', 'improving distributed word representation')
('Multilingual distributed representations', 'Used-for', 'learning word and sentence embeddings')
('Multilingual distributed representations', 'Used-for', 'cross-lingual document classification')
('Transferable information', 'Hyponym-Of', 'Words that do not change polarity or significance across domains in sentiment classification')
('Cross-domain Data Augmentation', 'Used-for', 'generating labeled target-domain data')
('Domain-Adaptive Language Modeling', 'Used-for', 'cross-domain Data Augmentation')
('Cross-domain aspect-based sentiment analysis', 'Evaluate-for', 'identifying aspect-sentiment pairs in target domain sentences')
('Cross-domain aspect-based sentiment analysis', 'Part-of', 'Aspect-Based Sentiment Analysis')
('Aspect-Based Sentiment Analysis', 'Is-a-Prerequisite-of', 'cross-domain aspect-based sentiment analysis')
('Cross-domain aspect-based sentiment analysis', 'Hyponym-Of', 'Aspect-Based Sentiment Analysis')
('spurious programs', 'Part-of', 'semantic parsing challenges')
('semantic parsing', 'Used-for', 'transducing natural language utterances into formal meaning representations')
('semantic parsing', 'Compare', 'syntactic parsing')
('semantic parsing', 'Conjunction', 'reinforcement learning and maximum marginal likelihood')
('semantic parsing', 'Part-of', 'natural language processing')
('semantic parsing', 'Evaluate-for', 'effectiveness in understanding natural language')
('neural semantic parser', 'Used-for', 'semantic parsing')
('counterfactual learning', 'Used-for', 'improving neural semantic parsers')
('counterfactual learning', 'Is-a-Prerequisite-of', 'reweighting estimators in semantic parsing')
('UCCA parsing', 'Part-of', 'semantic parsing')
('neural model', 'Used-for', 'semantic parsing over structured data')
('multit\n(representation learning', 'Used-for', 'modeling words in NLP tasks')
('multimodal word distributions', 'Part-of', 'representation learning')
('vector space representations', 'Part-of', 'representation learning')
('word embeddings', 'Part-of', 'representation learning')
('word embeddings', 'Compare', 'multimodal word distributions')
('distributed word representations', 'Part-of', 'representation learning')
('word embeddings', 'Used-for', 'semantic textual similarity tasks')
('word embeddings', 'Used-for', 'lexical substitution task')
('word embeddings', 'Used-for', 'modeling semantics in sentences')
('deep neural networks', 'Compare', 'kernel methods')
('deep neural links', 'Is-a-Prerequisite-of', 'representation learning')
('deep neural networks', 'Used-for', 'learning representations')
('kernel methods', 'Used-for', 'modeling structured textual data')
('kernelized neural network', 'Used-for', 'achieving state-of-the-art accuracy in tasks')
('specializing word embeddings', 'Used-for', 'semantic similarity tasks')
('Pseudofit', 'Is-a-Prerequisite-of', 'specializing word embeddings')
('external knowledge', 'Used-for', 'specializing word embeddings')
('pseudo-sense', 'Used-for', 'building several representations for each word')
('semantic similarity', 'Evaluate-for', 'specializing word embeddings')
('representations', 'Part-of', 'specializing word embeddings')
('annotated training data', 'Used-for', 'building NLP models for low-resource languages')
('neural network models', 'Evaluate-for', 'annotated training data')
('annotated training data', 'Is-a-Prerequisite-of', 'reliably estimating lexical feature weights')
('annotated training data', 'Used-for', 'Spoken Language Understanding models')
('neural networks', 'Used-for', 'annotated training data')
('regular training data', 'Compare', 'annotated training data')
('low-resource languages', 'Used-for', 'annotated training')
('Spoken Language Understanding models', 'Evaluate-for', 'annotated training data')
('lexical features', 'Evaluate-for', 'annotated training data')
('neural natural language inference models', 'Used-for', 'annotated training data')
('distant supervision', 'Part-of', 'annotated training data generation')
('unsupervised bilingual word embeddings', 'Used-for', 'bilingual dictionary induction')
('bilingual dictionary induction', 'Evaluate-for', 'unsupervised bilingual word embeddings')
('unsupervised bilingual word embeddings', 'Is-a-Prerequisite-of', 'unsupervised neural machine translation')
('unsupervised bilingual word embeddings', 'Part-of', 'cross-lingual NLP tasks')
('unsupervised machine translation', 'Used-for', 'unsupervised bilingual word embeddings')
('bilingual word embeddings', 'Part-of', 'machine translation')
('bilingual word embeddings', 'Used-for', 'cross-lingual sentiment classification')
('unsupervised bilingual word embeddings', 'Used-for', 'mining parallel sentences')
('unsupervised bilingual word embeddings', 'Compare', 'bilingual word embeddings')
('unsupervised neural machine translation', 'Evaluate-for', 'unsupervised bilingual word embeddings')
('unsupervised bilingual lexicon induction', 'Evaluate-for', 'unsupervised bilingual word embeddings')
('unsup\n(natural language explanation NLEs', 'Used-for', 'real-world question answering systems')
('natural language explanation NLEs', 'Used-for', 'generating answers with natural language')
('natural language explanation NLEs', 'Part-of', 'semantic parser')
('semantic parser', 'Used-for', 'converting natural language utterances to predicate-argument structures')
('predicate-argument structures', 'Used-for', 'mapping to target domains')
('predicate-argument structures', 'Evaluate-for', 'types of representations for semantic parsing')
('COREQA', 'Used-for', 'leveraging copying and retrieving mechanisms')
('neural semantic parser', 'Used-for', 'creating intermediate domain-general natural language representations')
('neural semantic parser', 'Is-a-Prerequisite-of', 'achieving state-of-the-art results in semantic parsing tasks')
('compositional distributional semantics model', 'Used-for', 'evaluation of Polish language semantics')
('compositional distributional semantics model', 'Evaluate-for', 'semantic relatedness and entailment')
('Poincaré embeddings', 'Used-for', 'detecting compositionality for noun phrases')
('Poincaré embeddings', 'Part-of', 'compositional distributional semantics model')
('SentiBERT', 'Is-a-Prerequisite-of', 'compositional distributional semantics model')
('SentiBERT', 'Used-for', 'phrase-level sentiment classification')
('SentiBERT', 'Evaluate-for', 'capturing negation and contrastive relations')
('Functional Distributional Semantics', 'Hyponym-Of', 'compositional distributional semantics model')
('Functional Distributional Semantics', 'Used-for', 'semantic similarity assessment in context')
('Pixie Autoencoder', 'Used-for', 'training Functional Distributional Semantics models')
('Anchored Packed Trees', 'Part-of', 'compositional distributional semantics model')
('Anchored Packed Trees', 'Used-for', 'counting grammatical type co-\n(None')
('existing word embedding', 'Compare', 'newly proposed word embedding methods')
('existing word embedding', 'Used-for', 'lexical analysis')
('neural word embeddings', 'Used-for', 'aspect extraction')
('distributional word embeddings', 'Used-for', 'linking visual and lexical information')
('word embeddings', 'Used-for', 'coherent aspect discovery')
('word embeddings', 'Hyponym-Of', 'vector space representations')
('neural word embeddings', 'Evaluate-for', 'model interpretability improvements')
('word embeddings', 'Compare', 'character-level embeddings')
('neural word embeddings', 'Used-for', 'Volatility prediction')
('existing word embedding', 'Is-a-Prerequisite-of', 'robust sentiment analysis methods')
('existing word embedding', 'Used-for', 'pre-trained context embeddings for NLP tasks')
('spectral clustering', 'Evaluate-for', 'analyzing synonyms and antonyms in word embeddings')
('Volatility prediction', 'Used-for', 'information retrieval term weighting models')
('existing word embedding\n(sarcasm detection', 'Is-a-Prerequisite-of', 'multi-modal sarcasm detection')
('multi-modal sarcasm detection', 'Part-of', 'sarcasm detection')
('textual sarcasm detection', 'Is-a-Prerequisite-of', 'multi-modal sarcasm detection')
('iSarcasm dataset', 'Used-for', 'sarcasm detection')
('MUStARD', 'Used-for', 'multi-modal sarcasm detection')
('textual sarcasm detection', 'Compare', 'multi-modal sarcasm detection')
('sarcasm detection', 'Evaluate-for', 'sarcasm annotation')
('BiLSTM', 'Used-for', 'multi-modal sarcasm detection')
('multi-modal hierarchical fusion model', 'Used-for', 'multi-modal sarcasm detection')
('sarcasm detection dataset', 'Hyponym-Of', 'sarcasm detection')
('author context', 'Used-for', 'textual sarcasm detection')
('neural parser', 'Used-for', 'AMR parsing')
('neural parser', 'Used-for', 'parsing benchmark treebanks')
('neural parser', 'Evaluate-for', 'accuracy improvement')
('neural parser', 'Hyponym-Of', 'natural language processing tool')
('neural parser', 'Used-for', 'aligning nodes in semantic graphs')
('neural summarization model', 'Evaluate-for', 'factual correctness')
('neural parser', 'Used-for', 'interpreting neural summarization decisions')
('neural parser', 'Is-a-Prerequisite-of', 'achieving state-of-the-art results on LDC2016E25')
('AMR parsing', 'Part-of', 'automatic meaning representations')
('syntactic divergence', 'Used-for', 'informing cross-lingual transfer')
('Fact checking article', 'Used-for', 'Identifying types of misinformation')
('Fact checking article', 'Compare', 'Review article')
('Fact checking article', 'Part-of', 'Fact-checking system')
('Fact checking article', 'Evaluate-for', 'Verdict generation')
('Fact Extraction and VERification', 'Part-of', 'Fact checking article')
('Misinformation types', 'Hyponym-Of', 'Fact checking article')
('Rationale extraction', 'Used-for', 'Improving fact checking article')
('Semantic role labeling', 'Used-for', 'Structure of evidence')
('Fact checking article', 'Evaluate-for', 'Factual correctness')
('Fact checking article', 'Evaluate-for', 'Evidence retrieval')
('generative neural models', 'Used-for', 'constituency parsing')
('constituency parsing', 'Is-a-Prerequisite-of', 'generative neural models')
('base parsers', 'Used-for', 'decoding')
('generative models', 'Used-for', 'rescoring candidate outputs')
('generative models', 'Part-of', 'natural language processing')
('model combination', 'Evaluate-for', 'improving performance in parsing')
('context information', 'Used-for', 'dialog processing')
('dialogue Act classification', 'Used-for', 'dialog systems')
('unsupervised NMT', 'Used-for', 'machine translation without labeled data')
('unsupervised NMT', 'Part-of', 'neural machine translation')
('GANs', 'Used-for', 'enhancing cross-language translation')
('context-query relevance', 'Used-for', 'weighting context vectors')
('novel\n(summarization task', 'Used-for', 'generate shorter version of the document')
('query-based summarization', 'Is-a-Prerequisite-of', 'summarization task')
('abstractive summarization', 'Is-a-Prerequisite-of', 'summarization task')
('extractive summarization', 'Is-a-Prerequisite-of', 'summarization task')
('extractive summarization', 'Compare', 'abstractive summarization')
('query-based summarization', 'Compare', 'abstractive summarization')
('encode-attend-decode paradigm', 'Used-for', 'query-based summarization')
('query attention model', 'Part-of', 'encode-attend-decode paradigm')
('diversity based attention model', 'Part-of', 'encode-attend-decode paradigm')
('hybrid pointer-generator network', 'Used-for', 'abstractive text summarization')
('coverage', 'Used-for', 'discourage repetition in summarization')
('machine translation mt', 'Compare', 'bi-directional LSTMs')
('machine translation mt', 'Compare', 'convolutional layers')
('machine translation mt', 'Compare', 'deep neural networks')
('convolutional layers', 'Used-for', 'encode the source sentence')
('bi-directional LSTMs', 'Used-for', 'encode the source sentence')
('deep neural networks', 'Evaluate-for', 'neural machine translation')
('convolutional layers', 'Compare', 'recurrent networks')
('linear associative units', 'Used-for', 'reduce the gradient propagation path')
('neural machine translation', 'Used-for', 'Chinese-English translation')
('Neural machine translation', 'Used-for', 'grammatical error correction')
('sequential encoder-decoder framework', 'Part-of', 'neural machine translation')
('semantic similarity', 'Used-for', 'dialogue state tracking (DST')
('generated sentence', 'Is-a-Prerequisite-of', 'neural machine translation')
('decoder', 'Used-for', 'generated sentence')
('sentence encoder', 'Used-for', 'generated sentence')
('target words', 'Part-of', 'generated sentence')
('neural model', 'Used-for', 'generated sentence')
('visual semantic pretraining', 'Used-for', 'mitigating anisotropy in word embeddings')
('visual semantic pretraining', 'Compare', 'traditional semantic pretraining')
('CLIP', 'Hyponym-Of', 'visual semantic pretraining')
('GPT-2', 'Evaluate-for', 'word-level semantic intrinsic evaluation tasks')
('CLIP', 'Used-for', 'encoding image captions')
('Socratic pretraining', 'Compare', 'visual semantic pretraining')
('multimodal neural architecture', 'Part-of', 'visual semantic pretraining')
('Poincaré embeddings', 'Used-for', 'taxonomy extraction')
('BERT embeddings', 'Evaluate-for', 'language modeling')
('visual context', 'Used-for', 'training neural language models')
('Socratic pretraining', 'Used-for', 'controllable summarization')
('semantic priming', 'Part-of', 'memory processes')
('sentence wrap-up', 'Part-of', 'memory processes')
('morphologically rich languages', 'Hyponym-Of', 'language typologies')
('morphological constraints', 'Used-for', 'improving distributional vector spaces')
('morphological inflection generation', 'Is-a-Prerequisite-of', 'language understanding systems')
('morphological disambiguation', 'Used-for', 'improving language understanding')
('morphological structure', 'Part-of', 'character-level models')
('morphological tagging', 'Used-for', 'low-resource languages')
('morphological family', 'Hyponym-Of', 'linguistic classification')
('morphological family', 'Compare', 'linguistic classification')
('cross-lingual morphological tagging', 'Is-a-Prerequisite-of', 'shared information between languages')
('monotonic transformation', 'Part-of', 'morphological inflection')
('morphological supervision', 'Used-for', 'improving character language models')
('morphological analyses', 'Evaluate-for', 'machine translation accuracy')
('vision language pre training', 'Is-a-Prerequisite-of', 'cross-modal downstream tasks')
('end-to-end vision-language pre-trained model', 'Used-for', 'V+L understanding and generation')
('vision language pre training', 'Used-for', 'multilingual multimodal representation learning')
('weakly supervised vision-and-language pre-training', 'Hyponym-Of', 'vision language pre training')
('E2E-VLP', 'Part-of', 'vision language pre training')
('relative representation-based retrieval and generation', 'Part-of', 'weakly supervised vision-and-language pre-training')
('cross-lingual cross-modal learning', 'Evaluate-for', 'multilingual vision-language pre-training')
('cross-modal representations', 'Used-for', 'enhancing visual learning')
('encoder-decoder model', 'Used-for', 'headline generation')
('pre-trained language models', 'Compare', 'manual rule-based systems')
('sparse retrieval', 'Used-for', 'open-domain question answering')
('phrase retrieval problem', 'Hyponym-Of', 'sparse retrieval')
('sparse retrieval', 'Evaluate-for', 'scalability and speed benefit')
('sparse retrieval', 'Evaluate-for', 'lowering accuracy')
('contextualized sparse representation', 'Used-for', 'improving phrase embedding quality')
('contextualized sparse representation', 'Part-of', 'sparse retrieval')
('DensePhrases', 'Compare', 'sparse retrieval')
('None', 'Used-for', 'multi-turn dialogue')
('None', 'Used-for', 'soft retrieval process')
('None', 'Used-for', 'determining user chat intent')
('KB-InfoBot', 'Is-a-Prerequisite-of', 'oriented dialogue system')
('dialogue agents', 'Used-for', 'accessing real-world knowledge')
('None', 'Used-for', 'modeling structured and unstructured language')
('neural model', 'Used-for', 'goal achievement in dialogue')
('None', 'Used-for', 'predicting adverbial presupposition triggers')
('None', 'Evaluate-for', 'automatic symptom collection')
('None', 'Evaluate-for', 'multi-domain scalability')
('None', 'Evaluate-for', 'handling multi-domain dialogues')
('None', 'Used-for', 'response selection in dialogue systems')
('None', 'Used-for', 'discourse relation identification')
('None', 'Evaluate-for', 'reference resolution')
('None', 'Evaluate-for', 'task-oriented dialogue systems')
('None', 'Used-for', 'adapting to new dialogue domains')
('None', 'Used-for', 'automatic diagnosis in medical dialogue')
('memory-to-sequence model', 'Used-for', 'dialogue system knowledge incorporation')
('neural semantic parser', 'Used-for', 'mapping natural language to executable programs')
('predicate-argument structures', 'Part-of', 'neural semantic parser')
('semantic parser', 'Is-a-Prerequisite-of', 'executable programs generation')
('reinforcement learning', 'Conjunction', 'maximum marginal likelihood')
('neural encoder-decoder transition-based parser', 'Hyponym-Of', 'neural semantic parser')
('semantic representations', 'Used-for', 'parsing sentences to linguistically-expressive forms')
('ADEM', 'Used-for', 'dialogue evaluation')
('human response scores', 'Used-for', 'dialogue evaluation')
('word-overlap metrics', 'Compare', 'ADEM')
('BLEU', 'Hyponym-Of', 'word-overlap metrics')
('dialogue models', 'Evaluate-for', 'dialogue evaluation')
('dialogue evaluation', 'Used-for', 'model testing')
('automatic evaluation', 'Used-for', 'rapid prototyping')
('unseen dialogue models', 'Evaluate-for', 'ADEM')
('cross-domain adaptability', 'Used-for', 'LSTM neural network model')
('syntactic information', 'Used-for', 'LSTM robustness')
('Integer Linear Programming', 'Used-for', 'syntactic constraints')
('data text generation', 'Used-for', 'parsing natural language descriptions into source code')
('data text m\n(discourse mode', 'Used-for', 'automatic essay scoring')
('discourse mode', 'Evaluate-for', 'writing composition evaluation')
('neural sequence labeling model', 'Used-for', 'identification of discourse modes')
('stancetaking', 'Part-of', 'sociolinguistic construct')
('discourse relation prediction', 'Is-a-Prerequisite-of', 'discourse mode identification')
('automatic essay scoring', 'Used-for', 'evaluation of narrative essays')
('discourse mode', 'Part-of', 'narrative essays')
('discourse mode', 'Evaluate-for', 'discourse structure analysis')
('attention-based Bi-LSTM', 'Used-for', 'modeling Chinese implicit discourse relations')
('Rhetorcial Structure Theory', 'Hyponym-Of', 'discourse analysis methods')
('hate speech detection', 'Is-a-Prerequisite-of', 'racial bias mitigation')
('hate speech detection', 'Evaluate-for', 'accuracy')
('hate speech detection', 'Evaluate-for', 'F1 score')
('hate speech detection', 'Used-for', 'toxicity assessment')
('hate speech detection', 'Used-for', 'social media monitoring')
('hate speech detection', 'Compare', 'sentiment analysis')
('dialect priming', 'Used-for', 'hate speech detection')
('race priming', 'Used-for', 'hate speech detection')
('hate speech detection', 'Used-for', 'determining offensive content')
('annotations', 'Used-for', 'hate speech detection')
('African American English', 'Hyponym-Of', 'English dialects')
('surface markers', 'Part-of', 'African American English')
('AAE\n(None', 'Is-a-Prerequisite-of', 'Aspect based sentiment analysis')
('None', 'Is-a-Prerequisite-of', 'Aspect-Category-Opinion-Sentiment Quadruple Extraction')
('Aspect-Category-Opinion-Sentiment Quadruple Extraction', 'Used-for', 'Aspect based sentiment analysis')
('Gated Tanh-ReLU Units', 'Used-for', 'Aspect based sentiment analysis')
('Aspect based sentiment analysis', 'Evaluate-for', 'sentiment polarities')
('Aspect-Category-Sentiment Analysis', 'Part-of', 'Aspect based sentiment analysis')
('Aspect-Term Sentintiment Analysis', 'Part-of', 'Aspect based sentiment analysis')
('Attention mechanisms', 'Used-for', 'Aspect based sentiment analysis')
('Convolutional Neural Networks', 'Used-for', 'Aspect based sentiment analysis')
('Gating mechanisms', 'Used-for', 'Aspect based sentiment analysis')
('reading comprehension task', 'Used-for', 'understanding natural texts')
('reading comprehension task', 'Used-for', 'answering questions')
('TriviaQA dataset', 'Used-for', 'reading comprehension task')
('cloze-style reading comprehension', 'Hyponym-Of', 'reading comprehension task')
('open-domain question answering', 'Used-for', 'reading comprehension task')
('natural-language understanding systems', 'Evaluate-for', 'reading comprehension task')
('topic-aware news representations', 'Used-for', 'news recommendation')
('news recommendation', 'Part-of', 'approach topic aware news')
('topic-aware news encoder', 'Part-of', 'approach topic aware news')
('user encoder', 'Part-of', 'approach topic aware news')
('CNN networks', 'Used-for', 'learning representations of news')
('attention networks', 'Used-for', 'selecting important words in news titles')
('topic classification', 'Used-for', 'learning topic-aware news representations')
('auxiliary topic classification task', 'Is-a-Prerequisite-of', 'topic-aware news representations')
('user representations', 'Evaluate-for', 'news recommendation')
('topic information', 'Evaluate-for', 'learning accurate news')
('news encoder', 'Used-for', 'learning representations of news')
('user encoder', 'Used-for', 'learning representations of users')
('None', 'Part-of', 'reasoning and inference')
('reasoning and inference', 'Used-for', 'modeling human intelligence')
('modeling inference in human language', 'Evaluate-for', 'reasoning and inference')
('neural network models', 'Used-for', 'reasoning ability')
('reasoning ability', 'Evaluate-for', 'Stanford Natural Language Inference Dataset')
('reasoning ability', 'Evaluate-for', 'syntactic parsing')
('recursive architectures', 'Part-of', 'reasoning ability')
('syntactic parsing', 'Is-a-Prerequisite-of', 'reasoning ability')
('reasoning about the unspoken implications', 'Part-of', 'reasoning ability')
('naive psychology', 'Evaluate-for', 'reasoning ability')
('geometric reasoning', 'Hyponym-Of', 'visual reasoning')
('reasoning ability', 'Is-a-Prerequisite-of', 'engaging dialogue')
('reasoning ability', 'Is-a-Prerequisite-of', 'QA systems')
('conversational reasoning model', 'Used-for', 'improving dialogue')
('reasoning ability', 'Evaluate-for', 'conversational intelligence')
('reasoning ability', 'Evaluate-for', 'pragmatic reasoning training')
('LambdaMART', 'Used-for', 'supporting argument detection')
('argument types', 'Used-for', 'facilitating argument detection task')
('feature extraction', 'Part-of', 'argument extraction')
('cognitive features', 'Conjunction', 'textual features')
('cognitive features', 'Used-for', 'classification tasks like sentiment analysis and sarcasm detection')
('None', 'Is-a-Prerequisite-of', 'Subgraph algorithms')
('None', 'Is-a-Prerequisite-of', 'Lagrangian Relaxation-based algorithm')
('transition based parser', 'Used-for', 'Parsing sentences')
('transition based parser', 'Compare', 'state-of-the-art transition-based parser')
('transition based parser', 'Used-for', 'semantic representations')
('Transition-based parsers', 'Hyponym-Of', 'Pointer Networks')
('transition based parser', 'Used-for', 'arc-swift')
('arc-swift', 'Evaluate-for', 'error reduction')
('arc-swift', 'Used-for', 'direct attachments between tokens')
('transition based parser', 'Used-for', 'two-stage parsing method')
('transition based parser', 'Used-for', 'RST tree generation')
('transition based parser', 'Used-for', 'error repair in sentences')
('None', 'Used-for', 'convolutional neural network composition')
('None', 'Compare', 'word-lookup model')
('None', 'Used-for', 'semantic graph production')
('None', 'Used-for', 'learning deep linguistic knowledge')
('transition based parser', 'Used-for', 'non-projectivity support')
('identifiability attention weight', 'Used-for', 'decoding process in ReCoSa')
('ReCoSa model', 'Used-for', 'multi-turn dialogue generation')
('word level LSTM encoder', 'Part-of', 'ReCoSa model')
('self-attention mechanism', 'Part-of', 'ReCoSa model')
('attention weights', 'Hyponym-Of', 'identifiability attention weight')
('key vector', 'Used-for', 'identifiability attention weight')
('traditional attention mechanism', 'Compare', 'self-attention mechanism')
('cosine similarity', 'Evaluate-for', 'relevance detection')
('ReCoSa model', 'Evaluate-for', 'Chinese customer services dataset')
('ReCoSa model', 'Evaluate-for', 'English Ubuntu dialogue dataset')
('Natural Language Sentence Matching', 'Used-for', 'syntactic generalization performance')
('syntactic generalization performance', 'Compare', 'perplexity scores')
('syntactic generalization performance', 'Evaluate-for', 'real-world adoptions')
('QuoraQP', 'Evaluate-for', 'syntactic generalization performance')
('syntactic generalization performance', 'Part-of', 'QuoraQP dataset')
('syntactic generalization performance', 'Evaluate-for', 'state-of-the-art neural network models')
('syntactic generalization performance', 'Evaluate-for', 'syntactic knowledge')
('syntactic generalization performance', 'Hyponym-Of', 'generalization performance')
('discourse treebank', 'Is-a-Prerequisite-of', 'discourse dependency parsers')
('discourse treebank', 'Used-for', 'evaluating discourse dependency parsers')
('discourse treebank', 'Part-of', 'discourse analysis')
('annotation corpus', 'Part-of', 'discourse treebank')
('discourse treebank', 'Used-for', 'discourse relation identification')
('discourse treebank', 'Compare', 'RST-DT')
('discourse treebank', 'Compare', 'PDTB')
('ScIDTB', 'Hyponym-Of', 'discourse treebank')
('discourse treebank', 'Used-for', 'NLP tasks')
('single document summarization', 'Is-a-Prerequisite-of', 'email subject line generation')
('single document summarization', 'Compare', 'multi-document summarization')
('single document summarization', 'Used-for', 'neural encoder-decoder models')
('unsupervised approach', 'Used-for', 'single document summarization')
('neural network models', 'Evaluate-for', 'single document summarization')
('abstractive summarization', 'Part-of', 'single document summarization')
('extractive summarization', 'Part-of', 'single document summarization')
('neural abstractive models', 'Hyponym-Of', 'single document summarization')
('sentence extraction', 'Used-for', 'document modeling')
('document modeling', 'Used-for', 'natural language understanding tasks')
('end-to-end model', 'Used-for', 'single document summarization')
('sentence scoring', 'Part-of', 'extractive document summarization systems')
('knowledge graph completion kgc', 'Is-a-Prerequisite-of', 'relation prediction')
('knowledge graph completion kgc', 'Used-for', 'infer unseen entity relationships')
('link prediction', 'Conjunction', 'knowledge graph completion kgc')
('knowledge graph completion kgc', 'Evaluate-for', 'plausibility of unobserved facts')
('neural model with dynamic knowledge graph embeddings', 'Used-for', 'knowledge graph completion kgc')
('knowledge bases', 'Used-for', 'knowledge graph completion kgc')
('Pocket Knowledge Base Population', 'Used-for', 'knowledge graph completion kgc')
('relational triple extraction', 'Used-for', 'knowledge graph completion kgc')
('MuGNN', 'Used-for', 'knowledge graph completion kgc')
('attention-based entity representation', 'Used-for', 'knowledge graph completion kgc')
('relation clusters', 'Part-of', 'knowledge graph completion kgc')
('fine grained entity typing', 'Used-for', 'classifying named entity mentions')
('cross-lingual contrastive learning', 'Used-for', 'enhancing fine grained entity typing')
('BERT Masked Language Model', 'Used-for', 'predicting context dependent hypernyms')
('ultra-fine entity typing', 'Compare', 'fine grained entity typing')
('box embeddings', 'Used-for', 'capturing hierarchies of entity types')
('Few-NERD dataset', 'Used-for', 'benchmarking few-shot named entity recognition')
('Feature Cluster Loss Correction', 'Used-for', 'improving fine grained entity typing accuracy')
('multilingual connotation frames', 'Used-for', 'studying public sentiments in multiple languages across social media')
('multilingual pre trained', 'Used-for', 'neural machine translation')
('multilingual skip-gram model', 'Used-for', 'learning word and sentence embeddings')
('cross-lingual sentence similarity model', 'Used-for', 'training alongside the multilingual skip-gram model for joint embeddings')
('cross-lingual word embedding', 'Used-for', 'reducing vocabulary mismatch in multilingual neural machine translation')
('multilingual unsupervised NMT scheme', 'Used-for', 'joint training of multiple languages with a shared encoder and multiple decoders')
('multilingual pre trained', 'Is-a-Prerequisite-of', 'low-resource neural machine translation')
('multilingual pre trained', 'Is-a-Prerequisite-of', 'zero-shot translation')
('multilingual sentence embeddings', 'Used-for', 'filtering noisy data in large text collections')
('multilingual sentence embeddings', 'Evaluate-for', '\n(None')
('None', 'Used-for', 'named entity recognition multiple')
('None', 'Used-for', 'information extraction')
('named entity recognition multiple', 'Is-a-Prerequisite-of', 'markable identification')
('named entity recognition multiple', 'Used-for', 'text segmentation')
('named entity recognition multiple', 'Compare', 'information extraction')
('None', 'Part-of', 'named entity recognition multiple')
('None', 'Hyponym-Of', 'named entity recognition multiple')
('None', 'Evaluate-for', 'named entity recognition multiple')
('markable identification', 'Evaluate-for', 'named entity recognition multiple')
('None', 'Used-for', 'sequence labeling')
('sequence labeling', 'Conjunction', 'named entity recognition multiple')
('neural language model', 'Used-for', 'learning implicit representation of poetry form and content')
('neural language model', 'Used-for', 'learning representations during training')
('neural language', 'Compare', 'structured representations')
('neural language', 'Used-for', 'generation of conversational text conditioned on affect categories')
('neural language model', 'Used-for', 'natural language generation')
('natural language representations', 'Part-of', 'neural semantic parser')
('neural language model', 'Hyponym-Of', 'language models')
('neural language model', 'Used-for', 'perplexity experiments focused on affect-discriminative word representations')
('Chinese Named Entity Recognition', 'Is-a-Prerequisite-of', 'Gazetteers')
('Gazetteers', 'Used-for', 'Named Entity Recognition')
('Named Entity Recognition', 'Part-of', 'Natural Language Processing')
('Chinese Named Entity Recognition', 'Evaluate-for', 'Ambiguity Resolution')
('Graph Neural Networks', 'Used-for', 'Incorporating Gazetteers Information')
('Ambiguity Resolution', 'Evaluate-for', 'Chinese Named Entity Recognition')
('Generative Model', 'Used-for', 'Estimating Lexical Feature Weights')
('political debate', 'Part-of', 'democratic political decision making')
('political debate', 'Used-for', 'comparing candidate positions')
('Argument Mining', 'Used-for', 'political debate')
('Argument Mining', 'Evaluate-for', 'typology of argument components')
('USElecDeb60To16 corpus', 'Used-for', 'Argument Mining')
('political framing', 'Used-for', 'control public perception')
('Graph Convolutional Networks', 'Used-for', 'capturing social information in media')
('political bias prediction', 'Used-for', 'media profiling')
('multimodal dialogue', 'Used-for', 'understanding user intention in diverse modalities')
('multimodal dialogue', 'Hyponym-Of', 'dialogue systems')
('multimodal dialogue', 'Used-for', 'capturing non-verbal cues like visual expressions and acoustic signals')
('multimodal dialogue', 'Part-of', 'multimodal language processing')
('multimodal dialogue', 'Compare', 'unimodal dialogue systems')
('multimodal dialogue', 'Used-for', 'improving interaction in goal-oriented systems')
('multimodal dialogue', 'Evaluate-for', 'task completion in complex scenarios')
('factuality prediction', 'Evaluate-for', 'commitment towards a predicate')
('factuality prediction', 'Used-for', 'mapping annotated corpora onto a single factuality scale')
('factuality prediction', 'Used-for', 'testing models across different datasets')
('rule-based factuality prediction system', 'Part-of', 'factuality prediction')
('dependency trees', 'Used-for', 'factuality prediction')
('supervised classifier', 'Used-for', 'factuality prediction')
('model performance', 'Evaluate-for', 'factuality prediction')
('unified factuality corpus', 'Used-for', 'factuality prediction')
('knowledge graph kg', 'Is-a-Prerequisite-of', 'knowledge base (KB')
('knowledge base enrichment', 'Used-for', 'relation extraction')
('relation extraction', 'Used-for', 'extracting entities and relationships')
('entities and relationships', 'Part-of', 'knowledge graph kg')
('knowledge graph kg', 'Used-for', 'link prediction')
('link prediction', 'Evaluate-for', 'incomplete knowledge graph applications')
('knowledge graph kg', 'Used-for', 'embedding methods')
('embedding methods', 'Used-for', 'learning low-rank representations')
('low-rank representations', 'Used-for', 'bilinear scoring functions')
('knowledge graph kg', 'Used-for', 'neural network-based KB-QA')
('neural network-based KB-QA', 'Evaluate-for', 'question answering effectiveness')
('neural network model', 'Used-for', 'dynamic question representation')
('dynamic question representation', 'Used-for', 'improving answer accuracy')
('Gated self-matching networks', 'Used-for', 'Reading comprehension question answering')
('Self-matching attention mechanism', 'Used-for', 'Refine passage representation')
('Pointer networks', 'Used-for', 'Locate answer positions')
('Exemplar Encoder-Decoder network', 'Used-for', 'Generate conversation responses')
('Syntactically supervised Transformer', 'Used-for', 'Improve decoding speed')
('Iterative predicate selection algorithm', 'Used-for', 'Semantic Dependency Parsing')
('Neural machine translation', 'Used-for', 'Facilitate multi-language communication')
('Error-correcting codes', 'Used-for', 'Improve model robustness')
('Recurrent neural network', 'Used-for', 'Part-of-speech tagging')
('Model combination', 'Evaluate-for', 'Improve parsing performance')
('argument mining', 'Used-for', 'identifying argument components')
('argument mining', 'Used-for', 'predicting argumentative relations')
('factor graph model', 'Is-a-Prerequisite-of', 'argument mining')
('argument mining', 'Part-of', 'artificial intelligence')
('SVM', 'Used-for', 'argument mining')
('RNN', 'Used-for', 'argument mining')
('stance polarity and intensity prediction', 'Evaluate-for', 'argument mining')
('model variations', 'Used-for', 'argument mining')
('argument components', 'Hyponym-Of', 'argument mining')
('argumentative relation prediction', 'Evaluate-for', 'argument mining')
('non-tree argument mining', 'Is-a-Prerequisite-of', 'argument mining')
('argument mining', 'Hyponym-Of', 'natural language processing')
('debating system', 'Used-for', 'argument mining')
('argument quality', 'Evaluate-for', 'argument mining')
('bias measurement', 'Evaluate-for', 'computational argumentation')
('nlg model', 'Used-for', 'automatic generation of rhythmic poetry')
('neural language model', 'Used-for', 'generating coherent poetry with arbitrary forms and themes')
('neural language model', 'Part-of', 'nlg model')
('neural model', 'Used-for', 'Chinese poem generation')
('neural model', 'Hyponym-Of', 'nlg model')
('generative neural language model', 'Part-of', 'nlg model')
('discriminative weighted finite state machine', 'Used-for', 'constraining generative model on basis of form')
('deep learning model', 'Used-for', 'semantic role labeling')
('neural encoder-decoder models', 'Used-for', 'modeling open-domain conversations')
('conditional variational autoencoders', 'Part-of', 'nlg model')
('shared layers', 'Part-of', 'multi-task learning')
('task-specific features', 'Part-of', 'multi-task learning')
('adversarial multi-task learning framework', 'Is-a-Prerequisite-of', 'alleviating shared and private latent feature spaces interference')
('adversarial multi-task learning framework', 'Used-for', 'multi-task learning')
('end-to-end computational argumentation mining', 'Used-for', 'multi-task learning')
('neural semantic parser', 'Used-for', 'natural language question')
('predicate-argument structures', 'Part-of', 'neural semantic parser')
('predicate-argument structures', 'Used-for', 'domain mapping')
('natural language question', 'Evaluate-for', 'semantic parsing effectiveness')
('semantic parser', 'Used-for', 'converting natural language question')
('natural language question', 'Is-a-Prerequisite-of', 'answer rationales generation')
('COREQA', 'Used-for', 'generating answers for natural language question')
('natural language question', 'Evaluate-for', 'COREQA efficiency')
('natural language question', 'Used-for', 'semantic parser training')
('semantic parser', 'Used-for', 'semantic parsing')
('semantic parser training', 'Used-for', 'improving answer accuracy')
('answer rationales', 'Used-for', 'scaffolding program structures from natural language question')
('natural\n(conversation model', 'Used-for', 'generating responses in chatbots')
('response generation', 'Part-of', 'conversation model')
('dialogue systems', 'Used-for', 'multi-turn conversation management')
('context information', 'Used-for', 'response selection in dialogue systems')
('generative conversational systems', 'Used-for', 'contextual dialogue handling')
('latent variable', 'Used-for', 'modelling conversational intents in conversation models')
('discourse-level diversity', 'Evaluate-for', 'conversation model performance in generating diverse responses')
('sequential context', 'Used-for', 'question answering in dialogue systems')
('neural encoder-decoder models', 'Used-for', 'open-domain conversation modeling')
('additive compositionality', 'Is-a-Prerequisite-of', 'success in solving word analogies')
('NLU task', 'Used-for', 'event coreference resolution')
('Kernel methods', 'Used-for', 'language learning and inference tasks')
('expressive kernels', 'Hyponym-Of', 'Kernel methods')
('deep neural networks', 'Used-for', 'automatically learning feature representations')
('Tree Kernels', 'Hyponym-Of', 'Kernel methods')
('Skip-Gram model', 'Used-for', 'Sufficient Dimensionality Reduction framework')
('NLU task', 'Part-of', 'natural language processing')
('event coreference resolution', 'Used-for', 'performance improvement in TAC KBP tasks')
('Distant supervision', 'Used-for', 'relation extraction training data generation')
('document clustering', 'Evaluate-for', 'latent relation learning')
('graph autoencoder', 'Used-for', 'latent relation learning')
('Keyword Correlation Graph', 'Part-of', 'graph autoencoding process in document clustering')
('latent representation', 'Used-for', 'document clustering')
('local and global features', 'Used-for', 'latent relation learning')
('latent relation learning', 'Part-of', 'knowledge graph representation techniques')
('neural ranking', 'Used-for', 'prediction of binary code for each word')
('neural ranking', 'Used-for', 'improving decoding speed on CPUs')
('neural ranking', 'Hyponym-Of', 'neural machine translation')
('Salience Rank', 'Hyponym-Of', 'neural ranking')
('neural ranking', 'Used-for', 'keyphrase extraction')
('neural ranking', 'Evaluate-for', 'ranking efficiency')
('neural ranking', 'Evaluate-for', 'translation performance improvements')
('None', 'Compare', 'Recurrent Neural Networks')
('machine translation model', 'Used-for', 'English-Romanian translation')
('machine translation model', 'Used-for', 'English-German translation')
('machine translation model', 'Used-for', 'English-French translation')
('machine translation model', 'Evaluate-for', 'translation accuracy')
('machine translation model', 'Part-of', 'Deep Neural Networks')
('machine translation model', 'Part-of', 'Neural Machine Translation')
('LSTM', 'Hyponym-Of', 'Recurrent Neural Networks')
('LAU', 'Part-of', 'Neural Machine Forensic Tools')
('GRU', 'Hyponym-Of', 'Recurrent Neural Networks')
('Linear Associative Units', 'Used-for', 'gradient reduction')
('LSTMs', 'Evaluate-for', 'source sentence encoding')
('Convolutional Layers', 'Compare', 'Recurrent Networks')
('Neural Machine Forensic Tools', 'Used-for', 'Chinese-English translation')
('Sequence-to-Dependency Neural Machine Translation', 'Hyponym-Of', 'machine translation model')
('retrieval model', 'Used-for', 'document retrieval')
('retrieval model', 'Used-for', 'finding similar datapoints')
('retrieval model', 'Part-of', 'memory-to-sequence model')
('retrieval model', 'Part-of', 'Entity-Duet Neural Ranking Model')
('retrieval model', 'Evaluate-for', 'task-oriented dialog systems')
('retrieval model', 'Is-a-Prerequisite-of', 'multi-layer recurrent neural network for detecting answers')
('retrieval model', 'Used-for', 'context-dependent semantic parsing')
('NeuralDater', 'Used-for', 'document dating')
('multi-turn conversation', 'Used-for', 'response selection in retrieval based chatbots')
('multi-turn conversation', 'Used-for', 'generation control mechanism in conversational models')
('TextFlow', 'Used-for', 'text similarity measurement')
('nlp community', 'Used-for', 'modeling documents and words')
('nlp community', 'Used-for', 'studying people behind the language')
('nlp community', 'Used-for', 'developing technologies to detect online abusive behavior')
('nlp community', 'Part-of', 'natural language processing')
('DNN models', 'Compare', 'convex models')
('state-of-the-art relation extraction', 'Compare', 'proposed new methodology for relation extraction')
('nlp community', 'Evaluate-for', 'mitigating online abusive behavior')
('nlp community', 'Evaluate-for', 'improvements in community question answering')
('Word Embedding Association Test', 'Used-for', 'evaluating demographic biases in word embeddings')
('nlp community', 'Evaluate-for', 'improvements in social scientific prediction tasks')
('Deep Neural Network models', 'Evaluate-for', 'sequence tagging tasks')
('clinical event extraction', 'Is-a-Prerequisite-of', 'contrastive learning objective')
('clinical event extraction', 'Is-a-Prerequisite-of', 'mention identification task')
('clinical event extraction', 'Used-for', 'identifying domain-specific terminologies')
('clinical event extraction', 'Used-for', 'deciding biomedical mention boundaries')
('contrastive learning objective', 'Used-for', 'clinical event extraction')
('mention identification task', 'Used-for', 'clinical event garbage option')
('DICE', 'Used-for', 'clinical event extraction')
('MACCROBAT-EE', 'Used-for', 'benchmarking clinical event extraction')
('DICE', 'Evaluate-for', 'state-of-the-art performance in clinical event extraction')
('clinical event extraction', 'Part-of', 'universal information extraction')
('cross lingual word embeddings', 'Used-for', 'bilingual lexicon induction')
('cross lingual word embeddings', 'Used-for', 'cross-lingual classification')
('cross lingual word embeddings', 'Compare', 'monolingual word embeddings')
('unsupervised bilingual dictionary induction', 'Evaluate-for', 'cross lingual word embeddings')
('adversarial training', 'Used-for', 'cross lingual word embeddings')
('cross lingual word embeddings', 'Part-of', 'domain adaptation')
('cross lingual word embeddings', 'Is-a-Prerequisite-of', 'low-resource language sentiment analysis')
('lexical information', 'Evaluate-for', 'cross lingual word embeddings')
('cross lingual word embeddings', 'Used-for', 'cross-lingual sentiment classification')
('word embeddings', 'Hyponym-Of', 'cross lingual word embeddings')
('cross lingual word embeddings', 'Used-for', 'unsupervised machine translation')
('semantic similarity', 'Evaluate-for', 'cross lingual word embeddings')
('semantic parsing datasets', 'Used-for', 'training semantic parsing models')
('semantic parsing datasets', 'Part-of', 'multilingual GeoQuery corpus')
('semantic parsing datasets', 'Part-of', 'ATIS corpus')
('semantic parsing datasets', 'Part-of', 'OVERNIGHT dataset')
('semantic parsing datasets', 'Evaluate-for', 'semantic parsing performance')
('semantic parsing datasets', 'Used-for', 'evaluating code generation models')
('semantic parsing datasets', 'Used-for', 'multilingual model training')
('semantic parsing datasets', 'Used-for', 'dual learning algorithms')
('semantic parsing', 'Is-a-Prerequisite-of', 'semantic parsing datasets')
('code generation', 'Is-a-Prerequisite-of', 'semantic parsing datasets')
('pre trained language kanguage model', 'Used-for', 'improving MRC capabilities')
('KT-NET', 'Used-for', 'improving BERT for MRC with KBs integration')
('pre trained language models', 'Is-a-Prerequisite-of', 'BERT')
('BERT', 'Part-of', 'MRC solutions')
('pre trained language models', 'Used-for', 'NLP tasks enhancement')
('pre trained language model', 'Evaluate-for', 'semantic pattern capture from text')
('pre trained language models', 'Used-for', 'base for ERNIE training')
('pre trained language model', 'Evaluate-for', 'language understanding')
('pre trained language model', 'Used-for', 'query auto-completion improvement')
('pre trained language model', 'Used-for', 'sentiment classification enhancement')
('pre trained language model', 'Used-for', 'language fluency in style transfer tasks')
('diverse conversational corpus', 'Part-of', 'linguistically diverse conversational corpora')
('diverse conversational corpus', 'Used-for', 'computational linguistics')
('diverese conversational corpus', 'Used-for', 'language technology')
('linguistically diverse conversational corpora', 'Used-for', 'natural language understanding')
('linguistically diverse conversational corpora', 'Used-for', 'design of conversational interfaces')
('pretrained model', 'Is-a-Prerequisite-of', 'dialogue representation and understanding')
('pretrained model', 'Evaluate-for', 'safety issues')
('pretrained model', 'Used-for', 'conversational response generation')
('KdConv', 'Hyponym-Of', 'multi-domain knowledge-driven conversation dataset')
('KdConv', 'Used-for', 'research on multi-turn conversations')
('response selection model', 'Used-for', 'task-oriented dialogue systems')
('reasoning datasets', 'Used-for', 'language understanding evaluation')
('reasoning datasets', 'Used-for', 'multi-hop QA')
('multi-hop QA', 'Is-a-Prerequisite-of', 'reasoning datasets')
('DuoRC', 'Part-of', 'reasoning datasets')
('SQuADRUn', 'Part-of', 'reasoning datasets')
('BIGPATENT', 'Part-of', 'reasoning datasets')
('DuoRC', 'Evaluate-for', 'deeper language understanding')
('SQuADRUn', 'Evaluate-for', 'natural language understanding task')
('BIGPATENT', 'Evaluate-for', 'summarization research')
('event knowledge', 'Is-a-Prerequisite-of', 'machine reading')
('KBLSTM', 'Used-for', 'machine reading')
('machine reading', 'Evaluate-for', 'event extraction')
('knowledge bases', 'Used-for', 'enhancing recurrent neural networks')
('recurrent neural networks', 'Used-for', 'machine reading')
('attention mechanism', 'Used-for', 'enhancing recurrent neural networks')
('KBLSTM', 'Used-for', 'enhancing recurrent neural networks with KB')
('ACE2005 dataset', 'Evaluate-for', 'KBLSTM performance')
('task-specific feature engineering', 'Evaluate-for', 'traditional knowledge integration methods')
('continuous KB representations', 'Compare', 'discrete knowledge features')
('discrete knowledge features', 'Compare', 'continuous KB representations')
('knowledge bases', 'Used-for', 'leveraging continuous representations for machine reading')
('machine translation NMT', 'Used-for', 'translating languages across different mediums')
('bi-directional LSTMs', 'Used-for', 'machine translation NMT')
('convolutional layers', 'Used-for', 'machine translation NMT')
('Recurrent Neural Networks', 'Part-of', 'machine translation NMT')
('Deep Neural Networks', 'Evaluate-for', 'machine translation NMT')
('linear associative units', 'Used-for', 'optimizing recurrent unit in RNNs')
('LAUs', 'Hyponym-Of', 'linear associative units')
('gradient diffusion', 'Is-a-Prerequisite-of', 'optimization difficulties in deep architecture NMT')
('LAUs', 'Used-for', 'reducing gradient diffusion')
('Sequence-to-Dependency Neural Machine Translation', 'Is-a-Prerequisite-of', 'incorporating dependency structure into NMT')
('word embeddings', 'Used-for', 'caption generation')
('Additive compositionality', 'Part-of', 'word embeddings')
('Skip-Gram model', 'Used-for', 'learning word embeddings')
('word embeddings', 'Compare', 'bag-of-words')
('Context-Aware Network Embedding', 'Used-for', 'network analysis')
('Neural word embeddings', 'Evaluate-for', 'aspect extraction')
('word embeddings', 'Used-for', 'query understanding')
('Gated-Attention Reader', 'Used-for', 'answering cloze-style questions')
('Sufficient Dimensionality Reduction', 'Is-a-Prerequisite-of', 'Skip-Gram model embeddings')
('Multimodal word distributions', 'Hyponym-Of', 'word embeddings')
('dialogue system', 'Is-a-Prerequisite-of', 'task oriented dialogue system')
('task oriented dialogue system', 'Used-for', 'tracking user goals and requests')
('belief spans', 'Part-of', 'task oriented dialogue system')
('Global-Locally Self-Attentive Dialogue State Tracker', 'Used-for', 'improving task oriented dialogue system')
('dialogue state tracking', 'Used-for', 'task oriented dialogue system')
('neural model', 'Used-for', 'task oriented dialogue system')
('end-to-end learning framework', 'Used-for', 'task oriented dialogue system')
('domain adaptation', 'Used-for', 'task oriented dialogue system')
('DAML', 'Used-for', 'task oriented dialogue system')
('WMM2Seq', 'Used-for', 'task oriented dialogue system')
('EmoDS', 'Used-for', 'enhancing user interaction in task oriented dialogue system')
('Incremental Dialogue System', 'Used-for', 'adapting to unconsidered user needs in task oriented dialogue system')
('dialogue features', 'Used-for', 'discourse relation identification in open-domain dialogue systems')
('natural language generation task', 'Used-for', 'generating corrective referring expressions')
('natural language generation task', 'Used-for', 'semantic parsing for source code generation')
('natural language utterances', 'Used-for', 'natural language generation task')
('encoder-decoder framework', 'Used-for', 'natural language generation task')
('natural language generation task', 'Used-for', 'learning commonsense knowledge from natural language text')
('neural models', 'Used-for', 'natural language generation task')
('contrastive focus', 'Used-for', 'natural language generation task')
('natural language generation task', 'Hyponym-Of', 'natural language processing tasks')
('Information Retrieval', 'Used-for', 'Volatility prediction')
('Information Retrieference', 'Used-for', 'Market risk forecasting')
('IR term weighting models', 'Part-of', 'Information Retrieval')
('Information Retrieval', 'Used-for', 'Text and market data fusion')
('Word embeddings', 'Part-of', 'Information Retrieval')
('Information Retrieval', 'Used-for', 'Semantic hashing')
('Entity-Duet Neural Ranking Model', 'Used-for', 'Information Retrieval')
('Knowledge graphs', 'Used-for', 'Information Retrieval')
('Information Retrieval', 'Used-for', 'Detecting concealed information')
('HEAD-QA', 'Evaluate-for', 'Information Retrieval techniques')
('Information Retrieval', 'Used-for', 'Neural Machine Translation data augmentation')
('Information Retrieval', 'Used-for', 'Cross-lingual document retrieval')
('Research on Sentence function', 'Evaluate-for', 'Information Retrieval-based conversation models')
('None', 'Is-a-Prerequisite-of', 'sentiment classification')
('Aspect sentiment classification', 'Used-for', 'sentiment classifier')
('sentiment classifier', 'Evaluate-for', 'sentiment polarity')
('Domain adaptation', 'Used-for', 'sentiment classifier')
('Cross-domain sentiment classification', 'Used-for', 'sentiment classifier')
('sentiment classifier', 'Used-for', 'Target-oriented sentiment classification')
('active sentiment domain adaptation', 'Used-for', 'sentiment classifier')
('sentiment classifier', 'Evaluate-for', 'Aspect sentiment classification')
('sentiment classifier', 'Evaluate-for', 'Multimodal sentiment analysis')
('Multimodal sentiment analysis', 'Used-for', 'sentiment classifier')
('Aspect sentiment classification', 'Hyponym-Of', 'sentiment classifier')
('Machine translation', 'Used-for', 'cross-lingual sentiment classifier')
('cross-lingual sentiment classifier', 'Hyponym-Of', 'sentiment classifier')
('Aspect-level sentiment classification', 'Hyponym-Of', 'sentiment classifier')
('sentence-level annotation', 'Used-for', 'sentiment classifier')
('Domain-sensitive word embeddings', 'Used-for', 'sentiment classifier')
('Generic word embeddings', 'Used-for', 'sentiment classifier')
('Domain Adapt\n(None', 'Is-a-Prerequisite-of', 'bilingual lexicon induction')
('None', 'Used-for', 'bilingual lexicon induction')
('bilingual lexicon induction', 'Evaluate-for', 'bilingual tasks')
('bilingual lexicon induction', 'Used-for', 'domain adaptation')
('machine translation', 'Evaluate-for', 'bilingual lexicon induction')
('adversarial unsupervised cross-lingual word embedding', 'Used-for', 'bilingual lexicon induction')
('Bilingual Sentiment Embeddings', 'Used-for', 'bilingual lexicon induction')
('unsupervised bilingual lexicon induction', 'Part-of', 'bilingual lexicon induction')
('morphological awareness', 'Evaluate-for', 'bilingual lexicon induction')
('edit distance', 'Used-for', 'bilingual lexicon induction')
('Hubless Nearest Neighbor', 'Used-for', 'bilingual lexicon induction')
('manuscript editing', 'Evaluate-for', 'bilingual lexicon induction')
('graph-based paradigm', 'Used-for', 'bilingual lexicon induction')
('InstaMap', 'Used-for', 'bilingual lexicon induction')
('None', 'Used-for', 'multi-task learning')
('None', 'Used-for', 'relation extraction')
('multi-task learning', 'Part-of', 'relation learning')
('relation extraction', 'Part-of', 'relation learning')
('None', 'Compare', 'None')
('Neural network models', 'Used-for', 'relation learning')
('adversarial multi-task learning framework', 'Used-for', 'relation learning')
('None', 'Is-a-Prerequisite-of', 'relation learning')
('None', 'Evaluate-for', 'improving classification performance')
('Distant supervision', 'Is-a-Prerequisite-of', 'Relation extraction task')
('Relation extraction task', 'Used-for', 'Knowledge Base Population')
('Convolutional Neural Network', 'Used-for', 'Relation extraction task')
('Relation extraction task', 'Used-for', 'Classifying text')
('Mono-lingual data', 'Used-for', 'Relation extraction task')
('Multilingual Neural Relation Extraction framework', 'Used-for', 'Relation extraction task')
('Cross-lingual attention', 'Used-for', 'Relation extraction task')
('Mono-lingual attention', 'Used-for', 'Relation extraction task')
('Dynamic transition matrix', 'Evaluate-for', 'Modeling noise in relation extraction task')
('Hierarchical Recurrent Neural Network', 'Used-for', 'Relation detection in KBQA systems')
('Deep Residual Bidirectional LSTMs', 'Used-for', 'Relation detection in hierarchical RNN for KBQA')
('Open Information Extraction', 'Hyponym-Of', 'Relation extraction task')
('event knowledge', 'Used-for', 'temporal relation classification')
('event ontology', 'Compare', 'domain ontology')
('event ontology', 'Hyponym-Of', 'ontology')
('temporal event knowledge', 'Used-for', 'improve narrative cloze task')
('dialogue state tracking', 'Evaluate-for', 'dialogue systems')
('dialogue state', 'Part-of', 'dialogue state tracking')
('event extraction', 'Used-for', 'extract narrative event knowledge')
('pretrained models', 'Used-for', 'zero-shot event extraction')
('concept normalization', 'Evaluate-for', 'linking textual mentions to concepts in an ontology')
('semantic type regularizer', 'Used-for', 'concept normalization')
('semantic similarity', 'Used-for', 'information sharing across dialogue domains')
('SUMBT', 'Is-a-Prerequisite-of', 'multi-domain dialogue handling')
('open-ended questions', 'Part-of', 'question generation framework')
('ontology terms\nNone\n(Neural Symbolic Machine', 'Used-for', 'language understanding task')
('language understanding task', 'Evaluate-for', 'statistical power of neural networks')
('language understanding systems', 'Part-of', 'language understanding task')
('morph-fitted vectors', 'Used-for', 'language understanding task')
('RC datasets', 'Used-for', 'language understanding task')
('Neural Belief Tracking', 'Used-for', 'language understanding task')
('Neural Belief Tracking', 'Evaluate-for', 'language understanding task')
('morph-fitting procedure', 'Used-for', 'language understanding task')
('reading comprehension datasets', 'Evaluate-for', 'language understanding task')
('multimodal posts', 'Evaluate-for', 'language understanding task')
('Neural Symbolic Machine', 'Part-of', 'language understanding systems')
('Neural machine translation', 'Used-for', 'Multilingual translation')
('Multlingual translation', 'Is-a-Prerequisite-of', 'Zero-shot translation')
('Multilingual translation', 'Evaluate-for', 'BLEU point improvement')
('Multilingual connotation frames', 'Used-for', 'Multilingual sentiment analysis')
('Multilingual semantic dependency parsing', 'Used-for', 'Polyglot semantic dependency parser')
('Multilingual neural machine translation', 'Part-of', 'Multilingual translation')
('Zero-shot translation', 'Part-of', 'Multilingual translation')
('Multilingual translation', 'Used-for', 'Improving NER performance')
('Language-sensitive embedding', 'Used-for', 'Multilingual neural machine translation')
('Simultaneous translation', 'Used-for', 'Low-latency multilingual communication')
('Cross-lingual transfer learning', 'Used-for', 'Multilingual NLP model development')
('Polyglot semantic dependency parser', 'Used-for', 'Multilingual semantic parsing')
('Semantic Relevance Based neural model', 'Is-a-Prerequisite-of', 'neural summarization model')
('neural summarization model', 'Hyponym-Of', 'encoder-decoder framework')
('neural summarization model', 'Used-for', 'improving semantic relevance')
('sentence scoring', 'Part-of', 'neural summarization model')
('sentence selection', 'Part-of', 'neural summarization model')
('GOLC', 'Used-for', 'optimization in neural summarization model')
('end-to-end neural network framework', 'Used-for', 'extractive document summarization')
('Global Optimization method under length constraint', 'Used-for', 'neural summarization model')
('Masque', 'Used-for', 'multi-style abstractive summarization for question answering')
('NeuralDater', 'Compare', 'neural summarization model')
('Hibert', 'Used-for', 'neural summarization model')
('Bi-directional Selective Encoding with Template', 'Used-for', 'neural summarization model')
('EigenSent', 'Used-for', 'constructing word-sequence embeddings')
('Neural conversation models', 'Compare', 'neural summarizing products')
('unsupervised bilingual lexicon induction', 'Is-a-Prerequisite-of', 'cross-lingual transfer of NLP models')
('morphological variation', 'Evaluate-for', 'unsupervised bilingual lexicon induction')
('unsupervised bilingual lexicon induction', 'Used-for', 'bilingual dictionary induction')
('cross-lingual word embeddings', 'Used-for', 'unsupervised bilingual lexicon induction')
('unsupervised machine translation', 'Part-of', 'unsupervised bilingual lexicon induction')
('adversarial training', 'Used-for', 'unsupervised bilingual lexicon induction')
('distribution matching', 'Used-for', 'unsupervised bilingual lexicon induction')
('alignment of word embeddings', 'Used-for', 'unsupervised bilingual lexicon induction')
('cross lingual semantic parsing', 'Is-a-Prerequisite-of', 'distributed representations of logical forms')
('cross lingual semantic parsing', 'Evaluate-for', 'performance on multilingual datasets')
('cross lingual semantic parsing', 'Part-of', 'multilingual natural language processing')
('distributed representations of logical forms', 'Used-for', 'cross lingual semantic parsing')
('multilingual GeoQuery dataset', 'Used-for', 'testing cross lingual semantic parsing approaches')
('semantic parser', 'Used-for', 'mapping natural language to logical forms')
('neural semantic parser', 'Hyponym-Of', 'semantic parser')
('predicate-argument structures', 'Part-of', 'semantic parser')
('intermediate representations', 'Part-of', 'semantic parser')
('semantic representation', 'Part-of', 'semantic parser')
('natural language utterances', 'Used-for', 'input to semantic parser')
('annotated logical forms', 'Used-for', 'training semantic parser')
('transition system', 'Used-for', 'inducing predicate-argument structures in semantic parser')
('semantic role labeling', 'Used-for', 'improving semantic parsing accuracy')
('deep learning', 'Used-for', 'developing advanced semantic parsers')
('domain-general representations', 'Conjunction', 'target domain-specific representations')
('multi-modal Neural Machine Translation', 'Is-a-Prerequisite-of', 'doubly-attentive decoder')
('doubly-attentive decoder', 'Used-for', 'incorporating spatial visual features')
('multi-modal Neural Machine Translation', 'Used-for', 'bridging the gap between image description and translation')
('multi-modal Neural Machine Translation', 'Part-of', 'neural machine translation advancements')
('doubly-attentive decoder', 'Part-of', 'multi-modal Neural Machine Translation')
('spatial visual features', 'Used-for', 'enhancing translation with visual context')
('multi-modal Neural Machine Translation', 'Evaluate-for', 'state-of-the-art results on the Multi30k data set')
('summarization dataset', 'Used-for', 'testing query-based summarization models')
('query-based summarization', 'Is-a-Prerequisite-of', 'summarization dataset')
('debatepedia', 'Part-of', 'summarization dataset')
('ROUGE-L scores', 'Evaluate-for', 'summarization models')
('encode-attend-decode', 'Used-for', 'query-based summarization')
('query attention model', 'Part-of', 'query-based summarization models')
('diversity based attention model', 'Part-of', 'query-based summarization models')
('query-based summarization', 'Used-for', 'highlighting relevant points')
('abstractive summarization', 'Compare', 'extractive summarization')
('Dependency parse', 'Is-a-Prerequisite-of', 'Semantic dependency parsing')
('Dependency parse', 'Used-for', 'Analyzing sentence structure')
('BiLSTMs', 'Used-for', 'Dependency parse')
('Token-based sequence tagging', 'Compare', 'Dependency parse')
('Token-based dependency parsing', 'Evaluate-for', 'Argumentation Mining')
('Multi-task learning', 'Evaluate-for', 'Dependency parse')
('Non-monotonic transition system', 'Used-for', 'Dependency parse')
('Dynamic oracle', 'Used-for', 'Non-monotonic transition system')
('Covington parser', 'Used-for', 'Dependency parse')
('Non-projective Covington algorithm', 'Part-of', 'Dependency parse')
('Sequence-to-Dependency Neural Machine Translation', 'Used-for', 'Dependency parse')
('Maximum Subgraph algorithms', 'Used-for', 'Dependency parse')
('Semantic dependency parsing', 'Used-for', 'Dependency parse')
('Deep neural architecture', 'Used-for', 'Semantic dependency parsing')
('Transition-based dependency parsers', 'Evaluate-for', 'Parsing correctness')
('Novel transition system', 'Used-for', 'Dependency parse')
('Jackknifing', 'Evaluate-for', 'Dependency parse')
('Stack-pointer\n(image text retrieval', 'Used-for', 'retrieving relevant images from textual queries')
('VisualSparta', 'Is-a-Prerequisite-of', 'image text retrieval')
('multimodal pre-training', 'Used-for', 'improving image text retrieval performance')
('cross-modal retrieval', 'Hyponym-Of', 'image text retrieval')
('Intra-modal Self-attention Distance', 'Used-for', 'quantifying relation consistency in image text retrieval')
('Inter-modal Alignment on Intra-modal Self-attentions', 'Used-for', 'optimizing performance in image text retrieval')
('political debate', 'Used-for', 'understanding democratic political decision making')
('political debate', 'Evaluate-for', 'Argument Mining')
('Argument Mining', 'Is-a-Prerequisite-of', 'empirical investigation of argument components')
('Argument Mining', 'Evaluate-for', 'classifying argumentative components as premises and claims')
('SVM learners', 'Compare', 'Neural Network architectures')
('Framing', 'Used-for', 'controlling public perception of issues')
('computational construction', 'Used-for', 'discourse networks construction from newspaper reports')
('Argument Mining', 'Used-for', 'annotating political debates')
('USElecDeb60To16', 'Used-for', 'research in Argument Mining')
('Semantic representation', 'Part-of', 'NLP')
('sentence representation learning', 'Evaluate-for', 'reading comprehension')
('sentence representation learning', 'Evaluate-for', 'question answering')
('sentence representation learning', 'Used-for', 'generating embeddings')
('sentence representation learning', 'Used-for', 'discriminative feature learning')
('sentence representation learning', 'Compare', 'word representation learning')
('sentence representation learning', 'Evaluate-for', 'rumor detection')
('sentence representation learning', 'Evaluate-for', 'syntactic information extraction')
('sentence representation learning', 'Evaluate-for', 'style and content disentangling')
('sentence embeddings', 'Part-of', 'sentence representation learning')
('lexical relations', 'Used-for', 'semantic clarity in sentence representation learning')
('sentence representation learning', 'Is-a-Prerequisite-of', 'downstream NLP tasks')
('semantic schemes', 'Compare', 'syntactic schemes')
('sentence representation learning', 'Used-for', 'abstractive text summarization')
('sentence representation learning', 'Evaluate-for', 'universal sentence encoding')
('neural machine translation', 'Compare', 'sentence representation learning')
('named entity relation', 'Used-for', 'joint extraction of entity mentions and relations')
('named entity relation', 'Used-for', 'extract semantic relations between entity mentions')
('named entity relation', 'Evaluate-for', 'Automatic Content Extraction (ACE')
('named entity relation', 'Part-of', 'named entity recognition')
('named entity recognition', 'Hyponym-Of', 'natural language processing')
('Agent-Artifact relations', 'Part-of', 'named entity relation')
('Physical relations', 'Part-of', 'named entity relation')
('Part-Whole relations', 'Part-of', 'named entity relation')
('named entity recognition', 'Is-a-Prerequisite-of', 'mention detection')
('mention detection', 'Used-for', 'named entity recognition')
('FOFE method', 'Used-for', 'named entity recognition')
('multimodal named entity disambiguation', 'Hyponym-Of', 'named entity recognition')
('external lexico\n(reading comprehension mrc model', 'Used-for', 'answering questions from passages')
('neural network model', 'Used-for', 'zero pronoun resolution')
('cloze-style reading comprehension', 'Is-a-Prerequisite-of', 'reading comprehension mrc model')
('attention-based recurrent networks', 'Used-for', 'question-aware passage representation')
('self-matching attention mechanism', 'Used-for', 'refine passage representation')
('pointer networks', 'Used-for', 'locate positions of answers')
('reinforcement learning', 'Used-for', 'train sentence selection as latent variable')
('Distantly supervised open-domain question answering', 'Compare', 'reading comprehension mrc model')
('neural approaches', 'Compare', 'traditional NLP techniques')
('reading comprehension mrc model', 'Used-for', 'multi-passage question answering')
('cloze-style reading comprehension', 'Part-of', 'reading comprehension mrc\n(Reading Comprehlosion (RC')
('Natural-Language Understanding Systems', 'Used-for', 'Evaluation of RC datasets')
('Evaluation of RC datasets', 'Evaluate-for', 'Readability')
('Reinforcement Learning', 'Used-for', 'Sentence Selection')
('Gated Attention-Based Recurrent Networks', 'Part-of', 'Reading Comprehlosion (RC')
('Self-Matching Attention Mechanism', 'Part-of', 'Reading Comprehlosion (RC')
('Pointer Networks', 'Used-for', 'Locate Positions of Answers')
('Commonsense Knowledge', 'Used-for', 'Enhance RC Model')
('Machine Reading at Scale', 'Hyponym-Of', 'Reading Comprehlosion (RC\n(None')
('recognition relation extraction', 'Is-a-Prerequisite-of', 'Knowledge Base Population')
('recognition relation extraction', 'Used-for', 'identifying relations between two entities')
('recognition relation extraction', 'Evaluate-for', 'models performance in classification tasks')
('recognition relation extraction', 'Part-of', 'Natural Language Processing')
('recognition relation extraction', 'Used-for', 'automated knowledge extraction from text')
('recognition relation extraction', 'Compare', 'manual relation extraction')
('recognition relation extraction', 'Hyponym-Of', 'relation extraction')
('relation extraction', 'Evaluate-for', 'multi-lingual information utilization')
('distant supervision', 'Used-for', 'building training data with reduced human effort')
('class ties', 'Used-for', 'enhancing extraction performance in distantly supervised scenarios')
('feature extraction', 'Used-for', 'reducing computation time in statistical NLP')
('temporal relation classification', 'Is-a-Prerequisite-of', 'relation extraction')
('Pocket Knowledge\n(fact check', 'Is-a-Prerequisite-of', 'veracity prediction')
('fact check', 'Used-for', 'verifying the truthfulness of a claim')
('fact check', 'Used-for', 'retrieving authoritative evidence')
('claim verification', 'Is-a-Prerequisite-of', 'fact check')
('FEVER dataset', 'Used-for', 'fact check')
('multi-task model', 'Evaluate-for', 'fact check')
('LogicalFactChecker', 'Used-for', 'fact check')
('neural retrieval model', 'Evaluate-for', 'fact check')
('graph module network', 'Used-for', 'fact check')
('veracity of a claim', 'Evaluate-for', 'fact check')
('claim context', 'Evaluate-for', 'fact check')
('evidence retrieval', 'Used-for', 'fact check')
('Recurrent Neural Networks', 'Is-a-Prerequisite-of', 'Hybrid Code Networks')
('Recurrent Neural Networks', 'Part-of', 'Deep Neural Networks')
('Recurrent Neural Networks', 'Is-a-Prerequisite-of', 'KBLSTM')
('Recurrent Neural Networks', 'Used-for', 'Language Modeling')
('Deep Neural Networks', 'Hyponym-Of', 'Neural Networks')
('KBLSTM', 'Used-for', 'Machine Reading')
('Hybrid Code Networks', 'Used-for', 'Dialog Systems')
('None', 'Part-of', 'word embedding model')
('context word vector', 'Used-for', 'unsupervised anomaly detection')
('context word vector', 'Used-for', 'pre-trained model')
('context word vector', 'Compare', 'target word vector')
('word embedding model', 'Used-for', 'capturing semantic regularities')
('Neural Belief Tracking', 'Used-for', 'spoken dialogue systems')
('Neural Belief Tracking', 'Evaluate-for', 'dialogue domain complexity')
('GloVe', 'Is-a-Prerequisite-of', 'context word vector')
('word embedding model', 'Is-a-Prerequisite-of', 'context word vector')
('context word vector', 'Used-for', 'capturing linguistic variations')
('Cold-Start Aware Attention', 'Used-for', 'sentiment analysis')
('None', 'Is-a-Prerequisite-of', 'Cross-lingual word embeddings')
('None', 'Used-for', 'Annotating NER data')
('None', 'Part-of', 'None')
('Noise contrastive estimation', 'Used-for', 'Learning word embeddings')
('Multilingual Neural Language Models', 'Used-for', 'Generating multilingual embeddings')
('Unsupervised bilingual word embeddings', 'Evaluate-for', 'Cross-lingual NLP tasks')
('Joint multilingual sentence embedding', 'Used-for', 'Mining for parallel data')
('Multilingual model transfer', 'Used-for', 'Low-resource neural machine translation')
('word-embedding models', 'Used-for', 'dialog generation')
('Skip-Gram model', 'Used-for', 'dialog generation')
('local coherence model', 'Used-for', 'dialog generation')
('encoder-decoder model', 'Used-for', 'dialog generation')
('dialog generation', 'Is-a-Prerequisite-of', 'interpretable response generation')
('neural dialogue generation', 'Used-for', 'dialog generation')
('dialog systems', 'Used-for', 'dialog generation')
('encoder-decoder dialog model', 'Used-for', 'dialog generation')
('deep latent variable models', 'Used-for', 'dialog generation')
('dialog generation', 'Evaluate-for', 'response generation')
('\n(None', 'Is-a-Prerequisite-of', 'Conditional Text Generation')
('Conditional Text Generation', 'Used-for', 'Natural Language Generation')
('Pre-train and Plug-in Variational Auto-Encoder', 'Used-for', 'Conditional Text Generation')
('Sequence-to-sequence models', 'Evaluate-for', 'Conditional Text Generation')
('unsupervised cross-lingual learning', 'Is-a-Prerequisite-of', 'unsupervised machine translation')
('unsupervised cross-lingual learning', 'Is-a-Prerequisite-of', 'unsupervised bilingual word embedding')
('unsupervised bilingual word embedding', 'Used-for', 'mining parallel sentences')
('unsupervised bilingual lexicon induction', 'Used-for', 'word translation from monolingual corpora')
('unsupervised bilingual word embedding', 'Part-of', 'unsupervised cross-lingual learning')
('unsupervised machine translation', 'Evaluate-for', 'improving low-resource language processing')
('unsupervised bilingual lexicon induction', 'Part-of', 'unsupervised cross-lingual learning')
('unsupervised bilingual lexicon induction', 'Compare', 'supervised bilingual lexicon induction')
('unsupervised machine translation', 'Compare', 'supervised machine translation')
('parallel data', 'Compare', 'monolingual data')
('cosine similarities\n(race nlp', 'Is-a-Prerequisite-of', 'recognize social biases')
('race nlp', 'Is-a-Prerequisite-of', 'racial justice in NLP research practices')
('race nlp', 'Hyponym-Of', 'NLP model development stages')
('race nlp', 'Used-for', 'surveying papers on race')
('ACL anthology', 'Used-for', 'race nlp research')
('race nlp', 'Evaluate-for', 'upholding racial hierarchies')
('racial hierarchies', 'Evaluate-for', 'race nlp')
('race nlp', 'Is-a-Prerequisite-of', 'inclusion in NLP research')
('Abstractive summarization', 'Evaluate-for', 'summarization datasets')
('Extractive summarization', 'Evaluate-for', 'summarization datasets')
('English Gigaword', 'Hyponym-Of', 'summarization datasets')
('DUC 2004', 'Hyponym-Of', 'summarization datasets')
('MSR', 'Hyponym-Of', 'summarization datasets')
('CNN/Daily Mail dataset', 'Hyponym-Of', 'summarization datasets')
('DUC dataset', 'Used-for', 'summarization evaluation')
('DUC-2002', 'Used-for', 'summarization evaluation')
('AMI corpus', 'Hyponym-Of', 'summarization datasets')
('ICSI corpus', 'Hyponym-Of', 'summarization datasets')
('WikiQA', 'Hyponym-Of', 'summarization datasets')
('adversarial training', 'Used-for', 'learning dialect invariant features in morphological tagging')
('adversarial training', 'Used-for', 'mitigating negative transfer in cross-lingual learning')
('adversarial training', 'Used-for', 'enhancing multi-dimensional emotion regression')
('adversarial training', 'Used-for', 'filtering distant supervision noise in relation extraction')
('adversarial training', 'Part-of', 'Japanese PAS analysis model')
('adversarial training', 'Part-of', 'disentangled latent representation learning')
('latent representation', 'Used-for', 'automatic style transfer')
('DSGAN', 'Used-for', 'sentence-level true-positive generation')
('multimodal language', 'Used-for', 'sentiment analysis')
('multimodal language', 'Used-for', 'emotion recognition')
('multimodal language', 'Used-for', 'multimodal dialogue systems')
('multimodal language', 'Used-for', 'multimodal machine translation')
('multimodal language', 'Used-for', 'multimodal named entity recognition')
('multimodal language', 'Hyponym-Of', 'human language processing')
('morphological analyzer', 'Used-for', 'tokenization of sentences in unsegmented languages')
('tokenization', 'Part-of', 'text classification process')
('morphological analyzer', 'Used-for', 'generating morphological constraints')
('morphological constraints', 'Part-of', 'morph-fitting procedure')
('morph-fitting procedure', 'Used-for', 'improving distributional vector spaces')
('morphological analyzer', 'Used-for', 'encoding sentences with word or subword representations')
('long form question answering', 'Used-for', 'machine comprehension')
('long form question answering', 'Used-for', 'evaluating generation systems')
('Semantic parsing', 'Used-for', 'long form question answering')
('Open-domain question answering', 'Compare', 'long form question answering')
('Knowledge bases', 'Used-for', 'long form question answering')
('Machine reading', 'Is-a-Prerequisite-of', 'long form question answering')
('Neural network models', 'Used-for', 'long form question answering')
('Distant supervision', 'Used-for', 'long form question answering')
('Adversarial inputs', 'Evaluate-for', 'long form question answering')
('Web text', 'Used-for', 'long form question answering')
('sentence generation', 'Used-for', 'code generation')
('sentence generation', 'Used-for', 'semantic parsing')
('abstract syntax trees', 'Part-of', 'semantic parsing')
('decoder', 'Used-for', 'sentence generation')
('sentence generation', 'Used-for', 'dialog response generation')
('sentence generation', 'Used-for', 'question generation')
('sentence generation', 'Used-for', 'automatic pun generation')
('neural machine translation', 'Used-for', 'sentence generation')
('Seq2Seq models', 'Used-for', 'sentence generation')
('latent variable models', 'Used-for', 'sentence generation')
('encoder-decoder models', 'Used-for', 'sentence generation')
('neural models', 'Used-for', 'sentence generation')
('controlled sentence function', 'Used-for', 'sentence generation')
('iterative training process', 'Used-for', 'sentence generation')
('sentence generation', 'Used-for', 'email subject line generation')
('dialogue generation model', 'Used-for', 'generating fluent natural language responses in conversational systems')
('dialogue generation model', 'Used-for', 'end-to-end neural dialogue generation tasks')
('dialogile generation model', 'Is-a-Prerequisite-of', 'knowledge-guided response generation')
('dialogue generation model', 'Evaluate-for', 'quality of response')
('dialogue generation model', 'Used-for', 'real-world industrial applications')
('neural knowledge diffusion model', 'Part-of', 'dialogue generation model')
('two-step generation architecture', 'Part-of', 'dialogue generation model')
('iterative inference algorithm', 'Used-for', 'text infilling in dialogue generation model')
('dialogue generation model', 'Evaluate-for', 'diversity and appropriateness of responses')
('dialogue generation model', 'Used-for', 'multi-turn dialogue generation')
('dialogue generation model', 'Used-for', 'producing suitable responses based on detected relevant contexts')
('Discourse coherence', 'Used-for', 'language assessment')
('Discourse coherence', 'Is-a-Prerequisite-of', 'effective discourse parsing')
('Discourse coherence', 'Hyponym-Of', 'text quality')
('Discourse coherence', 'Evaluate-for', 'perplexity')
('Discourse coherence', 'Evaluate-for', 'Normalized Pointwise Mutual Information')
('Discourse coherence', 'Evaluate-for', 'Micro F1 measure')
('Quantifiable Dialogue Coherence Evaluation', 'Used-for', 'discourse coherence assessment')
('Quantifiable Dialogue Coherence Evaluation', 'Evaluate-for', 'dialogue coherence')
('Neural semantic parser', 'Used-for', 'generating formal meaning representations')
('Discourse Representation Theory', 'Part-of', 'discourse coherence models')
('Open-domain neural semantic parser', 'Used-for', 'formal meaning representations generation')
('Rhetorical Structure Theory', 'Part-of', 'discourse analysis')
('Discourse segmenter', 'Used-for', 'identifying elementary discourse units')
('underrepresented language', 'Is-a-Prerequisite-of', 'linguistic diversity challenges')
('underrepresented language', 'Used-for', 'improving NLP systems')
('underrepresented language', 'Hyponym-Of', 'indigenous languages')
('NLP research', 'Evaluate-for', 'underrepresented language challenges')
('script normalization', 'Used-for', 'performance improvement in machine translation')
('linguistics knowledge', 'Used-for', 'enhancing Chinese language models')
('NLP research', 'Part-of', 'computer science')
('Heterogeneous Linguistics Graph', 'Used-for', 'enhancing pre-trained language models')
('transfer learning', 'Used-for', 'sentiment classification')
('neural retrieval model', 'Used-for', 'context-dependent semantic parsing')
('neural retrieval model', 'Used-for', 'generating source code conditioned on class environment')
('neural retrieval model', 'Evaluate-for', 'fast adaptation in model learning')
('neural retrieval model', 'Part-of', 'context-aware encoder-decoder systems')
('neural retrieval model', 'Hyponym-Of', 'information retrieval systems')
('context-aware encoder-decoder systems', 'Used-for', 'semantically parsing contextual information')
('meta-learner', 'Used-for', 'utilizing retrieved datapoints')
('meta-learner', 'Part-of', 'fast adaptation strategies')
('CONCODE dataset', 'Used-for', 'testing context-dependent semantic parsing')
('CSQA dataset', 'Used-for', 'evaluating conversational history semantic parsing')
('entity recognition ner aim', 'Is-a-Prerequisite-of', 'model generalization')
('entity recognition ner aim', 'Is-a-Prerequisite-of', 'multilingual learning')
('entity recognition ner aim', 'Is-a-Prerequisite-of', 'cross-domain domain adaptation')
('tag hierarchy', 'Used-for', 'entity recognition ner aim')
('external knowledge', 'Used-for', 'entity recognition ner aim')
('child models', 'Part-of', 'entity recognition ner aim')
('domain adaptation', 'Used-for', 'entity  recognition ner aim')
('gazetteers', 'Evaluate-for', 'entity recognition ner aim')
('discriminative models', 'Compare', 'generative models')
('dictionaries', 'Used-for', 'entity recognition ner aim')
('named entity dictionaries', 'Used-for', 'entity recognition ner aim')
('multitasking approach', 'Part-of', 'entity recognition ner aim')
('labeled data', 'Used-for', 'entity recognition ner aim')
('relation extraction model', 'Evaluate-for', 'multi-lingual texts')
('relation extraction model', 'Is-a-Prerequisite-of', 'distant supervision')
('relation extraction model', 'Evaluate-for', 'noise characterization in training data')
('multi-lingual neural relation extraction framework', 'Part-of', 'relation extraction model')
('cross-lingual attention', 'Used-for', 'considering information consistency among languages')
('mono-lingual attention', 'Used-for', 'utilizing information within mono-lingual texts')
('distant supervision', 'Used-for', 'building training data')
('relation extraction', 'Hyponym-Of', 'information extraction')
('experimental results', 'Used-for', 'evaluating the relation extraction model')
('training data', 'Used-for', 'relation extraction model performance enhancement')
('joint extraction of entities and relations', 'Part-of', 'relation extraction model')
('pre trained model', 'Used-for', 'enhancing performance of neural network architectures for NLP tasks')
('neural network architectures', 'Part-of', 'NLP systems')
('context embeddings', 'Hyponym-Of', 'embedding models')
('adding pretrained context embeddings', 'Evaluate-for', 'sequence labeling tasks')
('pre trained model', 'Used-for', 'sentence and corpus-level evaluation in MT metrics')
('pre trained model', 'Used-for', 'keyphrase extraction from scholarly documents')
('embedding knowledge graphs', 'Used-for', 'improving interpretability and efficiency of KG embeddings')
('morphological inflection', 'Is-a-Prerequisite-of', 'morphological tagging')
('morphological inflection', 'Hyponym-Of', 'morphological analysis')
('morphological inflection', 'Used-for', 'language understanding systems')
('morphological inflection', 'Part-of', 'morphology')
('morphological inflection', 'Is-a-Prerequisite-of', 'morphological tagging accuracy improvements')
('morphological inflection', 'Evaluate-for', 'morphological richness and dialectal variations handling')
('morphological inflection', 'Evaluate-for', 'semantic and morphological information incorporation')
('morphological inflection generation', 'Hyponym-Of', 'morphological inflection')
('morphological inflection', 'Is-a-Prerequisite-of', 'dialogue state tracking')
('morphological constraints', 'Part-of', 'morph-fitting procedure')
('morph-fitting procedure', 'Used-for', 'improving distributional vector spaces')
('social bias frame', 'Is-a-Prerequisite-of', 'commonsense reasoning on social implications')
('social bias frame', 'Used-for', 'modeling pragmatic frames in expressing social biases')
('social bias frame', 'Used-for', 'large-scale modelling and evaluation')
('neural embeddings', 'Evaluate-for', 'reflecting societal biases')
('neural embeddings', 'Part-of', 'NLP pipelines')
('Social Bias Frames', 'Hyponym-Of', 'semantic formalisms')
('Social Bias Inference Corpus', 'Used-for', 'supporting large-scale modelling of social biases')
('keyphrase extraction models', 'Used-for', 'integrating human attention data')
('unsupervised models', 'Used-for', 'incorporating human attention without supervision')
('human attention', 'Used-for', 'enhancing keyphrase extraction')
('neural network models', 'Part-of', 'keyphrase extraction enhancement methods')
('reading behavior\n(neural machine translation', 'Used-for', 'translation model')
('chunk-based decoders', 'Part-of', 'translation model')
('Multi-modal Neural Machine Translation model', 'Is-a-Prerequisite-of', 'translation model')
('zero-resource NMT', 'Used-for', 'translation model')
('NMT+RNNG', 'Used-for', 'translation model')
('bidirectional tree encoder', 'Part-of', 'translation model')
('sequence-to-dependency NMT', 'Used-for', 'translation model')
('gradient diffusion', 'Evaluate-for', 'translation model robustness')
('posterior regularization', 'Used-for', 'integrating prior knowledge into translation model')
('deep Neural Networks', 'Used-for', 'improving translation model')
('latent representation', 'Used-for', 'style transfer')
('adversarial robustness', 'Compare', 'transfer accuracy')
('adversarial robustness', 'Compare', 'content preservation')
('adversarial robustness', 'Compare', 'language fluency')
('low-resource languages', 'Is-a-Prerequisite-of', 'NMT-Adapt')
('adversarial robustness', 'Used-for', 'defending adversarial attacks')
('Flooding method', 'Used-for', 'generalization')
('DGSlow', 'Used-for', 'degrading DG models')
('RSMI', 'Used-for', 'improving adversarial robustness')
('hybrid retrieval', 'Used-for', 'information retrieval tasks')
('ATINTER', 'Used-for', 'improving adversarial robustness')
('adversarial robustness', 'Compare', 'task accuracy')
('word embeddings', 'Is-a-Prerequisite-of', 'Skip-Gram model')
('Skip-Gram model', 'Part-of', 'word embeddings')
('caption generation', 'Used-for', 'word embeddings')
('word analogy questions', 'Used-for', 'word embeddings')
('additive compositionality', 'Hyponym-Of', 'compositionality in word vectors')
('vector calculus', 'Used-for', 'solving word analogies')
('Skip-Gram model', 'Hyponym-Of', 'word embeddings')
('Sufficient Dimensionality Reduction framework', 'Evaluate-for', 'Skip-Gram model parameters')
('neural word embeddings', 'Used-for', 'aspect extraction')
('bilingual dictionaries', 'Used-for', 'learning bilingual word embeddings')
('statistical word segmentation', 'Compare', 'neural word segmentation')
('signed spectral normalized graph cut algorithm', 'Used-for', 'spectral clustering using word embeddings')
('neural network-based joint models', 'Used-for', 'Chinese word segmentation and POS tagging')
('\n(Question Answering Dataset SQuAD', 'Is-a-Prerequisite-of', 'Constituent-centric neural architecture')
('Constituent-centric neural architecture', 'Used-for', 'Generation of candidate answers')
('Question Answering Dataset SQuAD', 'Evaluate-for', 'State of the art performance')
('State of the art performance', 'Hyponym-Of', 'Effectiveness of question answering systems')
('Question Answering Dataset SQuAD', 'Used-for', 'Training QA systems')
('Question Answering', 'Used-for', 'Answering knowledge inquired questions')
('Semantic Parsing', 'Part-of', 'Question Answering')
('Answer generation', 'Part-of', 'Question Answering')
('COREQA', 'Used-for', '\n(None')
('multi-task learning', 'Used-for', 'extracting common features from different tasks')
('multi-task learning', 'Is-a-Prerequisite-of', 'adversarial training in multi-task frameworks')
('multi-task learning', 'Used-for', 'improving performance on multiple tasks using shared knowledge')
('shared knowledge', 'Part-of', 'multi-task learning')
('multi-task learning', 'Used-for', 'transfer learning')
('multi-task learning', 'Used-for', 'semantic parsing in multilingual contexts')
('multi-task learning', 'Hyponym-Of', 'machine learning')
('adversarial training', 'Used-for', 'preventing task interference in multi-task learning')
('task-specific features', 'Part-of', 'multi-task learning models')
('multi-task learning', 'Used-for', 'knowledge transfer in neural network models')
('multi-task learning', 'Used-for', 'neural machine translation')
('detect hate speech', 'Part-of', 'online hate identification systems')
('detect hate', 'Used-for', 'limiting social harms')
('racial bias', 'Is-a-Prerequisite-of', 'detect hate speech')
('racial bias', 'Compare', 'dialect sensitivity')
('dialect sensitivity', 'Used-for', 'reduce racial bias in annotation')
('African American English', 'Used-for', 'infer racial bias')
('hate speech detection models', 'Used-for', 'categorize offensive content')
('sentiment analysis', 'Conjunction', 'emotion classification')
('sentiment knowledge', 'Used-for', 'enhance hate speech detection')
('IntentCONAN', 'Used-for', 'generate counterspeech')
('PerFuMe', 'Used-for', 'incorporate intent-specific information')
('child-directed speech', 'Evaluate-for', 'language acquisition')
('encoder pre-training', 'Used-for', 'speech translation')
('Stacked Acoustic-and-Textual Encoding', 'Used-for', 'speech translation')
('Stacked Acoustic-and-Textual Encoding', 'Is-a-Prerequisite-of', 'speech translation adaptors')
('Mean opinion score\n(Labeled sequence transduction', 'Used-for', 'learning morphological inflection')
('Multi-space variational encoder-decoders', 'Used-for', 'learning morphological inflection')
('Generative model', 'Used-for', 'learning morphological inflection')
('Semi-supervised learning', 'Used-for', 'learning morphological inflection')
('Morphological inflection', 'Is-a-Prerequisite-of', 'learning morphological inflection')
('Hard attention mechanism', 'Used-for', 'learning morphological inflection')
('Soft attention mechanism', 'Used-for', 'learning morphological inflection')
('Neural networks', 'Used-for', 'learning morphological inflection')
('Morphological inflection generation datasets', 'Evaluate-for', 'learning morphological inflection')
('Latent Meaning Models', 'Used-for', 'learning morphological inflection')
('Statistical morphological inflectors', 'Used-for', 'learning morphological inflection')
('unsupervised selective rationalization', 'Used-for', 'producing rationales alongside predictions')
('rationale generator', 'Part-of', 'unsupervised selective rationalization')
('predictor', 'Part-of', 'unsupervised selective rationalization')
('unsupervised selective rationalization', 'Evaluate-for', 'rationale plausibility')
('unsupervised selective rationalization', 'Evaluate-for', 'task accuracy')
('noise injection', 'Used-for', 'limiting generation of implausible rationales')
('unsupervised selective rationalization', 'Used-for', 'improving model faithfulness')
('multi passage reading comprehension', 'Used-for', 'inferring answers from multiple documents')
('multi passage reading evidence', 'Part-of', 'multi passage reading comprehension')
('multi passage answer verification', 'Used-for', 'verifying correctness of answers in multi passage reading comprehension')
('Dynamic Self-attention Network', 'Used-for', 'multi passage reading comprehension')
('cross-passage information', 'Used-for', 'multi passage reading comprehension')
('cognitive graph', 'Used-for', 'multi-hop reading comprehension question answering')
('multi-hop reading comprehension', 'Hyponym-Of', 'multi passage reading comprehension')
('Heterogeneous Document-Entity graph', 'Used-for', 'multi-hop reading comprehension')
('Explore-Propose-Assemble reader', 'Used-for', 'multi-hop reading comprehension')
('PathNet', 'Used-for', 'multi-hop reading comprehension')
('KB-InfoBot', 'Is-a-Prerequisite-of', 'oriented dialogue')
('task-oriented dialogue systems', 'Used-for', 'interacting with external databases')
('symbolic queries', 'Part-of', 'previous systems')
('soft retrieval process', 'Used-for', 'enhancing task success in oriented dialogue')
('neural dialogue agents', 'Used-for', 'conducting multi-turn oriented dialogue')
('reinforcement learner', 'Used-for', 'improving performance of oriented dialogue')
('external database', 'Used-for', 'providing real-world knowledge in oriented dialogue')
('neural end-to-end agent', 'Used-for', 'personalized oriented dialogue')
('dialogue state tracking', 'Used-for', 'managing user interactions in oriented dialogue')
('SVM', 'Evaluate-for', 'task success prediction in oriented dialogue')
('Intelligent assistants', 'Hyponym-Of', 'task-oriented dialogue systems')
('Chinese Spelling Correction CSC', 'Used-for', 'detecting and correcting erroneous characters in Chinese texts')
('Chinese Spelling Correction CSC', 'Used-for', 'correcting misspelled characters in Chinese texts')
('Chinese Spelling Correction CSC', 'Used-for', 'handling character-level errors in Chinese texts')
('Chinese Spelling Correction CSC', 'Used-for', 'improving text quality in downstream tasks like ASR and OCR')
('SpellGCN', 'Part-of', 'Chinese Spelling Correction CSC')
('BERT', 'Used-for', 'extracting character representations for Chinese Spelling Correction CSC')
('SpellGCN', 'Used-for', 'mapping character graphs to inter-dependent classifiers')
('Soft-Masked BERT', 'Used-for', 'error detection and correction in Chinese Spelling Correction CSC')
('PLOME', 'Part-of', 'Chinese Spelling Correction CSC')
('PHMOSpell', 'Part-of', 'Chinese Spelling Correction CSC')
('convolutional layers', 'Compare', 'recurrent network')
('recurrent network', 'Hyponym-Of', 'neural networks')
('bi-directional LSTM', 'Part-of', 'recurrent network')
('recurrent network', 'Evaluate-for', 'machine translation')
('recurrent network', 'Used-for', 'reading comprehension')
('recurrent network', 'Used-for', 'dialog systems')
('recurrent network', 'Evaluate-for', 'handling long documents')
('recurrent network', 'Used-for', 'automatic question answering')
('gated self-matching networks', 'Part-of', 'recurrent network')
('stochastic gradient Markov Chain Monte Carlo', 'Used-for', 'recurrent network')
('recurrent network', 'Evaluate-for', 'knowledge base question answering')
('recurrent network', 'Used-for', 'sentiment analysis')
('Hybrid Code Networks', 'Part-of', 'recurrent network')
('language generation task', 'Used-for', 'generation of complex programs from natural language descriptions')
('language generation task', 'Used-for', 'corrective referring expressions generation')
('sequence-to-sequence model', 'Used-for', 'language generation task')
('neural networks', 'Used-for', 'language generation task')
('grammar model', 'Used-for', 'language generation task')
('grammatical representations', 'Used-for', 'language generation task')
('language generation', 'Evaluate-for', 'scaling up to generation of complex programs')
('statistical approaches', 'Evaluate-for', 'language generation task')
('Sent-Dehydrogenase', 'Used-for', 'removing biases')
('Social Bias Frames', 'Part-of', 'Social Bias Inference Corpus')
('Social Bias Inference Corpus', 'Used-for', 'large-scale modeling and evaluation')
('Social biases', 'Hyponym-Of', 'biases in word embeddings')
('social bias encoded', 'Part-of', 'biases in word embeddings')
('BLIND', 'Used-for', 'bias removal')
('Text-to-SQL models', 'Evaluate-for', 'social bias mitigation')
('Social biases', 'Used-for', 'shaping stereotypes')
('cyberbullying detection', 'Evaluate-for', 'impacts of unintended biases')
('seed lexicons', 'Used-for', 'bias measurement')
('direct speech-to-speech translation', 'Is-a-Prerequisite-of', 'multilingual speech-to-speech translation')
('SpeechMatrix', 'Used-for', 'training bilingual speech-to-speech translation models')
('direct speech-to-speech translation', 'Is-a-Prerequisite-of', 'audio-visual speech-to-speech translation')
('audio-visual speech-to-speech translation', 'Used-for', 'increasing system robustness')
('audio-visual speech-to-speech translation', 'Used-for', 'dubbing archival films')
('direct speech-to-speech translation', 'Compare', 'cascaded speech translation')
('direct speech-to-speech translation', 'Used-for', 'translating without intermediate text')
('audio signal', 'Used-for', 'providing additional information to reduce gender bias in speech translation')
('Stacked Acoustic-and-Textual Encoding method', 'Used-for', 'speech translation')
('speech translation', 'Used-for', 'reducing gender bias')
('encoder pre-training\n(contextualized embeddings', 'Used-for', 'achieving gains in Word Sense Disambiguation tasks')
('contextualized embeddings', 'Used-for', 'capturing affect dimensions in portrayals of people')
('contextualized embeddings', 'Used-for', 'encoding translation and reference sentences in machine translation evaluation')
('contextualized embeddings', 'Compare', 'traditional word embeddings')
('contextualized embeddings', 'Used-for', 'learning sense-level embeddings')
('context embeddings', 'Part-of', 'normalizing flow model in PCFG induction')
('contextualized embeddings', 'Used-for', 'analyzing portrayals of men and women')
('contextualized embeddings', 'Hyponym-Of', 'Neural Language Modeling outputs')
('contextualized embeddings', 'Used-for', 'deducing finer-grained sense distributions')
('contextualized embeddings', 'Evaluate-for', 'robustness against full sense inventory')
('contextualized embeddings', 'Used-for', 'detecting temporal changes in word meaning')
('\n(Intelligent Assistants', 'Is-a-Prerequisite-of', 'hybrid dialogue systems')
('hybrid dialogue systems', 'Part-of', 'Intelligent Assistants')
('hybrid dialogue systems', 'Compare', 'open-domain non-task-oriented dialogue systems')
('hybrid dialogue systems', 'Compare', 'task-oriented spoken dialogue systems')
('belief spans', 'Used-for', 'track dialogue beliefs')
('Two Stage CopyNet', 'Used-for', 'reduce model complexity')
('dialogue state tracking', 'Used-for', 'estimate user goals and requests')
('GLAD', 'Used-for', 'dialogue state tracking')
('Memory-to-sequence model', 'Used-for', 'incorporating knowledge bases into dialog systems')
('dialogue system', 'Used-for', 'automatic diagnosis')
('slot filling', 'Used-for', 'spoken language understanding')
('incremental learning framework', 'Used-for', 'task-oriented dialogue systems')
('emotion cause extraction', 'Compare', 'emotion cause pair extraction')
('emotion annotation', 'Used-for', 'emotion cause extraction')
('emotion cause extraction', 'Used-for', 'emotion cause pair extraction')
('benchmark emotion cause corpus', 'Evaluate-for', 'emotion cause pair extraction')
('emotion cause pair extraction', 'Used-for', 'synthetic question answering corpora generation')
('emotion-cause pairing and filtering', 'Part-of', 'emotion cause pair extraction')
('multi-task seasoning learning', 'Used-for', 'emotion cause pair extraction')
('graph attention', 'Used-for', 'emotion clause representation enhancement')
('boundary-adjusting classifiers', 'Used-for', 'emotion cause pair extraction representation improvement')
('emotion clauses', 'Conjunction', 'cause clauses')
('constrained learning', 'Used-for', 'emotion cause pair extraction model optimization')
('contextual embeddings', 'Used-for', 'understanding word usage in context')
('contextual embeddings', 'Is-a-Prerequisite-of', 'accurate sentiment analysis')
('contextual embeddings', 'Used-for', 'improving machine translation performance')
('contextual embeddings', 'Compare', 'non-contextual embeddings')
('contextual embeddings', 'Hyponym-Of', 'word embeddings')
('contextual embeddings', 'Evaluate-for', 'effectiveness in NLP tasks')
('non-contextual embeddings', 'Compare', 'contextual embeddings')
('lexical features', 'Compare', 'contextual embeddings')
('contextual embeddings', 'Evaluate-for', 'domain adaptation effectiveness')
('domain adaptation', 'Used-for', 'improving machine translation with contextual embeddings')
('sentiment analysis', 'Used-for', 'evaluating contextual embeddings')
('contextual embeddings', 'Used-for', 'enhancing bilingual word embeddings')
('bilingual word embeddings', 'Part-of', 'contextual embeddings strategies')
('annotated training data', 'Used-for', 'supervised learning')
('small hand-labeled data', 'Part-of', 'annotated training data')
('annotated training data', 'Part-of', 'Spoken Language Understanding models')
('Spoken Language Understanding models', 'Used-for', 'belief tracker')
('belief tracker', 'Is-a-Prerequisite-of', 'modern spoken dialogue systems')
('supervised learning', 'Used-for', 'event extraction')
('event extraction', 'Used-for', 'knowledge base population')
('hand-labeled training data', 'Compare', 'automatically labeled data')
('automatically labeled data', 'Evaluate-for', 'model performance')
('distant supervision', 'Used-for', 'building training data')
('noise', 'Hyponym-Of', 'training data issues')
('curriculum learning', 'Used-for', 'training without direct supervision')
('model performance', 'Used-for', 'relation extraction')
('comprehension datasets', 'Used-for', 'natural-language understanding systems development')
('comprehension datasets', 'Part-of', 'reading comprehension')
('comprehension datasets', 'Evaluate-for', 'prerequisite skills')
('comprehension datasets', 'Evaluate-for', 'readability')
('comprehension datasets', 'Is-a-Prerequisite-of', 'machine comprehension')
('comprehension datasets', 'Hyponym-Of', 'natural language processing datasets')
('reading comprehension', 'Used-for', 'question answering')
('None', 'Used-for', 'semantic parsing')
('semantic parsing', 'Is-a-Prerequisite-of', 'mapping natural language to executable programs')
('semantic parsing', 'Evaluate-for', 'generating structured meaning representations from natural language')
('neural semantic parsing', 'Hyponym-Of', 'semantic parsing')
('encoder-decoder framework', 'Used-for', 'neural semantic parsing')
('grammar model', 'Used-for', 'capturing target syntax in code generation')
('semantic role labeling', 'Used-for', 'state representation in neural networks')
('deep learning', 'Used-for', 'semantic role labeling')
('neural architecture', 'Part-of', 'semantic parsing models')
('constrained decoding', 'Used-for', 'maintaining target syntax integrity in code generation')
('natural language descriptions', 'Used-for', 'generating source code')
('source code generation', 'Evaluate-for', 'effectiveness of grammar models')
('AMR parsing', 'Compare', 'UCCA parsing')
('neural semantic parsers', 'Evaluate-for', 'confidence modeling')
('sequence-to-tree model', 'Hyponym-Of', 'syntactic parsers')
('multitask learning', 'Used-for', 'improving UCCA parsing')
('latent\n(professional fact checker', 'Used-for', 'review articles')
('review articles', 'Used-for', 'verify the veracity of claims')
('Premise articles', 'Used-for', 'support review')
('professional fact checker', 'Used-for', 'verify the veracity of claims')
('dense passage retrieval model', 'Used-for', 'retrieve passages in premise articles')
('FAVIQ', 'Is-a-Prerequisite-of', 'natural language understanding advancement')
('professional fact checker', 'Used-for', 'manual verification of claims')
('claims', 'Part-of', 'FAVIQ')
('financial reports', 'Used-for', 'discern critical financial signals')
('compare-and-contrast multistage pipeline', 'Used-for', 'recognize relationships in financial reports')
('summarization system', 'Used-for', 'generating summaries from text')
('extractive summarization', 'Hyponym-Of', 'summarization system')
('abstractive summarization', 'Hyponym-Of', 'summarization system')
('query-based summarization', 'Hyponym-Of', 'summarization system')
('extractive summarization', 'Part-of', 'summarization system')
('abstractive summarization', 'Part-of', 'summarization system')
('query-based summarization', 'Part-of', 'summarization system')
('neural semantic parser', 'Used-for', 'summarization system')
('SWAP-NET', 'Is-a-Prerequisite-of', 'extractive summarization')
('multi-document summarization', 'Part-of', 'summarization system')
('Integer Linear Programming', 'Evaluate-for', 'summarization system')
('ROUGE scores', 'Evaluate-for', '\n(None')
('Self Attentive Parser', 'Used-for', 'Improving Parsing Accuracy')
('Self Attentive Parser', 'Compare', 'LSTM Encoder')
('Contextualized Word Embeddings', 'Used-for', 'training self attentive parser')
('Lexical Representation', 'Evaluate-for', 'Parsing Accuracy')
('Parsing Accuracy', 'Part-of', 'Natural Language Processing')
('Adversarial Input Perturbations', 'Evaluate-for', 'Robustness of Self Attentive Parser')
('Self Training', 'Used-for', 'Disfluency Detection')
('Joint Parsing', 'Conjunction', 'Disfluency Detection')
('language model lm', 'Used-for', 'language modeling')
('language model lm', 'Part-of', 'natural language processing')
('language model lm', 'Evaluate-for', 'generating conversational text')
('neural language model', 'Hyponym-Of', 'language model lm')
('recurrent neural networks', 'Used-for', 'language model lm')
('Affect-LM', 'Is-a-Prerequisite-of', 'affective messages in text generation')
('RNNs', 'Compare', 'neural language model')
('neural language model', 'Evaluate-for', 'incorporating document context')
('neural language model', 'Used-for', 'sentence generation based on topic')
('language model perplexity', 'Evaluate-for', 'language model lm')
('affective information', 'Used-for', 'modifying language model lm')
('language model lm', 'Used-for', 'enhancing semantic understanding of natural language')
('language model lm', 'Evaluate-for', 'improving coherence in topic models')
('None', 'Used-for', 'hate speech detection')
('hate speech models', 'Evaluate-for', 'Bias reduction in hate speech detection')
('hate speech detection models', 'Evaluate-for', 'toxicity labeling accuracy')
('hate speech models', 'Evaluate-for', 'preventing racially biased labeling')
('hate speech detection models', 'Evaluate-for', 'F1 performance measure')
('Dynamic data creation', 'Used-for', 'hate speech detection model training')
('HateCheck', 'Used-for', 'evaluating hate speech detection models')
('hate speech detection models', 'Evaluate-for', 'handling minority dialects')
('AAE dialect recognition', 'Used-for', 'reducing bias in hate speech detection')
('race priming', 'Used-for', 'reducing racial bias in hate speech detection')
('hate speech detection models', 'Part-of', 'computational linguistics research')
('Argument Generation', 'Is-a-Prerequisite-of', 'Supporting Argument Detection')
('Argument Generation', 'Used-for', 'Interactive Natural Language Generation')
('Argument Generation', 'Part-of', 'Natural Language Processing')
('Argument Generation', 'Part-of', 'Automatic Essay Scoring')
('Machine Generation', 'Used-for', 'Poetry')
('Machine Learning', 'Used-for', 'Paraphrase Generation')
('Semantic Parsing', 'Used-for', 'Code Generation')
('Natural Language Descriptions', 'Used-for', 'Code Generation')
('Phonetic Encoding', 'Used-for', 'Poetry Generation')
('Crowdsourcing', 'Used-for', 'Paraphrase Collection')
('Text Similarity Measures', 'Used-for', 'Plagiarism Detection')
('Neural Language Model', 'Used-for', 'Poetry Generation')
('Discourse Modes', 'Used-for', 'Automatic Essay Scoring')
('graph embedding', 'Used-for', 'network analysis')
('graph embedding', 'Used-for', 'vertex representation')
('mutual attention mechanism', 'Used-for', 'learning context-aware embeddings')
('graph embedding', 'Compare', 'traditional network models')
('link prediction', 'Evaluate-for', 'graph embedding')
('vertex classification', 'Evaluate-for', 'graph embedding')
('semantic relationships', 'Evaluate-for', 'graph embedding')
('network embedding models', 'Part-of', 'network analysis')
('None', 'Evaluate-for', 'explanation methods')
('explanation methods', 'Used-for', 'interpreting DNNs in NLP')
('DNNs', 'Part-of', 'explanation methods')
('explanation methods', 'Evaluate-for', 'efficiency in understanding model behavior')
('explanation methods', 'Compare', 'attention mechanisms')
('explanation methods', 'Hyponym-Of', 'post hoc explanation methods')
('post hoc explanation methods', 'Part-of', 'explanation methods')
('post hoc explanation methods', 'Hyponym-Of', 'LIMSSE')
('LIMSSE', 'Hyponym-Of', 'post hoc explanation methods')
('explanation methods', 'Evaluate-for', 'generating human-readable explanations')
('generative explanation framework', 'Part-of', 'explanation methods')
('explanation methods', 'Evaluate-for', 'QA models interpretability')
('IP', 'Hyponym-Of', 'explanation methods')
('LIME', 'Hyponym-Of', 'explanation methods')
('explanation methods', 'Used-for', 'commonsense reasoning')
('commonsense reasoning', 'Is-a-Prerequisite-of', 'effective language model usage')
('Mono-lingual Attention', 'Used-for', 'Utilizing Information within Mono-lingual Texts')
('Cross-lingual Attention', 'Used-for', 'Consider Information Consistency and Complementarity among Cross-lingual Texts')
('Multilingual Neural Relation Extraction Framework', 'Used-for', 'Relation Extraction')
('Belief Tracker', 'Part-of', 'Spoken Dialogue Systems')
('Error Detection', 'Used-for', 'Creating High-quality Language Resources')
('Neural Architecture', 'Used-for', 'Generation of Programs from Natural Language Descriptions')
('Word-level Language Detection', 'Used-for', 'Analyzing Code-Switched Text')
('Word Embeddings', 'Used-for', 'Lexical Disambiguation')
('Code Commits', 'Used-for', 'Training Encoder-Decoder Architecture')
('dependency parser', 'Used-for', 'semantic dependency parsing')
('dependency parser', 'Used-for', 'dependency parsing task')
('dependency parsing', 'Is-a-Prerequisite-of', 'error propagation')
('dependency parser', 'Used-for', 'drawing syntactic structures')
('arc-swift', 'Is-a-Prerequisite-of', 'dependency parser')
('dependency parser', 'Evaluate-for', 'performance accuracy')
('BiLSTMs', 'Compare', 'token-based dependency parsing')
('neural machine translation', 'Used-for', 'language translation')
('maximum subgraph', 'Part-of', 'semantic graph')
('entity extraction', 'Part-of', 'information extraction')
('machine translation', 'Used-for', 'producing translations')
('dependency structure', 'Used-for', 'context modeling')
('stack-pointer networks', 'Hyponym-Of', 'dependency parser')
('dependency tree', 'Part-of', 'dependency parsing')
('conversational corpus', 'Used-for', 'dialogue system development')
('conversational corpus', 'Part-of', 'natural language processing')
('conversational corpus', 'Evaluate-for', 'model performance')
('conversational corpus', 'Hyponym-Of', 'text corpus')
('conversational corpus', 'Is-a-Prerequisite-of', 'task-oriented dialogue system framework')
('dialogue system development', 'Evaluate-for', 'conversational corpus')
('natural language processing', 'Part-of', 'conversational corpus')
('model performance', 'Evaluate-for', 'conversational corpus')
('task-oriented dialogue system framework', 'Evaluate-for', 'conversational corpus')
('machine reading', 'Used-for', 'entity extraction')
('machine reading', 'Used-for', 'event extraction')
('KBLSTM', 'Used-for', 'enhancing recurrent neural networks for machine reading')
('attention mechanism with a sentinel', 'Used-for', 'decision making in machine reading regarding knowledge base information')
('neural language model', 'Used-for', 'automatic generation of rhythmic poetry')
('neural language model', 'Is-a-Prerequisite-of', 'learning representation of content')
('constraint satisfaction problem', 'Used-for', 'poetry generation')
('Affect-LM', 'Used-for', 'generation of conversational text conditioned on affect categories')
('character-level language models', 'Used-for', 'creation of new word types')
('hierarchical LSTM language model', 'Used-for', 'sequence generation')
('Noisy Channel Model', 'Used-for', 'disfluency detection in spontaneous speech transcripts')
('transformer with self-attention mechanism', 'Used-for', 'character level language modeling')
('sentiment classifiers', 'Used-for', 'predict sentiment')
('target-sensitive memory networks', 'Used-for', 'predict sentiment')
('Multi-sentiment-resource Enhanced Attention Network', 'Used-for', 'predict sentiment')
('Transfer Capsule Network', 'Used-for', 'predict sentiment')
('Hybrid Contextualized Sentiment Classifier', 'Used-for', 'predict sentiment')
('Bilingual Sentiment Embeddings', 'Used-for', 'predict sentiment')
('deep learning', 'Used-for', 'predict sentiment')
('attention mechanism', 'Used-for', 'predict sentiment')
('neural word embeddings', 'Used-for', 'predict sentiment')
('active learning', 'Used-for', 'predict sentiment')
('cold-start problem', 'Evaluate-for', 'predict sentiment performance')
('task sentiment classification', 'Used-for', 'classifying sentiment polarities over individual opinion targets in a sentence')
('task sentiment classification', 'Used-for', 'classifying sentiment in texts from different domains')
('word embeddings', 'Used-for', 'task sentiment classification')
('Aspect sentiment classification', 'Part-of', 'task sentiment classification')
('Aspect sentiment classification', 'Used-for', 'detecting sentiment context for a specific target')
('Target-oriented sentiment classification', 'Part-of', 'task sentiment classification')
('cross-domain sentiment analysis', 'Is-a-Prerequisite-of', 'task sentiment classification')
('task-specific modifications', 'Evaluate-for', 'task sentiment classification')
('training from scratch', 'Evaluate-for', 'task sentiment classification')
('Universal Language Model Fine-tuning', 'Used-for', 'task sentiment classification')
('neural network models', 'Used-for', 'task sentiment classification')
('linguistic features', 'Evaluate-for', 'task sentiment classification')
('social interaction features', 'Evaluate-for', 'task sentiment classification')
('lexical\n(None', 'Is-a-Prerequisite-of', 'news summarization')
('Document modeling', 'Used-for', 'news summarization')
('Sentence extraction', 'Used-for', 'news summarization')
('CNN/Daily Mail summarization task', 'Evaluate-for', 'news summarization')
('Neural sequence-to-sequence models', 'Used-for', 'news summarization')
('SWAP-NET', 'Used-for', 'news summarization')
('Extractive summarization', 'Hyponym-Of', 'news summarization')
('Abstractive summarization', 'Hyponym-Of', 'news summarization')
('Sequence-to-sequence framework', 'Used-for', 'news summarization')
('Template-based summarization', 'Compare', 'news summarization')
('Integer Linear Programming', 'Used-for', 'news summarization')
('Automatic metrics', 'Evaluate-for', 'news summarization')
('Human judgment', 'Evaluate-for', 'news summarization')
('parser trained', 'Used-for', 'syntax tree generation')
('syntax tree generation', 'Part-of', 'natural language processing')
('parser trained', 'Evaluate-for', 'generalization to other domains')
('generalization to other domains', 'Part-of', 'machine learning')
('parser trained', 'Evaluate-for', 'high exact match accuracy')
('high exact match accuracy', 'Part-of', 'parser evaluation metrics')
('parser evaluation metrics', 'Part-of', 'natural language processing')
('neural parser', 'Is-a-Prerequisite-of', 'parser trained')
('pre-trained encoder representations', 'Used-for', 'parser trained')
('parser trained', 'Evaluate-for', 'state-of-the-art parsing results')
('state-of-the-art parsing results', 'Part-of', 'natural language processing')
('parser trained', 'Evaluate-for', 'F1 score optimization')
('F1 score optimization', 'Part-of', 'performance metrics')
('performance metrics', 'Part-of', 'evaluation')
('domain adaptation', 'Used-for', 'parser trained')
('adversarial sample', 'Is-a-Prerequisite-of', 'adversarial attack')
('adversarial attack', 'Used-for', 'text classification')
('adversarial sample', 'Used-for', 'decreasing accuracy')
('adversarial attack', 'Used-for', 'question deduplication')
('adversarial attack', 'Used-for', 'textual entailment')
('adversarial sample', 'Evaluate-for', 'model robustness')
('adversarial stability training', 'Used-for', 'NMT models')
('adversarial sample', 'Used-for', 'neural machine translation')
('adversarial stability training', 'Used-for', 'improving robustness')
('adversarial training', 'Used-for', 'boosting model generalization')
('text classification', 'Hyponym-Of', 'NLP tasks')
('adversarial attack', 'Evaluate-for', 'lexical correctness maintenance')
('adversarial stability training', 'Evaluate-for', 'encoder and decoder robustness')
('\n(Neural Machine Translation', 'Used-for', 'better language understanding')
('Sequence-to-Dependency Neural Machine Translation', 'Used-for', 'better language modeling in translation tasks')
('language model perplexity', 'Evaluate-for', 'better language models effectiveness')
('Affect-LM', 'Used-for', 'generation of conversational text with better emotional content')
('cross-lingual name tagging and linking framework', 'Used-for', 'better multilingual information retrieval')
('Aspect-level sentiment classification', 'Used-for', 'Determining sentiment of specific aspects in sentences')
('Deep learning', 'Used-for', 'Aspect-level sentiment classification')
('Aspect-level sentiment classification', 'Evaluate-for', 'Sentence-level sentiment knowledge')
('Aspect-level sentiment classification', 'Part-of', 'Natural language processing')
('Aspect-level data', 'Used-for', 'Training aspect-level sentiment classification models')
('Transfer learning', 'Used-for', 'Improving aspect-level sentiment classification models')
('Labeled data', 'Evaluate-for', 'Training efficacy in aspect-level sentiment classification')
('Attention mechanisms', 'Used-for', 'Weight determination in aspect-level sentiment classification')
('Document-level data', 'Used-for', 'Transferring knowledge to aspect-level classification')
('Aspect-level knowledge', 'Used-for', 'Training aspect-specific models')
('language generation NLG system', 'Used-for', 'generating corrective REs')
('language generation NLG system', 'Used-for', 'generating long and informative review text')
('language generation NLG system', 'Used-for', 'summarizing multi-person meetings')
('language generation NLG MI', 'Used-for', 'multi-style abstractive summarization for question answering')
('language generation NLG system', 'Used-for', 'generating responses in opinionated natural language generation tasks')
('language generation NLG system', 'Used-for', 'transforming graph-to-program in DAG transducer')
('language generation NLG system', 'Used-for', 'generating natural language from morphologically enriched data')
('generative grammars', 'Part-of', 'opinionated natural language generation ONLG system')
('contrastive focus', 'Used-for', 'emphasizing misunderstood information in NLG system outputs')
('morph-fitting procedure', 'Used-for', 'improving language generation NLG system performance')
('story ending generation', 'Part-of', 'natural language generation')
('story ending generation', 'Used-for', 'controlling the sentiment of story endings')
('sentiment analyzer', 'Used-for', 'acquiring sentiment intensities of the story dataset')
('sentimental generator', 'Used-for', 'controlling the sentiment of the output in story ending generation')
('natural language generation', 'Is-a-Prerequisite-of', 'story ending generation')
('story corpus', 'Used-for', 'story ending generation')
('Gaussian Kernel Layer', 'Used-for', 'controlling sentiment intensity in story ending generation')
('fine-grained sentiment intensity', 'Evaluate-for', 'story ending generation')
('Dialogue Generation', 'Used-for', 'Multi-turn Dialogue Agents')
('Dialogue Generation', 'Used-for', 'Personalized Dialogue Agents')
('Dialogue Generation', 'Conjunction', 'Knowledge Diffusion')
('Multi-turn Dialogue Agents', 'Part-of', 'Dialogue Systems')
('Dialogue Generation', 'Is-a-Prerequisite-of', 'End-to-end Neural Dialogue Generation')
('Dialogue Generation', 'Evaluate-for', 'Natural Responses Quality')
('Dialogue Generation', 'Hyponym-Of', 'Natural Language Generation')
('Knowledge Diffusion', 'Used-for', 'Dialogue Generation')
('End-to-end Neural Dialogue Generation', 'Part-of', 'Dialogue Agents')
('Knowledge Bases', 'Used-for', 'Dialogue Generation')
('Natural Language Generation', 'Used-for', 'Dialogue Generation')
('Dialogue Generation', 'Evaluate-for', 'Diversity of Responses')
('Encoder-Decoder Models', 'Used-for', 'Dialogue Generation')
('supervised NER', 'Is-a-Prerequisite-of', 'manually annotated data')
('cross-lingual NER', 'Used-for', 'NER in a target language without re-training')
('annotation projection', 'Used-for', 'automatically labeled NERRQ data for a target language')
('hybrid code networks', 'Compare', 'end-to-end supervised learning models')
('gold lemma annotated dataset', 'Part-of', 'training model on Bengali')
('supervised learning', 'Used-for', 'knowledge base population via event extraction')
('unsupervised learning', 'Compare', 'supervised learning')
('supervised aspect extraction', 'Used-for', 'leveraging prior knowledge in new domains')
('supervised learning', 'Evaluate-for', 'large scale data labeling')
('supervised attention mechanisms', 'Used-for', 'event detection')
('multi document summarization', 'Hyponym-Of', 'document summarization')
('multi document summarization', 'Compare', 'single document summarization')
('multi document summarization', 'Used-for', 'summarizing documents created by multiple authors')
('multi document summarization', 'Used-for', 'compressing content in large document collections')
('Multi-News', 'Is-a-Prerequisite-of', 'advances in summarization in a multi-document setting')
('automatic Pyramid scores', 'Used-for', 'optimization-based extractive multi-document summarization')
('genetic algorithm', 'Used-for', 'training data generation for automatic Pyramid scores estimation')
('email subject line generation', 'Compare', 'multi document summarization')
('sentence scoring', 'Part-of', 'extractive document summarization')
('\n(Multi-Prototype Mention Embedding model', 'Used-for', 'learning multiple sense embeddings for each mention')
('mention detection accuracy', 'Conjunction', 'mention clustering accuracy')
('mention detection', 'Is-a-Prerequisite-of', 'coreference resolution')
('mention', 'Part-of', 'entity linking')
('disambiguation method', 'Used-for', 'linking each mention to a specific sense')
('entity linking', 'Used-for', 'aligning textual mentions of named entities to corresponding entries in a knowledge base')
('mention phrase', 'Hyponym-Of', 'textual context')
('mention', 'Part-of', 'knowledge base integration process')
('bias mention', 'Evaluate-for', 'coreference resolution improvement')
('zero-shot cross-lingual', 'Used-for', 'multilingual sentiment classification')
('zero-shot cross-lingual', 'Used-for', 'cross-lingual sentence similarity')
('zero-shot cross-lingual', 'Used-for', 'cross-lingual OpenQA')
('zero-shot cross-lingual', 'Evaluate-for', 'language model transfer')
('Cross-lingual OpenQA', 'Part-of', 'zero-shot cross-lingual')
('Multilingual BERT', 'Used-for', 'zero-shot cross-lingual model transfer')
('Multilingual sentiment classification', 'Evaluate-for', 'multilingual embeddings')
('multilingual embeddings', 'Used-for', 'cross-lingual document classification')
('cross-lingual document classification', 'Evaluate-for', 'multilingual embeddings')
('multilingual embeddings', 'Part-of', 'multilingual embeddings learning methods')
('multi modal sarcasm detection', 'Part-of', 'natural language processing applications')
('multi modal sarcasm detection', 'Evaluate-for', 'effectiveness by dynamic network modeling')
('cross-modal graph', 'Used-for', 'multi modal sarcasm detection')
('cross-modal graph convolutional network', 'Used-for', 'identifying ironic relations between textual and visual modalities')
('sarcasm detection', 'Hyponym-Of', 'multi modal sarcasm detection')
('sarcasm detection', 'Part-of', 'multi modal sarcasm detection')
('textual sarcasm detection', 'Compare', 'multi modal sarcasm detection')
('Decomposition and Relation Network', 'Used-for', 'modeling cross-modality contrast in multi modal sarcasm detection')
('Multi-channel Graph Neural Networks with Sentiment-awareness', 'Used-for', 'image-text sentiment detection in multi modal contexts')
('Document level sentiment', 'Used-for', 'intra-aspect sentiment consistency')
('Document level sentiment', 'Used-for', 'inter-aspect sentiment tendency')
('Document Embedding Enhanced Bi-RNN model', 'Used-for', 'event detection in sentences')
('Aspect Sentiment Classification', 'Hyponym-Of', 'Aspect-based sentiment analysis')
('Cooperative Graph Attention Networks', 'Used-for', 'Aspect Sentiment Classification')
('document level sentiment', 'Evaluate-for', 'Aspect Sentiment Classification effectiveness')
('Aspect Sentiment Classification', 'Is-a-Prerequisite-of', 'document level sentiment preference information understanding')
('document-level knowledge', 'Used-for', 'improving aspect-level sentiment classification')
('attention-based LSTM', 'Used-for', 'aspect-level sentiment classification')
('attention-based LSTM', 'Evaluate-for', 'effectiveness with document-level knowledge')
('dialogue agent', 'Used-for', 'searching Knowledge Bases (KBs')
('dialogue agent', 'Part-of', 'multi-turn dialogue systems')
('dialogue agent', 'Used-for', 'task success prediction')
('dialogue agent', 'Used-for', 'chat detection with users')
('task-oriented dialogue systems', 'Used-for', 'automatic diagnosis')
('non-task-oriented dialogue systems', 'Used-for', 'open-domain user utterances handling')
('multi-turn dialogue systems', 'Is-a-Prerequisite-of', 'neural knowledge diffusion (NKD')
('reinforcement learner', 'Part-of', 'dialogue agent')
('neural dialogue agents', 'Is-a-Prerequisite-of', 'end-to-end training')
('symbolic queries', 'Used-for', 'retrieving knowledge in traditional systems')
('soft retrieval process', 'Used-for', 'interacting with Knowledge Bases (KBs')
('relation extraction', 'Used-for', 'knowledge base population')
('supervised relation', 'Is-a-Prerequisite-of', 'supervised learning methods')
('corpus', 'Used-for', 'supervised relation training')
('supervised relation', 'Evaluate-for', 'event extraction')
('supervised relation', 'Evaluate-for', 'relation classification tasks')
('class ties', 'Used-for', 'improving supervised relation extraction')
('supervised relation', 'Used-for', 'classifying discourse relations')
('ranking framework', 'Used-for', 'enhancing supervised relation extraction')
('supervised relation', 'Evaluate-for', 'distantly supervised scenario')
('annotation projection', 'Used-for', 'creating supervised relation data')
('hybrid code networks', 'Compare', 'end-to-end learning methods')
('joint model', 'Used-for', 'discourse relation prediction')
('Automatic dialogue evaluation', 'Used-for', 'Rapid prototyping')
('Automatic dialogue evaluation', 'Used-for', 'Testing new models')
('Automatic dialogue evaluation', 'Compare', 'Word-overlap metrics')
('Word-overlap metrics', 'Hyponym-Of', 'BLEU')
('Automatic dialogue evaluation', 'Evaluate-for', 'Unstructured domains')
('Automatic dialogue evaluation', 'Compare', 'Human judgement')
('ADEM', 'Evaluate-for', 'Human-like scores')
('ADEM', 'Used-for', 'Automatic dialogue evaluation')
('Dialogue responses', 'Part-of', 'Automatic dialogue evaluation')
('Dialogue mod-els', 'Evaluate-for', 'Generalization in automatic dialogue evaluation')
('CMADE', 'Used-for', 'Cleaning self-reported user ratings')
('CMADE', 'Evaluate-for', 'Automatic dialogue evaluation')
('Unreferenced automated evaluation metric', 'Used-for', 'Online automatic dialogue evaluation')
('Unreferenced automated evaluation metric', 'Evaluate-for', 'Temporal transitions in utterances')
('Automatic\n(aspect term extraction', 'Part-of', 'aspect-based sentiment analysis')
('aspect term extraction', 'Used-for', 'opinion summarizing')
('aspect term extraction', 'Is-a-Prerequisite-of', 'aspect sentiment classification')
('Supervised learning', 'Used-for', 'aspect term extraction')
('Deep learning', 'Used-for', 'aspect term extraction')
('Conditional Random Fields', 'Evaluate-for', 'aspect term extraction')
('neural approach', 'Used-for', 'aspect term extraction')
('pre-trained embeddings', 'Used-for', 'aspect term extraction')
('NeuralREG', 'Compare', 'aspect term extraction')
('aspect term extraction', 'Used-for', 'fine-grained opinion analysis')
('Conditional Random Fields', 'Compare', 'neural approach')
('neural word embeddings', 'Used-for', 'improving coherence')
('topic models', 'Compare', 'neural approach')
('attention mechanism', 'Used-for', 'improving aspect coherence')
('Sentence extraction', 'Part-of', 'document modeling')
('neural approach', 'Used-for', 'generating aspect terms')
('is-a relationships', 'Part-of', 'taxonomy inference')
('aspect term extraction', 'Part-of', 'fine-grained sentiment analysis')
('Seq2\n(fact checked claim', 'Used-for', 'detecting previously fact-checked claims')
('fact checked claim', 'Used-for', 'saving effort in manual fact-checking')
('fact checked claim', 'Part-of', 'FC-articles')
('fake news', 'Is-a-Prerequisite-of', 'fact checked claim')
('MTM', 'Used-for', 'ranking FC-articles')
('FC-articles', 'Used-for', 'providing evidence for detection')
('ROUGE-guided Transformer', 'Used-for', 'fine-tuning with regression of ROUGE')
('pattern vectors', 'Used-for', 'matching with sentences')
('social media', 'Used-for', 'spreading fact checked claims')
('event information', 'Used-for', 'selecting key sentences')
('pattern information', 'Used-for', 'generating pattern vectors')
('key sentences', 'Used-for', 'representing an article in MTM')
('MTM', 'Evaluate-for', 'claim verification')
('domain sentiment lexicon', 'Used-for', 'sentiment analysis')
('SemAxis', 'Evaluate-for', 'building domain-specific sentiment lexicon')
('domain sentiment lexicon', 'Is-a-Prerequisite-of', 'cross-domain sentiment analysis')
('domain sentiment lexicon', 'Used-for', 'characterizing word semantics')
('KinGDOM', 'Used-for', 'enriching semantics with domain-specific concepts')
('BERT', 'Evaluate-for', 'domain-aware processing')
('LIMSSE', 'Used-for', 'explaining DNNs in NLP')
('LRP', 'Used-for', 'explaining DNNs in NLP')
('DeepLIFT', 'Used-for', 'explaining DNNs in NLP')
('Explanation methods', 'Evaluate-for', 'interpretability of DNNs')
('post hoc explanation methods', 'Used-for', 'interpretability of machine learning models')
('input perturbation', 'Compare', 'self-explanatory attention mechanism')
('Query Focused Extractor', 'Used-for', 'evidence extraction')
('multi-task learning', 'Used-for', 'enhancing QA model performance')
('Text2SQL', 'Is-a-Prerequisite-of', 'answering complex reasoning questions in ODQA')
('EPT-X', 'Used-for', 'solving algebraic word problems with explanations')
('attribution method', 'Used-for', 'interpreting deep model predictions')
('Rule By Example', 'Used-for', 'textual content moderation')
('Explanation methods', 'Evaluate-for', 'model interpretability in QA')
('QFE', 'Evaluate-for', 'state-of-the-art evidence extraction')
('WikiReading dataset', 'Used-for', 'Testing models for sentence selection')
('Spades', 'Used-for', 'Evaluating fill-in-the-blank QA models')
('WebQuestions', 'Used-for', 'Assessing question-representation models')
('WikiQA', 'Used-for', 'Testing models for question answering')
('SemEval-2016 Task 3A', 'Used-for', 'Evaluating entailment tasks')
('Yahoo! Answers dataset', 'Used-for', 'Testing EviNets for factoid QA')
('DAREDS', 'Used-for', 'Evaluating dialect term detection methods')
('joint entity relation extraction', 'Used-for', 'identifying entity mention spans and relations in raw text')
('joint entity relation exptraction', 'Is-a-Prerequisite-of', 'relation type inference')
('joint entity relation extraction', 'Part-of', 'end-to-end approaches in NLP')
('neural encoder-decoder model', 'Used-for', 'joint entity relation extraction')
('entity-relation bipartite graph', 'Used-for', 'joint entity relation extraction')
('joint entity relation extraction', 'Evaluate-for', 'ACE05 benchmark')
('binary relation classification', 'Used-for', 'entity-relation graph analysis in joint entity relation extraction')
('generating natural language', 'Used-for', 'real-world question answering systems')
('generating natural language', 'Used-for', 'creating answer rationales')
('neural language model', 'Used-for', 'generating rhythmic poetry')
('neural language model', 'Used-for', 'learning representation of content')
('discriminative weighted finite state machine', 'Used-for', 'constraining poetry generation on the basis of form')
('neural semantic parser', 'Part-of', 'interpretable and scalable models')
('predicate-argument structures', 'Part-of', 'semantic parser output')
('transition system', 'Used-for', 'inducing predicate-argument structures')
('logical forms', 'Used-for', 'training semantic parsers')
('rhythmic poetry generation', 'Is-a-Prerequisite-of', 'constraint satisfaction problem')
('neural semantic parser', 'Evaluate-for', 'state-of-the-art performance on SPADES')
('COREQA', 'Used-for', 'knowledge-inquired question answering')
('gated self-matching networks', 'Used-for', 'reading comprehension style question answering system')
('reading comprehension style question answering system', 'Used-for', 'answering questions from a given passage')
('pointer networks', 'Used-for', 'locating positions of answers in question answering system')
('COREQA', 'Used-for', 'generating natural answers in a question answering system')
('semantic parsing', 'Used-for', 'question answering system')
('relation detection', 'Used-for', 'enhancing KBQA system')
('Generative Domain-Adaptive Nets', 'Used-for', 'training question answering models')
('Recurrent Neural Networks', 'Used-for', 'automatic question answering')
('natural language sentence generation', 'Used-for', 'real-world question answering systems')
('EviNets', 'Used-for', 'factoid question answering')
('open-domain question answering', 'Used-for', 'answering factoid questions using Wikipedia')
('open domain question answering', 'Used-for', 'answering factoid questions using Wikipedia articles')
('open domain question answering', 'Is-a-Prerequisite-of', 'machine reading at scale')
('machine reading at scale', 'Part-of', 'open domain question answering')
('question answering', 'Part-of', 'open domain question answering')
('open domain question answering', 'Used-for', 'employing Memory networks in question answering')
('text span detection', 'Used-for', 'open domain question answering')
('distant supervision', 'Used-for', 'training open domain question answering models')
('open domain question unstructured form', 'Used-for', 'aligning structured KBs and unstructured text in a common embedded space')
('open domain question answering', 'Evaluate-for', 'exploiting universal schema for question answering')
('open domain question answering', 'Hyponym-Of', 'question answering')
('image text pair', 'Used-for', 'multimodal sentiment detection')
('image text pair', 'Used-for', 'cross-modal downstream tasks')
('image text pair', 'Used-for', 'vision-language pre-training')
('image text text pair', 'Part-of', 'multimodal posts')
('Multi-channel Graph Neural Networks', 'Used-for', 'image-text sentiment detection')
('multi-head attention', 'Used-for', 'multimodal in-depth fusion')
('image representation', 'Conjunction', 'text embedding')
('vision-language pre-training', 'Used-for', 'image-text retrieval')
('Intra-modal Self-attention Distance', 'Used-for', 'quantifying relation consistency')
('Inter-modal Alignment on Intra-modal Self-attentions', 'Evaluate-for', 'optimizing Intra-modal Self-attention Distance')
('vision-language pre-training', 'Hyponym-Of', 'cross-modal tasks')
('WikiReading dataset', 'Is-a-Prerequisite-of', 'question answering dataset')
('WikiQA', 'Is-a-Prerequisite-of', 'question answering dataset')
('SemEval-2016 Task 3A', 'Is-a-Prerequisite-of', 'question answering dataset')
('Spades fill-in-the-blank', 'Is-a-Prerequisite-of', 'question answering dataset')
('pre trained language model', 'Used-for', 'natural language understanding')
('pre trained language model', 'Used-for', 'semantic parsing')
('pre trained language model', 'Part-of', 'NLP system')
('pre trained language model', 'Evaluate-for', 'effectiveness in procedural task completion')
('pre trained language model', 'Evaluate-for', 'effectiveness in language generation tasks')
('pre trained language model', 'Hyponym-Of', 'machine learning models')
('neural network', 'Used-for', 'building pre trained language models')
('semantic parsing', 'Used-for', 'mapping natural language to logical forms')
('natural language understanding', 'Part-of', 'tasks for pre trained language models')
('syntax analysis', 'Part-of', 'semantic parsing')
('syntax analysis', 'Is-a-Prerequisite-of', 'code generation from natural language')
('predicate-argument structures', 'Part-of', 'semantic parsing')
('aspect level sentiment', 'Is-a-Prerequisite-of', 'opinion term extraction')
('aspect level sentiment', 'Is-a-Prerequisite-of', 'aspect-level sentiment classification')
('aspect extraction', 'Used-for', 'ABSA')
('opinion term extraction', 'Used-for', 'ABSA')
('aspect-level sentiment classification', 'Used-for', 'determining sentiment polarity')
('aspect-level sentiment classification', 'Part-of', 'ABSA')
('ABSA', 'Used-for', 'determining sentiment polarity towards specific aspects in text')
('aspect level sentiment', 'Evaluate-for', 'transfer learning effectiveness')
('aspect level sentiment', 'Evaluate-for', 'model performance on ABSA tasks')
('selective encoding model', 'Used-for', 'abstractive sentence summarization')
('sentence encoder', 'Part-of', 'selective encoding model')
('selective gate network', 'Part-of', 'selective encoding model')
('attention\n(controllable text generation', 'Used-for', 'open-domain dialog systems')
('conditional response generation', 'Part-of', 'controllable text generation')
('dialog states', 'Used-for', 'reflecting personal features in responses')
('attributes', 'Used-for', 'conditional response generation')
('Emotion-controllable response generation', 'Hyponym-Of', 'controllable text generation')
('Conditional Text Generation', 'Hyponym-Of', 'Natural Language Generation')
('sentiment states', 'Used-for', 'conditional response generation')
('Pre-train and Plug-in Variational Auto-Encoder', 'Used-for', 'controllable text generation')
('Curriculum Dual Learning', 'Used-for', 'Emotion-controllable response generation')
('flexible conditional text generation', 'Is-a-Prerequisite-of', 'Pre-train and Plug-in Variational Auto-Encoder')
('conditional text generation', 'Hyponym-Of', 'controllable text generation')
('syntax-controlled text generation', 'Part-of', 'controllable text\n(None')
('None', 'Used-for', 'None')
('Neural Symbolic Machine', 'Used-for', 'language generation')
('language generation', 'Used-for', 'parsing natural language descriptions')
('language generation', 'Used-for', 'producing referring expressions')
('Natural language generation', 'Evaluate-for', 'recognizing misunderstandings')
('language generation', 'Used-for', 'opinionated responses')
('language generation', 'Hyponym-Of', 'natural language processing')
('language generation', 'Evaluate-for', 'generating corrective referring expressions')
('Natural language generation', 'Used-for', 'creating subjective responses')
('Neural Belief Tracking', 'Used-for', 'interpreting user utterances')
('language generation', 'Used-for', 'code-switched text analysis')
('Neural Machine Translation', 'Used-for', 'paraphrase generation')
('language generation', 'Evaluate-for', 'SQL query generation')
('TextFlow', 'Used-for', 'text similarity evaluation')
('language variation', 'Hyponym-Of', 'social interactions')
('bi-directional LSTMs', 'Used-for', 'encode source sentence')
('convolutional layers', 'Used-for', 'encode source source sentence simultaneously')
('convolutional layers', 'Compare', 'bi-directional LSTMs')
('LAU', 'Used-for', 'reduce gradient propagation path')
('neural machine translation', 'Used-for', 'generate translations')
('Multi-modal Neural Machine Translation', 'Part-of', 'neural machine translation')
('syntactic knowledge', 'Used-for', 'improve statistical machine translation')
('posterior regularization', 'Used-for', 'integrate multiple overlapping sources into NMT')
('word reordering knowledge', 'Used-for', 'improve translation performance')
('neural system combination framework', 'Used-for', 'combine advantages of NMT and SMT')
('mixed fine tuning', 'Used-for', 'improve translation performance')
('domain adaptation', 'Used-for', 'improve NMT performance')
('semantic dependency parsing', 'Used-for', 'capturing semantic relations between words')
('semantic dependency parsing', 'Hyponym-Of', 'dependency parsing')
('dependency parsing', 'Used-for', 'building dependency trees')
('dependency parsing', 'Is-a-Prerequisite-of', 'semantic dependency parsing')
('deep neural architecture', 'Used-for', 'semantic dependency parsing')
('Lagrangian Relaxation-based algorithm', 'Used-for', 'combining pages into a book for semantic dependency parsing')
('Bidirectional LSTM', 'Used-for', 'semantic dependency parsing')
('multi-layer perceptron', 'Used-for', 'semantic dependency parsing')
('multitask learning', 'Evaluate-for', 'performance improvement in semantic dependency parsing')
('SPIGOT', 'Used-for', 'backpropagating through neural networks for semantic dependency parsing')
('discourse relation', 'Used-for', 'discourse coherence assessment')
('discourse relation', 'Used-for', 'stance dimension validation')
('discourse relation', 'Part-of', 'sociolinguistic construct')
('discourse relation', 'Used-for', 'implicit discourse relation classification')
('discourse relation', 'Used-for', 'modeling argument pairs in sequential data')
('implicit discourse relation classification', 'Evaluate-for', 'lack of strong linguistic cues')
('discourse relation prediction', 'Evaluate-for', 'phrase-based content selection')
('discourse relation prediction', 'Evaluate-for', 'salient discussion points identification')
('RST Discourse Treebank', 'Used-for', 'discourse analysis of written texts')
('discourse relation', 'Used-for', 'discourse-specific word embedding learning')
('discourse relation', 'Used-for', 'creating differentiable approximations in seq2seq models')
('Hybrid Code Networks', 'Used-for', 'dialog systems')
('retrofitting', 'Used-for', 'semantic specialization of distributional word vectors')
('neural reading comprehension model', 'Used-for', 'enhancing common nouns dataset performance')
('neuro-symbolic integration', 'Evaluate-for', 'enhancing comprehension and generation in NLP')
('knowledge graphs', 'Used-for', 'improving data integration and querying')
('transfer learning', 'Used-for', 'domain adaptation in NLP')
('domain-specific knowledge', 'Part-of', 'Hybrid Code Networks')
('dialog state', 'Part-of', 'dialog systems')
('Open Information Extraction', 'Used-for', 'knowledge reasoning')
('support graph optimization', 'Used-for', 'question answering')
('external knowledge', 'Is-a-Prerequisite-of', 'enhanced neural network performance')
('automated reasoning', 'Used-for', 'machine comprehension')
('declarative knowledge', 'Used-for', 'augmenting neural network learning')
('cross-domain knowledge transfer', 'Used-for', 'named entity recognition')
('linguistic knowledge', 'Used-for', 'alias identification')
('data-to-text generation model', 'Used-for', 'producing coherent grammatically correct text from structured data inputs')
('data-to-text generation model', 'Part-of', 'natural language generation')
('tracking module', 'Used-for', 'keeping track of salient information')
('generation module', 'Used-for', 'generating text conditioned on tracking state')
('entity-centric neural architecture', 'Part-of', 'data-to-text generation model')
('entity-specific representations', 'Used-for', 'enhancing data-to-text generation model')
('hierarchical attention', 'Used-for', 'controlling generation based on data and entity memory in data-to-text models')
('Finite State Machine', 'Used-for', 'structuring neural sequential generation processes in data-to-text models')
('SSiD', 'Is-a-Prerequisite-of', 'SSiL')
('Pre-train and Plug-in Variational Auto-Encoder', 'Compare', '(None')
('morphological paradigm', 'Used-for', 'morphological analysis')
('morphological analysis', 'Used-for', 'predicting syntactic traits')
('morphological paradigm', 'Part-of', 'language modeling')
('language-independent model', 'Used-for', 'morphological analysis')
('morphological analysis', 'Evaluate-for', 'linguistic structure')
('morphological constraints', 'Used-for', 'improving distributional vector spaces')
('inflectional forms', 'Part-of', 'morphological paradigm')
('declension classes', 'Hyponym-Of', 'morphological paradigm')
('morphological typology', 'Conjunction', 'morphological paradigm')
('morphological richness', 'Compare', 'typological variation')
('morphological supervision', 'Used-for', 'improving bits-per-character performance')
('analogical reasoning', 'Used-for', 'capturing morphological relations')
('Dialogue State Tracking', 'Evaluate-for', 'Estimating User Goals')
('E2E architecture', 'Used-for', 'Extracting Unknown Slot Values')
('Global-Locally Self-Attentive Dialogue State Tracker', 'Part-of', 'Dialogue State Tracking')
('Pointer Network', 'Used-for', 'Dialogue State Tracking')
('Neural Belief Tracking', 'Is-a-Prerequisite-of', 'Dialogue State Tracking')
('Dialogue State Tracking with Slot Connections', 'Part-of', 'Dialogue State Tracking')
('Natural Language Understanding', 'Is-a-Prerequisite-of', 'Dialogue State Tracking')
('Meta-Reinforced Multi-Domain State Generator', 'Part-of', 'Dialogue State Tracking')
('Slot Attention', 'Used-for', 'Improving Dialogue Context Tracking')
('Transferable Dialogue State Generator', 'Used-for', 'Generating Dialogue States')
('Slot Information Sharing', 'Used-for', 'Integrating Slot-Specific Features')
('Cognitive NLP systems', 'Used-for', 'feature extraction')
('feature extraction', 'Part-of', 'Cognitive NLP systems')
('feature extraction', 'Used-for', 'Sentiment Analysis')
('feature extraction', 'Used-for', 'Sarcasm Detection')
('Convolutional Neural Network', 'Used-for', 'feature learning')
('feature learning', 'Part-of', 'Convolutional Neural Network')
('event extraction', 'Used-for', 'knowledge base population')
('Supervised learning', 'Is-a-Prerequisite-of', 'event extraction')
('data labeling', 'Used-for', 'event extraction')
('event extraction', 'Hyponym-Of', 'knowledge base population')
('event relation', 'Used-for', 'event detection')
('Attention mechanisms', 'Used-for', 'event detection')
('Supervised attention', 'Part-of', 'Attention mechanisms')
('event detection', 'Used-for', 'ACE 2005 dataset')
('class ties', 'Used-for', 'relation extraction')
('CNN', 'Used-for', 'relation extraction')
('relation extraction', 'Hyponym-Of', 'event relation')
('BERT', 'Hyponym-Of', 'contextual word embeddings')
('BPEmb', 'Hyponym-Of', 'non contextual subword embeddings')
('FastText', 'Hyponym-Of', 'non contextual subword embeddings')
('BERT', 'Used-for', 'multilingual named entity recognition')
('BPEmb', 'Used-for', 'part-of-speech tagging')
('non contextual subword embeddings', 'Used-for', 'low-resource language tasks')
('contextual word embeddings', 'Used-for', 'automatic machine translation evaluation')
('natural language generation', 'Used-for', 'answer generation in question answering systems')
('neural semantic parser', 'Part-of', 'natural language generation')
('natural language generation', 'Used-for', 'generating rhythmic poetry')
('text similarity measures', 'Used-for', 'tasks in natural language generation')
('natural language generation', 'Used-for', 'generating corrective referring expressions')
('COREQA', 'Used-for', 'natural language generation')
('language model downstream task', 'Used-for', 'named entity recognition')
('language model downstream task', 'Evaluate-for', 'named entity recognition')
('language model downstream', 'Is-a-Prerequisite-of', 'crypable ential performance')
('language model downstream task', 'Evaluate-for', 'cross-lingual transfer of NLP models')
('language model downstream task', 'Evaluate-for', 'natural language generation')
('language model downstream task', 'Used-for', 'diachronic accuracy assessment')
('language model downstream task', 'Evaluate-for', 'multilingual modeling')
('language model downstream task', 'Evaluate-for', 'bilingual lexicon induction')
('language model downstream task', 'Used-for', 'language normalization')
('language model downstream task', 'Evaluate-for', 'user profiling')
('language model downstream', 'Is-a-Prerequisite-of', 'generalization performance')
('language model downstream task', 'Evaluate-for', 'semantic drift measurement')
('language model downstream task', 'Used-for', 'query auto-completion')
('morphological constraints', 'Used-for', 'improving distributional vector spaces')
('domain adaptation', 'Evaluate-for', 'distributional semantics')
('distributional semantics', 'Is-a-Prerequisite-of', 'sentiment analysis')
('semantic lexicons', 'Part-of', 'distributional semantics')
('SICK corpus', 'Used-for', 'validation of compositional distributional semantics')
('compositional distributional semantics', 'Hyponym-Of', 'distributional semantics')
('temporal shift', 'Evaluate-for', 'distribution mismatch in distributional semantics')
('distributional semantics models', 'Used-for', 'evaluation of Polish language processing')
('neural domain adaptation', 'Used-for', 'improving distributional semantics')
('external lexical knowledge', 'Used-for', 'retrofitting in distributional semantics')
('neural text generation', 'Used-for', 'video captioning')
('neural text generation', 'Used-for', 'dialog systems')
('neural text generation', 'Used-for', 'pun generation')
('neural text generation', 'Used-for', 'derived word generation')
('neural text generation', 'Used-for', 'information-seeking conversation systems')
('neural text generation', 'Used-for', 'data-to-text generation')
('neural text generation', 'Used-for', 'table-to-text generation')
('neural text generation', 'Is-a-Prerequisite-of', 'effective data-to-text generation')
('neural models', 'Part-of', 'neural text generation')
('sequence-to-sequence models', 'Part-of', 'neural text generation')
('abstractive summarization', 'Hyponym-Of', 'document summarization')
('sequence-to-sequence\n(aspect sentiment', 'Is-a-Prerequisite-of', 'aspect-based sentiment analysis')
('aspect-based sentiment analysis', 'Part-of', 'natural language processing')
('topic models', 'Used-for', 'aspect extraction')
('neural word embeddings', 'Used-for', 'improving aspect coherence')
('attention mechanism', 'Used-for', 'de-emphasizing irrelevant words')
('aspect extraction', 'Used-for', 'aspect-based sentiment analysis')
('neural approach', 'Evaluate-for', 'discovering coherent aspects')
('word co-occurrences', 'Used-for', 'neural word embeddings')
('interpretation models', 'Evaluate-for', 'adequacy and sentiment polarity')
('code-switching', 'Used-for', 'sentiment detection in multilingual texts')
('KinGDOM', 'Used-for', 'cross-domain sentiment analysis')
('Graph convolutional autoencoder', 'Used-for', 'learning inter-domain concepts')
('synthetic code-switched text', 'Used-for', 'improving sentiment labeling accuracy')
('sent\n(speech translation e2e st', 'Is-a-Prerequisite-of', 'encoder pre-training')
('speech translation e2e st', 'Compare', 'cascade speech translation models')
('encoder pre-training', 'Used-for', 'speech translation e2e st')
('Target syntax incorporation', 'Used-for', 'speech translation e2e st')
('context-aware modeling', 'Used-for', 'speech translation e2e st')
('multitask learning', 'Used-for', 'speech translation e2e st')
('phone feature incorporation', 'Used-for', 'speech translation e2e st')
('context concatenation', 'Used-for', 'speech translation e2e st')
('in-model ensemble decoding', 'Used-for', 'speech translation e2e st')
('word embeddings', 'Part-of', 'Skip-Gram model')
('word embeddings', 'Part-of', 'network embedding methods')
('word embeddings', 'Evaluate-for', 'coherence in aspect extraction')
('word embeddings', 'Evaluate-for', 'sentiment analysis in financial forecasting')
('word embeddings', 'Hyponym-Of', 'multimodal word distributions')
('word embeddings', 'Used-for', 'bilingual lexicon induction')
('word embeddings', 'Used-for', 'document clustering')
('word embeddings', 'Part-of', 'discourse-specific word embeddings')
('Skip-Gram model', 'Is-a-Prerequisite-of', 'additive compositionality in word vectors')
('additive compositionality', 'Evaluate-for', 'vector calculus applications')
('Skip-Gram model', 'Used-for', 'Sufficient Dimensionality Reduction parameter estimation')
('word analogy questions', 'Used-for', 'evaluating word embeddings')
('caption generation', 'Used-for', 'evaluating word embeddings')
('vector calculus', 'Used-for', 'solving word analogies')
('multimodal word distributions', 'Compare', 'skip-grams')
('context sensitive embeddings', 'Evaluate-for', 'improving accuracy in NLP tasks')
('context sensitive embeddings', 'Part-of', 'deep neural network architectures')
('context sensitive embeddings', 'Compare', 'type-level word embeddings')
('neural network architectures', 'Used-for', 'natural language processing tasks')
('neural network architectures', 'Used-for', 'sentiment classification')
('type-level word embeddings', 'Used-for', 'semantic representations of words')
('pre-trained word embeddings', 'Used-for', 'sequence labeling tasks')
('pre-trained context embeddings', 'Is-a-Prerequisite-of', 'context sensitive embeddings')
('deep neural network architectures', 'Is-a-Prerequisite-of', 'context sensitive embeddings')
('neural network architectures', 'Hyponym-Of', 'context sensitive embeddings')
('context sensitive embeddings', 'Used-for', 'domain-sensitive and sentiment-aware word embeddings generation')
('context sensitive embeddings', 'Evaluate-for', 'domain-common embeddings differentiation')
('context sensitive embeddings', 'Hyponym-Of', 'neural vector representations')
('Virtual adversarial training', 'Used-for', 'Improving model robustness')
('SeqVAT', 'Used-for', 'Improving sequence labeling performance')
('SeqVAT', 'Evaluate-for', 'Adversarial robustness')
('Text-to-SQL models', 'Evaluate-for', 'Adversarial robustness')
('Spider-Syn', 'Used-for', 'Testing Text-to-SQL robustness')
('Adversarial training', 'Used-for', 'Improving model robustness')
('Deep learning models', 'Evaluate-for', 'Natural Language Inference')
('AREC', 'Used-for', 'Generating alignment rationale explanations')
('LOVE', 'Used-for', 'Extending word representation')
('RSMI', 'Used-for', 'Improving adversarial robustness')
('RSMI', 'Evaluate-for', 'Adversarial robustness')
('ATINTER', 'Used-for', 'Rewriting adversarial inputs')
('ATINTER', 'Evaluate-for', 'Adversarial robustness')
('Adversarial robustness', 'Is-a-Prerequisite-of', 'Reliable NLP systems')
('syntactic information', 'Evaluate-for', 'domain learning')
('cross-domain setting', 'Hyponym-Of', 'domain learning')
('Nested Named Entity', 'Is-a-Prerequisite-of', 'Named Entity Recognition')
('Nested Named Entity', 'Hyponym-Of', 'Named Entity Recognition')
('Pyramid', 'Used-for', 'Nested Named Entity Recognition')
('BiFlaG', 'Used-for', 'Nested Named Entity Recognition')
('Nested Named Entity Recognition', 'Is-a-Prerequisite-of', 'Overlapping Named Entity Recognition')
('Nested Named Entity', 'Part-of', 'Unified Framework')
('Nested Named Entity', 'Part-of', 'Biomedical Named Entity Recognition')
('Nested Named Entity Recognition', 'Used-for', 'Biomedical Text Analysis')
('Nested Named Entity Recognition', 'Evaluate-for', 'Improving Text Segmentation Quality')
('Generative Domain-Adaptive Nets', 'Used-for', 'training question answering models')
('Universal schema', 'Used-for', 'natural language question answering')
('Memory networks', 'Used-for', 'reasoning on structured KBs and unstructured text')
('Visual Question Answering', 'Is-a-Prerequisite-of', 'Visual and Textual Question Answering')
('Visual and Textual Question Answering', 'Used-for', 'answer questions based on image and text inputs')
('Conversational Question Answering', 'Part-of', 'natural language question answering')
('Conversational Question Answering', 'Used-for', 'answering sequences of simple but inter-related questions')
('Visual Question Answering', 'Used-for', 'infer answers from images using deep learning models')
('paragraph captions', 'Used-for', 'Visual Question Answering')
('Reinforced Dynamic Reasoning network', 'Used-for', 'Conversational Question Generation')
('automatic argument generation', 'Used-for', 'generating arguments of a different stance')
('automatic argument machine', 'Part-of', 'encoder-decoder neural network')
('encoder-decoder neural network', 'Used-for', 'automatic argument generation')
('talking point phrases', 'Used-for', 'automatic argument generation')
('automatic argument generation', 'Used-for', 'providing topic-relevant content')
('automatic argument machine', 'Part-of', 'retrieval system')
('retrieval system', 'Used-for', 'automatic argument generation')
('Wikipedia', 'Used-for', 'automatic argument generation')
('automatic argument generation', 'Evaluate-for', 'stance determination')
('automatic argument generation', 'Evaluate-for', 'claim specificity assessment')
('None', 'Used-for', 'encode the source sentence')
('Neural Machine Translation Model', 'Used-for', 'WMT’16 English-Romanian translation')
('Neural Machine Translation Model', 'Used-for', 'WMT’15 English-German translation')
('Neural Machine Translation Model', 'Compare', 'Deep LSTM')
('Neural Machine Translation Model', 'Used-for', 'CPU decoding')
('Deep Neural Networks', 'Used-for', 'Neural Machine Translation')
('Neural Machine Translation Model', 'Evaluate-for', 'capture linguistic structures')
('Linear Associative Units', 'Used-for', 'reduce gradient propagation in RNNs')
('Neural Machine Translation Model', 'Used-for', 'Chinese-English translation')
('source syntax', 'Used-for', 'improve Neural Machine Translation')
('Neural Machine Translation Model', 'Evaluate-for', 'translation quality')
('Neural Machine Translation Model', 'Used-for', 'English-German task')
('Neural Machine Translation Model', 'Used-for', 'modeling source and target language')
('Neural Machine Translation Model', 'Evaluate-for', 'learning morphology')
('keyphrase extraction', 'Used-for', 'organizing text content')
('keyphrase extraction', 'Used-for', 'retrieving text content')
('keyphrase extraction', 'Is-a-Prerequisite-of', 'human attention keyphrase extraction')
('encoder-decoder framework', 'Used-for', 'keyphrase prediction')
('human attention', 'Used-for', 'revealing word relevance')
('human attention', 'Used-for', 'human attention keyphrase extraction')
('human attention', 'Is-a-Prerequisite-of', 'human attention keyphrase extraction')
('attention mechanism', 'Used-for', 'integrating human attention in neural networks')
('neural network models', 'Used-for', 'keyphrase extraction')
('unsupervised models', 'Used-for', 'keyphrase extraction')
('human attention keyphrase extraction', 'Evaluate-for', 'effectiveness on Twitter datasets')
('Aspect-Category-Opinion-Sentiment Quadruple Extraction', 'Used-for', 'aspect-based sentiment analysis with implicit aspects and opinions')
('Restaurant-ACOS', 'Part-of', 'Aspect-Category-Opinion-Sentiment Quadruple Extraction')
('Laptop-ACOS', 'Part-of', 'Aspect-Category-Opinion-Sentiment Quadruple Extraction')
('Restaurant-ACOS', 'Is-a-Prerequisite-of', 'Restaurant dataset')
('Laptop-ACOS', 'Is-a-Prerequisite-of', 'Laptop dataset')
('category opinion sentiment', 'Part-of', 'Aspect-Category-Opinion-Sentiment Quadruple Extraction')
('referential word meaning', 'Used-for', 'linking visual to lexical information')
('distributional word embeddings', 'Used-for', 'linking visual to lexical information')
('object naming', 'Used-for', 'referring expression generation')
('object names', 'Hyponym-Of', 'referring expression generation')
('zero-shot learning', 'Evaluate-for', 'projecting visual objects into the distributional space')
('bilingual word embeddings', 'Used-for', 'learning bilingual lexicon induction')
('self-learning approach', 'Used-for', 'reducing bilingual resources')
('bilingual word embeddings', 'Hyponym-Of', 'linguistic features')
('lingual word embeddings', 'Used-for', 'connecting separate monolingual embeddings')
('document-aligned corpora', 'Is-a-Prerequisite-of', 'learning bilingual word embeddings')
('bilingual dictionaries', 'Used-for', 'lingual word embeddings')
('unsupervised bilingual lexicon induction\n(free text relation', 'Is-a-Prerequisite-of', 'Relation Schema Induction')
('Relation Schema Induction', 'Part-of', 'Higher-order Relation Schema Induction')
('event extraction', 'Used-for', 'knowledge base population')
('automatically label training data', 'Used-for', 'event extraction')
('linguistic knowledge', 'Used-for', 'automatically label training data')
('human-labeled data', 'Compare', 'automatically labeled data')
('ideas', 'Conjunction', 'texts')
('relations between ideas', 'Used-for', 'systematic characterization')
('prevalence correlation', 'Used-for', 'relations between ideas')
('prerequisite relation', 'Used-for', 'MOOCs')
('latent representations', 'Used-for', 'prerequisite relation')
('character-level language models', 'Used-for', 'open-vocabulary language modeling')
('caching mechanism', 'Used-for', 'word type reuse')
('feature extraction', 'Used-for', 'statistical NLP')
('sentence embeddings', 'Is-a-Prerequisite-of', 'textual similarity sts task')
('sentence embeddings', 'Used-for', 'natural language processing tasks')
('ConSERT', 'Evaluate-for', 'textual similarity sts task')
('DefSent', 'Used-for', 'unsupervised semantic textual similarity sts task')
('WhitenedCSE', 'Used-for', 'semantic textual similarity tasks')
('semantic textual similarity tasks', 'Part-of', 'textual similarity sts task')
('sentence meta-embeddings', 'Evaluate-for', 'semantic textual similarity')
('mutual information', 'Used-for', 'word embedding-based similarity measures')
('word embeddings', 'Used-for', 'sentence meta-embeddings')
('Deep Learning Model', 'Used-for', 'Semantic Role Labeling (SRL')
('Deep Highway BiLSTM Architecture', 'Used-for', 'Semantic Role Labeling (SRL')
('Progressive Neural Network', 'Used-for', 'Semantic Role Labeling (SRL')
('Character-Level Models', 'Evaluate-for', 'Semantic Role Labeling (SRL')
('Chinese SemBank', 'Used-for', 'Semantic Role Labeling (SRL')
('Syntactic Information', 'Is-a-Prerequisite-of', 'Dependency SRL')
('chain thought prompting', 'Compare', 'Zero-shot-CoT')
('chain thought prompting', 'Hyponym-Of', 'NLP task enhancement methods')
('Zero-shot-CoT', 'Used-for', 'enabling LLMs to generate reasoning steps without prior examples')
('few-shot chain-of-thought prompting', 'Part-of', 'chain thought prompting')
('Symbolic Chain-of-Thought Distillation', 'Used-for', 'training smaller models with rationalizations from larger models')
('fastText', 'Evaluate-for', 'inductive bias')
('BERT', 'Evaluate-for', 'inductive bias')
('SCOTT', 'Is-a-Prerequisite-of', 'faithful knowledge distillation')
('Verify-and-Edit framework', 'Used-for', 'increasing prediction factuality in CoT')
('Selection-Inference', 'Compare', 'Backward Chaining')
('probabilistic generative models', 'Used-for', 'unsupervised dependency parsing')
('unsupervised constituency parsing', 'Evaluate-for', 'standardized settings')
('Parsing-Reading-Predict architecture', 'Used-for', 'unsupervised syntactic parsing')
('structural consistency', 'Used-for', 'unsupervised constituency parsing')
('constituency parsers', 'Part-of', 'unsupervised constituency parsing')
('standardized settings', 'Used-for', 'comparability between methods in unsupervised constituency parsing')
('parse tree annotations', 'Hyponym-Of', 'constituency parsing')
('COREQA', 'Is-a-Prerequisite-of', 'domain question answering qa')
('COREQA', 'Used-for', 'generating natural answers')
('semantic units', 'Used-for', 'domain question answering qa')
('knowledge base', 'Used-for', 'domain question answering qa')
('neural network-based methods', 'Used-for', 'domain question answering qa')
('cross-attention mechanism', 'Used-for', 'dynamic question representation')
('relation detection', 'Part-of', 'Knowledge Base Question Answering')
('Open Information Extraction', 'Used-for', 'reasoning in domain question answering qa')
('EviNets', 'Used-for', 'scoring in domain question answering qa')
('derived word generation', 'Evaluate-for', 'domain question answering qa')
('dynamic neural semantic parsing', 'Used-for', 'domain question answering qa')
('convolutional neural network', 'Used-for', 'domain question answering qa')
('None', 'Is-a-Prerequisite-of', 'Cross lingual transfer')
('Cross lingual transfer', 'Used-for', 'Improve accuracy on low-resource languages')
('Cross lingual transfer', 'Used-for', 'Adaptation in multilingual NLP environments')
('Cross lingual transfer', 'Hyponym-Of', 'Cross-lingual training')
('Cross lingual transfer', 'Used-for', 'Multilingual transfer setting')
('Cross lingual transfer', 'Evaluate-for', 'Resource scarcity in NLP')
('Cross lingual transfer', 'Used-for', 'cross-lingual sentence similarity')
('Universal Dependencies', 'Is-a-Prerequisite-of', 'Cross lingual transfer')
('EuroSense', 'Evaluate-for', 'Cross lingual transfer')
('Universal Dependencies', 'Part-of', 'Cross lingual transfer')
('Cross lingual transfer', 'Evaluate-for', 'Multilingual word embedding induction')
('Cross lingual transfer', 'Used-for', 'Named entity recognition')
('Parallel corpora', 'Is-a-Prerequisite-of', 'Cross lingual transfer')
('Machine translation', 'Evaluate-for', 'Cross lingual transfer')
('embeddings represent word', 'Used-for', 'sentiment classification')
('embeddings represent word', 'Used-for', 'sequence modeling')
('embeddings represent word', 'Used-for', 'detecting temporal changes')
('Neural Language Modelling', 'Used-for', 'Learning contextual embeddings')
('Contextual embeddings', 'Used-for', 'Word Sense Disambiguation tasks')
('Contextual embeddings', 'Hyponym-Of', 'embeddings represent word')
('Bilingual Sentiment Embeddings', 'Evaluate-for', 'sentence-level cross-lingual sentiment classification')
('word embeddings', 'Used-for', 'semantic similarity estimation')
('Bilingual Sentiment Embeddings', 'Part-of', 'cross-lingual sentiment approaches')
('Dynamic contextualized word embeddings', 'Hyponym-Of', 'embeddings represent word')
('Dynamic contextualized word embeddings', 'Used-for', 'capturing semantic variability')
('SynGCN', 'Used-for', 'learning word embeddings')
('SemGCN', 'Used-for', 'incorporating diverse semantic knowledge into word representations')
('summary generation', 'Used-for', 'content planning')
('summary generation', 'Used-for', 'surface realization')
('structured convolutional decoder', 'Used-for', 'summary generation')
('automatic evaluation', 'Evaluate-for', 'summary generation')
('human evaluation', 'Evaluate-for', 'summary amendment')
('text generation', 'Compare', 'abstractive summarization')
('abstractive summarization', 'Used-for', 'text generation')
('text generation', 'Used-for', 'automatic pun generation')
('text generation', 'Used-for', 'data-to-text generation')
('text generation', 'Used-for', 'table-to-text generation')
('text generation', 'Part-of', 'natural language processing')
('text generation', 'Used-for', 'AMR-to-text generation')
('text generation', 'Used-for', 'knowledge acquisition')
('text generation', 'Used-for', 'poetry generation')
('poetry generation', 'Is-a-Prerequisite-of', 'text generation')
('Entity Recognition', 'Used-for', 'Relation Extraction')
('DocRED', 'Used-for', 'Document-Level Relation Extraction')
('Cross-lingual Attention', 'Used-for', 'Multi-lingual Relation Extraction')
('MGNER', 'Used-for', 'Multi-Grained Named Entity Recognition')
('Bi-LSTM along Dependency Paths', 'Evaluate-for', 'Temporal Relation Classification')
('Feature Extraction', 'Used-for', 'Statistical NLP')
('Distant Supervision', 'Used-for', 'Relation Extraction Training Data Generation')
('Curriculum Learning', 'Used-for', 'Noise Characterization in Training Data')
('Dynamic Transition Matrix', 'Used-for', 'Characterizing Noise in Training Data')
('Mono-Lingual Attention', 'Used-for', 'Mono-lingual Relation Extraction')
('NER using FOFE', 'Hyponym-Of', 'Entity Recognition')
('None', 'Is-a-Prerequisite-of', 'unintended bias in text classifiers')
('unintended bias in text classifiers', 'Used-for', 'neutralizing identity terms')
('unintended bias in text classifiers', 'Used-for', 'improving classifier performance in scarce data settings')
('model building', 'Evaluate-for', 'incorporating priors')
('feature attributions', 'Part-of', 'objective function')
('L2 distance loss', 'Part-of', 'objective function')
('unintended biases', 'Compare', 'document-level label bias and word-level keyword bias')
('Corsair', 'Used-for', 'mitigating document-level label bias and word-level keyword bias')
('Corsair', 'Evaluate-for', 'generalizability and fairness')
('text classification debiasing framework', 'Used-for', 'avoiding data manipulations')
('text classification debiasing framework', 'Used-for', 'designing balancing mechanisms')
('model-agnostic debiasing training framework', 'Used-for', 'recovering the non-discrimination distribution')
('speech-to-speech translation', 'Used-for', 'translating speech without intermediate text')
('neural semantic parser', 'Used-for', 'converting natural language utterances into intermediate representations')
('predicate-argument structures', 'Part-of', 'intermediate representations in neural semantic parsers')
('transition system', 'Used-for', 'inducing predicate-argument structures')
('AMR parser', 'Part-of', 'semantic parsing systems')
('intermediate representations', 'Compare', 'linguistically motivated representations')
('contrastive REs', 'Used-for', 'correcting misunderstandings')
('semantic roles', 'Part-of', 'Abstract Meaning Representations')
('contrastive focus', 'Used-for', 'emphasizing misunderstood information in NLG')
('neural semantic parser', 'Is-a-Prerequisite-of', 'building semantic content representations')
('generated summary', 'Hyponym-Of', 'summary')
('encode-attend-decode', 'Used-for', 'generated summary')
('data-to-text generation model', 'Used-for', 'generated summary')
('query-based summarization', 'Used-for', 'generated summary')
('abstractive summarization', 'Used-for', 'generated summary')
('scientific paper summarization', 'Used-for', 'generated summary')
('multi-sentence compression', 'Used-for', 'generated summary')
('sequence-to-sequence model', 'Used-for', 'generated summary')
('diversity based attention model', 'Evaluate-for', 'generated summary')
('adversarial training', 'Evaluate-for', 'generated summary')
('Implicit Event Argument Detection', 'Is-a-Prerequisite-of', 'Document-level Event Argument Extraction')
('Head-to-span expansion', 'Part-of', 'Implicit Event Argument Detection')
('Document-level Event Extraction', 'Used-for', 'Recognizing event and argument spread across a document')
('Multi-granularity reader', 'Used-for', 'Dynamic information aggregation')
('Heterogeneous Graph-based Interaction Model', 'Used-for', 'Capture global interactions among sentences')
('Tracker module', 'Used-for', 'Capture interdependency among events')
('Event proxy nodes', 'Used-for', 'Capturing global information between events')
('Document-level Event Argument Extraction', 'Used-for', 'Identifying event arguments beyond sentence level')
('Neural sequence models', 'Evaluate-for', 'Document-level role filler extraction')
('Implicit Event Argument Extraction', 'Hyponym-Of', 'Event Argument Extraction')
('Cross-sentence argument candidates', 'Part-of', 'Implicit Event Argument Detection')
('(neural dialogue generation', 'Part-of', 'end-to-end neural dialogue generation')
('(end-to-end neural dialogue generation', 'Compare', 'neural knowledge diffusion model')
('(neural knowledge diffusion model', 'Used-for', 'introducing knowledge into dialogue generation')
('(neural dialogue generation', 'Evaluate-for', 'capability of convergent and divergent thinking over the knowledge base')
('(neural knowledge diffusion model', 'Compare', 'competitive baseline models')
('(neural dialogue generation', 'Is-a-Prerequisite-of', 'dialogue system building')
('Distant Supervision', 'Used-for', 'entity relation extraction')
('entity relation extraction', 'Evaluate-for', 'model performance')
('entity relation extraction', 'Used-for', 'knowledge base enrichment')
('semantic information', 'Part-of', 'entity relation extraction')
('relation extraction', 'Used-for', 'feature extraction efficiency')
('BIO tag embeddings', 'Used-for', 'entity relation extraction')
('Dynamic transition matrix', 'Used-for', 'characterize noise')
('Curriculum learning', 'Used-for', 'train dynamic transition matrix')
('DocRED', 'Evaluate-for', 'document-level entity relation extraction')
('Open Information Extraction', 'Used-for', 'semi-structured knowledge generation')
('deep learning architecture', 'Used-for', 'learn relations')
('class ties', 'Evaluate-for', 'entity relation characterizing')
('entity relation bipartite graph', 'Used-for', 'joint type inference')
('linguistically diverse conversational corpus', 'Used-for', 'natural language understanding')
('linguistically diverse conversational corpus', 'Used-for', 'design of conversational interfaces')
('linguistically diverse conversational corpus', 'Used-for', 'language technology')
('linguistically diverse conversational corpus', 'Hyponym-Of', 'conversational corpora')
('linguistically diverse conversational corpus', 'Is-a-Prerequisite-of', 'flexible language technologies')
('QCPG', 'Used-for', 'generating high-quality paraphrases')
('paraphrase generation', 'Used-for', 'downstream tasks')
('paraphrase', 'Hyponym-Of', 'linguistic output')
('conversation', 'Part-of', 'mental health counseling')
('computational framework', 'Used-for', 'study of conversational evolution')
('computational framework', 'Used-for', 'quantify linguistic behavior changes')
('Natural language explanation prediction', 'Used-for', 'Training classifiers with explanations instead of labels')
('Natural language explanation prediction', 'Used-for', 'Generating explanation-guided representations')
('Semantics', 'Part-of', 'Natural language explanation prediction')
('Predicate-argument structures', 'Is-a-Prerequisite-of', 'Semantic parsing')
('Text similarity measures', 'Used-for', 'Plagiarism detection')
('Text similarity measures', 'Used-for', 'Recognition of paraphrases and textual entailment')
('Semantic parser', 'Used-for', 'Converting natural language to logical forms')
('Predicate-argument structures', 'Used-for', 'Mapping to target domains')
('Natural language generation', 'Used-for', 'Generating coherent and diversified story endings')
('Semantic parser', 'Used-for', 'Training classifiers using programmatic labeling functions')
('Variational auto-encoders', 'Used-for', 'Natural language generation')
('Question answering', 'Conjunction', 'Natural language generation')
('text generation model', 'Used-for', 'Question generation')
('Generative Domain-Adaptive Nets', 'Used-for', 'text generation model')
('text generation model', 'Used-for', 'Generating SQL queries')
('neural network', 'Used-for', 'text generation model')
('Generative Domain-Adaptive Nets', 'Part-of', 'text generation model')
('Abstract syntax networks', 'Used-for', 'text generation model')
('neural models', 'Used-for', 'abstractive sentence summarization')
('neural abstractive method', 'Hyponym-Of', 'text generation model')
('neural knowledge diffusion model', 'Hyponym-Of', 'text generation model')
('pun generation', 'Used-for', 'text generation model')
('derivational morphology', 'Evaluate-for', 'text generation model')
('response generation', 'Used-for', 'open-domain dialog systems')
('conditional response generation', 'Part-of', 'response generation')
('response generation', 'Used-for', 'chatbots')
('response generation', 'Used-for', 'customer service')
('iterative training process', 'Used-for', 'improving response generation')
('Seq2Seq models', 'Used-for', 'response generation')
('deep latent variable models', 'Used-for', 'response generation')
('encoder-decoder models', 'Used-for', 'response generation')
('neural models', 'Used-for', 'response generation')
('memory augmented neural models', 'Part-of', 'neural models')
('Diaogue context', 'Used-for', 'response selection')
('response selection', 'Is-a-Prerequisite-of', 'response generation')
('semantic gap', 'Evaluate-for', 'response selection')
('response selection', 'Used-for', 'dialogue systems')
('multi-turn conversation', 'Evaluate-for', 'response selection')
('rhyme', 'Part-of', 'poetic devices')
('rhythm', 'Part-of', 'poetic devices')
('alliteration', 'Part-of', 'poetic devices')
('trained language model', 'Used-for', 'constraint satisfaction in poetry generation')
('constraint satisfaction problem', 'Part-of', 'second approach in poetry generation')
('discriminative weighted finite state machine', 'Used-for', 'constraining generation based on poetry form')
('English poetry', 'Evaluate-for', 'coherence and thematic relevance by manipulating model constraints')
('neural language model', 'Is-a-Prerequisite-of', 'spoken language understanding')
('neural language model', 'Evaluate-for', 'infusion of affective information')
('Affect-LM', 'Used-for', 'generation of emotionally colored conversational text')
('\nNone\n(gated self-matching networks', 'Used-for', 'reading comprehension question answering')
('self-matching attention mechanism', 'Used-for', 'refining passage representations')
('semantic parsing', 'Is-a-Prerequisite-of', 'question answering')
('pointer networks', 'Used-for', 'locating answer positions in passages')
('global knowledge', 'Used-for', 'enhancing answer representation')
('memory networks', 'Used-for', 'attending to facts in question answering')
('EviNets', 'Used-for', 'scoring candidate answer entities')
('transfer learning', 'Used-for', 'improving question answering model performance')
('Generative Domain-Adaptive Nets', 'Used-for', 'semi-supervised question answering')
('Recurrent Neural Networks', 'Used-for', 'processing natural language for question answering')
('universal schema', 'Used-for', 'reasoning on structured and unstructured knowledge')
('pretrained multilingual', 'Used-for', 'improving NLP task performance')
('Neural Machine Translation', 'Used-for', 'zero-shot translation')
('ERNIE', 'Is-a-Prerequisite-of', 'knowledge-driven tasks')
('ERNIE', 'Hyponym-Of', 'pretrained multilingual')
('pretrained multilingual', 'Used-for', 'multilingual document classification')
('BERT', 'Compare', 'non-contextual subword embeddings')
('cross-lingual word embeddings', 'Used-for', 'multilingual natural language processing systems')
('pretrained multilingual', 'Evaluate-for', 'language representation')
('multilingual datasets', 'Used-for', 'semantic parsing')
('pretrained multilingual', 'Used-for', 'zero-shot translation enhancement')
('pretrained multilingual', 'Used-for', 'language identification')
('pretrained multilingual\n(translation quality', 'Used-for', 'assessing NMT system performance')
('NMT', 'Evaluate-for', 'translation quality')
('Machine translation', 'Evaluate-for', 'translation quality')
('Chunk-based decoders', 'Used-for', 'improving translation quality')
('Triangular training architecture', 'Used-for', 'improving translation quality')
('Adversarial stability training', 'Used-for', 'improving NMT robustness and translation quality')
('Low-frequency word targeting', 'Used-for', 'enhancing translation quality in low-resource settings')
('Data augmentation', 'Used-for', 'improving translation quality')
('Image-based translation', 'Compare', 'text-based translation for translation quality')
('Domain-specific adaptation', 'Used-for', 'enhancing translation quality')
('Unsupervised Neural Machine Translation', 'Used-for', 'translation between distant languages')
('Unsupervised pivot translation', 'Used-for', 'improving translation quality for distant languages')
('Relation Prediction', 'Used-for', 'Knowledge Base Question Answering')
('Relation Extraction', 'Is-a-Prerequisite-of', 'Relation Prediction')
('Relation Detection', 'Hyponym-Of', 'Relation Prediction')
('Sentence-level Analysis', 'Evaluate-for', 'Relation Prediction')
('Deep Learning', 'Used-for', 'Relation Prediction')
('Neural Semantic Parser', 'Used-for', 'Relation Prediction')
('Multi-lingual Neural Relation Extraction Framework', 'Used-for', 'Relation Prediction')
('DSGAN', 'Used-for', 'Relation Prediction')
('Entity Linking', 'Evaluate-for', 'Relation Prediction')
('event argument extraction EAE', 'Used-for', 'identifying arguments relevant to an event')
('implicit event argument extraction', 'Is-a-Prerequisite-of', 'document-level modeling')
('implicit event argument extraction', 'Compare', 'explicit event argument extraction')
('Frame-aware Event Argument Extraction FEAE', 'Evaluate-for', 'reasoning in event frame-level scope')
('Multi-tier Knowledge Projection Network MKPNet', 'Used-for', 'event relation extraction')
('event argument extraction EAE', 'Used-for', 'generating argument roles in response to an event')
('event-centric knowledge graphs', 'Used-for', 'mining relations between events')
('knowledge projection', 'Used-for', 'reducing labelled data requirement in event relation extraction')
('Bi-directional Entity-level Recurrent Decoder BERD', 'Evaluate-for', 'distinguishing implicit argument distribution patterns')
('Siamese neural network architecture', 'Evaluate-for', 'assessing convincingness in argument detection')
('reasoning task', 'Used-for', 'comprehending natural language')
('reasoning task', 'Is-a-Prerequisite-of', 'effective human decision-making')
('reasoning task', 'Is-a-Prerequisite-of', 'human intelligence')
('reasoning task', 'Is-a-Prerequisite-of', 'artificial intelligence')
('artificial intelligence', 'Used-for', 'modeling human language inference')
('data annotation', 'Used-for', 'zero pronoun resolution improvement')
('crowdsourcing', 'Used-for', 'paraphrase generation')
('crowdsourcing', 'Hyponym-Of', 'data collection')
('machine learning systems', 'Used-for', 'training on linguistically diverse datasets')
('machine comprehension task', 'Is-a-Prerequisite-of', 'language understanding task')
('natural language understanding', 'Is-a-Prerequisite-of', 'dialogue state tracking')
('natural language explanation', 'Used-for', 'solving algebraic word problems')
('answer rationales', 'Part-of', 'natural language explanation')
('arithmetic operations', 'Part-of', 'natural language explanation')
('natural language explanation', 'Evaluate-for', 'learning arithmetic programs')
('natural language explanation', 'Used-for', 'understanding question-answer systems')
('crossmodal attention', 'Compare', 'multimodal attention')
('crossmodal attention', 'Used-for', 'bridging semantic gap between modalities')
('crossmodal attention', 'Is-a-Prerequisite-of', 'multimodal emotion regression')
('crossmodal attention', 'Used-for', 'improving performance on text-image retrieval tasks')
('crossmodal attention', 'Used-for', 'enhancing contextualized representation of image-text pairs')
('crossmodal attention', 'Evaluate-for', 'performance on Flickr30k and MS COCO datasets')
('crossmodal attention', 'Part-of', 'inter-modal alignment')
('inter-modal alignment', 'Used-for', 'optimizing crossmodal attention')
('crossmodal attention', 'Used-for', 'enhancing model interpretability by calibrating intra-modal self-attentions')
('Intra-modal Self-attention Distance', 'Evaluate-for', 'crossmodal attention effectiveness')
('crossmodal attention', 'Hyponym-Of', 'attention mechanisms')
('contrastive visual semantic pretraining', 'Used-for', 'mitigating anisotropy in word embeddings')
('GPT-2', 'Part-of', 'contrastive visual semantic pretraining')
('CLIP', 'Part-of', 'contrastive visual semantic pretraining')
('contrastive visual semantic pretraining', 'Evaluate-for', 'semantic properties of contextualized language representations')
('CLIP word embeddings', 'Compare', 'GPT-2 word embeddings')
('CLIP', 'Used-for', 'zero-shot multimodal image classification')
('CLIP', 'Used-for', 'encoding image captions')
('Spearman’s Interactive semantic parsing', 'Is-a-Prerequisite-of', 'natural language feedback')
('feedback simulator', 'Used-for', 'error correction in semantic parsing')
('lilGym', 'Used-for', 'language-conditioned reinforcement learning')
('text classification task', 'Used-for', 'categorizing documents in different languages')
('text classification operations', 'Part-of', 'multi-task learning')
('text classification task', 'Is-a-Prerequisite-of', 'learning representations from text')
('BiLSTMs', 'Used-for', 'text classification task')
('Cognitive NLP systems', 'Used-for', 'complex classification tasks like Sentiment Analysis and Sarcasm Detection')
('text classification task', 'Used-for', 'classification of utterances in videos')
('Lexico-syntactic features', 'Used-for', 'text classification task')
('Neural network models', 'Used-for', 'text classification task')
('text classification task', 'Used-for', 'argument mining')
('neural language model', 'Used-for', 'sentence generation')
('neural language model', 'Part-of', 'COREQA system')
('neural language class', 'Hyponym-Of', 'recurrent neural networks')
('neural language model', 'Used-for', 'language modeling')
('neural language model', 'Used-for', 'improving perplexity of language models')
('document context', 'Used-for', 'enhancing neural language models')
('neural language model', 'Compare', 'LSTM language model')
('neural language model', 'Compare', 'ITransF embedding model')
('neural language model', 'Used-for', 'generating conversational text conditioned on affect categories')
('neural language model', 'Evaluate-for', 'performance in text similarity assessment')
('neural language model', 'Used-for', 'natural language interface to databases')
('biomedical entity linking', 'Is-a-Prerequisite-of', 'cross-lingual biomedical entity linking task')
('entity linking', 'Part-of', 'knowledge base question answering')
('entity linking', 'Used-for', 'aligning textual mentions of named entities to their corresponding entries in a knowledge base')
('entity linking', 'Evaluate-for', 'improving accuracy in KBQA systems')
('biomedical entity linking', 'Used-for', 'handling specialised in-domain tasks')
('biomedical entity linking', 'Evaluate-for', 'advancing capabilities of language models to handle specialized tasks')
('entity embeddings', 'Used-for', 'neural entity linking models')
('seed mentions', 'Used-for', 'bridging other mentions and uninformative entities in List-only Entity Linking')
('cross-lingual transfer methods', 'Used-for', 'biomedical entity linking')
('latent topic', 'Is-a-Prerequisite-of', 'matrix factorization')
('latent topic', 'Used-for', 'modeling inter-topic preferences')
('latent topic', 'Hyponym-Of', 'user-topic matrix')
('latent topic', 'Hyponym-Of', 'Document structure')
('latent digram', 'Used-for', 'representing users preferences')
('latent topic', 'Part-of', 'LDA')
('latent topic', 'Hyponym-Of', 'Gaussian mixtures')
('latent topic', 'Part-of', 'neural topic model')
('Document structure', 'Used-for', 'aspect-based summarization')
('latent feature space', 'Hyponym-Of', 'latent topic')
('latent topic', 'Hyponym-Of', 'latent variable')
('latent topic', 'Hyponym-Of', 'disentangled syntactic and semantic spaces')
('latent topic', 'Hyponym-Of', 'latent lexical meaning')
('latent topic', 'Used-for', 'coherence between topics')
('None', 'Used-for', 'representation learning')
('representation learning', 'Part-of', 'natural language understanding')
('aware news representation', 'Used-for', 'improving dialogue state tracking')
('COREQA', 'Used-for', 'Generate sentence')
('COREQA', 'Used-for', 'natural language sentence generation')
('Abstractive summarization', 'Used-for', 'Generate sentence')
('Query-based summarization', 'Used-for', 'Generate sentence')
('Selective encoding model', 'Used-for', 'Generate sentence')
('Japanese sentence compression', 'Used-for', 'Generate sentence')
('Neural parser', 'Used-for', 'Generate sentence')
('DSGAN', 'Used-for', 'Generate sentence')
('Decoder in NMT', 'Used-for', 'Generate sentence')
('compositional distributional semantics', 'Is-a-Prerequisite-of', 'evaluating semantic relatedness')
('compositional distributional semantics', 'Is-a-Prerequisite-of', 'evaluating entailment')
('compositional distributional semantics', 'Used-for', 'analyzing multiword expressions')
('evaluation dataset', 'Part-of', 'compositional distributional semantics models')
('SICK corpus', 'Used-for', 'validation of compositional distributional semantics')
('semantic composition', 'Used-for', 'compositional distributional semantics')
('Poincaré embeddings', 'Used-for', 'detecting compositionality in noun phrases')
('semantic parsers', 'Evaluate-for', 'compositional distributional semantics models')
('compositional distributional semantics', 'Evaluate-for', 'negation function in fMRI studies')
('Functional Distributional Semantics', 'Hyponym-Of', 'compositional distributional semantics')
('Pixie Autoencoder', 'Used-for', 'enhancing performance of Functional Distributional Semantics')
('distributional semantics', 'Used-for', 'natural language generation')
('compositionality prediction', 'Part-of', 'compositional distributional semantics applications')
('com\n(named entity', 'Part-of', 'natural language processing')
('named entity recognition', 'Used-for', 'named entity')
('metonymy resolution', 'Evaluate-for', 'named entity recognition')
('named entity', 'Used-for', 'specific entity identification')
('named entity recognition', 'Is-a-Prerequisite-of', 'entity linking')
('entity linking', 'Evaluate-for', 'named entity disambiguation')
('named entity', 'Part-of', 'multimodal named entity disambiguation task')
('named entity recognition', 'Used-for', 'taxonomic classification')
('cross-lingual named entity recognition', 'Used-for', 'named entity')
('named entity', 'Part-of', 'knowledge graph embeddings')
('named entity recognition', 'Evaluate-for', 'multilingual learning')
('entity linking', 'Evaluate-for', 'named entity')
('named entity recognition', 'Used-for', 'domain adaptation')
('task oriented dialogue', 'Used-for', 'automatic diagnosis')
('task oriented dialogue', 'Used-for', 'multimodal dialogue systems')
('task oriented dialogue', 'Is-a-Prerequisite-of', 'robust dialogue belief tracking')
('task oriented dialogue', 'Is-a-Prerequisite-of', 'knowledge base integration')
('task oriented dialogue', 'Part-of', 'Multi-turn dialogue agent system')
('task oriented dialogue', 'Part-of', 'dialogue systems')
('task oriented may matchup', 'Compare', 'multi-domain dialogues')
('multimodal dialogue systems', 'Is-a-Prerequisite-of', 'task oriented dialogue')
('automatic diagnosis', 'Used-for', 'task oriented dialogue')
('multimodal dialogue systems', 'Evaluate-for', 'visual and textual user input handling')
('robust dialogue belief tracking', 'Evaluate-for', 'task oriented dialogue system quality maintenance')
('belief tracker', 'Used-for', 'estimating user goals')
('spoken dialogue system', 'Part-of', 'task-oriented dialogue system')
('spoken dialogue system', 'Evaluate-for', 'user adaptivity')
('task-oriented dialogue system', 'Used-for', 'automatic diagnosis')
('task-oriented dialogue system', 'Used-for', 'handling unknown slot values')
('spoken dialogue system', 'Part-of', 'multimodal dialogue system')
('multimodal dialogue system', 'Used-for', 'capturing multimodal user information')
('task-oriented dialogue system', 'Compare', 'open-domain dialogue system')
('open-domain dialogue system', 'Used-for', 'handling informal dialogue')
('spoken dialogue system', 'Used-for', 'dialogue state tracking')
('document modeling', 'Used-for', 'event detection')
('document modeling', 'Used-for', 'document retrieval')
('external information', 'Used-for', 'improving document modeling')
('hierarchical document encoder', 'Part-of', 'document modeling framework')
('attention-based extractor', 'Part-of', 'document modeling framework')
('document encoder', 'Used-for', 'sentence extraction')
('document date', 'Used-for', 'document retrieval')
('document date', 'Used-for', 'event detection')
('document date', 'Used-for', 'summarization')
('document embedding', 'Used-for', 'event detection')
('document embedding', 'Used-for', 'Document Grounded Conversations')
('DEEB-RNN', 'Used-for', 'event detection in sentences')
('DEEB-RNN', 'Part-of', 'Document Embedding Enhanced Bi-RNN model')
('Multi Party Dialogue', 'Used-for', 'Multi-domain Dialogue Tasks')
('Multi Party Dialogue', 'Used-for', 'Hierarchical Representation Learning')
('Multi Party Dialogue', 'Used-for', 'Information Sharing Across Multiple Participants')
('Multi Party Dialogue', 'Used-for', 'Dialogue Act Generation')
('Multi Party Agent', 'Is-a-Prerequisite-of', 'Multi Party Dialogue')
('Hierarchical Representation', 'Used-for', 'Multi Party Dialogue')
('Dialogue Act Generation', 'Part-of', 'Multi Party Dialogue')
('Dialogue Act', 'Hyponym-Of', 'Dialogue Components')
('Multi-domain Dialogue Tasks', 'Part-of', 'Multi Party Dialogue')
('Information Sharing', 'Used-for', 'Multi Party Dialogue')
('Context Encoding', 'Used-for', 'Multi Party Dialogue')
('Utterances', 'Part-of', 'Multimodal sentiment analysis')
('Domain sentiment', 'Is-a-Prerequisite-of', 'Adopting a model with good performance to a target domain')
('Domain sentiment', 'Used-for', 'Extracting domain specific and invariant representations')
('Domain sentiment', 'Evaluate-for', 'Improving the generalizability and domain adaptability of sentiment analysis models')
('Sentiment analysis', 'Hyponym-Of', 'Natural Language Processing')
('Domain adaptability', 'Part-of', 'Domain sentiment')
('Domain-specific information', 'Used-for', 'Training domain-specific representation based classifiers')
('Invariance', 'Part-of', 'Domain-specific information')
('Cold-start problem', 'Used-for', 'Evaluating sentiment analysis models in new or sparse user/product environments')
('Sentiment conflict', 'Used-for', 'Humor recognition')
('oriented dialogue summarization', 'Is-a-Prerequisite-of', 'natural language generation')
('dialogue state tracking', 'Used-for', 'task-oriented dialogue systems')
('GLAD', 'Used-for', 'dialogue state tracking')
('Global-Locally Self-Attentive Dialogue State Tracker', 'Hyponym-Of', 'GLAD')
('task-oriented dialogue system framework', 'Used-for', 'automatic diagnosis')
('response selection models', 'Used-for', 'task-oriented dialogue tasks')
('dialogue policy optimization', 'Evaluate-for', 'task completion in task-oriented dialogue systems')
('reward learning', 'Used-for', 'semi-supervised policy learning in task-oriented dialogue systems')
('NLU and NLG', 'Conjunction', 'task-oriented dialogue systems')
('textual adversarial', 'Used-for', 'improving model robustness')
('textual adversarial', 'Used-for', 'generating adversarial examples')
('adversarial examples', 'Hyponym-Of', 'textual adversarial')
('implicit relation network', 'Used-for', 'implicit discourse relation classification')
('adversarial model', 'Used-for', 'adaptive imitation scheme')
('Word embeddings', 'Used-for', 'capturing linguistic regularities')
('unsupervised bilingual lexicon induction task', 'Used-for', 'evaluating cross-lingual word embeddings')
('compositor attribution', 'Used-for', 'bibliographic analysis')
('neural machine translation', 'Is-a-Prerequisite-of', 'understanding language representation')
('style transfer', 'Used-for', 'changing textual style without altering meaning')
('PWWS algorithm', 'Used-for', 'text adversarial attack')
('adversarial attacks', 'Compare', 'attacks on image classification')
('multi-task learning', 'Used-for', 'text classification')
('text classification', 'Used-for', 'sentiment analysis')
('text classification', 'Used-for', 'sarcasm detection')
('sentiment analysis', 'Is-a-Prerequisite-of', 'text classification')
('sarcasm detection', 'Is-a-Prerequisite-of', 'text classification')
('BiLSTMs', 'Used-for', 'text classification')
('attention-based methods', 'Used-for', 'text classification')
('automatic speech recognition', 'Used-for', 'text classification')
('LSTM-based model', 'Used-for', 'text classification')
('feature extraction', 'Used-for', 'text classification')
('manual feature extraction', 'Compare', 'automatic feature extraction')
('Bayesian Network Ensembles', 'Part-of', 'neural network interpretability bayesian')
('deep neural networks', 'Used-for', 'high accuracy')
('Bayesian Networks', 'Used-for', 'interpretability')
('Entity-Aware Convolutional Neural Networks', 'Used-for', 'diagnosis system')
('Bayesian Network Ensembles', 'Used-for', 'interpretability')
('neural network interpretability bayesian', 'Evaluate-for', 'AI-empowered healthcare')
('Electronic Medical Record', 'Used-for', 'automatic text-based diagnosis')
('QAGS', 'Used-for', 'factual consistency evaluation')
('Grammatical Error Correction', 'Used-for', 'language learning interpretability')
('Example-Based GEC', 'Used-for', 'interpretability')
('end-to-end relation extraction', 'Is-a-Prerequisite-of', 'joint learning methods')
('tagging based methods', 'Used-for', 'end-to-end relation extraction')
('distant supervision', 'Evaluate-for', 'end-to-end relation extraction')
('neural encoder-decoder model', 'Used-for', 'KB enrichment')
('knowledge base population', 'Part-of', 'relation extraction')
('neural Open IE system', 'Used-for', 'argument and relation tuple extraction')
('deep learning', 'Evaluate-for', 'relation extraction effectiveness')
('relation extraction', 'Used-for', 'information extraction')
('relation extraction', 'Compare', 'temporal relation classification')
('long short term memory', 'Used-for', 'predicting sequences in unannotated text')
('long short term memory', 'Evaluate-for', 'language model prediction')
('long short term memory', 'Used-for', 'extracting semantic relations between entity mentions')
('long short term offer memory', 'Used-for', 'sentence compression')
('long short term memory', 'Used-for', 'disfluency detection in spontaneous speech transcripts')
('long short term memory', 'Used-for', 'scoring n-best candidate disfluency analyses')
('long short term memory', 'Hyponym-Of', 'neural approaches')
('semantic relation extraction', 'Is-a-Prerequisite-of', 'long short term memory')
('long short term memory', 'Used-for', 'joint extraction of entity mentions and relations')
('long short term memory', 'Used-for', 'aspect-level sentiment classification')
('Common Sense Explanations', 'Is-a-Prerequisite-of', 'Commonsense Auto-Generated Explanation framework')
('Commonsense Auto-Generated Explanation framework', 'Used-for', 'improving CommonsenseQA task performance')
('Knowledge Enhanced Multimodal BART', 'Used-for', 'reasoning about commonsense knowledge')
('Visual Commonsense Generation', 'Evaluate-for', 'Knowledge-based Commonsense Generation pretraining')
('Knowledge-based Commonsense Generation', 'Used-for', 'boosting performance on Visual Commonsense Generation task')
('SEmantic-based Question Answering', 'Used-for', 'unsupervised commonsense question answering')
('Commonsense knowledge bases', 'Used-for', 'event commonsense evaluation')
('ACCENT', 'Used-for', 'event commonsense evaluation')
('event commonsense evaluation', 'Evaluate-for', 'compatibility with commonsense knowledge bases')
('text generation task', 'Used-for', 'natural language descriptions into source code')
('text generation task', 'Used-for', 'generation of complex programs from natural language descriptions')
('text generation task', 'Used-for', 'neural abstractive document summarization')
('text generation task', 'Used-for', 'automatic question generation')
('text generation task', 'Compare', 'semantic parsing')
('text generation task', 'Is-a-Prerequisite-of', 'sequential models in natural language generation')
('text generation task', 'Conjunction', 'neural models')
('neural models', 'Used-for', 'abstractive sentence summarization')
('neural models', 'Used-for', 'seq2seq summarization systems')
('sequential models', 'Used-for', 'text similarity measures')
('source code', 'Hyponym-Of', 'executable outputs')
('executable outputs', 'Used-for', 'mapping unstructured inputs')
('cross-lingual continual learning', 'Used-for', 'improving performance in zero-shot and low-resource language contexts')
('cross-lingual continual learning', 'Used-for', 'addressing NLP tasks in multiple languages simultaneously')
('cross lingual transfer learning', 'Is-a-Prerequisite-of', 'cross-lingual continual learning')
('syntax augmentation', 'Used-for', 'enhancing cross-lingual continual learning')
('cross-lingual continual learning', 'Evaluate-for', 'cross-lingual natural language understanding')
('pre-trained multilingual models', 'Used-for', 'facilitating cross-lingual continual learning')
('cross-lingual continual learning', 'Evaluate-for', 'zero-shot transfer in task-oriented semantic parsing')
('cross-lingual continual learning', 'Evaluate-for', 'disaster response')
('pre-trained multilingual models', 'Hyponym-Of', 'pre-trained language models')
('cross-lingual continual learning', 'Evaluate-for', 'multilingual open-domain dialog generation')
('c\n(Sememes', 'Used-for', 'lexical sememe prediction')
('lexical sememe prediction', 'Used-for', 'improving annotation efficiency')
('lexical sememe prediction', 'Used-for', 'improving annotation consistency')
('lexical sememe prediction', 'Evaluate-for', 'low-frequency words')
('lexical sememe prediction', 'Evaluate-for', 'out-of-vocabulary words')
('HowNet', 'Used-for', 'lexical sememe prediction')
('sentence relation extraction', 'Used-for', 'identifying relation class')
('sentence relation extraction', 'Is-a-Prerequisite-of', 'DocRED')
('sentence relation extraction', 'Evaluate-for', 'document-level RE')
('sentence relation extraction', 'Used-for', 'mapping entities to knowledge bases')
('dynamic transition matrix', 'Used-for', 'characterizing noise in training data')
('cross-lingual attention', 'Used-for', 'considering information consistency among texts')
('multi-lingual neural relation extraction framework', 'Used-for', 'relation extraction on multi-lingual texts')
('distant supervision', 'Used-for', 'building training data')
('BIO tag embeddings', 'Used-for', 'improving relation extraction models')
('DocRED', 'Part-of', 'document-level RE')
('relation extraction', 'Hyponym-Of', 'natural language processing')
('relation classification', 'Used-for', 'assigning correct relation class to entity pairs')
('pretrained language', 'Used-for', 'machine reading comprehension')
('pretrained language', 'Used-for', 'neural language translation')
('pretrained language', 'Is-a-Prerequisite-of', 'natural language interface')
('machine reading comprehension', 'Used-for', 'knowledge extraction')
('grammar model', 'Part-of', 'neural architecture')
('neural architecture', 'Used-for', 'code generation')
('semantic parsing', 'Used-for', 'code generation')
('code generation', 'Hyponym-Of', 'language generation')
('semantic parsing', 'Compare', 'code generation')
('visual reasoning language dataset', 'Used-for', 'linguistic phenomena analysis')
('crowdsourcing', 'Used-for', 'linguistically-diverse data collection')
('word segmentation', 'Used-for', 'Arash NLP application')
('word embeddings', 'Used-for', 'POS tagging')
('adversarially trained', 'Used-for', 'robustness of NMT models')
('adversarially trained', 'Used-for', 'robustness of self-attentive models')
('adversarially trained', 'Used-for', 'neural image captioning systems')
('adversarially trained', 'Used-for', 'generalizing classifiers in stance classification')
('adversarially trained', 'Is-a-Prerequisite-of', 'learning cross-lingual word embeddings')
('adversarially trained', 'Used-for', 'improving translation quality')
('adversarially trained', 'Used-for', 'evaluation of style transfer')
('adversarially trained', 'Used-for', 'extractive reading comprehension systems')
('SQuADRUn', 'Used-for', 'evaluation of question answering models')
('factoid question answering', 'Used-for', 'leveraging structured knowledge bases')
('factoid question answering', 'Used-for', 'evaluating open-domain questions using Wikipedia')
('neural network model', 'Evaluate-for', 'dynamic representation of questions and answers')
('cross-attention mechanism', 'Used-for', 'adapting representation to various candidate answers')
('global knowledge', 'Part-of', 'knowledge base')
('knowledge base', 'Used-for', 'integrating information into answer representations')
('OOV problem', 'Is-a-Prerequisite-of', 'effective question representation')
('relation detection', 'Part-of', 'Knowledge Base Question Answering')
('deep residual bidirectional LSTMs', 'Used-for', 'comparing questions and relation names')
('entity linking', 'Conjunction', 'relation detection')
('sequential question answering', 'Used-for', 'handling inter-related questions in conversation')
('Named Entity Disambiguation', 'Used-for', 'archival and historic corpus analysis')
('Named Entity Disambiguation', 'Used-for', 'improving retrieval accuracy in open-domain NLP tasks')
('Named Entity Disambiguation', 'Is-a-Prerequisite-of', 'relation extraction for knowledge base enrichment')
('Named Entity Disambiguation', 'Used-for', 'streaming cross document entity coreference')
('Named Entity Disambiguation', 'Hyponym-Of', 'Word Sense Disambiguation')
('Named Entity Disambiguation', 'Used-for', 'entity coreference resolution')
('Named Entity Disambiguation', 'Used-for', 'knowledge base mapping')
('Word Sense Disambiguation', 'Used-for', 'training data generation for NLP models')
('topic distribution', 'Hyponym-Of', 'document specific topic distributions')
('topic distribution', 'Used-for', 'topic assignments in documents')
('document specific topic distributions', 'Part-of', 'LDA-based models')
('Latent Dirichlet Allocation', 'Used-for', 'inferring latent topic distribution')
('Latent Dirichlet Allocation', 'Used-for', 'performing PageRank in Salience Rank')
('topic distribution', 'Is-a-Prerequisite-of', 'Normalized Pointwise Mutual Information calculation')
('topic distribution', 'Used-for', 'text classification')
('pretraining language', 'Used-for', 'neural word segmentation')
('neural word segmentation', 'Evaluate-for', 'improving Arabic NLP applications')
('neural word segmentation', 'Used-for', 'Machine Translation')
('neural word segmentation', 'Used-for', 'POS tagging')
('character CNN', 'Hyponym-Of', 'neural word segmentation')
('data-driven sub-word units', 'Hyponym-Of', 'neural word segmentation')
('pretraining language', 'Evaluate-for', 'learning feature representations')
('deep neural networks', 'Used-for', 'automatically learning feature representations')
('expressive kernels', 'Compare', 'deep neural networks')
('neural word embeddings', 'Is-a-Prerequisite-of', 'effective neural word segmentation')
('pretraining language', 'Part-of', 'modular segmentation model')
('pretraining language', 'Used-for', 'building large-scale raw text corpora')
('kernelized neural network\n(entity recognition', 'Is-a-Prerequisite-of', 'named entity recognition')
('named entity recognition', 'Used-for', 'mention detection')
('mention detection', 'Hyponym-Of', 'entity recognition')
('entity recognition', 'Used-for', 'zero-shot learning')
('lexical resources', 'Used-for', 'entity recognition')
('entity recognition', 'Hyponym-Of', 'natural language processing')
('entity recognition', 'Part-of', 'automatic content extraction')
('automatic content extraction', 'Evaluate-for', 'entity recognition')
('named entity recognition', 'Compare', 'joint model by Li and Ji')
('named entity recognition', 'Compare', 'tree-based LSTM model by Miwa and Bansal')
('entity recognition', 'Used-for', 'multilingual learning')
('entity recognition', 'Used-for', 'domain adaptation for named-entity recognition')
('entity recognition', 'Used-for', 'emotion recognition in conversations')
('entity recognition', 'Part-of', 'discourse relation recognition')
('named entity recognition', 'Is-a-Prerequisite-of', 'part-of-speech induction')
('part-of-speech induction', 'Evaluate-for', 'named entity recognition')
('Neural Machine Translation', 'Used-for', 'translation task')
('Neural Machine Translation models', 'Evaluate-for', 'translation task')
('Multi-modal Neural Machine Translation', 'Used-for', 'translation task')
('Sequence-to-Dependency Neural Machine Translation', 'Used-for', 'translation task')
('Parallel RNN encoder', 'Used-for', 'translation task')
('Aspect Extraction', 'Is-a-Prerequisite-of', 'Aspect-Based Sentiment Analysis')
('Neural Approach', 'Used-for', 'Aspect Extraction')
('Word Embedding Models', 'Used-for', 'Aspect Extraction')
('Attention Mechanism', 'Used-for', 'Aspect Extraction')
('Topic Models', 'Used-for', 'Aspect Extraction')
('Word Co-Occurrences', 'Evaluate-for', 'Aspect Extraction')
('Distribution Exploitation', 'Used-for', 'Aspect Extraction')
('Convolutional Neural Network', 'Used-for', 'Feature Extraction')
('Feature Extraction', 'Hyponym-Of', 'Information Extraction')
('Multi-Lingual Neural Relation Extraction Framework', 'Used-for', 'Relation Extraction')
('Cross-Lingual Texts', 'Evaluate-for', 'Multi-Lingual Neural Relation Extraction Framework')
('Mono-Lingual Texts', 'Evaluate-for', 'Multi-Lingual Neural Relation Extraction Framework')
('neural language model lm', 'Used-for', 'learning implicit representation of poetic form and content')
('neural language model lm', 'Evaluate-for', 'language model perplexity improvement')
('neural language model lm', 'Used-for', 'generation of conversational text conditioned on affect categories')
('neural language model lm', 'Is-a-Prerequisite-of', 'affective language generation')
('neural language model lm', 'Hyponym-Of', 'language models')
('neural language model lm', 'Part-of', 'language processing technologies')
('neural language model lm', 'Used-for', 'generating related sentences for a topic')
('phonetic encoding', 'Used-for', 'training neural language model lm')
('discriminative weighted finite state machine', 'Used-for', 'constraining neural language model lm on basis of form')
('lingual embeddings', 'Used-for', 'bilingual lexicon induction')
('lingual embeddings', 'Used-for', 'cross-lingual classification')
('bilingual text embeddings', 'Hyponym-Of', 'lingual embeddings')
('lingual embeddings', 'Compare', 'monolingual embeddings')
('lingual embeddings', 'Compare', 'cross-lingual word embeddings')
('lingual embeddings', 'Part-of', 'bilingual tasks')
('structural similarity', 'Evaluate-for', 'lingual embeddings')
('lingual embeddings', 'Used-for', 'cross-lingual image description retrieval')
('bilingual dictionaries', 'Used-for', 'lingual embeddings')
('Unsupervised bilingual lexicon induction', 'Evaluate-for', 'lingual embeddings')
('domain adaptation', 'Evaluate-for', 'lingual embeddings')
('neural word embeddings', 'Used-for', 'lingual embeddings')
('None', 'Used-for', 'linguistic fact finding')
('Mono-lingual data', 'Used-for', 'multilingual neural machine translation')
('Cross-lingual attention', 'Used-for', 'maintaining information consistency')
('Multi-lingual texts', 'Used-for', 'multilingual neural machine translation')
('Source syntax', 'Used-for', 'improving neural machine translation')
('Mono-lingual attention', 'Used-for', 'utilizing information within texts')
('None', 'Is-a-Prerequisite-of', 'multilingual neural machine translation')
('Language-sensitive embedding', 'Used-for', 'enhancing model performance')
('Language-aware interlingua', 'Used-for', 'capturing language-specific specialization')
('Multilingual pre-trained models', 'Used-for', 'improving performance on low resource languages')
('None', 'Compare', 'baseline models')
('Parallel RNN encoder', 'Part-of', 'source syntax incorporation methods')
('Hierarchical RNN encoder', 'Part-of', 'source syntax incorporation methods')
('Mixed RNN encoder', 'Part-of', 'source syntax incorporation methods')
('entity recognition', 'Used-for', 'identifying important elements from text')
('named entity recognition', 'Is-a-Prerequisite-of', 'information extraction')
('named entity recognition', 'Used-for', 'news filtering')
('named entity recognition', 'Used-for', 'data organizing')
('mention detection', 'Used-for', 'discovering relational data')
('generative model', 'Used-for', 'modeling lexical resources')
('annotation projection', 'Used-for', 'creating labeled data for NER')
('distributed representations of words', 'Used-for', 'improving cross-lingual NER')
('generative model', 'Hyponym-Of', 'Machine learning models')
('imitation learning', 'Used-for', 'querying informative data points')
('local detection approach', 'Used-for', 'NER task')
('FOFE method', 'Used-for', 'encoding sentence fragments')
('contextual embeddings', 'Used-for', 'enhancing NER')
('negative medical findings', 'Part-of', 'clinical report analysis')
('neural text classifier', 'Used-for', 'text classification')
('neural text classifier', 'Is-a-Prerequisite-of', 'feature attribution')
('neural text classifier', 'Is-a-Prerequisite-of', 'character-level manipulation')
('neural text classifier', 'Used-for', 'weighting input components')
('tokenization', 'Used-for', 'neural text classifier')
('adversarial examples', 'Evaluate-for', 'neural text classifier robustness')
('visual character embedding', 'Used-for', 'neural text classifier')
('cross-lingual text classification', 'Used-for', 'neural text classifier')
('attention mechanisms', 'Used-for', 'neural text classifier')
('model distillation', 'Compare', 'neural text classifier')
('Coherent paragraph summary', 'Part-of', 'Summarization datasets')
('Summarization datasets', 'Used-for', 'Summarization tasks')
('Human evaluation', 'Evaluate-for', 'Summarization output')
('Coherent paragraph summary', 'Compare', 'Readable article summary')
('Readable article summary', 'Used-for', 'Easier human evaluation')
('Speech pre-training', 'Used-for', 'Classification tasks')
('Generative Spoken Language Modeling', 'Hyponym-Of', 'Speech pre-training')
('pGSLM', 'Is-a-Prerequisite-of', 'Expressive speech generation')
('pGSLM', 'Used-for', 'Prosody and content modeling')
('MS-TLM', 'Part-of', 'pGSLM')
('HiFi-GAN model', 'Part-of', 'pGSLM')
('image text', 'Hyponym-Of', 'multimodal data')
('image text', 'Used-for', 'visual grounding in speech perception')
('image text', 'Used-for', 'joint semantic space projection')
('Multimodal language processing', 'Used-for', 'Analyzing human multimodal language')
('CMU Multimodal Opinion Sentiment and Emotion Intensity', 'Is-a-Prerequisite-of', 'Dynamic Fusion Graph application')
('Multi-hop reading comprehension datasets', 'Evaluate-for', 'Multi-hop logical reasoning')
('Dynamic Fusion Graph', 'Used-for', 'Multimodal sentiment analysis')
('CMU Multimodal Opinion Sentiment and Emotion Intensity', 'Part-of', 'Multimodal language research')
('CMU Multimodal Opinion Sentient and Emotion Intensity', 'Used-for', 'Sentiment analysis and emotion recognition')
('Multi-hop reading comprehension datasets', 'Used-for', 'Improving multi-hop reasoning abilities in machine learning models')
('Dynamic Fusion Graph', 'Compare', 'Previous multimodal fusion techniques')
('Multimodal sentiment analysis', 'Evaluate-for', 'New multimodal fusion methods')
('topic discovery', 'Used-for', 'classifying document corpora')
('topic discovery', 'Part-of', 'natural language processing tasks')
('topic discovery', 'Evaluate-for', 'discovery of spatially distinct topics')
('topic discovery', 'Evaluate-for', 'discovery of temporal topics')
('spatial aggregation', 'Used-for', 'topic discovery')
('matrix factorization', 'Used-for', 'topic discovery')
('topic discovery', 'Used-for', 'learning text representations')
('NB-NTM', 'Used-for', 'topic discovery')
('GNB-NTM', 'Used-for', 'topic discovery')
('topic models', 'Used-for', 'topic discovery')
('topic discovery', 'Used-for', 'insight into document corpora')
('topic discovery', 'Is-a-Prerequisite-of', 'topic guided keyphrase generation')
('topic discovery', 'Evaluate-for', 'understanding document content')
('neural model', 'Used-for', 'semantic parsing')
('neural model', 'Used-for', 'generation of rhythmic poetry')
('neural model', 'Used-for', 'language modeling')
('neural model', 'Evaluate-for', 'handling discourse-level diversity in conversations')
('neural model', 'Used-for', 'automatically generating market comments from stock prices')
('neural model', 'Evaluate-for', 'learning to predict surrounding words for every word in the dataset')
('neural model', 'Is-a-Prerequisite-of', 'multi-task learning framework')
('neural model', 'Part-of', 'encoder-decoder framework')
('neural model', 'Hyponym-Of', 'machine learning models')
('weight uncertainty in RNNs', 'Used-for', 'enhancing model-parameter space exploration')
('Treebank conversion', 'Used-for', 'boosting parsing performance')
('source syntax', 'Used-for', 'improving the Neural Machine Translation (NMT')
('syntactic information', 'Is-a-Prerequisite-of', 'Semantic role labeling (SRL')
('SD-NMT', 'Used-for', 'improving statistical machine translation')
('Bidirectional tree encoder', 'Used-for', 'learning both sequential and tree structured representations')
('syntactic information', 'Used-for', 'making deletion-based LSTM models more robust')
('neural SRL models', 'Compare', 'previous studies highlighting the importance of syntax in SRL')
('deep generative model of machine translation', 'Used-for', 'accounting for local lexical and syntactic variation in parallel corpora')
('word embeddings', 'Used-for', 'document clustering')
('word embeddings', 'Used-for', 'learning bilingual word embeddings')
('word embeddings', 'Used-for', 'sentiment analysis')
('word embeddings', 'Used-for', 'extracting pseudo-parallel sentences')
('word embeddings', 'Used-for', 'connecting monolingual embeddings without supervision')
('word embeddings', 'Used-for', 'modeling temporal word analogies')
('word embeddings', 'Used-for', 'inducing embeddings for rare words')
('distributional word embeddings', 'Used-for', 'linking visual to lexical information')
('neural word embeddings', 'Used-for', 'improving aspect coherence')
('type-level word embeddings', 'Part-of', 'word embeddings')
('temporal word analogies', 'Used-for', 'diachronic analysis of language change')
('sentiment analysis', 'Used-for', 'volatility prediction')
('DSWE', 'Is-a-Prerequisite-of', 'implicit discourse relation recognition')
('DSWE', 'Used-for', 'discourse analysis')
('Knowledge Graph embedding', 'Used-for', 'link prediction')
('aspect implicit opinion', 'Used-for', 'Aspect-Category-Opinion-Sentiment Quadruple Extraction')
('Aspect-Category-Opinion-Sentiment Quadruple Extraction', 'Part-of', 'aspect-based sentiment analysis')
('Restaurant-ACOS', 'Used-for', 'Aspect-Category-Opinion-Sentiment Quadruple Extraction')
('Laptop-ACOS', 'Used-for', 'Aspect-Category-Opinion-Sentiment Quadruple Extraction')
('aspect-based sentiment analysis', 'Evaluate-for', 'extracting and describing implicit aspects and opinions')
('Stochastic Gradient Descent', 'Used-for', 'learning word representations')
('AllVec', 'Compare', 'Stochastic Gradient Descent')
('Plagdet', 'Evaluate-for', 'plagiarim detection')
('Dialogue State Tracking', 'Part-of', 'Natural Language Processing')
('Neural Machine Translation', 'Used-for', 'Japanese-English translation task')
('Discourse Parsing', 'Used-for', 'identifying long-span dependencies between discourse units')
('Vision-and-Language Navigation', 'Is-a-Prerequisite-of', 'language understanding')
('Dialogue State Tracking', 'Used-for', 'handling unknown slot values')
('Neural Language Generation', 'Used-for', 'data refinement')
('Cross-lingual Transfer', 'Used-for', 'building syntactic analysis tools')
('Norm-based Curriculum Learning', 'Used-for', 'improving training efficiency in NMT systems')
('MixText', 'Used-for', 'text classification')
('Recurrent Neural Networks', 'Used-for', 'Language Modeling')
('Stochastic Gradient Markov Chain Monte Carlo', 'Used-for', 'Training Recurrent Neural Networks')
('Neural Language Model Incorporating Document Context', 'Hyponym-Of', 'Language Models')
('Affect-LM', 'Used-for', 'Generating Emotionally Colored Conversational Text')
('Hierarchical LSTM', 'Used-for', 'Generating Word Sequences')
('Token-Level Loss Smoothing', 'Evaluate-for', 'Improving Language Model Predictions')
('Query Auto-Completion', 'Used-for', 'Generating Completed Search Queries')
('fake news detection', 'Is-a-Prerequisite-of', 'reasoning over evidence')
('fake news detection', 'Used-for', 'preventing misinformation on social media')
('fake news detection', 'Used-for', 'maintaining a healthy society')
('LIAR dataset', 'Used-for', 'fake news detection')
('convolutional neural network', 'Used-for', 'integrating metadata with text')
('style analysis', 'Evaluate-for', 'distinguishing hyperpartisan news from mainstream')
('hyperpartisan news', 'Compare', 'mainstream news')
('stylometry', 'Evaluate-for', 'fake news detection')
('CompareNet', 'Used-for', 'comparing news to knowledge base for fake news detection')
('graph neural model', 'Used-for', 'fake news detection')
('social media framework', 'Part-of', 'fake news spread')
('inference operators', 'Used-for', 'revealing unobserved interactions in social media')
('NEP framework', 'Used-for', 'improving performance of fake news detectors')
('CCD framework', 'Used-for', 'debiasing multi-modal fake news detection')
('causal intervention', 'Used-for', 'removing psycholinguistic bias')
('counterfactual\n(Named Entity Recognition NER', 'Used-for', 'Information Extraction')
('Named Entity Recognition NER', 'Used-for', 'Mention Detection MD')
('Named Entity Recognition NER', 'Part-of', 'Natural Language Processing')
('Long Short Term Memory', 'Used-for', 'predicting sequences')
('Hidden Markov Model', 'Part-of', 'sequence aggregation methods')
('Gazetteers', 'Used-for', 'Named Entity Recognition NER')
('Lexical resources', 'Used-for', 'Part-of-Speech induction')
('Feedforward Neural Network', 'Used-for', 'Local Detection Approach')
('Named Entity Recognition NER', 'Is-a-Prerequisite-of', 'Alias Identification')
('Named Entity Recognition NER', 'Evaluate-for', 'improving topic quality in topic modeling')
('Cross-lingual Named Entity Recognition', 'Used-for', 'NER in multiple languages')
('Markov Logic Network', 'Used-for', 'Alias Identification')
('Bidirectional LSTM', 'Used-for', 'Named Entity Recognition')
('Multilingual learning', 'Used-for', 'Neural Named Entity Recognition NER')
('Domain adaptation', 'Used-for', 'Named Entity Recognition NER')
('Multi-\n(treebank embeddings', 'Used-for', 'training monolingual dependency parsers')
('treebank embeddings', 'Compare', 'concatenation strategies')
('treebank embeddings', 'Evaluate-for', 'flexibility and extensibility')
('treebank embedding vector', 'Used-for', 'selecting training data from preferred treebanks')
('treebank embedding vector', 'Used-for', 'testing preferred treebanks')
('fine-tuning', 'Evaluate-for', 'improving parser performance')
('fine-tuning', 'Part-of', 'training strategies for dependency parsers')
('concatenation strategies', 'Used-for', 'training monolingual dependency parsers')
('concatenation strategies', 'Is-a-Prerequisite-of', 'treebank embeddings')
('fact checking model', 'Used-for', 'verifying the truthfulness of claims')
('fact checking model', 'Is-a-Prerequisite-of', 'manual evaluation')
('fact checking model', 'Used-for', 'retrieving authoritative evidence')
('fact checking model', 'Evaluate-for', 'claim veracity')
('fact checking model', 'Used-for', 'detecting misinformation and disinformation')
('manual fact checking', 'Compare', 'automatic fact checking')
('manual fact checking', 'Part-of', 'fact checking model')
('automatic fact checking', 'Part-of', 'fact checking model')
('claim veracity', 'Evaluate-for', 'fact checking model')
('claim matching', 'Used-for', 'scaling fact checking')
('FEVER', 'Used-for', 'benchmarking fact checking models')
('multilingual models', 'Used-for', 'evaluating in diverse languages')
('FEVER score', 'Evaluate-for', 'fact checking models')
('generating summary', 'Is-a-Prerequisite-of', 'salient information selection')
('generating summary', 'Used-for', 'multi-document summarization')
('generating summary', 'Used-for', 'single document summarization')
('encoder-decoder framework', 'Used-for', 'generating summary')
('multi-modal hierarchical attention', 'Used-for', 'generating summary')
('semantic units', 'Part-of', 'natural language sentence')
('encoder', 'Part-of', 'encoder-decoder framework')
('decoder', 'Part-of', 'encoder-decoder framework')
('COREQA', 'Used-for', 'generating summary')
('data-to-text generation model', 'Used-for', 'generating summary')
('Gaussian focal bias', 'Used-for', 'generating summary')
('saliency-selection network', 'Used-for', 'generating summary')
('Natural Language\n(language technology', 'Used-for', 'natural language processing')
('natural language processing', 'Part-of', 'Artificial Intelligence')
('Artificial Intelligence', 'Used-for', 'LegalAI')
('LegalAI', 'Used-for', 'benefiting tasks in the legal domain')
('language technology', 'Used-for', 'promoting multilingualism')
('language technology', 'Used-for', 'linguistic diversity')
('speech translation', 'Part-of', 'language technology')
('language technology', 'Used-for', 'machine translation')
('machine translation', 'Evaluate-for', 'overcoming language barriers')
('language technology', 'Evaluate-for', 'NLP systems quality')
('NLP systems', 'Hyponym-Of', 'language technology')
('language technology', 'Is-a-Prerequisite-of', 'computational linguistics')
('seq2seq text generation', 'Used-for', 'language entailment generation')
('seq2seq text generation', 'Hyponym-Of', 'text generation')
('video captioning', 'Is-a-Prerequisite-of', 'seq2seq text generation')
('language entailment generation', 'Is-a-Prerequisite-of', 'seq2refseq text generation')
('machine translation', 'Used-for', 'seq2seq text generation')
('formality style transfer', 'Used-for', 'seq2seq text generation')
('sentence compression', 'Used-for', 'seq2seq text generation')
('sentence simplification', 'Used-for', 'seq2seq text generation')
('text generation', 'Part-of', 'NLP')
('NLP', 'Used-for', 'seq2seq text generation')
('NLP', 'Part-of', 'computer science')
('automatic grammatical error correction', 'Evaluate-for', 'seq2seq text generation')
('neural network rnns', 'Part-of', 'Natural Language Processing')
('recurrent neural networks', 'Is-a-Prerequisite-of', 'language modeling')
('stochastic gradient Markov Chain Monte Carlo', 'Used-for', 'learning weight uncertainty in RNNs')
('deep pyramid CNN', 'Used-for', 'text categorization')
('neural network rnns', 'Used-for', 'dialog systems')
('Neural Symbolic Machine', 'Part-of', 'neural network rnns')
('linear associative units', 'Used-for', 'reducing gradient propagation in RNNs')
('end-to-end learning', 'Hyponym-Of', 'training techniques for RNNs')
('neural network rnns', 'Used-for', 'sequence transduction')
('Neural network rnns', 'Used-for', 'multi-task learning')
('adversarial multi-task learning', 'Used-for', 'alleviating feature space interference in neural network rnns')
('cross domain sentiment analysis', 'Is-a-Prerequisite-of', 'classifier for an unlabeled target domain')
('cross domain sentiment analysis', 'Used-for', 'predicting sentiment polarity')
('polarity orientation', 'Part-of', 'cross domain sentiment analysis')
('word significance', 'Part-of', 'cross domain sentiment analysis')
('Integer Linear Programming', 'Used-for', 'syntactic constraints')
('syntactic features', 'Used-for', 'sentence compression')
('KinGDOM framework', 'Used-for', 'cross domain sentiment analysis')
('sentiment classifier', 'Evaluate-for', 'unlabeled target domain')
('BERT', 'Used-for', 'unsupervised domain adaptation')
('domain-specific features', 'Hyponym-Of', 'domain features')
('Adversarial Soft Prompt Tuning method', 'Used-for', 'cross domain sentiment analysis')
('cross domain named entity recognition', 'Compare', 'supervised domain adaptation methods')
('cross-modal attribute insertions', 'Used-for', 'text-to-image retrieval')
('identifiability attention', 'Part-of', 'Attention mechanism')
('Attention mechanism', 'Used-for', 'NLP tasks')
('identifiability attention', 'Evaluate-for', 'trustworthiness of a model’s predictions')
('Attention weights', 'Compare', 'Gradient update')
('Transformer', 'Used-for', 'explaining predictions')
('Attention weights', 'Hyponym-Of', 'Attention mechanism')
('identifiability attention', 'Is-a-Prerequisite-of', 'unique Attention weights')
('Encoder layer', 'Used-for', 'providing identifiable weights')
('Key vector', 'Used-for', 'generating Attention weights')
('Value vector', 'Conjunction', 'Key vector')
('dialogue model', 'Used-for', 'building dialog systems')
('dialogue model', 'Used-for', 'response generation')
('dialogue model', 'Is-a-Prerequisite-of', 'encoder-decoder architecture')
('dialogue model', 'Is-a-Prerequisite-of', 'belief tracker')
('dialogue model', 'Hyponym-Of', 'task-oriented dialogue systems')
('dialogue model', 'Hyponym-Of', 'open-domain dialogue systems')
('encoder-decoder architecture', 'Used-for', 'interpretable response generation')
('belief tracker', 'Used-for', 'estimating user’s goals')
('task-oriented dialogue systems', 'Part-of', 'intelligent assistants like Siri and Alexa')
('open-domain dialogue systems', 'Used-for', 'generating responses based on random variables')
('task-oriented dialogue systems', 'Evaluate-for', 'chat detection task')
('open-domain dialogue systems', 'Compare', 'task-oriented dialogue systems')
('neural language model', 'Used-for', 'sentence level processing')
('language model', 'Used-for', 'sentence level prediction')
('language model', 'Used-for', 'context incorporation')
('phonetic encoding', 'Used-for', 'training neural language models')
('neural language model', 'Part-of', 'automatic generation of rhythlical poetry')
('neural language model', 'Part-of', 'poetry generation')
('weighted finite state machine', 'Used-for', 'constraining generative models by form')
('constraint satisfaction problem', 'Is-a-Prerequisite-of', 'poetry generation')
('stochastic optimization', 'Evaluate-for', 'model uncertainty estimates')
('Markov Chain Monte Carlo', 'Used-for', 'learning weight uncertainty in RNNs')
('document context', 'Evaluate-for', 'language model perplexity improvement')
('LSTM', 'Part-of', 'Affect-LM')
('affective information', 'Used-for', 'emotionally colored word generation in language models')
('Bayesian model', 'Used-for', 'text segmentation based on stylistic features')
('c\n(Skip-Gram model', 'Part-of', 'word-embedding models')
('embedding model', 'Used-for', 'knowledge base completion')
('embedding model', 'Used-for', 'multimodal word distributions')
('embedding model', 'Used-for', 'self-learning approach for bilingual embeddings')
('ITransF', 'Hyponym-Of', 'embedding model')
('Gaussian mixtures', 'Used-for', 'multimodal word distributions in embedding model')
('embedding model', 'Used-for', 'document clustering')
('embedding model', 'Evaluate-for', 'performance on NER and chunking tasks')
('embedding model', 'Evaluate-for', 'semantic relationship modeling in networks')
('SGNS', 'Part-of', 'Skip-Gram Negative Sampling (SGNS')
('language understanding', 'Is-a-Prerequisite-of', 'natural language utterances mapping into executable programs')
('language understanding', 'Is-a-Prerequisite-of', 'development of natural-language understanding systems')
('statistical power of neural networks', 'Used-for', 'language understanding')
('symbolic reasoning', 'Used-for', 'language paragraphs')
('Neural Symbolic Machine', 'Used-for', 'language understanding')
('Lisp interpreter', 'Used-for', 'program execution for language understanding tasks')
('REINFORCE', 'Evaluate-for', 'optimizing language understanding prediction models')
('natural language', 'Hyponym-Of', 'language understanding')
('semantic parsing', 'Used-for', 'language understanding')
('Neural Belief Tracking', 'Used-for', 'language understanding in dialogue systems')
('transductive learning approach', 'Used-for', 'improving language understanding in hypernym prediction')
('ParaNMT-50M', 'Used-for', 'improving downstream language understanding tasks')
('cross-lingual\n(paraphrase generation', 'Used-for', 'expanding natural language datasets')
('paraphrase generation', 'Used-for', 'training robust machine learning systems')
('paraphrase generation', 'Used-for', 'improving downstream natural language understanding tasks')
('crowdsourcing', 'Used-for', 'paraphrase generation')
('ParaNMT-50M', 'Used-for', 'paraphrase generation')
('neural machine translation', 'Used-for', 'generating paraphrase pairs')
('DNPG', 'Hyponym-Of', 'neural models for paraphrase generation')
('unsupervised domain adaptation', 'Evaluate-for', 'paraphrase generation')
('semantic parsing', 'Is-a-Prerequisite-of', 'code generation from natural language')
('grammar model', 'Used-for', 'capturing syntax in code generation')
('neural architecture', 'Part-of', 'semantic parsing approach\n(None')
('aspect based sentiment analysis', 'Is-a-Prerequisite-of', 'aspect extraction')
('aspect based sentiment analysis', 'Is-a-Prerequisite-of', 'aspect sentiment classification')
('aspect based sentiment analysis', 'Used-for', 'determine sentiment polarity towards specific aspect in online reviews')
('aspect extraction', 'Part-of', 'aspect based sentiment analysis')
('aspect extraction', 'Used-for', 'identifying specific aspects or entities in the text')
('aspect extraction', 'Conjunction', 'aspect sentiment classification')
('aspect sentiment classification', 'Part-of', 'aspect based sentiment analysis')
('aspect sentiment classification', 'Used-for', 'classify sentiment expressed toward extracted aspect')
('aspect term-polarity co-extraction', 'Part-of', 'aspect based sentiment analysis')
('aspect term extraction', 'Used-for', 'extracting aspects from opinion document')
('aspect sentiment classification', 'Used-for', 'identifying sentiment about extracted aspect')
('bias nlp', 'Used-for', 'mitigating effects of bias in machine translation')
('bias nlp', 'Used-for', 'improving fairness in automatic hate speech detection')
('bias nlp', 'Evaluate-for', 'predictive bias framework assessment')
('predictive bias framework', 'Is-a-Prerequisite-of', 'bias nlp')
('mitigation techniques', 'Used-for', 'reducing bias in nlp')
('bias nlp', 'Hyponym-Of', 'natural language processing')
('None', 'Used-for', 'Distant supervision')
('Distant supervision', 'Compare', 'Manual annotation process')
('Transition matrix', 'Used-for', 'Characterizing noise')
('Curriculum learning', 'Used-for', 'Training transition matrix')
('Relation extraction', 'Is-a-Prerequisite-of', 'Distant supervision')
('Argument mining', 'Hyponym-Of', 'Relation extraction')
('SVM', 'Used-for', 'Argument mining')
('RNN', 'Used-for', 'Argument mining')
('Implicit discourse relation classification', 'Compare', 'Connective-based classification')
('Model distillation', 'Used-for', 'Cross-lingual text classification')
('Adversarial feature adaptation', 'Used-for', 'Reducing distribution mismatch in CLTC')
('Sentence-level sentiment classification', 'Hyponym-Of', 'Sentiment classification')
('Neural network models', 'Used-for', 'Sentence-level sentiment classification')
('Linguistic resources', 'Evaluate-for', 'Sentiment expression')
('Temporal relation classification', 'Hyponym-Of', 'Relation extraction')
('Question classification', 'Evaluate-for', 'Utilizing answer data')
('multilingual model', 'Used-for', 'language identification on diverse linguistic data')
('embedding learning by concept induction', 'Part-of', 'multilingual model')
('multilingual connotation frames', 'Part-of', 'multilingual model')
('multi-task learning framework', 'Is-a-Prerequisite-of', 'multilingual model')
('semantic parsing', 'Evaluate-for', 'multilingual model')
('language identification', 'Evaluate-for', 'multilingual model')
('multilingual model', 'Hyponym-Of', 'machine learning models')
('public sentiment analysis', 'Used-for', 'multilingual model')
('multilingual neural machine translation', 'Hyponym-Of', 'multilingual model')
('learning multilingual distributed representations of text', 'Used-for', 'multilingual model')
('generation semantic parsing', 'Is-a-Prerequisite-of', 'mapping natural language utterances into structured meaning representations')
('abstract syntax trees', 'Used-for', 'generation semantic parsing')
('neural network models', 'Used-for', 'generation semantic parsing')
('parse', 'Used-for', 'generation semantic parsing')
('code generation', 'Conjunction', 'generation semantic parsing')
('natural language utterances', 'Evaluate-for', 'generation semantic parsing')
('executable programs', 'Evaluate-for', 'generation semantic parsing')
('chinese word segmentation cws', 'Part-of', 'natural language processing')
('chinese word segmentation cws', 'Is-a-Prerequisite-of', 'chinese NLP tasks')
('statistical segmentation', 'Used-for', 'chinese word segmentation cws')
('neural models', 'Used-for', 'chinese word segmentation cws')
('subword units', 'Evaluate-for', 'neural machine translation')
('cross-domain CWS', 'Used-for', 'chinese word segmentation cws')
('word embeddings', 'Used-for', 'dependency parsing')
('joint CWS and POS tagging', 'Is-a-Prerequisite-of', 'chinese language processing')
('subword regularization', 'Used-for', 'neural machine translation NMT')
('neural graph matching networks', 'Used-for', 'chinese short text matching')
('Chinese short text matching', 'Evaluate-for', 'multi-granular input information')
('semantic representation', 'Is-a-Prerequisite-of', 'linguistic representation')
('Morph-fitting procedure', 'Used-for', 'improving linguistic representation')
('low-frequency word estimates', 'Used-for', 'enhancing linguistic representation')
('Long-tail phenomena', 'Evaluate-for', 'linguistic representation')
('semantic parsing', 'Part-of', 'linguistic representation')
('dialogue state tracking', 'Used-for', 'testing linguistic representation effectiveness')
('Word representation', 'Part-of', 'linguistic representation')
('Morphological constraints', 'Used-for', 'refining linguistic representation')
('Semantic models', 'Used-for', 'developing linguistic representation frameworks')
('Neural machine translation', 'Evaluate-for', 'linguistic representation performance')
('None', 'Part-of', 'Semitic languages')
('morphological feature', 'Used-for', 'disambiguate ambiguous lexical choices')
('morphological feature', 'Is-a-Prerequisite-of', 'joint modeling')
('lexicalized', 'Used-for', 'context modeling')
('non-lexicalized', 'Compare', 'lexicalized')
('diacritized forms', 'Hyponym-Of', 'lexicalized')
('gender', 'Hyponym-Of', 'non-lexicalized')
('number', 'Hyponym-Of', 'non-lexicalized')
('part-of-speech tags', 'Hyponym-Of', 'non-lexicalized')
('Modern Standard Arabic', 'Evaluate-for', 'joint modeling')
('Egyptian Arabic', 'Evaluate-for', 'joint modeling')
('noise', 'Compare', 'standard orthography')
('unsupervised semantic parsing', 'Is-a-Prerequisite-of', 'learning from unlabeled data')
('unsupervised semantic parsing', 'Used-for', 'semantic frame induction')
('semantic frame induction', 'Used-for', 'unsupervised semantic parsing')
('unsupervised semantic parsing', 'Hyponym-Of', 'semantic parsing')
('semantic parsing', 'Part-of', 'natural language processing')
('unsupervised semantic parsing', 'Evaluate-for', 'parsing natural language into formal meaning representations')
('formal meaning representations', 'Used-for', 'semantic parsing')
('unsupervised semantic parsing', 'Compare', 'supervised semantic parsing')
('unsupervised semantic parsing', 'Used-for', 'dependency tree inference')
('dependency tree', 'Part-of', 'unsupervised semantic parsing')
('unsupervised semantic parsing', 'Used-for', 'Semantic Textual Similarity tasks')
('language model trained', 'Used-for', 'generation of rhythmic poetry')
('language model trained', 'Used-for', 'learning a representation of content')
('phonetic encoding', 'Part-of', 'language model trained')
('neural language model', 'Hyponym-Of', 'language model trained')
('stochastic gradient Markov Chain Monte Carlo', 'Used-for', 'training language model trained')
('language model trained', 'Used-for', 'generation of conversational text conditioned on affect categories')
('affective information', 'Evaluate-for', 'improving language model prediction')
('language model trained', 'Used-for', 'creating artificial code-mixed language data')
('training curriculum', 'Evaluate-for', 'reducing perplexity in language model trained')
('reward augmented maximum likelihood', 'Used-for', 'training language model trained')
('statistical NLP', 'Used-for', 'feature extraction')
('message passing algorithm', 'Used-for', 'restructuring feature templates')
('pointer network', 'Used-for', 'extracting unknown slot values')
('SGD with negative sampling', 'Used-for', 'learning word representations')
('plagdet', 'Evaluate-for', 'plagiarism detection')
('dialogue state tracking', 'Evaluate-for', 'handling unknown slot values')
('Beam search', 'Used-for', 'Neural Machine Translation')
('transition-based discourse parser', 'Used-for', 'discourse parsing')
('neural machine translation', 'Evaluate-for', 'low-resource conditions')
('cross-lingual transfer', 'Used-for', 'syntactic analysis')
('Span-ConveRT', 'Used-for', 'dialog slot-filling')
('masked language model', 'Used-for', 'natural language understanding')
('autoregressive language model', 'Used-for', 'natural language generation')
('contextualized word used_embedding', 'Used-for', 'argument classification')
('contextualized word embeddings', 'Evaluate-for', 'classifying topic-dependent arguments')
('contextualized word embeddings', 'Evaluate-for', 'clustering topic-dependent arguments')
('BERT', 'Hyponym-Of', 'contextualized word embeddings')
('ELMo', 'Hyponym-Of', 'contextualized word embeddings')
('contextualized word embeddings', 'Compare', 'non-contextual subword embeddings')
('contextualized word embeddings', 'Used-for', 'multilingual named entity recognition')
('contextualized word embeddings', 'Used-for', 'part-of-speech tagging')
('multi-lingual neural relation extraction framework', 'Used-for', 'lingual transfer')
('cross-lingual attention', 'Used-for', 'lingual transfer')
('cross-lingual transfer method', 'Used-for', 'paradigm completion')
('mono-lingual attention', 'Part-of', 'multi-lingual neural relation extraction framework')
('cross-lingual attention', 'Part-of', 'multi-lingual neural relation extraction framework')
('cross-lingual transfer', 'Evaluate-for', 'lingual transfer effectiveness')
('cross-lingual syntactic variation', 'Is-a-Prerequisite-of', 'lingual transfer')
('Universal Dependencies', 'Used-for', 'standardizing cross-lingual transfer')
('language relatedness', 'Evaluate-for', 'ability to transfer morphological knowledge')
('multilingual datasets', 'Used-for', 'semantic parsing')
('syntax tree processing', 'Used-for', 'reducing anisomorphism')
('\n(None', 'Evaluate-for', 'sentiment classification')
('sentiment classification', 'Is-a-Prerequisite-of', 'polarity detection')
('sentiment classification', 'Is-a-Prerequisite-of', 'sarcasm detection')
('sentiment classification', 'Used-for', 'domain adaptation')
('sentiment classification', 'Used-for', 'active sentiment domain adaptation')
('sentiment classification', 'Used-for', 'discourse classification')
('sentiment classification', 'Used-for', 'polarity detection')
('sentiment classification', 'Compare', 'text classification')
('sentiment classification', 'Compare', 'sarcasm detection')
('Domain adaptation', 'Used-for', 'sentiment classification')
('active learning', 'Used-for', 'sentiment classification')
('sentiment words', 'Used-for', 'sentiment classification')
('cognitive features', 'Used-for', 'sentiment classification')
('gaze data', 'Used-for', 'sentiment classification')
('domain-specific sentiment similarities', 'Used-for', 'sentiment classification')
('sentiment lexicons', 'Used-for', 'sentiment classification')
('None', 'Used-for', 'chinese spelling correction')
('chinese spelling correction', 'Used-for', 'detect and correct spelling errors in Chinese natural language')
('SpellGCN', 'Used-for', 'chinese spelling correction')
('BERT', 'Evaluate-for', 'chinese spelling correction')
('PLOME', 'Used-for', 'chinese spelling correction')
('PHMOSpell', 'Used-for', 'chinese spelling correction')
('UMRSpell', 'Used-for', 'chinese spelling correction')
('Soft-Masked BERT', 'Used-for', 'chinese spelling correction')
('phonological and visual similarity knowledge', 'Used-for', 'chinese spelling correction')
('character prediction', 'Part-of', 'chinese spelling correction')
('pronunciation prediction', 'Part-of', 'chinese spelling override')
('confusion set', 'Used-for', 'chinese spelling correction')
('phonetic information', 'Used-for', 'chinese spelling correction')
('error detection', 'Part-of', 'chinese spelling correction')
('error correction', 'Part-of', 'chinese spelling correction')
('COREQA', 'Used-for', 'sequence-to-sequence learning')
('COREQA', 'Used-for', 'generating natural answers')
('COREQA', 'Part-of', 'end-to-end question answering systems')
('encoder-decoder framework', 'Part-of', 'COREQA')
('semantic units', 'Used-for', 'generating natural answer')
('FOIL-COCO', 'Evaluate-for', 'language and vision (LaVi')
('source code', 'Used-for', 'language generation')
('natural language descriptions', 'Used-for', 'generation of complex programs')
('GuessTwo', 'Evaluate-for', 'deep language understanding')
('natural language interfaces', 'Used-for', 'complex actions')
('neural sequence models', 'Used-for', 'mapping utterances directly to SQL')
('error detection', 'Used-for', 'supporting high-quality language resources')
('generative language model', 'Used-for', 'learning representations of content')
('generative language model', 'Used-for', 'constraining based on form')
('weighted finite state machine', 'Part-of', 'generative language model')
('neural language model', 'Used-for', 'language modeling')
('stochastic gradient Markov Chain Monte Carlo', 'Used-for', 'training generative language model')
('neural language model', 'Part-of', 'generative language model')
('neural language model', 'Evaluate-for', 'document context incorporation')
('neural language model', 'Used-for', 'generation of rhythmic poetry')
('constraint satisfaction problem', 'Evaluate-for', 'poetry generation')
('recurrent neural network', 'Used-for', 'language modeling')
('Bayesian learning algorithm', 'Used-for', 'training generative language model')
('document context', 'Is-a-Prerequisite-of', 'effective language modeling')
('stochastic\n(monolingural embeddings', 'Used-for', 'vector space representations of words')
('monolingural embeddings', 'Is-a-Prerequisite-of', 'bilingual word embeddings')
('cross-lingual signals', 'Used-for', 'connecting monolingural embeddings')
('parallel corpus', 'Used-for', 'supervising connection of monolingural embeddings')
('seed lexicon', 'Used-for', 'supervising connection of monolingural embeddings')
('unsupervised bilingual lexicon induction', 'Evaluate-for', 'performance of monolingual embeddings without supervision')
('natural adversarial game', 'Used-for', 'training monolingual embeddings without supervision')
('cross-lingual word embeddings', 'Part-of', 'bilingual tasks')
('domain adaptation', 'Used-for', 'enhancing performance of bilingual word embeddings')
('cross-lingual classification', 'Used-for', 'evaluating bilingual word embeddings')
('None', 'Is-a-Prerequisite-of', 'Domain Specific (DS')
('Generic word embeddings', 'Compare', 'Domain Specific (DS')
('Generic word embeddings', 'Hyponym-Of', 'embeddings')
('General-purpose embeddings', 'Conjunction', 'Domain-specific embeddings')
('General-purpose embeddings', 'Used-for', 'Aspect extraction')
('gated self-matching networks for reading comprehension', 'Is-a-Prerequisite-of', 'stanford question answering dataset(SQuAD')
('self-matching attention mechanism', 'Used-for', 'refine passage representation')
('pointer networks', 'Used-for', 'locate answer positions')
('constituent-centric neural architecture', 'Used-for', 'candidate answers generation')
('parse tree', 'Used-for', 'guide constituent-centric neural architecture')
('dynamic neural semantic parsing', 'Used-for', 'conversational question answering')
('Wikipedia', 'Used-for', 'open-domain question answering')
('EviNets', 'Used-for', 'factoid question answering')
('Universal schema', 'Used-for', 'natural language question answering')
('SciDTB', 'Used-for', 'evaluate discourse dependency parsers')
('DEISTE', 'Used-for', 'textual entailment in QA')
('morphological learning', 'Is-a-Prerequisite-of', 'morphological tagging')
('morphological learning', 'Used-for', 'boosting cross-lingual transfer')
('morphological analysis', 'Used-for', 'predicting syntactic traits')
('Universal Dependencies', 'Used-for', 'cross-lingual parser transfer')
('adversarial training', 'Used-for', 'knowledge-transfer scheme')
('neural machine translation', 'Used-for', 'machine translation')
('semantic role labeling', 'Used-for', 'high-level semantic analysis')
('neural networks', 'Used-for', 'modeling morphological features')
('character-level models', 'Evaluate-for', 'revealing morphological structure')
('multi-space variational encoder-decoders', 'Used-for', 'labeled sequence transduction')
('semi-supervised learning', 'Used-for', 'exploiting labeled and unlabeled data')
('factorial conditional random fields', 'Used-for', 'cross-lingual morphological tagging')
('morphological inflection', 'Hyponym-Of', 'morphological learning')
('generalization semantic parsing', 'Compare', 'compositional generalization semantic parsing')
('generalization semantic parsing', 'Used-for', 'mapping user utterances to executable programs')
('Hierarchical Semantic Parsing', 'Is-a-Prerequisite-of', 'generalization semantic parsing')
('semantic parsing', 'Part-of', 'generalization semantic parsing')
('zero-shot setting', 'Used-for', 'testing generalization of neural parsers')
('NQG-T5', 'Used-for', 'compositional generalization challenges on non-synthetic data')
('conversational semantic parsers', 'Used-for', 'generalization in parsing dialogue contexts')
('out-of-domain corpora', 'Used-for', 'testing generalization of neural parsers')
('Improve summarization system', 'Evaluate-for', 'ROUGE scores')
('Document summarization research', 'Is-a-Prerequisite-of', 'Improve summarization system')
('Factual correctness', 'Evaluate-for', 'Improve summarization system')
('Learning cross-sentence relations', 'Used-for', 'Improve summarization system')
('Neural models', 'Used-for', 'Improve summarization system')
('Human judgments', 'Used-for', 'Improve summarization system')
('Feedback-based concept selection', 'Used-for', 'Improve summarization system')
('word embeddings', 'Used-for', 'capturing linguistic regularities')
('textual adversarial attack', 'Evaluate-for', 'reducing classification accuracy')
('textual adversarial attack', 'Used-for', 'generating adversarial examples')
('neural machine translation', 'Used-for', 'translation tasks')
('textual adversarial attack', 'Used-for', 'vulnerability testing')
('adversarial examples', 'Part-of', 'textual adversarial attack')
('probability weighted word saliency', 'Used-for', 'textual adversarial attack')
('adversarial training', 'Used-for', 'improving robustness')
('unsupervised bilingual lexicon induction', 'Evaluate-for', 'word embeddings performance')
('cross-lingual connection', 'Hyponym-Of', 'word embeddings')
('text classification', 'Is-a-Prerequisite-of', 'understanding word embeddings')
('textual adversarial attack', 'Used-for', 'evaluating NLP system reliability')
('textual adversarial attack', 'Used-for', 'exposing pitfalls in NMT')
('adversarial attack', 'Hyponym-Of', 'textual adversarial attack')
('entity embeddings', 'Used-for', 'representing semantic information')
('entity embeddings', 'Hyponym-Of', 'word embeddings')
('entity embeddings', 'Used-for', 'link prediction')
('transductive learning', 'Used-for', 'mapping entities to hypernyms')
('Multi-Prototype Mention Embedding model', 'Used-for', 'learning multiple sense embeddings for entity mentions')
('Context-Await Network Embedding', 'Used-for', 'learning context-aware embeddings for network vertices')
('entity linking', 'Evaluate-for', 'entity embeddings')
('pretrained context embeddings', 'Used-for', 'enhancing NLP systems')
('Hybrid Code Networks', 'Used-for', 'dialogue system')
('dialogue system', 'Part-of', 'spoken dialogue systems')
('dialogue system', 'Part-of', 'task-oriented dialogue systems')
('encoder-decoder dialog model', 'Used-for', 'dialogue system')
('dialogue system', 'Used-for', 'chat detection')
('Neural Belief Tracking', 'Used-for', 'dialogue system')
('task-oriented dialogue systems', 'Is-a-Prerequisite-of', 'dialogue system')
('open-domain non-task-oriented dialogue systems', 'Hyponym-Of', 'dialogue system')
('bAbI dialog dataset', 'Evaluate-for', 'dialogue system')
('dialogue states', 'Part-of', 'dialogue system')
('Global-Locally Self-Attentive Dialogue State Tracker', 'Used-for', 'dialogue system')
('Mem2Seq', 'Used-for', 'dialogue system')
('chit-chat models', 'Used-for', 'dialogue system')
('dialogue system', 'Used-for', 'automatic diagnosis')
('multilingual masked language modeling', 'Used-for', 'cross-lingual transfer tasks')
('multilingual masked language modeling', 'Hyponym-Of', 'language modeling')
('BERT', 'Is-a-Prerequisite-of', 'multilingual masked language modeling')
('language-agnostic information', 'Used-for', 'multilingual masked language modeling')
('shared parameters', 'Evaluate-for', 'multilingual masked language modeling')
('XLM-R', 'Is-a-Prerequisite-of', 'multilingual masked language modeling')
('universal syntax', 'Used-for', 'improving multilingual masked language modeling')
('multilingual masked language modeling', 'Used-for', 'zero-shot training')
('interactive semantic parsing', 'Is-a-Prerequisite-of', 'natural language feedback correction')
('semantic parsing', 'Used-for', 'code generation')
('semantic parsing', 'Used-for', 'executing logical forms')
('interactive semantic processing', 'Compare', 'semantic parsing')
('natural language interaction', 'Conjunction', 'natural language feedback correction')
('interactive semantic parsing', 'Hyponym-Of', 'semantic parsing')
('SPLASH', 'Evaluate-for', 'natural language to SQL systems accuracy')
('interactive semantic parsing', 'Used-for', 'semantic parse correction with natural language feedback')
('semantic graphs', 'Part-of', 'semantic parsing')
('interactive semantic parsing', 'Used-for', 'improving semantic parsing models')
('human correction accuracy', 'Evaluate-for', 'interactive semantic parsing effectiveness')
('neural models', 'Used-for', 'mapping sentences to action sequences for semantic graph generation')
('machine reading comprehension', 'Used-for', 'answer prediction')
('gated self-matching networks', 'Used-for', 'machine reading comprehension')
('dynamic self-attention network', 'Used-for', 'multi-passage machine reading comprehension')
('question-aware passage representation', 'Part-of', 'machine reading comprehension')
('pointer networks', 'Used-for', 'locating answer positions in passages')
('ensemble model', 'Evaluate-for', 'machine reading comprehension performance')
('single model', 'Evaluate-for', 'machine reading comprehension performance')
('latent variable training', 'Used-for', 'model optimization in machine reading comprehension')
('attention-over-attention reader', 'Used-for', 'cloze-style machine reading comprehension')
('question answering', 'Used-for', 'assessing machine reading comprehension')
('SQuAD dataset', 'Used-for', 'evaluating machine reading comprehension models')
('cross-passage answer verification', 'Used-for', 'enhancing machine reading comprehension accuracy')
('multi-turn question answering', 'Used-for', 'in-depth machine reading comprehension')
('downstream tasks', 'Hyponym-Of', 'machine learning tasks')
('machine learning tasks', 'Part-of', 'natural language processing')
('language model', 'Evaluate-for', 'diachronic accuracy')
('language model', 'Used-for', 'natural language generation')
('natural language generation', 'Part-of', 'downstream tasks')
('language model', 'Used-for', 'query auto-completion')
('query auto-completion', 'Is-a-Prerequisite-of', 'search engine optimization')
('language model', 'Used-for', 'text generation')
('text generation', 'Part-of', 'downstream tasks')
('discourse structure', 'Used-for', 'text categorization')
('UCCA', 'Compare', 'other semantic DAG structures')
('UCCA', 'Part-of', 'semantic representation frameworks')
('recursive neural network', 'Used-for', 'computing text representation')
('attention mechanism', 'Used-for', 'focusing on salient content in text')
('composite deep neural network', 'Used-for', 'context sensitive lemmatization')
('discourse structure', 'Hyponym-Of', 'Rhetorical Structure Theory')
('SPIGOT', 'Used-for', 'backpropagation in neural networks')
('structured attention', 'Evaluate-for', 'discourse-relevant tasks')
('BIGPATENT', 'Used-for', 'training summary generation models')
('Discourse Representation Theory', 'Used-for', 'semantic parsing')
('structured attention', 'Used-for', 'text classification')
('generating corrective referring expressions REs', 'Used-for', 'emphasizing misunderstood information')
('natural language generation NLG', 'Used-for', 'creating responses in opinionated natural language generation ONLG')
('opinionated natural language generation ONLG', 'Used-for', 'generating subjective responses')
('natural language generation NLG', 'Compare', 'semantic parsing')
('natural language generation NLG', 'Is-a-Prerequisite-of', 'text similarity measures')
('text similarity measures', 'Used-for', 'paraphrase detection')
('text similarity measures', 'Used-for', 'textual entailment recognition')
('text similarity measures', 'Used-for', 'ranking relevance')
('text similarity measures', 'Evaluate-for', 'textual analysis')
('None', 'Used-for', 'answering user questions given a knowledge base text')
('conversational machine reading', 'Used-for', 'asking clarification questions')
('conversational machine reading systems', 'Evaluate-for', 'user question answering')
('conversational machine reading', 'Evaluate-for', 'determining user qualification for government benefits')
('decision rules', 'Part-of', 'conversational machine reading')
('E3', 'Is-a-Prerequisite-of', 'conversational machine reading')
('conversational history', 'Used-for', 'conversational machine reading')
('Entailment-driven Extract and Edit network', 'Hyponym-Of', 'conversational machine reading models')
('procedural text', 'Used-for', 'conversational machine reading')
('Summary', 'Used-for', 'Attracting readers')
('Coherent summary', 'Part-of', 'Summary')
('Neural abstractive multi-document summarization model', 'Used-for', 'Generating coherent summary')
('Graphs', 'Used-for', 'Guiding the summary generation process')
('Coherent summary', 'Evaluate-for', 'Increasing reader comprehension')
('Pre-trained language models', 'Used-for', 'Improving summarization performance')
('Extractive summarization', 'Compare', 'Abstractive summarization')
('Stylistic Headline Generation', 'Used-for', 'Enriching headlines')
('TitleStylist', 'Used-for', 'Generating stylistic headlines')
('Parameter sharing scheme', 'Used-for', 'Disentangling style from text')
('Gold-standard set', 'Is-a-Prerequisite-of', 'Extractive summarization')
('Summary/chapter pairs', 'Used-for', 'Training summarization models')
('Automatic metrics', 'Evaluate-for', 'Measuring improvement in summarization tasks')
('Pyramid analysis', 'Evaluate-for', 'Assessing summary quality')
('natural language generation', 'Is-a-Prerequisite-of', 'semantic parsing')
('natural language generation', 'Used-for', 'producing referring expressions (REs')
('natural language generation', 'Used-for', 'ONLG')
('natural language generation', 'Used-for', 'generating natural language descriptions of chess games')
('semantic parsing', 'Part-of', 'task natural language generation')
('ONLG', 'Part-of', 'task natural language generation')
('generating natural language descriptions of chess games', 'Part-of', 'task natural language generation')
('CLIP', 'Is-a-Prerequisite-of', 'contrastive visual semantic pretraining')
('contrastive visual semantic pretraining', 'Used-for', 'mitigating anisotropy in contextualized word embeddings')
('GPT-2', 'Compare', 'CLIP')
('contrastive visual semantic pretraining', 'Evaluate-for', 'zero-shot multimodal image classification')
('intra-layer self-similarity', 'Part-of', 'CLIP word embeddings')
('CLIP word embeddings', 'Used-for', 'word-level semantic intrinsic evaluation')
('CLIP word embeddings', 'Evaluate-for', 'RG65 evaluation')
('contrastive alignment pretraining', 'Is-a-Prerequisite-of', 'Doubly Aligned Multilingual Parser')
('Doubly Aligned Multigrated Parser', 'Used-for', 'improving mBERT transfer performance')
('Doubly Aligned Multilingual Parser', 'Compare', 'XLM-R')
('Doubly Aligned Multilingual Parser', 'Compare', 'mT5-Large')
('contrastive alignment pretraining', 'Evaluate-for', 'English performance improvement')
('orthography', 'Is-a-Prerequisite-of', 'disambiguate ambiguous lexical choices')
('lexicalized features', 'Hyponym-Of', 'morphological features')
('non-lexicalized features', 'Hyponym-Of', 'morphological features')
('lexicalized features', 'Conjunction', 'non-lexicalized features')
('lemmas', 'Part-of', 'lexicalized features')
('diacritized forms', 'Part-of', 'lexicalized features')
('gender', 'Part-of', 'non-lexicalized features')
('number', 'Part-of', 'non-lexicalized features')
('part-of-speech tags', 'Part-of', 'non-lexicalized features')
('joint modeling', 'Used-for', 'context modeling')
('Arabic', 'Evaluate-for', 'joint modeling')
('Modern Standard Arabic', 'Evaluate-for', 'joint modeling')
('Egyptian Arabic', 'Evaluate-for', 'joint modeling')
('generate coherent informative comment', 'Used-for', 'user engagement on online news platforms')
('graph-to-sequence model', 'Used-for', 'generate coherent informative comment')
('topic interaction graph', 'Used-for', 'understand the internal structure of the article')
('topic interaction graph', 'Used-for', 'connection between topics')
('graph-to-sequence model', 'Evaluate-for', 'coherent and informative comments generation')
('continuous latent variable', 'Used-for', 'capture various word patterns')
('type controller', 'Used-for', 'controlling sentence function')
('type controller', 'Evaluate-for', 'generating informative content')
('latent variable', 'Part-of', 'sentence function model')
('type controller', 'Part-of', 'sentence to function model')
('word embeddings', 'Used-for', 'semantic representations of words')
('word embeddings', 'Is-a-Prerequisite-of', 'neural network architectures for NLP tasks')
('word embeddings', 'Used-for', 'document analysis')
('word embeddings', 'Hyponym-Of', 'vector space representations')
('neural networks', 'Used-for', 'part-of-speech tagging')
('bilingual word embeddings', 'Used-for', 'cross-lingual sentiment classification')
('bilingual word embeddings', 'Hyponym-Of', 'word embeddings')
('self-learning approach', 'Used-for', 'reducing bilingual resource needs')
('dictionary-based mapping', 'Part-of', 'self-learning approach')
('Probabilistic FastText', 'Hyponym-Of', 'word embeddings')
('noise contrastive estimation', 'Used-for', 'learning word embeddings')
('sentiment analysis', 'Used-for', 'volatility prediction in financial markets')
('Domain Adapted\n(extractive summarization', 'Compare', 'abstractive summarization')
('extractive summarizer', 'Used-for', 'sentence-level attention')
('extractive summarizer', 'Is-a-Prerequisite-of', 'objective function')
('extractive summarizer', 'Evaluate-for', 'semantic relevance')
('ROUGE', 'Used-for', 'evaluating extractive summarization')
('Integer Linear Programming', 'Used-for', 'obtaining oracle summary for compressive summarization')
('document modeling', 'Used-for', 'extractive document summarization')
('distributional semantics model', 'Is-a-Prerequisite-of', 'language understanding systems')
('morph-fitting procedure', 'Used-for', 'improving distributional vector spaces')
('distributional semantics model', 'Used-for', 'evaluation of compositional semantics')
('morphological constraints', 'Used-for', 'improving distributional semantics model')
('Morphologically rich languages', 'Evaluate-for', 'distributional semantics model')
('low-frequency word forms', 'Part-of', 'distributional semantics model challenges')
('lexical relations', 'Hyponym-Of', 'distributional semantics model features')
('distributional semantics model', 'Used-for', 'tackling long-tail phenomena')
('distributional semantics model', 'Evaluate-for', 'semantic quality of word vector collection')
('distributional semantics model', 'Used-for', 'dialogue state tracking')
('distributional semantics model', 'Used-for', 'decoding brain activity patterns')
('sarcasm detection', 'Is-a-Prerequisite-of', 'satire detection')
('textual data analysis', 'Used-for', 'sarcasm detection')
('multimodal cues', 'Used-for', 'sarcasm detection')
('automatic classification', 'Used-for', 'satire detection')
('neural semantic parser', 'Used-for', 'converting natural language utterances to predicate-argument structures')
('predicate-argument structures', 'Used-for', 'mapping to target domains')
('neural semantic parser', 'Used-for', 'semantic parsing')
('neural MT models', 'Used-for', 'neural machine translation')
('deep neural networks', 'Used-for', 'automatically learning feature representations')
('cross-lingual word embedding', 'Part-of', 'multilingual pre-training')
('low-resource neural machine translation', 'Evaluate-for', 'multilingual pre-training effectiveness')
('multilingual pre-training', 'Is-a-Prerequisite-of', 'zero-shot translation')
('zero-shot translation', 'Evaluate-for', 'multilingual pre-training effectiveness')
('language-sensitive embedding', 'Part-of', 'multilingual translation strategies')
('multilingual model', 'Used-for', 'semantic parsing')
('multilingual translation', 'Used-for', 'language commonality exploitation')
('language commonality', 'Compare', 'parameter sharing')
('text generation', 'Part-of', 'natural language processing')
('natural language descriptions', 'Used-for', 'source code generation')
('neural architecture', 'Used-for', 'text generation')
('grammar model', 'Used-for', 'syntax capturing')
('affective information', 'Used-for', 'emotional text generation')
('Affect-LM', 'Is-a-Prerequisite-of', 'perception studies for emotional language')
('neural models', 'Used-for', 'abstractive summarization')
('neural models', 'Compare', 'extractive methods')
('TextFlow', 'Used-for', 'text similarity measures')
('sequence-to-sequence models', 'Used-for', 'video captioning')
('human evaluations', 'Evaluate-for', 'text generation models')
('neural semantic parsing', 'Used-for', 'semantic graph generation')
('neural language models', 'Hyponym-Of', 'text generation')
('sequence learning model', 'Used-for', 'automatic question generation')
('extractive summarization model', 'Is-a-Prerequisite-of', 'sentence selection')
('extractive summarization model', 'Conjunction', 'abstractive summarization model')
('sentence scoring', 'Part-of', 'extractive summarization model')
('sentence selection', 'Part-of', 'extractive summarization model')
('extractive summarization model', 'Used-for', 'generating summaries from key sentences')
('extractive summarization model', 'Evaluate-for', 'ROUGE scores')
('SWAP-NET', 'Hyponym-Of', 'extractive summarization model')
('extractive summarization model', 'Used-for', 'summarizing multi-document news articles')
('extractive summarization', 'Compare', 'abstractive summarization')
('commonsense knowledge base', 'Used-for', 'storing loosely structured open-text descriptions of knowledge')
('commonsense knowledge base', 'Is-a-Prerequisite-of', 'automatic commonsense KB completion')
('COMET', 'Used-for', 'generating explicit knowledge in commonsense knowledge base')
('Manual annotation', 'Used-for', 'forming linguistic common-sense knowledge bases')
('linguistic common-sense knowledge bases', 'Used-for', 'various NLP tasks')
('ATOMIC', 'Is-a-Prerequisite-of', 'COMET')
('ConceptNet', 'Is-a-Prerequisite-of', 'COMET')
('ATOMIC', 'Hyponym-Of', 'commonsense knowledge base')
('ConceptNet', 'Hyponym-Of', 'commonsense knowledge base')
('WSC', 'Evaluate-for', 'commonsense knowledge')
('ConceptFlow', 'Used-for', 'leveraging commonsense knowledge graphs')
('adversarial attack', 'Used-for', 'generating adversarial examples')
('adversarial training', 'Used-for', 'enhancing model robustness against adversarial attacks')
('adversarial examples', 'Evaluate-for', 'model robustness testing')
('adversarial attack', 'Is-a-Prerequisite-of', 'adversarial training')
('adversarial attack', 'Is-a-Prerequisite-of', 'creating robust neural networks')
('adversarial examples', 'Used-for', 'misleading neural models')
('attribute manipulation in adversarial examples', 'Evaluate-for', 'defense strategy development')
('model perturbation', 'Part-of', 'adversarial attack techniques')
('self-attentive models', 'Evaluate-for', 'robustness against adversarial inputs')
('prob\n(stereotypical human biases', 'Is-a-Prerequisite-of', 'bias category')
('gender bias', 'Hyponym-Of', 'bias category')
('ageism', 'Hyponym-Of', 'bias category')
('appearance biases', 'Hyponym-Of', 'bias category')
('CHBias', 'Used-for', 'bias category evaluation')
('debiasing methods', 'Evaluate-for', 'bias category mitigation')
('CHBias', 'Used-for', 'mitigation of Chinese conversational language models biases')
('word embeddings', 'Used-for', 'representing semantic regularities between words')
('word embeddings', 'Used-for', 'linking visual and lexical information')
('word embeddings', 'Compare', 'Gaussian embeddings')
('word embeddings', 'Compare', 'word2vec skip-grams')
('word embeddings', 'Evaluate-for', 'deriving embeddings for semantic word classifications')
('word embeddings', 'Evaluate-for', 'sentiment classification')
('word embeddings', 'Evaluate-for', 'domain-specific embedding learning')
('word embeddings', 'Is-a-Prerequisite-of', 'bilingual word embeddings')
('word embeddings', 'Is-a-Prerequisite-of', 'multimodal word distributions')
('word embeddings', 'Part-of', 'NLP systems')
('word embeddings', 'Hyponym-Of', 'type-level word embeddings')
('neural word segmentation', 'Used-for', 'improving NLP task accuracies')
('multimodal word distributions', 'Compare', 'word embeddings')
('multimodal word distributions', 'Compare', 'type-level word embeddings')
('multimodal word distributions', 'Used-for', 'capturing multiple word meanings')
('Abstractive summarization', 'Used-for', 'Covering salient points in a compact format')
('Query-based summarization', 'Used-for', 'Highlighting contextually relevant points')
('Abstractive summarization', 'Compare', 'Extractive summarization')
('Encode-attend-decode paradigm', 'Used-for', 'Abstractive summarization')
('Query attention model', 'Part-of', 'Encode-attend-decode paradigm')
('Diversity based attention model', 'Part-of', 'Encode-attend-decode paradigm')
('Document summarization', 'Hyponym-Of', 'Abstractive summarization')
('Neural models', 'Used-for', 'Abstractive summarization')
('Pointer-generator network', 'Part-of', 'Abstractive summarization')
('Coverage mechanism', 'Part-of', 'Abstractive summarization')
('Selective encoding model', 'Used-for', 'Abstractive sentence summarization')
('Sentence encoder', 'Part-of', 'Selective encoding model')
('language model', 'Used-for', 'sentence level processing')
('language model', 'Used-for', 'document context incorporation')
('RNN', 'Used-for', 'language modeling')
('LSTM', 'Hyponym-Of', 'RNN')
('language model', 'Part-of', 'Neural Symbolic Machine')
('language model', 'Part-of', 'COREQA')
('Affect-LM', 'Is-a-Prerequisite-of', 'emotionally colored word generation')
('language model', 'Used-for', 'generation of conversational text')
('Affect-LM', 'Hyponym-Of', 'language model')
('Kernel methods', 'Used-for', 'language learning')
('LSTM language model', 'Used-for', 'generation of conversational text conditioned on affect categories')
('Vision-and-Language Navigation', 'Is-a-Prerequisite-of', 'Agents interpret natural language instructions and visual scenes')
('Vision-and-Language Navigation', 'Used-for', 'Moving through environments and reach goals')
('Room-to-Room dataset', 'Evaluate-for', 'Vision-and-Language Navigation')
('Coverage weighted by Length Score', 'Used-for', 'Evaluating Vision-and-Language Navigation')
('Grounding instructions', 'Part-of', 'Vision-and-Language Navigation')
('Visual features', 'Used-for', 'Grounding natural language in visual environments')
('Route structure', 'Used-for', 'Grounding directional language instructions')
('Visual objects', 'Used-for', 'Grounding object-related language instructions')
('Vision-and-Language Navigation', 'Used-for', 'Navigating long paths with sequential instructions')
('Prompt-based Environmental Self-exploration', 'Used-for', 'Generating structured instructions for Vision-and-Language Navigation')
('fact-checking datasets', 'Used-for', 'training factual error correction systems')
('fact-checking datasets', 'Used-for', 'developing automated fact-checking models')
('fact-checking datasets', 'Used-for', 'evaluate multilingual fact-checking models')
('factual error correction', 'Part-of', 'fact-checking datasets')
('fake news detection', 'Used-for', 'employing fact-checking datasets')
('veracity assessment', 'Evaluate-for', 'fact-checking datasets')
('FACTIFY-5WQA', 'Part-of', 'fact-checking datasets')
('DialFact', 'Part-of', 'fact-checking datasets')
('FAVIQ', 'Part-of', 'fact-checking datasets')
('grammatical error correction gec', 'Used-for', 'correcting both global errors in word order and usage and local errors in spelling and inflection')
('grammatical error correction gec', 'Used-for', 'facilitating language learning')
('neural machine translation', 'Is-a-Prerequisite-of', 'grammatical error correction gec')
('nested attention mechanism', 'Used-for', 'correcting local errors in grammatical error correction gec')
('ERRANT', 'Used-for', 'error type evaluation in grammatical error correction gec')
('dependency parsing', 'Used-for', 'repairing grammatical errors')
('low coverage bias', 'Evaluate-for', 'GEC systems evaluation')
('seq2seq models', 'Used-for', 'grammatical error correction')
('maege', 'Used-for', 'metric validation in grammatical error correction gec')
('sentiment analysis absa', 'Used-for', 'predicting sentiment polarities')
('aspect classification', 'Is-a-Prerequisite-of', 'sentiment analysis absa')
('neural networks', 'Used-for', 'sentiment analysis absa')
('text processing', 'Used-for', 'sentiment analysis absa')
('sentiment classification', 'Hyponym-Of', 'sentiment analysis absa')
('aspect term extraction', 'Evaluate-for', 'sentiment analysis absa')
('sentiment expression', 'Used-for', 'sentiment analysis absa')
('machine learning models', 'Used-for', 'sentiment analysis absa')
('domain-specific embeddings', 'Used-for', 'sentiment analysis absa')
('multimodal aspect identification', 'Is-a-Prerequisite-of', 'sentiment analysis absa')
('Tandem Anchors', 'Used-for', 'interactive topic modeling')
('Generative Adversarial Network', 'Compare', 'Wasserstein autoencoders')
('Wasserstein autoencoders', 'Used-for', 'producing coherent topics')
('Maximum Mean Discrepancy', 'Used-for', 'distribution matching in topic models')
('Dirichlet distribution', 'Is-a-Prerequisite-of', 'Wasserstein autoencoders')
('Topic uniqueness metric', 'Evaluate-for', 'topic diversity')
('NPMI', 'Evaluate-for', 'topic coherence evaluation')
('HLTM systems', 'Used-for', 'Human-in-the-Loop Topic Modeling')
('Control metric', 'Evaluate-for', 'refinement operations in HLTM systems')
('Relation Extraction Method', 'Used-for', 'Finding Unknown Relational Facts')
('Relation Extraction Method', 'Used-for', 'Building Training Data')
('Mono-lingual Neural Relation Extraction Framework', 'Part-of', 'Relation Extraction Method')
('Cross-lingual Attention', 'Used-for', 'Utilizing Information Consistency')
('Relation Extraction', 'Evaluate-for', 'Multi-lingual Texts')
('Distant Supervision', 'Is-a-Prerequisite-of', 'Relation Extraction Method')
('Curriculum Learning', 'Used-for', 'Training Transition Matrix')
('Abstractive Summarization', 'Compare', 'Extractive Summarization')
('Joint Extraction of Entities and Relations', 'Is-a-Prerequisite-of', 'Tagging Scheme')
('Dependency Parsing', 'Used-for', 'Information Extraction')
('Neural Open IE Approach', 'Hyponym-Of', 'Relation Extraction Method')
('Graph-based Neural Network Model', 'Part-of', 'Relation Extraction Method')
('Deep Reinforcement Learning Strategy', 'Used-for', 'Noise Reduction in Distant Supervision')
('Seed Selection and Noise Reduction', 'Used-for', 'Enhancing Relation Extraction Method')
('gated self-matching networks', 'Used-for', 'task question answering')
('relation detection', 'Used-for', 'Knowledge Base Question Answering')
('dynamic neural semantic parsing', 'Used-for', 'task question answering')
('universal schema', 'Used-for', 'task question answering')
('TriviaQA', 'Used-for', 'task question answering')
('EviNets', 'Used-for', 'task question answering')
('hierarchical attention network', 'Used-for', 'task question answering')
('Named Entity Recognition', 'Used-for', 'Information Extraction')
('Named Entity Recognition', 'Used-for', 'Geographical Parsing')
('Chinese Named Entity Recognition', 'Hyponym-Of', 'Named Entity Recognition')
('Gazetteers', 'Used-for', 'Named Entity Recognition')
('Generalized Resource-Adversarial Discriminator', 'Used-for', 'Chinese Named Entity Recognition')
('Graph Neural Networks', 'Used-for', 'Chinese Named Entity Recognition')
('Lexical Resources', 'Used-for', 'Named Entity Recognition')
('Markable Identification', 'Part-of', 'Named Entity Recognition')
('Dual Adversarial Transfer Network', 'Used-for', 'Chinese Named Entity Recognition')
('Sequence Labeling', 'Is-a-Prerequisite-of', 'Named Entity Recognition')
('semantic parser', 'Used-for', 'converting natural language utterances to intermediate representations')
('intermediate representations', 'Part-of', 'semantic parser')
('predicate-argument structures', 'Used-for', 'representing intermediate representations')
('natural language representations', 'Hyponym-Of', 'intermediate representations')
('semantic parser', 'Is-a-Prerequisite-of', 'domain mapping')
('annotated logical forms', 'Used-for', 'training semantic parser')
('denotations', 'Used-for', 'training semantic parser')
('predicate-argument structures', 'Part-of', 'semantic parser')
('intermediate milestones', 'Used-for', 'structuring answer rationales')
('semantic parser', 'Evaluate-for', 'semantic parsing efficiency')
('COREQA', 'Used-for', 'end-to-end question answering')
('copying mechanisms', 'Used-for', 'natural language answer generation in COREQA')
('retrieving mechanisms', 'Used-for', 'natural language answer generation in COREQA')
('CommonsenseQA dataset', 'Evaluate-for', 'explanation prediction')
('explanation prediction', 'Used-for', 'refuting incorrect answers')
('positive and negative properties', 'Part-of', 'explanation prediction')
('ECQA dataset', 'Evaluate-for', 'explanation prediction')
('semantic-based evaluation metric', 'Evaluate-for', 'explanation prediction')
('None', 'Is-a-Prerequisite-of', 'detecting emotion from natural language')
('None', 'Is-a-Prerequisite-of', 'detecting contractual obligations and prohibitions')
('None', 'Is-a-Prerequisite-of', 'detecting critical plot twists in reviews')
('None', 'Is-a-Prerequisite-of', 'detecting sentiment from multimodal posts')
('None', 'Is-a-Prerequisite-of', 'detecting commonsense causal relations')
('detecting', 'Used-for', 'identifying emotion types')
('detecting', 'Used-for', 'classifying primary emotion dimensions')
('detecting', 'Used-for', 'improving linguistic understanding in machine translation')
('detecting', 'Used-for', 'de-identification in medical text')
('detecting', 'Used-for', 'spelling errors in texts')
('detecting', 'Used-for', 'disclosures of employment status on social media')
('correcting', 'Used-for', 'spelling errors in Chinese natural language')
('None', 'Is-a-Prerequisite-of', 'deep learning models')
('None', 'Compare', 'hierarchical BILSTM vs. flat BILSTM')
('Named Entity Recognition', 'Used-for', 'Improving Topic Quality')
('Named Entity Recognition', 'Used-for', 'Text Segmentation')
('Named Entity Recognition', 'Used-for', 'Part-of-Speech Induction')
('Named Entity Recognition', 'Used-for', 'Mention Detection')
('Named Entity Recognition', 'Evaluate-for', 'Cross-Lingual Applications')
('Named Entity Recognition', 'Evaluate-for', 'Multilingual Learning')
('Named Entity Recognition', 'Part-of', 'Natural Language Processing')
('Named Entity Recognition', 'Used-for', 'Markable Identification')
('Named Entity Recognition', 'Evaluate-for', 'Negation Detection')
('dataset bias', 'Is-a-Prerequisite-of', 'dataset difficulty')
('dataset bias', 'Evaluate-for', 'annotation artifacts')
('dataset bias', 'Evaluate-for', 'partial-input baselines')
('dataset bias', 'Evaluate-for', 'generalization and transfer in RC datasets')
('dataset bias', 'Used-for', 'improving dataset creation')
('Syntactic parsing', 'Used-for', 'modeling sentence structures')
('A* CCG parsing model', 'Part-of', 'syntactic parsing')
('SynTime', 'Evaluate-for', 'syntactic behaviour')
('Neural semantic parsing approach', 'Used-for', 'syntactic parsing')
('Grammar model', 'Used-for', 'syntactic parsing')
('Morpheme segmentation', 'Part-of', 'syntactic parsing')
('Morpho-syntactic regularities', 'Used-for', 'syntactic parsing')
('Bidirectional tree encoder', 'Used-for', 'syntactic parsing')
('Syntactic constraints', 'Used-for', 'sentence compression')
('Statistical discourse segmenters', 'Used-for', 'syntactic parsing')
('Constituency parsing scheme', 'Part-of', 'syntactic parsing')
('Syntactic distance', 'Used-for', 'constituency parsing scheme')
('Structure-aware neural architecture', 'Used-for', 'syntactic parsing')
('Source syntax', 'Evaluate-for', 'improvements in NMT')
('Sequential encoder-decoder framework', 'Is-a-Prerequisite-of', 'syntactic parsing')
('word embeddings trained', 'Used-for', 'discovering coherent aspects')
('neural word embeddings', 'Part-of', 'word embeddings trained')
('word embeddings trained', 'Used-for', 'creating synsets')
('word embeddings trained', 'Used-for', 'translation model training')
('word embeddings trained', 'Used-for', 'text-based user geolocation')
('word embeddings trained', 'Used-for', 'discourse-specific embedding learning')
('word embeddings trained', 'Used-for', 'sentiment analysis for volatility prediction')
('word embeddings trained', 'Used-for', 'improving text clustering methods')
('word embeddings trained', 'Used-for', 'MCI detection in neuropsychological assessments')
('distribution of word co-occurrences', 'Evaluate-for', 'word embeddings trained')
('dialogue learning', 'Is-a-Prerequisite-of', 'Hybrid Code Networks (HCNs')
('dialogue learning', 'Used-for', 'Semantic parsing')
('end-to-end neural dialogue generation', 'Used-for', 'dialogue learning')
('dialogue learning', 'Is-a-Prerequisite-of', 'Natural Language Understanding in dialog systems')
('dialogue learning', 'Used-for', 'Improving dialog systems interaction')
('dialogue learning', 'Is-a-Prerequisite-of', 'Task-completion dialogue agent training')
('dialogue learning', 'Evaluate-for', 'dialog state latency representation')
('dialogue learning', 'Used-for', 'dialogue state optimization')
('dialogue learning', 'Is-a-Prerequisite-of', 'Conversational model training')
('dialogue learning', 'Is-a-Prerequisite-of', 'Deep Dyna-Q framework application')
('dialogue learning', 'Used-for', 'adaptive conversational agents')
('dialogue learning', 'Used-for', 'dialogue systems that\n(None')
('neural language model', 'Part-of', 'trained language models (PLMs')
('constraint satisfaction', 'Used-for', 'poetry generation')
('phonetic encoding', 'Used-for', 'training neural language models')
('phonetic encoding', 'Part-of', 'first approach in poetry generation')
('weighted finite state machine', 'Used-for', 'constraining poetry generation models')
('Sequence-to-sequence models', 'Part-of', 'Deep neural networks')
('Deep neural networks', 'Hyponym-Of', 'Machine learning models')
('Machine reading', 'Used-for', 'Interpretable description')
('Variational autoencoders', 'Used-for', 'Interpretable semantics in dialog systems')
('DI-VAE', 'Is-a-Prerequisite-of', 'Variational autoencoders')
('DI-VST', 'Is-a-Prerequisite-of', 'Variational autoencoders')
('ESPRIT', 'Used-for', 'Interpretable description of physical events')
('Logic-based reasoning', 'Used-for', 'Interpretable rule inference for answering')
('Interpretable inference process', 'Evaluate-for', 'High interpretability in structured prediction')
('Deep neural networks', 'Compare', 'Rule-based models for interpretability')
('PhotoBook\n(AMR-to-text generation', 'Used-for', 'recover a text representing the same meaning as an AMR graph')
('sequence-to-sequence model', 'Used-for', 'AMR-to-text generation')
('LSTM', 'Used-for', 'encoding a linearized AMR structure')
('neural graph-to-sequence model', 'Used-for', 'directly encoding graph-level semantics')
('Seq2Seq', 'Part-of', 'abstractive text summarization models')
('source content of social media', 'Evaluate-for', 'learning accurate semantic representation')
('sequence labeling', 'Used-for', 'assigning labels to sequences in NLP tasks')
('Recurrent Neural Networks', 'Used-for', 'sequence labeling')
('GCDT', 'Used-for', 'enhancing global context in sequence labeling')
('multilingual Bible corpus', 'Used-for', 'evaluating language modeling')
('recurrent neural network language models', 'Used-for', 'language modeling')
('COREQA', 'Used-for', 'generating natural answers in question answering systems')
('visual question answering', 'Compare', 'tabular question answering')
('visual question answering', 'Compare', 'paragraph comprehension')
('visual question answering', 'Is-a-Prerequisite-of', 'understanding visual content')
('DS-QA', 'Used-for', 'open-domain question answering')
('DSMN', 'Used-for', 'geometric reasoning in visual question answering')
('question answering', 'Used-for', 'accessing knowledge from structured and unstructured sources')
('EviNets', 'Used-for', 'scoring candidate answers in factoid question answering')
('read comprehension', 'Is-a-Prerequisite-of', 'answering questions in visual question answering')
('neural network model', 'Used-for', 'dynamic representation of question aspects')
('semi-supervised question answering', 'Used-for', 'enhancing model performance using unlabeled data')
('attributions', 'Used-for', 'investigating model performance in visual question answering')
('domain sentiment classification', 'Is-a-Prerequisite-of', 'domain adaptation')
('domain sentiment classification', 'Used-for', 'sentiment feature analysis')
('sentiment feature analysis', 'Compare', 'source domain sentiment classifiers')
('sentiment feature analysis', 'Evaluate-for', 'domain sentiment classification')
('domain adaptation', 'Used-for', 'handling domain dependence in sentiment analysis')
('domain sentiment classification', 'Part-of', 'sentiment analysis')
('active sentiment domain adaptation', 'Used-for', 'domain sentiment classification')
('sentiment lexicons', 'Used-for', 'active sentiment domain adaptation')
('active learning', 'Used-for', 'label selection in domain sentiment classification')
('cross-lingual classification', 'Hyponym-Of', 'domain sentiment classification')
('string kernels', 'Used-for', 'automatic sentiment essay scoring')
('sentiment lexicon', 'Used-for', 'sentiment analysis')
('\n(visual semantic', 'Used-for', 'dataset analysis')
('dataset analysis', 'Part-of', 'visual reasoning language dataset')
('visual reasoning language tendrils', 'Used-for', 'broad set of linguistic phenomena analyzing')
('linguistic phenomena', 'Used-for', 'visual reasoning language dataset testing')
('visual reasoning language dataset', 'Evaluate-for', 'compositional distributional semantics models')
('Semantic Relevance Based neural model', 'Used-for', 'improve semantic relevance in summaries')
('semantic relevance', 'Hyponym-Of', 'semantic similarity')
('semantic similarity', 'Evaluate-for', 'source texts and summaries comparison')
('source text', 'Conjunction', 'summary')
('semantic role labeling', 'Is-a-Prerequisite-of', 'character-level semantic analysis')
('character-level semantic analysis', 'Part-of', 'high-level semantic tasks')
('semantic parsing', 'Used-for', 'transducing natural language into formal meaning representations')
('None', 'Used-for', 'neural machine translation')
('neural machine translation', 'Evaluate-for', 'performance')
('state-of-the-art', 'Compare', 'neural machine translation')
('bi-directional LSTM', 'Compare', 'convolutional neural network layers')
('neural machine translation', 'Used-for', 'English-Romanian translation')
('neural machine translation', 'Used-for', 'English-German translation')
('neural machine translation', 'Used-for', 'English-French translation')
('Deep Neural Networks', 'Used-for', 'neural machine translation')
('gradient diffusion', 'Part-of', 'RNNs')
('linear associative units', 'Used-for', 'reducing gradient propagation')
('layer-wise relevance propagation', 'Used-for', 'interpreting neural machine translation')
('posterior regularization', 'Used-for', 'integrating prior knowledge')
('chunks', 'Part-of', 'neural machine translation')
('NMT+RNNG', 'Hyponym-Of', 'neural machine translation')
('attention weight', 'Used-for', 'weighting words in sentiment analysis')
('attention weight', 'Used-for', 'determining importance of tokens in sequence tasks')
('attention weight', 'Used-for', 'controlling focus in multi-dimensional emotion regression')
('generative models', 'Part-of', 'natural language processing')
('sentiment analysis', 'Part-of', 'natural language processing')
('sequence tasks', 'Part-of', 'machine translation')
('multi-dimensional emotion regression', 'Part-of', 'natural language processing')
('hard attention mechanism', 'Compare', 'soft attention mechanism')
('average attention network', 'Used-for', 'enhancing expressiveness in neural networks')
('doubly-attentive decoder', 'Used-for', 'incorporating visual and textual features in translation')
('Monotonic Infinite Lookback', 'Used-for', 'balancing quality and latency in simultaneous machine translation')
('word embedding', 'Used-for', 'capturing linguistic regularities')
('word embedding', 'Used-for', 'vector space representation of words')
('Skip-Gram Negative Sampling model', 'Part-of', 'word embedding techniques')
('distributional word embeddings', 'Part-of', 'word embedding strategies')
('neural word embeddings', 'Part-of', 'word embedding methods')
('word embedding', 'Is-a-Prerequisite-of', 'aspect extraction in sentiment analysis')
('word embedding', 'Is-a-Prerequisite-of', 'semantic analysis')
('word embedding', 'Used-for', 'modeling word analogies')
('word embedding', 'Used-for', 'bilingual word embeddings learning')
('cross-lingual word embedding', 'Part-of', 'word embedding applications')
('temporal word embedding', 'Part-of', 'diachronical studies in word embedding')
('word embedding', 'Used-for', 'improving performance in NLP tasks\n(None')
('language processing', 'Part-of', 'Natural Language Processing')
('Natural Language Processing', 'Used-for', 'machine translation')
('Natural Language Processing', 'Used-for', 'automatic question answering')
('Natural Language Processing', 'Used-for', 'named entity recognition')
('language processing', 'Used-for', 'parsing sentences')
('language processing', 'Used-for', 'error detection')
('Natural Language Processing', 'Used-for', 'knowledge base completion')
('Natural Language Processing', 'Used-for', 'generating emotional language')
('Natural Language Processing', 'Used-for', 'modeling documents')
('Natural Language Processing', 'Used-for', 'studying linguistic data')
('language processing', 'Evaluate-for', 'generating empathetic natural language processing agents')
('language processing', 'Compare', 'modeling documents')
('A* CCG parsing model', 'Is-a-Prerequisite-of', 'English and Japanese CCG parsing')
('Generative models', 'Used-for', 'parsing and language modeling')
('parsing model', 'Used-for', 'recovering long-distance dependencies')
('parsing model', 'Used-for', 'syntactic analysis')
('Discriminative models', 'Compare', 'Generative models')
('Syntactic dependencies', 'Part-of', 'A* CCG parsing model')
('Factored model', 'Used-for', 'precomputation of all probabilities')
('Bi-directional LSTMs', 'Part-of', 'A* CCG parsing model')
('Encoder-decoder setting', 'Used-for', 'parsing and language modeling')
('Deep learning model', 'Evaluate-for', 'semantic role labeling')
('Bidirectional LSTM', 'Used-for', 'Japanese sentence compression modeling')
('form question answering', 'Used-for', 'accessing knowledge from knowledge bases')
('form question answering', 'Evaluate-for', 'efficiency in large document contexts')
('neural networks', 'Used-for', 'form question answering')
('cross-attention mechanism', 'Used-for', 'dynamic question representation in form question answering')
('knowledge bases', 'Evaluate-for', 'effectiveness in form question answering')
('form question answering', 'Is-a-Prerequisite-of', 'understanding and using underlying knowledge bases')
('form question answering', 'Used-for', 'leveraging semi-structured knowledge in Open IE for answering complex questions')
('reinforcement learning', 'Used-for', 'training form question answering models on semi-supervised data')
('dynamic neural semantic parsing', 'Used-for', 'sequential form question answering')
('natural language processing', 'Used-for', 'building form question answering systems')
('form question answering', 'Used-for', 'achieving state-of-the-art performance on QA datasets')
('EntSUM', 'Part-of', 'controllable summarization')
('semantic units', 'Used-for', 'controllable summarization')
('aspect-specific summaries', 'Part-of', 'controllable summarization')
('latent variables', 'Used-for', 'controllable summarization')
('conditional variational auto-encoder', 'Used-for', 'controllable summarization')
('user preferences', 'Evaluate-for', 'controllable summarization')
('inter-sentence relation extraction', 'Used-for', 'document-level relation extraction')
('multi-instance learning', 'Used-for', 'inter-sentence relation extraction')
('bi-affine pairwise scoring', 'Used-for', 'prediction of relation of an entity pair in inter-sentence relation extraction')
('labelled edge graph convolutional neural network', 'Used-for', 'inter-sentence relation extraction')
('neural models', 'Evaluate-for', 'performance on inter-sentence relation extraction')
('local and non-local dependency information', 'Used-for', 'improving inter-sentence relation extraction')
('semantic dependencies', 'Part-of', 'inter-sentence relation extraction')
('syntactic dependencies', 'Part-of', 'inter-sentence relation extraction')
('morphological task', 'Is-a-Prerequisite-of', 'language understanding systems')
('morphological task', 'Used-for', 'dialogue state tracking')
('morphological task', 'Used-for', 'morphological inflection generation')
('morphological task', 'Used-for', 'semantic role labeling')
('morphological task', 'Used-for', 'cross-lingual transfer')
('morphological task', 'Used-for', 'morphological disambiguation')
('morphological task', 'Used-for', 'morphological tagging')
('morphological constraints', 'Part-of', 'morph-fitting procedure')
('morphological inflection', 'Is-a-Prerequisite-of', 'morphological task')
('morphological tagging', 'Is-a-Prerequisite-of', 'morphological task')
('distributional vector space models', 'Evaluate-for', 'morphologically rich languages')
('language-specific rules', 'Used-for', 'generating morphological constraints')
('contextualized representation', 'Used-for', 'chunking')
('contextualized representation', 'Evaluate-for', 'capturing affect dimensions')
('contextualized representation', 'Is-a-Prerequisite-of', 'examining differences in portrayals of men and women')
('contextualized representation', 'Part-of', 'NLP systems')
('contextualized representation', 'Used-for', 'language understanding benchmarks')
('deep neural networks', 'Compare', 'kernel methods')
('kernel methods', 'Used-for', 'language learning and inference tasks')
('deep neural networks', 'Evaluate-for', 'learning feature representations')
('kernel methods', 'Is-a-Prerequisite-of', 'tree kernels')
('tree kernels', 'Used-for', 'achieving excellent performance in NLP')
('semantic representation', 'Evaluate-for', 'achieving general goals of research on semantic schemes')
('semantic representation', 'Compare', 'syntactic schemes')
('kernelized neural network', 'Hyponym-Of', 'deep neural networks')
('kernelized neural network\n(implicit discourse relation classification', 'Used-for', 'improving recognition')
('implicit discourse relation network', 'Used-for', 'learning salient features')
('implicit relation network', 'Is-a-Prerequisite-of', 'accurate classification')
('adversarial model', 'Used-for', 'adaptive imitation scheme')
('extractive summary', 'Hyponym-Of', 'document summarization')
('extractive summary', 'Used-for', 'conveying salient points')
('implicit connectives', 'Evaluate-for', 'implicit discourse relation classification')
('connectives', 'Used-for', 'driving learning in neural networks')
('neural network', 'Used-for', 'learning from data')
('feature discriminator', 'Used-for', 'competition in adversarial models')
('PDTB benchmark', 'Used-for', 'evaluating performance')
('abstractive summarization', 'Compare', 'extractive summary')
('query-based summarization', 'Used-for', 'highlighting relevant points')
('encode-attend-decode paradigm', 'Used-for', 'machine translation')
('encode-attend-decode paradigm', 'Used-for', 'dialog systems')
('query attention model', 'Used-for', 'focusing on different portions of the query')
('(topic aware news representation', 'Used-for', 'news recommendation')
('attention networks', 'Used-for', 'select important words')
('CNN networks', 'Used-for', 'learn representations of news from their titles')
('topic classification', 'Hyponym-Of', 'classification tasks')
('user encoder', 'Used-for', 'learn the representations of users')
('auxiliary topic classification task', 'Used-for', 'train news encoder')
('news encoder', 'Used-for', 'learn topic-aware news representations')
('relation extraction', 'Used-for', 'finding unknown relational facts')
('relation extraction', 'Evaluate-for', 'model performance')
('aspect extraction', 'Part-of', 'aspect-based sentiment analysis')
('neural relation extraction framework', 'Used-for', 'relation extraction')
('cross-lingual attention', 'Used-for', 'handling multi-lingual texts')
('mono-lingual attention', 'Used-for', 'utilizing mono-lingual texts')
('neural word embeddings', 'Used-for', 'improving coherence in aspect extraction')
('attention mechanism', 'Used-for', 'de-emphasizing irrelevant words')
('entity extraction', 'Used-for', 'knowledge base population')
('event extraction', 'Used-for', 'populating knowledge bases with events')
('hand-labeled data', 'Is-a-Prerequisite-of', 'traditional supervised event extraction methods')
('automatically labeled data', 'Used-for', 'training event extraction models')
('keyphrase prediction', 'Used-for', 'understanding text content')
('distant\n(transformer language model', 'Used-for', 'neural machine translation')
('transformer language model', 'Compare', 'LSTM-based models')
('transformer language model', 'Is-a-Prerequisite-of', 'language understanding')
('transformer language model', 'Part-of', 'neural language representation models')
('transformer language model', 'Evaluate-for', 'improving NLP task performance')
('Grammatical Error Correction', 'Is-a-Prerequisite-of', 'ERRANT')
('Grammatical Error Correction', 'Is-a-Prerequisite-of', 'Fluency boost learning and inference mechanism')
('Grammatical Error Correction', 'Is-a-Prerequisite-of', 'Cross-sentence context')
('Grammatical Error Correction', 'Is-a-Prerequisite-of', 'Soft-Masked BERT')
('Grammatical Error Correction', 'Is-a-Prerequisite-of', 'Neural machine translation')
('Grammatical Error Correction', 'Is-a-Prerequisite-of', 'error detection')
('Grammatical Error Correction', 'Is-a-Prerequisite-of', 'Encoder-decoder model')
('Grammatical Error Correction', 'Is-a-Prerequisite-of', 'Sequence-to-sequence model')
('Grammatical Error Correction', 'Is-a-Prerequisite-of', 'Nested attention mechanism')
('ERRANT', 'Used-for', 'Error type evaluation')
('Fluency boost learning and inference mechanism', 'Used-for', 'Sentence fluency improvement')
('aspect-based sentiment analysis', 'Used-for', 'predicting sentiment polarities')
('aspect-based sentiment analysis', 'Compare', 'general sentiment analysis')
('aspect term extraction', 'Part-of', 'aspect-based sentiment analysis')
('aspect term-polarity co-extraction', 'Part-of', 'aspect-based sentiment analysis')
('aspect-category sentiment analysis', 'Part-of', 'aspect-based sentiment analysis')
('aspect-term sentiment analysis', 'Part-of', 'aspect-based sentiment tovince analysis')
('aspect sentiment classification', 'Used-for', 'determining sentiment of specific aspects')
('sentiment polarity', 'Used-for', 'Aspect sentiment classification')
('sentiment polarity', 'Used-for', 'Target-oriented sentiment classification')
('sentiment polarity', 'Used-for', 'Open-domain targeted sentiment analysis')
('sentiment polarity', 'Part-of', 'sentiment analysis')
('Aspect sentiment classification', 'Evaluate-for', 'sentiment polarity')
('sentiment polarity', 'Used-for', 'Aspect Sentiment Classification towards Question-Answering')
('Aspect term-polarity co-extraction', 'Used-for', 'sentiment polarity identification')
('Deep convolutional neural networks', 'Used-for', 'sentiment polarity classification')
('Target-oriented sentiment classification', 'Is-a-Prerequisite-of', 'sentiment polarity classification')
('Open-domain targeted sentiment analysis', 'Used-for', 'sentiment polarity detection')
('None', 'Is-a-Prerequisite-of', 'goal oriented visual dialogue')
('goal oriented visual dialogue', 'Used-for', 'generating questions about an image')
('End-to-end training', 'Evaluate-for', 'goal oriented visual dialogue')
('Reinforcement learning', 'Used-for', 'goal oriented visual dialogue')
('goal oriented visual dialogue', 'Compare', 'chatbots')
('Multimodal dialogue systems', 'Evaluate-for', 'goal oriented visual dialogue')
('Rational Speech Act framework', 'Used-for', 'goal oriented visual dialogue')
('goal oriented visual dialogue', 'Hyponym-Of', 'dialogue systems')
('RNN', 'Compare', 'CNN')
('RNN', 'Part-of', 'DRNN')
('CNN', 'Part-of', 'DRNN')
('CNN', 'Used-for', 'multiple choice question answering')
('DRNN', 'Used-for', 'text categorization')
('RNN', 'Used-for', 'capturing long-term dependencies')
('CNN', 'Used-for', 'extracting local features')
('CNN', 'Used-for', 'position-invariant feature extraction')
('DRNN', 'Evaluate-for', 'text categorization')
('Text Categorization', 'Is-a-Prerequisite-of', 'DRNN')
('Multiple Choice Question Answering', 'Is-a-Prerequisite-of', 'CNN')
('LSTM', 'Compare', 'CNN')
('Textbook Question Answering', 'Evaluate-for', 'CNN')
('SciQ', 'Evaluate-for', 'CNN')
('fact checking', 'Used-for', 'verifying the truthfulness of a claim')
('fact checking', 'Used-for', 'saving effort in validating already checked claims')
('fact checking', 'Used-for', 'increasing the efficiency of news validation processes')
('fact checking', 'Is-a-Prerequisite-of', 'claim verification')
('claim verification', 'Part-of', 'fact checking')
('manual fact-checking', 'Used-for', 'verifying the truthfulness of a claim')
('automated fact checking', 'Used-for', 'predicting veracity of claims')
('fact checking', 'Evaluate-for', 'factual correctness of generated summaries')
('fact checking', 'Evaluate-for', 'stance detection in social media')
('automated fact checking', 'Evaluate-for', 'efficiency in clearing misinformation')
('claim verification accuracy', 'Used-for', 'evaluating fact checking systems')
('manual fact-checking', 'Compare', 'automated fact checking')
('\n(None', 'Is-a-Prerequisite-of', 'token-level loss smoothing')
('None', 'Is-a-Prerequisite-of', 'sequence-level loss smoothing')
('token-level loss smoothing', 'Conjunction', 'sequence-level loss smoothing')
('token-level loss smoothing', 'Used-for', 'improve model performance')
('sequence-level loss smoothing', 'Used-for', 'improve model performance')
('mutual-information-based decoding', 'Used-for', 'improve diversity and relevance of responses')
('reward-augmented maximum likelihood learning', 'Used-for', 'generate sentences close to the ground truth')
('ensemble method', 'Used-for', 'improve diversity and relevance of responses')
('exposure bias', 'Evaluate-for', 'training token prediction method')
('iterative training process', 'Used-for', 'enhance training effectiveness')
('visual question answering vqa', 'Used-for', 'answering questions based on images')
('visual question answering vqa', 'Evaluate-for', 'accuracy using attributions')
('accuracy', 'Hyponym-Of', 'evaluation metric')
('attributions', 'Used-for', 'strengthening adversarial attacks')
('visual question answering model', 'Evaluate-for', 'logical correctness via attributions')
('attributions', 'Evaluate-for', 'investigating model performance')
('adversarial attacks', 'Used-for', 'testing robustness of models')
('(question answer', 'Used-for', 'solving word analogies')
('question answer', 'Used-for', 'caption generation')
('question answer', 'Used-for', 'locating positions of answers in passages')
('word-vector compositionality', 'Used-for', 'solving word analogies')
('Skip-Gram model', 'Used-for', 'theoretical justification of additive compositionality in word vectors')
('Skip-Gram model', 'Part-of', 'word-embedding models')
('additive compositionality', 'Evaluate-for', 'word-vectors in Skip-Gram model')
('Sufficient Dimensionality Reduction', 'Hyponym-Of', 'dimensionality reduction')
('Skip-Gram model', 'Is-a-Prerequisite-of', 'obtain parameters for Sufficient Dimensionality Reduction models')
('gated self-matching networks', 'Used-for', 'question aware passage representation')
('COREQA', 'Used-for', 'generating natural language answers in question answering systems')
('relation detection', 'Is-a-Prerequisite-of', 'Knowledge Base Question Answering')
('Latent variable model', 'Used-for', 'question answering in reading comprehension')
('neural networks', 'Used-for', '(machine reading comprehension (MRC')
('reinforcement learning', 'Used-for', 'training the latent variable in sentence selection for MRC')
('BERT', 'Used-for', 'achieving state-of-the-art results in MRC')
('attention mechanisms', 'Part-of', 'machine reading comprehension (MRC')
('multi-choice reading comprehension', 'Hyponym-Of', 'machine reading comprehension (MRC')
('Gated self-matching networks', 'Used-for', 'reading comprehension style question answering')
('SQuAD leaderboard', 'Evaluate-for', 'performance of machine reading comprehension (MRC')
('domain-specific sentiment lexicons', 'Used-for', 'sentiment analysis')
('sentiment knowledge', 'Part-of', 'SemAxis')
('sentiment axis', 'Used-for', 'building domain-specific sentiment lexicons')
('SemAxis', 'Compare', 'state-of-the-art approaches in building domain-specific sentiment lexicons')
('computational psycholinguistics', 'Used-for', 'evaluating human reading behavior')
('computational psycholinguistics', 'Used-for', 'building human-like computational models')
('computational psycholinguistics', 'Is-a-Prerequisite-of', 'understanding human processing times through language models')
('neural language models', 'Evaluate-for', 'computational psycholinguistics')
('parameter size', 'Evaluate-for', 'psychometric quality in computational psycholinguistics')
('Transformer-based language models', 'Evaluate-for', 'generating probabilistic estimates for computational psycholinguistics')
('lingual cross modal', 'Used-for', 'aligning different views into a common semantic space')
('Unsupervised machine translation', 'Used-for', 'translating text using monolingual corpora')
('Multimodal back-translation', 'Used-for', 'promoting latent space alignment in unsupervised MMT')
('Bilingual lexicons', 'Used-for', 'mapping words to their translations')
('Premise-based Multi-modal Reasoning', 'Is-a-Prerequisite-of', 'visual commonsense reasoning')
('Cross-Modal Code Matching', 'Used-for', 'forcing similar distribution over discrete embedding space')
('Temporal Knowledge Graph', 'Used-for', 'studying relation patterns with temporality')
('Cross-view language modeling', 'Used-for', 'cross-lingual and cross-modal pre-training')
('character level language modeling', 'Used-for', 'creating word types not attested in the training corpus')
('character level language modeling', 'Used-for', 'handling new words with bursty distribution')
('character level language modeling', 'Evaluate-for', 'effectiveness across a range of languages')
('character level language modeling', 'Part-of', 'open-vocabulary language modeling')
('open-vocabulary language modeling', 'Used-for', 'extending capabilities of language models')
('open-vocabulary language modeling', 'Part-of', 'natural language processing')
('caching mechanism', 'Used-for', 'reusing previously generated words')
('neural language model', 'Used-for', 'poetry generation')
('constraint satisfaction problem', 'Used-for', 'poetry generation with form constraints')
('weighted finite state machine', 'Used-for', 'constraining language models')
('character embeddings', 'Used-for', 'processing rare characters')
('convolutional neural network', 'Used-for', 'producing visual character embeddings')
('monolingual word embeddings', 'Used-for', 'document analysis')
('monolingual word embeddings', 'Hyponym-Of', 'word embeddings')
('cross-lingual word embeddings', 'Is-a-Prerequisite-of', 'bilingual lexicon induction')
('cross-lingual word embeddings', 'Compare', 'monolingual word embeddings')
('distributional word embeddings', 'Part-of', 'vector space representations')
('word embeddings', 'Used-for', 'modeling linguistic regularities')
('vector space representations', 'Used-for', 'spectral clustering')
('neural word embeddings', 'Evaluate-for', 'aspect extraction')
('neural word embeddings', 'Used-for', 'improving coherence of aspects')
('word embeddings', 'Used-for', 'synset induction')
('Probabilistic FastText', 'Used-for', 'capturing multiple word senses')
('neural abstractive summarization', 'Used-for', 'document summarization')
('neural abstractive summarization', 'Used-for', 'generating summaries')
('neural abstractive summarization', 'Hyponym-Of', 'text summarization')
('neural abstractive summarization', 'Part-of', 'natural language processing')
('encoder-decoder model', 'Used-for', 'neural abstractive summarization')
('global encoding framework', 'Used-for', 'neural abstrategic summarization')
('global encoding framework', 'Evaluate-for', 'improving source-side information representation')
('multi-task learning', 'Used-for', 'improving performance of neural abstractive summarization')
('Hard Debias algorithm', 'Used-for', 'reducing gender bias')
('gender bias', 'Evaluate-for', 'translation quality in NMT')
('gender bias', 'Hyponym-Of', 'bias')
('English', 'Part-of', 'gender bias mitigation approaches')
('WinoMT', 'Used-for', 'measuring gender bias in machine translation')
('gender bias', 'Used-for', 'increased privacy in learned representations')
('Double Hard Debias', 'Used-for', 'preserving distributional semantics while reducing gender bias')
('feature attributions', 'Used-for', 'mitigating gender bias in classifiers')
('gender stereotypes', 'Is-a-Prerequisite-of', 'gender bias in NLP')
('unsupervised semantic parsing', 'Used-for', 'generating formal meaning representations without labeled data')
('semantic parsing', 'Used-for', 'transducing natural language utterances into formal meaning representations')
('StructVAE', 'Used-for', 'semi-supervised semantic parsing')
('Semantic parsing', 'Is-a-Prerequisite-of', 'natural language understanding')
('unsupervised semantic parsing', 'Part-of', 'natural language processing')
('unsupervised semantic parsing', 'Evaluate-for', 'limited labeled data scenarios')
('recurrent neural network rnns', 'Used-for', 'language modeling')
('recurrent neural network rnns', 'Hyponym-Of', 'neural networks')
('language modeling', 'Is-a-Prerequisite-of', 'machine translation')
('recurrent neural network rnns', 'Part-of', 'Hybrid Code Networks')
('recurrent neural network rnns', 'Evaluate-for', 'performance in dialog systems')
('recurrent neural network rnns', 'Used-for', 'dialog state representation')
('stochastic gradient Markov Chain Monte Carlo', 'Used-for', 'learning weight uncertainty in RNNs')
('recurrent neural network rnns', 'Used-for', 'sentence parsing')
('recurrent neural network rnns', 'Used-for', 'automatic question answering')
('sentence parsing', 'Used-for', 'Abstract Meaning Representation')
('Abstract Meaning Representation', 'Part-of', 'semantic content representation')
('None', 'Used-for', 'joint extraction of entity mentions and relations')
('LSTM', 'Used-for', 'extraction of entity mentions')
('attention-based recurrent neural network', 'Used-for', 'joint extraction of entity mentions and relations')
('Dependency trees', 'Evaluate-for', 'extraction of semantic relations')
('Joint extraction of entities and relations', 'Is-a-Prerequisite-of', 'information extraction')
('Tagging scheme', 'Used-for', 'converting joint extraction to a tagging problem')
('End-to-end models', 'Used-for', 'extraction of entities and relations')
('Distant supervision', 'Used-for', 'generating experimental datasets')
('Entity mention relation', 'Hyponym-Of', 'Joint extraction of entities and relations')
('Entity mention relation', 'Used-for', 'Information extraction')
('Entity typing task', 'Used-for', 'predicting types for entity mentions')
('Head words', 'Used-for', 'indicating the type in noun phrases')
('Ultra-fine types', 'Used-for', 'crowd-sourced entity typing evaluation')
('Knowledge Graph embedding', 'Used-for', 'link prediction')
('Relation compositions', 'Evaluate-for', 'interpreting Knowledge Graph embeddings')
('Entity mention\n(cross lingual embeddings', 'Used-for', 'cross-lingual transfer of NLP models')
('cross lingual embeddings', 'Used-for', 'bilingual lexicon induction')
('cross lingual embeddings', 'Used-for', 'cross-lingual classification')
('cross lingual embeddings', 'Used-for', 'cross-lingual sentiment classification')
('cross lingual embeddings', 'Used-for', 'cross-lingual word similarity')
('cross lingual embeddings', 'Used-for', 'cross-lingual document classification')
('cross lingual embeddings', 'Used-for', 'cross-lingual gender prediction')
('cross lingual embeddings', 'Used-for', 'cross-lingual coreference resolution')
('cross lingual embeddings', 'Is-a-Prerequisite-of', 'low-resource language NLP tasks')
('word embeddings', 'Compare', 'cross lingual embeddings')
('parallel corpus', 'Used-for', 'training cross lingual embeddings')
('seed lexicon\n(Graph Neural Network', 'Is-a-Prerequisite-of', 'semantic parsing')
('Graph Neural Network', 'Used-for', 'relation extraction')
('Graph Neural Networks', 'Hyponym-Of', 'neural networks')
('Semantic parsing', 'Used-for', 'building natural language interfaces')
('Semantic parsing', 'Used-for', 'query generation')
('Multi-channel Graph Neural Network', 'Used-for', 'Entity alignment')
('Multi-channel Graph Neural Network', 'Compare', 'Graph Neural Network')
('Transition matrices', 'Part-of', 'Graph Neural Network propagation module')
('Message passing', 'Used-for', 'Graph Neural Network inference')
('Graph Neural Network', 'Used-for', 'multi-hop relational reasoning')
('Semantic parsing', 'Used-for', 'generating logical forms with entities')
('Graph Neural Network', 'Part-of', 'Structured NLP pipelines')
('neural dialogue', 'Part-of', 'task-oriented dialogue systems')
('neural dialogue', 'Evaluate-for', 'naturalness of generated responses')
('multi-turn dialogue agent', 'Is-a-Prerequisite-of', 'neural dialogue')
('end-to-end training', 'Used-for', 'optimizing neural dialogue models')
('KB-InfoBot', 'Hyponym-Of', 'neural dialogue')
('neural model with dynamic knowledge graph embeddings', 'Used-for', 'evolving as the dialogue progresses in neural dialogue')
('Two Stage CopyNet', 'Evaluate-for', 'simplifying neural dialogue systems')
('automatic dialogue evaluation', 'Used-for', 'assessing performance of neural dialogue models')
('visual language grounding', 'Used-for', 'enhancing context understanding in neural dialogue systems')
('Multi-Prototype Mention Embedding', 'Part-of', 'Mention Embedding')
('Multi-Prototype Mention Embedding', 'Used-for', 'Disambiguation')
('Sentence Embeddings', 'Used-for', 'Probing Tasks')
('Multi-Prototype Mention Embedding', 'Evaluate-for', 'Entity Linking')
('Entity Linking', 'Is-a-Prerequisite-of', 'Multi-Prototype Mention Embedding')
('Mention Embedding', 'Part-of', 'Prototype Mention Embeddings')
('Textual Contexts', 'Used-for', 'Mention Embedding')
('Knowledge Base', 'Used-for', 'Entity Derivation')
('Sentence Embeddings', 'Compare', 'LASER Sentence Embeddings')
('LASER Sentence Embeddings', 'Hyponym-Of', 'Sentence Embeddings')
('Attention-based recurrent neural network', 'Used-for', 'Joint extraction of entity mentions and relations')
('Attention-based recurrent neural network', 'Evaluate-for', 'semantic relations between entity mentions')
('LSTM network', 'Part-of', 'Attention-based recurrent neural network')
('Semantic relations', 'Hyponym-Of', 'Annotated semantic relatedness')
('Annotated semantic relatedness', 'Used-for', 'Fact verification')
('Tree structures', 'Used-for', 'Semantic relatedness tasks')
('Analogical reasoning', 'Evaluate-for', 'Annotated semantic relatedness')
('Hierarchical text classification', 'Evaluate-for', 'Annotated semantic relatedness')
('Fact verification', 'Evaluate-for', 'Annotated semantic relatedness')
('Tree Aggregation Transformer', 'Used-for', 'Answer Sentence Selection')
('Semantic matching', 'Used-for', 'Hierarchical text classification')
('Annotated semantic relatedness', 'Evaluate-for', 'Transformer-based language models')
('HiMatch', 'Used-for', 'Text-label semantics matching')
('Semantic relations\n(Linguistic typology', 'Is-a-Prerequisite-of', 'morphological typology')
('morphological typology', 'Used-for', 'predicting syntactic traits of words')
('morphological typology', 'Used-for', 'morphological disambiguation')
('morphological typology', 'Used-for', 'cross-lingual morphological tagging')
('morphological typology', 'Evaluate-for', 'language modeling')
('morphological typology', 'Evaluate-for', 'improving information sharing between languages')
('morphological analysis', 'Part-of', 'morphological typology')
('morphological tagging', 'Part-of', 'morphological typology')
('statistical morphological inflectors', 'Part-of', 'morphological typology')
('language modeling', 'Used-for', 'assessing morphological typology')
('cross-lingual morphological tagging', 'Used-for', 'morphological typology assessment')
('parse trees', 'Evaluate-for', 'syntax representation in morphological typology')
('morpheme', 'Hyponym-Of', 'morphological typology')
('distributional vector space models', 'Evaluate-for', 'morphologically rich languages')
('morph-fitting procedure', 'Used-for', 'improving distributional vector spaces')
('language-specific rules', 'Used-for', 'generating morphological constraints')
('inflectional forms', 'Part-of', 'morphologically rich languages')
('derivational antonyms', 'Part-of', 'morphologically rich languages')
('morphological constraints', 'Used-for', 'morph-fitted vectors')
('dialogue state tracking', 'Evaluate-for', 'morph-fitted vectors')
('morphological inflection generation', 'Used-for', 'morphological analysis')
('language modeling', 'Evaluate-for', 'character representations')
('cross-lingual transfer tasks', 'Evaluate-for', 'morphological disambiguation')
('morphological disambiguation', 'Used-for', 'handling long-tail phenomena')
('semantic role labeling', 'Evaluate-for', 'character-level models')
('morph\n(Pseudofit', 'Used-for', 'specializing word embeddings')
('semantic similarity', 'Is-a-Prerequisite-of', 'specializing word embeddings')
('Pseudofit', 'Used-for', 'acquiring synonyms')
('external knowledge', 'Compare', 'semantic similarity')
('pseudo-sense', 'Used-for', 'building representations')
('initial embeddings', 'Evaluate-for', 'genericness')
('representations', 'Part-of', 'Pseudofit')
('word embedding model', 'Used-for', 'word analogy questions')
('word embedding model', 'Used-for', 'caption generation')
('word embedding model', 'Part-of', 'Skip-Gram model')
('Skip-Gram model', 'Is-a-Prerequisite-of', 'additive compositionality in word vectors')
('word embedding model', 'Part-of', 'Sufficient Dimensionality Reduction framework')
('aspect extraction', 'Used-for', 'aspect-based sentiment analysis')
('neural word embedding', 'Used-for', 'discovering coherent aspects')
('attention mechanism', 'Used-for', 'improving coherence of aspects')
('bilingual word embedding', 'Used-for', 'learning bilingual lexicon induction')
('Sufficient Dimensionality Reduction framework', 'Used-for', 'vector calculus in solving word analogies')
('Skip-Gram model', 'Used-for', 'training word embeddings')
('Skip-Gram model', 'Hyponym-Of', 'word embedding model')
('\n(None', 'Is-a-Prerequisite-of', 'contextual information')
('contextual entity', 'Used-for', 'capturing semantic nuances in sentences')
('contextual entity', 'Part-of', 'LSTM-based model')
('LSTM-based model', 'Evaluate-for', 'contextual entity recognition')
('TextFlow', 'Evaluate-for', 'measuring text similarity using contextual entity placement')
('contextual entity', 'Hyponym-Of', 'entity')
('entity linking', 'Used-for', 'disambiguation of contextual entities')
('Grammatical Error Correction', 'Used-for', 'correcting errors in word order and usage')
('Grammatical Error Correction', 'Used-for', 'correcting local errors in spelling and inflection')
('Grammatical Error Correction', 'Evaluate-for', 'error type performance')
('Grammatical Error Correction', 'Part-of', 'neural machine translation')
('Grammatical Error Correction', 'Compare', 'Text Simplification')
('hybrid neural model', 'Used-for', 'Grammatical Error Correction')
('nested attention layers', 'Used-for', 'correcting local errors involving small edits in orthography')
('ERRANT', 'Used-for', 'error type evaluation in Grammatical Error Correction')
('ERRANT', 'Used-for', 'reducing annotator workload in Grammatical Error Correction')
('dependency parsing scheme', 'Used-for', 'repairing grammatical errors')
('offensive language classifier', 'Evaluate-for', 'detecting out-of-domain explicitly abusive utterances')
('offensive language', 'Hyponym-Of', 'abusive language')
('TBO', 'Used-for', 'offensive language classification')
('text style transfer', 'Used-for', 'translating offensive sentences into non-offensive ones')
('offensive language classifier', 'Used-for', 'content moderation')
('neural models', 'Evaluate-for', 'predicting offensiveness scores')
('Encoding-Decoding Models', 'Used-for', 'Language identification')
('Character-based sequence-to-sequence model', 'Used-for', 'Language identification')
('text style transfer', 'Evaluate-for', 'reducing offensive content')
('offensive language classifier', 'Evaluate-for', 'robustness against adversarial attacks')
('Testing Concept Activation Vector', 'Used-for', 'quantifying model sensitivity')
('Degree of Explicitness', 'Used-for', 'enriching training data')
('Best–Worst Scaling', 'Used-for', 'annotating offensiveness scores')
('knowledge graph embedding', 'Is-a-Prerequisite-of', 'link prediction')
('holographic embeddings', 'Compare', 'complex embeddings')
('knowledge graph embedding', 'Used-for', 'achieving common goals in dialogues')
('neural model', 'Used-for', 'knowledge graph embedding')
('knowledge graph embedding', 'Hyponym-Of', 'information extraction techniques')
('information extraction', 'Used-for', 'relation extraction')
('relation extraction', 'Part-of', 'information extraction')
('holographic embeddings', 'Evaluate-for', 'efficient computation')
('complex embeddings', 'Used-for', 'modeling knowledge graphs')
('knowledge graph', 'Part-of', 'dialogue systems')
('knowledge graph embedding', 'Evaluate-for', 'machine learning performance')
('knowledge graph embedding', 'Used-for', 'joint entity and relation representation learning')
('WordNet', 'Evaluate-for', 'knowledge graph embedding')
('explanation attention', 'Is-a-Prerequisite-of', 'explainability in ML models')
('explanation attention', 'Used-for', 'offering plausible explanations for model predictions')
('explanation attention', 'Compare', 'LIME')
('explanation attention', 'Compare', 'input perturbation')
('LIME', 'Evaluate-for', 'explanation effectiveness')
('input perturbation', 'Hyponym-Of', 'explanation methods')
('LIME', 'Hyponym-Of', 'post hoc explanation methods')
('input perturbation', 'Evaluate-for', 'explanation clarity')
('natural language explanations', 'Part-of', 'interpretability in AI systems')
('explanation attention', 'Used-for', 'generating natural language explanations for predictions')
('attention mechanism', 'Used-for', 'context- and knowledge-aware predictions in MRC')
('constituency parsing', 'Used-for', 'identifying syntactic structures in sentences')
('constituency parsing', 'Evaluate-for', 'performance on Penn Treebank')
('constituency parsing', 'Evaluate-for', 'performance on French Treebank')
('constituency parsing', 'Part-of', 'natural language processing')
('shift-reduce parsing schemes', 'Is-a-Prerequisite-of', 'constituency parsing')
('constituency parsing', 'Evaluate-for', 'single model F1 score')
('LSTM encoder', 'Used-for', 'decoding in constituency parsing')
('recursive partitioning', 'Used-for', 'greedy top-down inference in constituency parsing')
('Dynamic programming techniques', 'Used-for', 'classical approaches in constituency parsing')
('greedy top-down inference', 'Used-for', 'novel prediction in constituency parsing')
('semi-supervised learning', 'Used-for', 'improving constituency parsing')
('state-of-the-art performance', 'Hyponym-Of', 'evaluation metrics for constituency parsing')
('Penn Treebank', 'Used-for', 'evaluating constituency parsing models')
('None', 'Used-for', 'metonymy resolution')
('None', 'Used-for', 'Named Entity Recognition')
('None', 'Used-for', 'geographical parsing')
('Named Entity Recognition', 'Is-a-Prerequisite-of', 'metonymy resolution')
('semantic information', 'Used-for', 'Event Factuality Prediction')
('syntactic information', 'Used-for', 'Event Factuality Prediction')
('event causality identification', 'Used-for', 'Document-level Event Causality Identification')
('event causality identification', 'Used-for', 'understanding implicit associations')
('event causality identification', 'Used-for', 'modeling semantic structures')
('event-centric structure', 'Part-of', 'event causality identification')
('event-associated structure', 'Part-of', 'event causality identification')
('event causality identification', 'Evaluate-for', 'improving causal interpretation in texts')
('event causality identification', 'Hyponym-Of', 'Document-level Event Causality Identification')
('data augmentation', 'Used-for', 'event causality identification')
('knowledge bases', 'Used-for', 'generating training data for event causality identification')
('Latent Meaning Models', 'Used-for', 'incorporating latent meanings of morphemes')
('morphological compositionality', 'Used-for', 'capturing morphological structure in BERT')
('morphological analyzer', 'Used-for', 'two-tier BERT architecture')
('latent meanings of morphemes', 'Evaluate-for', 'Latent Meaning Models')
('morphological supervision', 'Used-for', 'improving bits-per-character performance')
('morphological compositionality', 'Compare', 'semantic compositionality')
('morphological compositionality', 'Hyponym-Of', 'semantic compositionality')
('Neural Symbolic Machine', 'Part-of', 'neural programmer')
('Neural Symbolic Machine', 'Part-of', 'symbolic computer')
('neural programmer', 'Used-for', 'mapping language utterances to programs')
('symbolic computer', 'Used-for', 'program execution')
('Pre-trained word embeddings', 'Used-for', 'neural network architectures for NLP tasks')
('semantic parsing', 'Used-for', 'converting natural language into formal semantic representations')
('Noise contrastive estimation', 'Used-for', 'learning word embeddings')
('pretrained language model', 'Used-for', 'query auto-completion')
('pretrained language model', 'Is-a-Prerequisite-of', 'Universal Language Model Fine-tuning (ULMFiT')
('pretrained language model', 'Used-for', 'text classification tasks')
('pretrained language model', 'Evaluate-for', 'diachronic semantic drifts analysis')
('diachronic semantic drifts analysis', 'Used-for', 'tracking language changes on social media')
('text classification', 'Evaluate-for', 'effectiveness of pretrained models')
('query auto-completion', 'Used-for', 'enhancing user experience in search engines')
('transfer learning methodology', 'Used-for', 'NLP domain adaptation')
('SpanBasedSP', 'Is-a-Prerequisite-of', 'compositional generalization semantic parsing')
('compositional generalization semantic parsing', 'Part-of', 'natural language processing')
('compositional generalization', 'Used-for', 'generalizing to new linguistic structures')
('Seq2seq models', 'Evaluate-for', 'compositional generalization semantic parsing')
('NQG-T5', 'Used-for', 'handling compositional generalization challenges')
('compositional generalization semantic parsing', 'Evaluate-for', 'SCAN dataset')
('compositional generalization semantic parsing', 'Part-of', 'semantic parsing')
('CNNs', 'Compare', 'RNNs in compositional generalization')
('sequence-to-sequence models', 'Used-for', 'handling natural language variation')
('SpanBasedSP', 'Used-for', 'predicting a span tree for improving compositional generalization')
('compositional generalization semantic parsing', 'Evaluate-for', 'new train-test splits')
('Transformers', 'Used-for', 'providing parse trees as attention masks')
('explainable factor', 'Used-for', 'generating explanations')
('generative explanation framework', 'Used-for', 'classification decisions')
('explainable systems', 'Evaluate-for', 'predictions interpretability')
('Complex NLP tasks', 'Evaluate-for', 'explainable nlp techniques effectiveness')
('Query Focused Extractor', 'Used-for', 'evidence extraction')
('multi-hop QA', 'Is-a-Prerequisite-of', 'explainable nlp')
('CogQA framework', 'Used-for', 'multi-hop reading comprehension')
('meta-words', 'Used-for', 'open domain dialogue generation')
('rule-based models', 'Compare', 'neural models')
('Natural Language Processing', 'Hyponym-Of', 'computer science')
('open-ended visual captioning', 'Evaluate-for', 'explainable evaluation')
('Decision Tree-based Co-Attention model', 'Used-for', 'explainable claim verification')
('Indian Legal Documents Corpus', 'Used-for', 'Court Judgment Prediction and Explanation')
('PErsonalized Transformer\n(Speech Text Translation ST', 'Is-a-Prerequisite-of', 'Encoder Pre-training')
('Speech Text Translation ST', 'Used-for', 'Multitask Learning')
('Speech Text Translation ST', 'Part-of', 'End-to-End Speech Translation Models')
('Encoder Pre-training', 'Used-for', 'Speech Text Translation ST')
('Multitask Learning', 'Evaluate-for', 'Speech Text Translation ST')
('End-to-End Speech Translation Models', 'Compare', 'Cascaded Speech Translation Models')
('End-to-End Speech Translation Models', 'Hyponym-Of', 'Speech Text Translation ST')
('Automatic Speech Recognition ASR', 'Is-a-Prerequisite-of', 'Speech Text Translation ST')
('Machine Translation MT', 'Is-a-Prerequisite-of', 'Speech Text Translation ST')
('SimulSpeech', 'Used-for', 'Real-time Speech Text Translation ST')
('SimulSpeech', 'Part-of', 'Speech Text Translation ST')
('multimodal embeddings', 'Used-for', 'cross-lingual image description retrieval')
('multimodal embeddings', 'Used-for', 'multilingual word similarity')
('multimodal embeddings', 'Used-for', 'sentiment analysis')
('multimodal embeddings', 'Used-for', 'Multimodal Named Entity Disambiguation')
('multimodal embeddings', 'Is-a-Prerequisite-of', 'Multimodal Named Entity Disambiguation')
('DPCCA', 'Used-for', 'multimodal embeddings')
('PCCA', 'Used-for', 'multimodal embeddings')
('Deep PCCA', 'Hyponym-Of', 'PCCA')
('DPCCA', 'Hyponym-Of', 'PCCA')
('PCCA', 'Used-for', 'maximizing canonical correlation between bilingual embeddings')
('semantic information', 'Used-for', 'multimodal embeddings')
('mult\n(summarization', 'Compare', 'extractive summarization')
('summarization', 'Compare', 'abstractive summarization')
('summarization', 'Compare', 'query-based summarization')
('query-based summarization', 'Used-for', 'highlighting relevant points')
('abstractive summarization', 'Is-a-Prerequisite-of', 'neural sequence-to-sequence models')
('abstractive summarization', 'Used-for', 'generating concise summaries')
('extractive summarization', 'Used-for', 'selecting key sentences')
('encode-attend-decode paradigm', 'Used-for', 'machine translation')
('encode-attend-decode paradigm', 'Used-for', 'dialog systems')
('diversity based attention model', 'Used-for', 'alleviating phrase repetition')
('hybrid pointer-generator network', 'Used-for', 'accurate information reproduction')
('hybrid pointer-generator network', 'Used-for', 'novel word production')
('bias mitigation', 'Used-for', 'developing fairer AI systems')
('predictive bias', 'Is-a-Prerequisite-of', 'bias mitigation')
('bias symptoms/effects', 'Evaluate-for', 'bias mitigation')
('outcome disparities', 'Part-of', 'predictive bias')
('error disparities', 'Part-of', 'predictive bias')
('SCM-based debiasing', 'Used-for', 'bias mitigation')
('group-specific debiasing', 'Compare', 'social-group-agnostic debiasing')
('pretrained models', 'Used-for', 'bias mitigation')
('language target language', 'Part-of', 'Neural Machine Translation model')
('language target redistribution', 'Used-for', 'boost low-resource cross-lingual document retrieval performance')
('language target language', 'Used-for', 'evaluate bilingual tasks like cross-lingual classification')
('language target language', 'Hyponym-Of', 'linguistics')
('language target language', 'Is-a-Prerequisite-of', 'cross-lingual transfer learning')
('language target language', 'Evaluate-for', 'sentiment analysis in bilingual context')
('language target language', 'Evaluate-for', 'cross-lingual information retrieval')
('natural question dataset', 'Used-for', 'machine reading comprehension benchmark')
('natural question dataset', 'Is-a-Prerequisite-of', 'developing effective question answering systems')
('short answer', 'Part-of', 'natural question dataset')
('long answer', 'Part-of', 'natural question dataset')
('RikiNet', 'Evaluate-for', 'natural question dataset')
('BERT-LARGE', 'Compare', 'natural question dataset performance')
('SQuAD', 'Compare', 'natural question dataset')
('machine reading comprehension', 'Used-for', 'natural question dataset evaluation')
('long answer', 'Used-for', 'providing detailed responses in natural question dataset')
('short answer', 'Used-for', 'quick information retrieval in natural question dataset')
('transcribed speech', 'Used-for', 'training ASR systems')
('transcribed speech', 'Used-for', 'language model training')
('QASR', 'Part-of', 'transcribed speech')
('transcribed speech', 'Is-a-Prerequisite-of', 'speech-to-text translation')
('ASR', 'Evaluate-for', 'transcribed speech effectiveness')
('transcribed speech', 'Used-for', 'evaluating speech recognition systems')
('transcribed speech', 'Used-for', 'linguistics-based Arabic dialect identification')
('transcribed speech', 'Used-for', 'punctuation restoration')
('transcribed speech', 'Used-for', 'speaker identification')
('transcribed speech', 'Used-for', 'speaker linking')
('VoxPopuli', 'Part-of', 'transcribed speech')
('transcribed speeches', 'Part-of', 'spoken language understanding')
('transcribed speech', 'Used-for', 'NLP modules for spoken data')
('SQuAD', 'Part-of', 'reading comprehension datasets')
('MCTest', 'Part-of', 'reading comprehension datasets')
('WikiReading', 'Part-of', 'reading comprehension datasets')
('Childrens Book Test', 'Part-of', 'reading comprehension datasets')
('TriviaQA', 'Part-of', 'reading comprehension datasets')
('Common Nouns dataset', 'Part-of', 'reading comprehension datasets')
('DuoRC', 'Part-of', 'reading comprehension datasets')
('None', 'Compare', 'Data scarcity issue in low-resource languages')
('None', 'Part-of', 'Sequence-to-sequence models')
('None', 'Part-of', 'Attention mechanisms')
('None', 'Used-for', 'Enhancing syntactic incorporation')
('None', 'Used-for', 'Accelerating computation in translation tasks')
('None', 'Is-a-Prerequisite-of', 'Advanced natural language understanding')
('A* CCG parsing model', 'Used-for', 'dialogue modeling')
('dialogue modeling', 'Compare', 'open-ended dialogue state')
('dialogue modeling', 'Used-for', 'symmetric collaborative dialogue setting')
('dialogue modeling', 'Used-for', 'neural model with dynamic knowledge graph embeddings')
('dialogue modeling', 'Evaluate-for', 'achieving common goals')
('dialogue modeling', 'Evaluate-for', 'improving dialogue systems')
('neural conversational systems', 'Part-of', 'dialogue modeling')
('automatic evaluations', 'Used-for', 'assessing dialogue modeling effectiveness')
('encoder-decoder dialog model', 'Part-of', 'dialogue modeling')
('unsupervised discrete sentence representation learning', 'Used-for', 'enhancing dialogue modeling')
('dialogue modeling', 'Used-for', 'multi-turn dialogues handling')
('response selection', 'Used-for', 'dialogue modeling')
('dialogue modeling', 'Evaluate-for', 'interpreting user responses')
('dialogue modeling', 'Used-for', 'handling multi-domain dialogues')
('dialogue systems', 'Hyponym-Of', 'dialogue modeling')
('retrieval-based dialogues', 'Part-of', 'dialogue modeling')
('dialogue modeling\n(Position encoding', 'Used-for', 'self-attention networks')
('Position encoding', 'Used-for', 'preserving word order')
('SANs', 'Part-of', 'multilingual speech-to-text translation')
('Machine translation', 'Part-of', 'cross-lingual scenarios')
('Transfer learning', 'Used-for', 'building multilingual ST translation')
('wav2vec 2.0', 'Used-for', 'acoustic modeling')
('mBART', 'Used-for', 'multilingual text generation')
('Cross-View Language Modeling', 'Is-a-Prerequisite-of', 'Cross-lingual Cross-modal Language Model')
('Multi-modal data', 'Conjunction', 'Multi-lingual data')
('Conditional masked language modeling', 'Conjunction', 'Contrastive learning')
('Cross-lingual Cross-modal Language Model', 'Used-for', 'aligning cross-lingual and cross-modal pre-training')
('Cross-lingual Cross-modal Language Model', 'Used-for', 'multi-lingual image-text retrieval')
('neural topic model', 'Is-a-Prerequisite-of', 'language model perplexity evaluation')
('neural topic model', 'Used-for', 'document context representation')
('neural topic model', 'Part-of', 'neural language model')
('neural topic model', 'Hyponym-Of', 'topic model')
('neural topic model', 'Used-for', 'generating related sentences')
('language model perplexity evaluation', 'Evaluate-for', 'neural topic model')
('document context representation', 'Used-for', 'neural topic model')
('topic model', 'Part-of', 'neural language model')
('neural language model', 'Used-for', 'interpreting topics')
('related sentences generation', 'Used-for', 'topic interpretation')
('textual feature', 'Used-for', 'sentiment analysis')
('textual feature', 'Used-for', 'sarcasm detection')
('textual feature', 'Used-for', 'part-of-speech induction')
('textual feature', 'Used-for', 'named-entity recognition')
('textual feature', 'Part-of', 'Natural Language Processing')
('lexical feature', 'Compare', 'textual feature')
('textual feature', 'Is-a-Prerequisite-of', 'domain adaptation')
('textual feature', 'Used-for', 'coreference resolution')
('textual feature', 'Used-for', 'relation extraction')
('textual feature', 'Used-for', 'text classification tasks')
('deep neural networks', 'Compare', 'expressive kernels')
('deep neural networks', 'Used-for', 'learning feature representations')
('expressive kernels', 'Used-for', 'modeling structured information')
('language model like', 'Used-for', 'generating rhythmic poetry')
('language model like', 'Used-for', 'constraint satisfaction in poetry generation')
('phonetic encoding', 'Used-for', 'training language models')
('discriminative weighted finite state machine', 'Part-of', 'language model like')
('language model perplexity', 'Evaluate-for', 'language model like')
('language model', 'Is-a-Prerequisite-of', 'language model like')
('Affect-LM', 'Is-a-Prerequisite-of', 'language model like')
('character-level language models', 'Is-a-Prerequisite-of', 'language model like')
('caching mechanism', 'Used-for', 'enhanced language model performance')
('hierarchical LSTM language model', 'Is-a-Prerequisite-of', 'language model like')
('output attention weight', 'Hyponym-Of', 'attention weights')
('output attention practical usage', 'Is-a-Prerequisite-of', 'interpreting model predictions')
('output attention weight', 'Used-for', 'auditing algorithms in fairness and accountability contexts')
('deceptive attention masks', 'Evaluate-for', 'output attention weight')
('output attention weight', 'Compare', 'gradient-based rankings of attention weights')
('output attention weight', 'Compare', 'identifiable weights')
('neural word segmentation', 'Used-for', 'pretraining character and word embeddings')
('neural word segmentation', 'Evaluate-for', 'improving model accuracies')
('neural word segmentation', 'Is-a-Prerequisite-of', 'Chinese word segmentation as part of NLP')
('neural word segmentation', 'Part-of', 'neural network-based joint models')
('neural word segmentation', 'Hyponym-Of', 'text segmentation')
('statistical segmentation', 'Compare', 'neural word segmentation')
('modular segmentation model', 'Used-for', 'neural word segmentation')
('lattice-based encoders', 'Used-for', 'neural word segmentation')
('multi-grained lattice framework', 'Used-for', 'Chinese relation extraction')
('nested named entity recognition', 'Is-a-Prerequisite-of', 'Named Entity Recognition')
('nested named entity recognition', 'Used-for', 'identifying entities of interest in a narrative')
('nested named entity recognition', 'Part-of', 'Named Entity Recognition tasks')
('nested named entity recognition', 'Hyponym-Of', 'Named Entity Recognition')
('sequential crowd labels', 'Used-for', 'training data for a model to predict sequences in unannotated text')
('Hidden Markov Model', 'Used-for', 'aggregating sequential crowd labels')
('Long Short Term Memory', 'Used-for', 'predicting sequences in unannotated text')
('Named-Entity Recognition', 'Evaluate-for', 'news articles')
('Named-Entity Recognition', 'Evaluate-for', 'Information Extraction from biomedical abstracts')
('Multimodal word distributions', 'Used-for', 'grained sentiment')
('Aspect-based sentiment analysis', 'Used-for', 'grained sentiment')
('Aspect extraction', 'Part-of', 'Aspect-based sentiment analysis')
('Cross-domain sentiment classification', 'Used-for', 'grained sentiment')
('Bilingual Sentiment Embeddings', 'Used-for', 'grained sentiment')
('Opinionated Natural Language Generation', 'Evaluate-for', 'grained sentiment')
('Active sentiment domain adaptation', 'Used-for', 'grained sentiment')
('Domain adaptation', 'Used-for', 'grained sentiment')
('Domain-specific information', 'Used-for', 'grained sentiment')
('Fine-grained sentiment analysis', 'Hyponym-Of', 'grained sentiment')
('Fine-grained entity categorization', 'Used-for', 'grained sentiment')
('Generative Models', 'Compare', 'Discriminative Models')
('Lexical Resources', 'Used-for', 'Part-of-Speech Induction')
('Lexical Features', 'Evaluate-for', 'Named Entity Recognition (NER')
('Gazetteers', 'Used-for', 'Named Entity Recognition (NER')
('neural language model', 'Used-for', 'generation of rhythmic poetry')
('neural language model', 'Used-for', 'document context representation')
('neural language model', 'Used-for', 'affective communication in text')
('neural language model', 'Part-of', 'natural language processing')
('neural language model', 'Evaluate-for', 'language model perplexity')
('neural language model', 'Is-a-Prerequisite-of', 'conversational text generation')
('perplexity language model', 'Evaluate-for', 'text classification')
('perplexity language model', 'Is-a-Prerequisite-of', 'natural language understanding')
('neural language model', 'Used-for', 'text classification')
('neural language model', 'Evaluate-for', 'generation of emotional sentences')
('neural language model', 'Used-for', 'opinionated natural language generation')
('model generated summary', 'Is-a-Prerequisite-of', 'evaluate-for effectiveness')
('evaluate-for effectiveness', 'Used-for', 'headline generation')
('evaluate-for effectiveness', 'Used-for', 'summarization')
('model generated summary', 'Evaluate-for', 'semantic relevance')
('encoder-decoder framework', 'Used-for', 'model generated summary')
('model generated summary', 'Part-of', 'NMT pipeline')
('Sequence-to-Dependency Neural Machine Translation', 'Used-for', 'model generated summary')
('model generated summary', 'Hyponym-Of', 'summarization output')
('statistical machine translation', 'Used-for', 'model generated summary')
('Non-autoregressive models', 'Compare', 'Autoregressive models')
('AR models', 'Evaluate-for', 'dependency among target tokens')
('Sequence-to-sequence network', 'Used-for', 'model generated summary')
('information retrieval task', 'Used-for', 'detecting review spam')
('information retrieval task', 'Used-for', 'volatility prediction in financial markets')
('information retrieval task', 'Used-for', 'open-domain question answering')
('information retrieval task', 'Used-for', 'detecting concealed information')
('information retrieval', 'Is-a-Prerequisite-of', 'information retrieval task')
('neural networks', 'Used-for', 'information retrieval task')
('Entity-Duet Neural Ranking Model', 'Used-for', 'information retrieval task')
('AliMe Chat', 'Used-for', 'information retrieval task')
('Sequential Matching Network', 'Used-for', 'multi-turn conversation response selection')
('BM25', 'Compare', 'learned retrieval system for question answering')
('neural network model', 'Used-for', 'detecting review spam')
('AliMe Chat', 'Evaluate-for', 'real-world industrial applications')
('EDRM', 'Hyponym-Of', 'information retrieval systems')
('Opinion entity extraction', 'Is-a-Prerequisite-of', 'Aspect-Opinion Pair Extraction')
('Opinion entity extraction', 'Used-for', 'sentiment classification')
('Opinion entity extraction', 'Used-for', 'opinion summarization')
('Aspect-Opinion Pair Extraction', 'Used-for', 'sentiment analysis')
('Aspect-Opinion Pair Extraction', 'Evaluate-for', 'performance measurement')
('Opinion entity extraction', 'Part-of', 'Synchronous Double-channel Recurrent Network')
('Opinion entity extraction', 'Evaluate-for', 'automatic rule mining')
('Aspect-Opinion Pair Extraction', 'Hyponym-Of', 'fine-grained Aspect Based Sentiment Analysis')
('dependency parsing performance', 'Evaluate-for', 'multi-task learning')
('dependency parsing performance', 'Evaluate-for', 'dynamic oracles for Covington parser')
('dependency parsing performance', 'Evaluate-for', 'non-monotonic transition system')
('dependency parsing performance', 'Part-of', 'computational argumentation mining')
('dependency parsing performance', 'Evaluate-for', 'book-embedding framework')
('dependency parsing performance', 'Evaluate-for', 'BiLSTM models')
('dependency parsing performance', 'Evaluate-for', 'neural network models for Chinese linguistic analysis')
('neural techniques', 'Used-for', 'end-to-end computational argumentation mining')
('dependency parsing performance', 'Part-of', 'semantics')
('dependency parsing performance', 'Evaluate-for', 'joint Chinese analysis')
('dependency parsing performance', 'Evaluate-for', 'stack-pointer networks (StackPtr')
('dependency parsing performance', 'Evaluate-for', 'parser adaptation using normalization')
('dependency parsing performance', 'Evaluate-for', 'cross-lingual dependency parsing on low-resource languages')
('\n(None', 'Part-of', 'morphological tagging')
('morphological tagging', 'Is-a-Prerequisite-of', 'morphological analysis')
('morphological tagging', 'Used-for', 'improving cross-lingual NLP tasks')
('modeling morphological', 'Evaluate-for', 'morphological well-formedness')
('character-level models', 'Evaluate-for', 'semantic role labeling')
('unsupervised machine translation', 'Used-for', 'bilingual dictionary induction')
('neural networks', 'Used-for', 'handling latent variables')
('semantic role labeling', 'Used-for', 'high-level semantic analysis')
('sub-word units', 'Used-for', 'neural machine translation')
('adversarial training', 'Used-for', 'knowledge-transfer in dialectal variants')
('multi-space variational encoder-decoders', 'Used-for', 'labeled sequence transduction')
('hard attention mechanism', 'Used-for', 'morphological inflection generation')
('embeddings pre', 'Part-of', 'Neural Networks')
('embeddings pre', 'Used-for', 'Word Embedding')
('embeddings pre', 'Used-for', 'Language Models')
('embeddings pre', 'Is-a-Prerequisite-of', 'Semantic Similarity Modeling')
('embeddings pre', 'Used-for', 'Vector Calculus')
('embeddings pre', 'Is-a-Prerequisite-of', 'Sequence Labeling Tasks')
('embeddings pre', 'Is-a-Prerequisite-of', 'Answering Cloze-Style Questions')
('embeddings pre', 'Is-a-Prerequisite-of', 'Named Entity Recognition')
('embeddings pre', 'Is-a-Prerequisite-of', 'Word Segmentation')
('embeddings pre', 'Used-for', 'Knowledge Base Completion')
('embeddings pre', 'Is-a-Prerequisite-of', 'Joint Task for Chinese Analysis')
('embeddings pre', 'Is-a-Prerequisite-of', 'Prepositional Phrase Attachments')
('multilingual machine translation', 'Used-for', 'bidirectional translation tasks')
('multilingual machine translation', 'Hyponym-Of', 'neural machine translation')
('multilingual machine translation', 'Used-for', 'generating translations')
('neural machine translation', 'Is-a-Prerequisite-of', 'multilingual machine translation')
('statistical machine translation', 'Is-a-Prerequisite-of', 'multilingual machine translation')
('error correction', 'Part-of', 'multilingual machine translation')
('bidirectional translation', 'Evaluate-for', 'multilingual machine extended capabilities')
('neural models', 'Used-for', 'enhancing multilingual machine translation performance')
('linguistic knowledge integration', 'Used-for', 'improving multilingual machine translation')
('discourse segmenters', 'Used-for', 'detecting intra-sentential segment boundaries')
('discourse segmenters', 'Evaluate-for', 'building end-to-end discourse parsers')
('discourse parsers', 'Part-of', 'end-to-end discourse parsers')
('statistical discourse segmenters', 'Is-a-Prerequisite-of', 'segmentation without gold pre-annotations')
('segmentation', 'Used-for', 'discourse analysis')
('statistical discourse segmenters', 'Hyponym-Of', 'discourse segmenters')
('English newswire', 'Evaluate-for', 'discourse segmentation performance assessment')
('Discourse Representation Theory', 'Used-for', 'semantic parsing')
('unsupervised morphological', 'Is-a-Prerequisite-of', 'morphological inflection generation')
('unsupervised morphological', 'Used-for', 'analyzing word formation in NMT')
('unsupervised morphological', 'Used-for', 'morphological paradigm completion')
('unsupervised morphological', 'Hyponym-Of', 'morphological analysis')
('morphological inflection generation', 'Used-for', 'evaluating hard and soft attention mechanisms')
('morphological inflection generation datasets', 'Used-for', 'evaluating neural model performance')
('hard attention mechanism', 'Part-of', 'neural model for morphological inflection generation')
('Bahdanau attention', 'Part-of', 'soft attention models')
('gender bias evaluation', 'Evaluate-for', 'machine translation systems')
('unsupervised morphological paradigm completion', 'Is-a-Prerequisite-of', 'unsupervised learning in NLP')
('source-side morphological analysis', 'Used-for', 'improving word formation modeling in NMT')
('morphological segments', 'Used-for', 'evaluating Hebrew PLMs')
('NMT\n(predicate-argument structures', 'Part-of', 'natural language representations')
('natural language representations', 'Part-of', 'neural semantic parser')
('neural semantic parser', 'Used-for', 'mapping natural language utterances to domain-specific logic')
('logical forms', 'Used-for', 'training semantic parsers')
('predicate-argument structures', 'Evaluate-for', 'shedding light on representation types in semantic parsing')
('inducing predicate-argument structures', 'Used-for', 'solving algebraic word problems')
('natural language', 'Conjunction', 'human-readable mathematical expressions')
('semantic parser', 'Evaluate-for', 'achieving state-of-the-art results')
('natural language', 'Hyponym-Of', 'English poetry')
('phonetic encoding', 'Used-for', 'learning implicit representation in poetry generation')
('natural language sentences', 'Used-for', 'real-world question answering systems')
('natural language', 'Is-a-Prerequisite-of', 'generating answer rationales')
('neural text matching models', 'Compare', 'convolutional neural networks models')
('convolutional neural networks', 'Used-for', 'multi-turn conversation model')
('knowledge adaptation', 'Used-for', 'performance enhancement in industrial applications')
('performance enhancement in industrial applications', 'Evaluate-for', 'AliMe Assist')
('neural text simplification', 'Used-for', 'text simplification at lexical and syntactic levels')
('unsupervised neural text simplification', 'Is-a-Prerequisite-of', 'unlabeled text corpora usage')
('Siamese Networks', 'Used-for', 'zero and few-shot text classification')
('neural textual entailment models', 'Used-for', 'building text classifiers with little or no training data')
('Dynamic-Tree Driven Theorem Solver', 'Used-for', 'theorem proving')
('neural theorem\n(language model fine tuning', 'Is-a-Prerequisite-of', 'text classification tasks')
('Universal Language Model Fine-tuning', 'Used-for', 'language model fine tuning')
('language model fine tuning', 'Used-for', 'reducing error rates on datasets')
('pretrained language models', 'Used-for', 'language model fine tuning')
('language model pretraining', 'Compare', 'language model fine tuning')
('transfer learning', 'Hyponym-Of', 'language model fine tuning')
('language model fine tuning', 'Used-for', 'sentiment classification')
('Semantic retrieval', 'Used-for', 'Machine comprehension of text')
('Semantic retrieval', 'Used-for', 'Document retrieval')
('Document retrieval', 'Is-a-Prerequisite-of', 'Machine comprehension of text')
('Semantic retrieval', 'Used-for', 'Information Retrieval systems')
('Information Retrieval systems', 'Part-of', 'Semantic retrieval')
('Machine comprehension of text', 'Used-for', 'Identifying answer spans in Wikipedia paragraphs')
('Semantic retrieval', 'Used-for', 'Joint semantic and syntactic parsing')
('Semantic hashing', 'Hyponym-Of', 'Semantic retrieval')
('Information Retrieval term weighting', 'Evaluate-for', 'Volatility prediction')
('Text classification', 'Used-for', 'Leveraging semantic retrieval for label-word joint embeddings')
('bilingual word embeddings', 'Used-for', 'bilingual lexicon induction')
('bilingual word embeddings', 'Used-for', 'cross-lingual classification')
('bilingual word embeddings', 'Used-for', 'domain adaptation')
('neural network model', 'Used-for', 'joint training from bilingual word embeddings')
('bilingual word embeddings', 'Evaluate-for', 'inducing bilingual dictionaries')
('adversarial training', 'Used-for', 'learning bilingual word embeddings without parallel data')
('self-learning algorithm', 'Used-for', 'improving bilingual word embeddings')
('bilingual word embeddings', 'Used-for', 'improving bilingual text embeddings')
('bilingual word embeddings', 'Evaluate-for', 'cross-lingual twitter sentiment classification')
('bilingual word embeddings', 'Evaluate-for', 'medical bilingual lexicon induction')
('cross-lingual word embeddings', 'Is-a-Prerequisite-of', 'bilingual word embeddings')
('bilingual word embeddings', 'Part-of', 'unsupervised machine translation models')
('event extraction', 'Used-for', 'knowledge base population')
('distant supervision', 'Used-for', 'event extraction')
('neural network', 'Used-for', 'dependency parsing')
('dependency parsing', 'Evaluate-for', 'event extraction')
('event extraction', 'Compare', 'supervised learning')
('supervised learning', 'Is-a-Prerequisite-of', 'event extraction')
('argument information', 'Used-for', 'event detection improvement')
('event detection', 'Part-of', 'event extraction')
('event extraction', 'Hyponym-Of', 'information extraction')
('neural stacking', 'Used-for', 'cross-lingual dependency parsing')
('cross-lingual dependency parsing', 'Evaluate-for', 'dependency parsing')
('neural network models', 'Compare', 'joint extraction models')
('event extraction', 'Compare', 'relation extraction')
('multi-lingual multi-task architecture', 'Used-for', 'event extraction')
('Nugget Proposal Networks', 'Used-for', 'event extraction in Chinese language')
('L\n(entity detection', 'Is-a-Prerequisite-of', 'joint entity relation extraction')
('entity detection', 'Used-for', 'natural language processing')
('joint entity relation pledge extraction', 'Used-for', 'knowledge extraction')
('natural language processing', 'Used-for', 'automatic fake news detection')
('natural language processing', 'Part-of', 'computer science')
('entity detection', 'Part-of', 'natural language processing')
('joint models', 'Used-for', 'natural language processing')
('relation detection', 'Used-for', 'knowledge base question answering')
('mention detection', 'Part-of', 'entity detection')
('event detection', 'Evaluate-for', 'event analysis')
('relation detection', 'Evaluate-for', 'relation categorization')
('document dating', 'Evaluate-for', 'information retrieval')
('personal health mention detection', 'Evaluate-for', 'health condition reporting')
('TAC KBP 2016 Event Nugget Detection and Coreference task', 'Used-for', 'trigger detection')
('tri-lingual entity discovery', 'Used-for', 'named entity recognition')
('rumor detection', 'Used-for', 'classifying tweets')
('progressive neural networks', 'Used-for', 'rumor detection')
('progressive neural networks', 'Hyponym-Of', 'bottom-up tree-structured neural networks')
('progressive neural networks', 'Hyponym-Of', 'top-down tree-structured neural networks')
('unsupervised hypernym detection', 'Compare', 'pattern-based methods')
('unsupervised hypernym detection', 'Compare', 'distributional methods')
('personal health mention detection', 'Evaluate-for', 'improving figurative usage detection')
('sarcasm detection', 'Compare', 'textual sarcasm detection')
('sarcasm detection', 'Compare', 'multi-modal sarcasm detection')
('knowledge graph building', 'Used-for', 'natural language processing')
('minimum spans', 'Used-for', 'coreference resolution')
('argument detection', 'Evaluate-for', 'persuasive argument identification')
('TAC\n(language generation nlg', 'Used-for', 'generating corrective REs')
('language generation nlg', 'Is-a-Prerequisite-of', 'natural language interfaces to databases')
('language generation nlg', 'Part-of', 'natural language processing')
('neural networks', 'Used-for', 'language generation nlg')
('semantic parsing', 'Is-a-Prerequisite-of', 'language generation nlg')
('sequential models', 'Used-for', 'language generation nlg')
('statistical models', 'Used-for', 'language generation nlg')
('syntax analysis', 'Used-for', 'language generation nlg')
('neural symbolic machine', 'Used-for', 'language generation nlg')
('contrastive focus', 'Used-for', 'language generation nlg')
('generation systems', 'Evaluate-for', 'language generation nlg performance')
('Opinionated Natural Language Generation ONLG', 'Hyponym-Of', 'language generation nlg')
('ON\n(natural language understanding', 'Used-for', 'semantic parsing')
('natural language understanding', 'Used-for', 'language model training')
('natural language understanding', 'Compare', 'natural language generation')
('natural language understanding', 'Evaluate-for', 'question answering systems')
('natural language understanding', 'Used-for', 'building knowledge bases')
('semantic parsing', 'Used-for', 'converting utterances to logical forms')
('semantic parsing', 'Hyponym-Of', 'natural language understanding')
('machine learning', 'Is-a-Prerequisite-of', 'natural language understanding')
('semantic parsing', 'Used-for', 'intermediate representations')
('knowledge bases', 'Used-for', 'support in natural language understanding tasks')
('COREQA', 'Used-for', 'natural language understanding in question answering')
('statistical power', 'Used-for', 'neural network effectiveness in language tasks')
('natural language utterances', 'Part-of', 'lingual semantic parsing')
('formal meaning representations', 'Part-of', 'lingual semantic parsing')
('lingual semantic parsing', 'Is-a-Prerequisite-of', 'generating structured queries from natural language')
('structured queries', 'Part-of', 'semantic parsing task')
('semantic parsing task', 'Hyponym-Of', 'lingual semantic parsing')
('lingual semantic parsing', 'Is-a-Prerequisite-of', 'knowledge base querying')
('knowledge bases', 'Used-for', 'semantic graph generation in lingual semantic parsing')
('lingual semantic parsing', 'Evaluate-for', 'accuracy in structured data interpretation')
('structured data interpretation', 'Part-of', 'lingual semantic parsing')
('lingual semantic parsing', 'Used-for', 'machine understanding of human language')
('machine understanding of human language', 'Part-of', 'lingual semantic parsing')
('None', 'Used-for', 'retrieving information from knowledge bases')
('COREQA', 'Is-a-Prerequisite-of', 'answering system')
('answering system', 'Used-for', 'generating natural answers')
('COREQA', 'Used-for', 'answering system')
('EviNets', 'Is-a-Prerequisite-of', 'answering system')
('answering system', 'Used-for', 'selecting final answer in QA')
('EviNets', 'Used-for', 'answering system')
('answering system', 'Used-for', 'multimodal question answering')
('Aspect Sentiment Classification', 'Is-a-Prerequisite-of', 'Sentiment Classification')
('Aspect Sentiment Classification', 'Used-for', 'Classifying sentiment polarities over individual opinion targets')
('Attention Mechanism', 'Used-for', 'Aspect Sentiment Classification')
('Target-Specific Representations', 'Part-of', 'Aspect Sentiment Classification')
('Memory Networks', 'Used-for', 'Aspect Sentiment Classification')
('CNN Layer', 'Used-for', 'Aspect Sentiment Classification')
('RNN Layer', 'Used-for', 'Aspect Sentiment Classification')
('Aspect Sentiment Classification', 'Evaluate-for', 'Opinion Target Sentiment Detection')
('Aspect Sentiment Classification', 'Compare', 'General Sentiment Classification')
('Aspect Sentiment Classification', 'Hyponym-Of', 'Sentiment Analysis')
('Attention Mechanism', 'Evaluate-for', 'Aspect Sentiment Classification')
('Document-Level Knowledge', 'Used-for', 'Aspect Sentiment Classification')
('hierarchical attention network', 'Used-for', 'reading comprehension')
('hierarchical attention network', 'Used-for', 'answering questions for narrative paragraphs')
('hierarchical attention network', 'Used-for', 'modeling long-range dependencies in texts')
('hierarchical attention network', 'Used-for', 'learning word embeddings of OOV words')
('hierarchical attention network', 'Used-for', 'claim verification')
('multi-dimensional emotion regression', 'Evaluate-for', 'adversarial attention network')
('translation tasks', 'Evaluate-for', 'neural Transformer')
('sentiment classification', 'Evaluate-for', 'Multi-sentiment-resource Enhanced Attention Network')
('story cloze task', 'Evaluate-for', 'hierarchical recurrent networks with attention')
('spelling error', 'Used-for', 'detecting the native language of a writer')
('spelling error', 'Part-of', 'spelling error features')
('spelling error features', 'Used-for', 'classifying texts in the TOEFL11 corpus')
('spelling error', 'Part-of', 'Chinese Spelling Check')
('spelling error', 'Hyponym-Of', 'linguistic errors')
('spelling error correction', 'Used-for', 'improving language understanding')
('spelling error', 'Part-of', 'relation extraction task')
('spelling error correction', 'Used-for', 'reducing machine translation errors')
('spelling error', 'Part-of', 'grammatical error correction systems')
('adversarial example', 'Used-for', 'adversarial training')
('adversarial example', 'Used-for', 'adversarial attacks on text classification')
('adversarial example', 'Used-for', 'adversarial generation techniques')
('adversarial example', 'Hyponym-Of', 'adversarial perturbation')
('adversarial example', 'Evaluate-for', 'showing the weakness of NLP systems')
('adversarial example', 'Evaluate-for', 'robustness testing')
('adversarial example', 'Hyponym-Of', 'adversarial stability training')
('adversarial example', 'Is-a-Prerequisite-of', 'adversarial stability training')
('adversarial example', 'Compare', 'adversarial perturbation')
('adversarial perturbation', 'Part-of', 'adversarial training')
('adversarial training', 'Used-for', 'improving robustness of NMT models')
('adversarial training', 'Used-for', 'enhancing model robustness against adversarial attacks')
('adversarial training', 'Evaluate-for', 'assessing security against attacks')
('attention based explanation', 'Used-for', 'facilitating user understanding of model decision-making')
('computational attention mechanisms', 'Evaluate-for', 'adjusting focus on specific input data parts')
('human attention', 'Compare', 'computational attention mechanisms')
('human-centric attention-based explanations', 'Used-for', 'design of machine learning interpretability')
('YELP-HAT', 'Used-for', 'collecting human attention data for text classification')
('machine attention maps', 'Evaluate-for', 'analyzing overlap in word selections')
('attention flow explanations', 'Hyponym-Of', 'Shapley Values')
('deep learning models', 'Used-for', 'text classification tasks')
('natural language processing', 'Part-of', 'computer science')
('morphological analysis', 'Used-for', 'predicting syntactic traits of words')
('morphological analysis', 'Evaluate-for', 'language understanding systems')
('morphological constraints', 'Used-for', 'improving distributional vector spaces')
('morphological inflection', 'Hyponym-Of', 'morphological analysis')
('morph-fitting procedure', 'Used-for', 'improving low-frequency word estimates')
('distributional vector space models', 'Part-of', 'NLP systems')
('distributional vector space models', 'Hyponym-Of', 'language representation models')
('morphological tagging', 'Is-a-Prerequisite-of', 'accurate natural language processing')
('neural model', 'Used-for', 'morphological inflection generation')
('cross-lingual transfer', 'Evaluate-for', 'resource scarcity in NLP')
('gated attention-based recurrent networks', 'Used-for', 'question-aware passage representation')
('self-matching attention mechanism', 'Used-for', 'refine representation')
('pointer networks', 'Used-for', 'locate answers')
('attention mechanism', 'Used-for', 'sequence-to-sequence learning')
('attention mechanism', 'Hyponym-Of', 'neural models techniques')
('layer-wise relevance propagation', 'Used-for', 'compute contribution in NMT')
('hierarchical attention network', 'Used-for', 'reading comprehension QA')
('average attention network', 'Used-for', 'enhance decoding speed in neural Transformer')
('neural Transformer', 'Part-of', 'attention based methods')
('attention model', 'Used-for', 'enhance Tree-LSTMs')
('attention-based Bi-LSTM', 'Used-for', 'Chinese implicit discourse relations')
('attention mechanism', 'Used-for', 'enhance multi-source sequence-to-sequence learning')
('attention mechanisms', 'Compare', 'flat and hierarchical methods')
('(sentence compression model', 'Used-for', 'reducing text length while preserving facts')
('sentence compression model', 'Compare', 'non-neural-network-based model')
('syntactic information', 'Used-for', 'improving domain adaptability of sentence compression model')
('Integer Linear Programming', 'Used-for', 'introducing syntactic constraints in sentence compression model')
('evaluation', 'Evaluate-for', 'sentence compression model efficacy')
('Japanese sentence compression', 'Is-a-Prerequisite-of', 'creation of large Japanese training dataset')
('training dataset', 'Used-for', 'training sentence compression models')
('linguistic context', 'Used-for', 'predicting quantifiers in sentence compression')
('lexical and morpho-syntactic patterns', 'Used-for', 'sentence compression')
('language-model-based evaluator', 'Used-for', 'deletion-based sentence compression assessment')
('reinforcement learning', 'Used-for', 'optimizing sentence compression operations')
('Convolutional layers', 'Used-for', 'Simultaneous sentence encoding in Neural Machine Translation')
('Convolutional layers', 'Compare', 'Bi-directional LSTMs')
('Bi-directional LSTMs', 'Evaluate-for', 'Handling temporal dependencies in Neural Machine Translation')
('Grammatical error correction systems', 'Used-for', 'Correcting errors in\nNone\n(None')
('None', 'Is-a-Prerequisite-of', 'Document-level event extraction')
('Event-centric knowledge graphs', 'Used-for', 'Relation extraction between events')
('Argument role type information', 'Used-for', 'Enhancing event argument extraction')
('Event argument roles', 'Part-of', 'Event argument extraction')
('Argument distribution patterns', 'Used-for', 'Implicit event argument extraction')
('Implicit event argument extraction', 'Part-of', 'Event argument extraction')
('Document-level event extraction', 'Used-for', 'Event argument extraction')
('Open IE system', 'Evaluate-for', 'Argument extraction performance')
('Event argument extraction', 'Evaluate-for', 'Natural language understanding')
('Event argument extraction', 'Used-for', 'Supporting argument detection')
('Event argument extraction', 'Evaluate-for', 'Understanding temporal and causal relations')
('Event argument extraction', 'Part-of', 'Natural language understanding')
('None', 'Part-of', 'unsupervised syntactic parsing')
('unsupervised syntactic parsing', 'Used-for', 'learning natural language syntax')
('unsupervised syntactic parsing', 'Evaluate-for', 'discrepancy in datasets')
('unsupervised syntactic parsing', 'Compare', 'unsupervised semantic parsing')
('statistical methods', 'Used-for', 'unsupervised syntactic parsing')
('neural methods', 'Used-for', 'unsupervised syntactic parsing')
('unsupervised syntactic parsing', 'Is-a-Prerequisite-of', 'better comparability between methods')
('Order Neuron LSTM', 'Used-for', 'unsupervised syntactic parsing')
('unlabeled data', 'Used-for', 'unsupervised syntactic parsing')
('unsupervised syntactic parsing', 'Evaluate-for', 'F-1 score')
('Long Short Term Memory', 'Hyponym-Of', 'short term memory')
('Bi-LSTM', 'Hyponym-Of', 'short term memory')
('Tree-LSTMs', 'Hyponym-Of', 'short term memory')
('bidirectional-LSTMs', 'Hyponym-Of', 'short term memory')
('Gated Recurrent Units', 'Hyponym-Of', 'short term memory')
('Long Short Term Memory', 'Used-for', 'predicting sequences in unannotated text')
('Long Short Term Memory', 'Used-for', 'language model prediction')
('SIVAE', 'Used-for', 'generating sentences and syntactic trees using Long Short Term Memory')
('Attention-based Long Short Term Memory', 'Used-for', 'aspect-level sentiment classification')
('Long Short Term Checkbox', 'Used-for', 'classification of conversational text')
('Bi-LSTM', 'Used-for', 'relation extraction using dependency paths')
('Speech Speech Translation S2ST', 'Is-a-Prerequisite-of', 'Speech Translation ST')
('Speech Speech Translation S2ST', 'Used-for', 'Translating speech in one language to another without intermediate text')
('SimulSpeech', 'Part-of', 'Speech Speech Translation S2ST')
('End-to-end Speech Translation E2E ST', 'Compare', 'Speech Speech Translation S2ST')
('Encoder', 'Used-for', 'transcribe and understand in Speech Speech Translation S2ST')
('Discrete speech encoder', 'Used-for', 'Encoding target speech in Speech Speech Translation S2ST')
('Speech-to-unit translation S2UT model', 'Used-for', 'Predicting discrete representations in Speech Speech Translation S2ST')
('Joint speech and text training framework', 'Used-for', 'Generating dual modality output in Speech Speech Translation S2ST')
('Simultaneous translation', 'Hyponym-Of', 'Speech Speech Translation S2ST')
('word representation', 'Used-for', 'language modeling')
('word embedding', 'Hyponym-Of', 'word representation')
('morphological segmentation', 'Used-for', 'word representation')
('semantic parser', 'Used-for', 'natural language understanding')
('neural machine translation', 'Used-for', 'learning word representation')
('semantic quality', 'Evaluate-for', 'word representation')
('multimodal word distributions', 'Hyponym-Of', 'word representation')
('distributional vector space', 'Used-for', 'word representation')
('morph-fitted vectors', 'Used-for', 'improving word representation')
('pretrained context embeddings', 'Used-for', 'enhancing word representation')
('word2vec', 'Used-for', 'generating word embeddings')
('subword units', 'Part-of', 'word representation')
('character n-grams', 'Part-of', 'word representation')
('abstracitve summarization model', 'Part-of', 'neural text summarization')
('abstractive summarization model', 'Is-a-Prerequisite-of', 'abstractive document summarization')
('encode-attend-decode paradigm', 'Used-for', 'abstractive summarization model')
('global encoding framework', 'Used-for', 'abstractive summarization model')
('query attention model', 'Part-of', 'abstractive summarization model')
('diversity based attention model', 'Part-of', 'abstracitve summarization model')
('Transformer-based encoder-decoder framework', 'Used-for', 'abstractive summarization model')
('email subject line generation', 'Evaluate-for', 'abstractive summarization model')
('hybrid pointer-generator network', 'Part-of', 'abstractive summarization model')
('coverage mechanism', 'Part-of', 'abstractive summarization model')
('pointer-generator', 'Compare', 'sequence-to-sequence model')
('global optimization\n(semantic decoding', 'Used-for', 'mapping natural language utterances into structured meaning representations')
('semantic decoding', 'Is-a-Prerequisite-of', 'semantic parsing')
('semantic parsing', 'Used-for', 'transducing natural language utterances into formal meaning representations')
('neural language model', 'Used-for', 'automatic generation of rhythmic poetry')
('neural semantic parser', 'Used-for', 'generating formal meaning representations in Discourse Representation Theory')
('semantic parsing', 'Evaluate-for', 'accuracy in transforming natural language to executable outputs')
('neural network models', 'Used-for', 'representation learning and prediction in semantic graph generation')
('discriminative weighted finite state machine', 'Used-for', 'constraining generative models based on form')
('deep learning model', 'Used-for', 'semantic role labeling')
('semantic role labeling', 'Hyponym-Of', 'semantic parsing')
('BiLSTM architecture', 'Used-for', 'deep models in semantic role labeling')
('deep highway Bi\n(entity representation', 'Used-for', 'semantic information capture')
('entity grid representation', 'Hyponym-Of', 'entity representation')
('semantic information', 'Part-of', 'entity representation')
('word embeddings', 'Used-for', 'entity representation')
('multimodal word distributions', 'Used-for', 'entity representation')
('distributed representation', 'Part-of', 'entity representation')
('convolutional neural network', 'Used-for', 'entity representation in coherence model')
('local coherence model', 'Evaluate-for', 'entity representation')
('neural machine translation', 'Evaluate-for', 'entity representation quality')
('semantic parsing model', 'Used-for', 'entity representation in technical documentation')
('None', 'Is-a-Prerequisite-of', 'fake news detection')
('fake news detection', 'Used-for', 'political fact-checking')
('fake news detection', 'Evaluate-for', 'social media posts')
('fake news detection', 'Used-for', 'preventing misinformation dissemination')
('fake news detection', 'Evaluate-for', 'comparing language patterns')
('fake news detection', 'Evaluate-for', 'environmental signals')
('News Environment Perception Framework', 'Used-for', 'fake news detection')
('Graph-aware Co-Attention Networks', 'Used-for', 'fake news detection')
('LIAR dataset', 'Used-for', 'fake news detection')
('CompareNet', 'Used-for', 'fake news detection')
('Causal intervention and Counterfactual reasoning', 'Used-for', 'multi-modal fake news detection')
('hybrid convolutional neural network', 'Used-for', 'fake news detection')
('statistical approaches', 'Part-of', 'fake news detection')
('social impacts', 'Part-of', 'fake news detection')
('PolitiFact.com', 'Used-for', 'fake news detection')
('benchmark datasets', 'Used-for', 'fake news detection')
('surface-level linguistic patterns\n(event mention', 'Used-for', 'event coreference resolution')
('event coreference resolution', 'Used-for', 'grouping coreferent event mentions')
('event mention', 'Is-a-Prerequisite-of', 'event coreference resolution')
('event mention', 'Part-of', 'dense video event captioning')
('event mention', 'Part-of', 'event extraction')
('event mention', 'Part-of', 'event ontology mapping')
('event extraction', 'Compare', 'dense video event captioning')
('event extraction', 'Evaluate-for', 'generic grounding problem')
('event ontology', 'Used-for', 'type mapping in event extraction')
('dense video event captioning', 'Used-for', 'generating captions for video events')
('event mention', 'Part-of', 'dialogue state tracking')
('dialogue state tracking', 'Used-for', 'inferring slot correlations')
('event mention', 'Part-of', 'coreference resolution')
('event mention', 'Is-a-Prerequisite-of', 'semantic relation extraction')
('event\n(document level relation extraction', 'Used-for', 'integrating information within and across multiple sentences of a document')
('document level relation other', 'Evaluate-for', 'capturing complex interactions between inter-sentence entities')
('document level relation extraction', 'Part-of', 'Neural Relation Extraction')
('inter-sentence relation extraction', 'Compare', 'document level relation extraction')
('inter-sentence relation extraction', 'Is-a-Prerequisite-of', 'document level relation extraction')
('document level relation extraction', 'Used-for', 'multi-hop reasoning')
('syntactic trees', 'Used-for', 'constructing static document-level graphs')
('co-references', 'Used-for', 'constructing static document-level graphs')
('latent document-level graph', 'Used-for', 'empowering relational reasoning across sentences')
('latent document-level graph', 'Part-of', 'document level relation extraction')
('multi-hop reasoning', 'Used-for', 'incrementally aggregating relevant information')
('BLEU', 'Evaluate-for', 'cross-lingual summarization')
('human judgment', 'Evaluate-for', 'cross-lingual summarization')
('cross-lingual summarization', 'Used-for', 'summarization')
('summarization', 'Part-of', 'natural language processing')
('cross-lingual summarization', 'Used-for', 'reducing language barriers')
('cross-lingual word embedding', 'Used-for', 'bilingual dictionary induction')
('bilingual dictionary induction', 'Is-a-Prerequisite-of', 'cross-lingual summarization')
('bilingual dictionary induction', 'Compare', 'cross-lingual classification')
('cross-lingual classification', 'Part-of', 'cross-lingual tasks')
('cross-lingual tasks', 'Used-for', 'overcoming data sparsity')
('domain adaptation', 'Used-for', 'cross-lingual tasks')
('unsupervised machine translation', 'Is-a-Prerequisite-of', 'cross-lingual summarization')
('unsupervised machine translation', 'Hyponym-Of', 'machine translation')
('machine translation', 'Part-of', 'natural language processing')
('sentence embeddings', 'Used-for', 'sentence classification')
('sentence embeddings', 'Hyponym-Of', 'word embeddings')
('sentence embeddings', 'Evaluate-for', 'probing tasks')
('sentence embeddings', 'Evaluate-for', 'downstream tasks')
('sentence embeddings', 'Is-a-Prerequisite-of', 'semantic similarity prediction')
('sentence embeddings', 'Used-for', 'embedding sequences of sentences')
('sentence embeddings', 'Used-for', 'thematic clustering of sentences')
('sentence embeddings', 'Used-for', 'capturing linguistic features')
('sentence embeddings', 'Used-for', 'improving machine translation performance')
('generic sentence embeddings', 'Compare', 'domain specific embeddings')
('sentence embeddings', 'Part-of', 'NLP models')
('sentence embeddings', 'Part-of', 'multilingual distributed representations')
('Deep learning', 'Used-for', 'training sentence embeddings')
('sentence embeddings', 'Hyponym-Of', 'vector representations')
('BabbleLabble', 'Used-for', 'training classifiers with human annotated explanations')
('semantic parser', 'Used-for', 'converting human annotated explanations into programmatic labels')
('ExpBERT', 'Used-for', 'interpreting human annotated explanations for relation extraction tasks')
('human annotated data set EntSUM', 'Used-for', 'controllable summarization leveraging entity-centric summaries')
('adversarial framework', 'Evaluate-for', 'sanity checking models against inconsistent human annotated explanations')
('zero-shot classifiers', 'Used-for', 'training with human annotated explanations and without labeled examples')
('E-CARE', 'Used-for', 'providing human annotated explanations alongside causal reasoning questions')
('annotated data', 'Is-a-Prerequisite-of', 'zero pronoun resolution task')
('annotated data', 'Is-a-Prerequisite-of', 'supervised machine learning models')
('supervised machine learning models', 'Used-for', 'named entity recognition systems')
('annotated data', 'Used-for', 'training Grammatical Error Correction systems')
('annotated data', 'Used-for', 'training neural network based inference models')
('annotated data', 'Used-for', 'natural language inference')
('annotated data', 'Used-for', 'Japanese predicate-argument structure analysis')
('annotated data', 'Used-for', 'sentiment analysis')
('annotated data', 'Used-for', 'error detection in automatically annotated text')
('annotated data', 'Hyponym-Of', 'pseudo training data')
('annotated data', 'Part-of', 'Natural Language Processing tasks')
('Gated self-matching networks', 'Used-for', 'Question Answering (QA')
('Pointer networks', 'Used-for', 'locating answer positions in Question Answering (QA')
('SQuAD dataset', 'Evaluate-for', 'Question Answering (QA')
('COREQA', 'Used-for', 'generating natural answers in Question Answering (QA')
('Semantic parsing', 'Used-for', 'Question Answering (QA')
('TriviaQA', 'Used-for', 'evaluating reading comprehension in Question Answering (QA')
('Web text', 'Used-for', 'source of facts for Question Answering (QA')
